# ğŸ§  Intelligent Onboarding Assistant â€” MLOps Data Pipeline

## ğŸ“˜ Overview
This repository contains the **Intelligent Onboarding Assistant Data Pipeline**, developed as part of the MLOps course project.

The goal of this project is to automate the **ingestion, validation, and fairness analysis** of onboarding materials from GitLab â€” combining both **web documentation** and **meeting transcripts**.  
The pipeline detects potential **bias** in text content and mitigates it by generating debiased versions of all processed data.

By the end of the pipeline:
- All text data (from handbook + YouTube meetings) is **scraped, validated, analyzed and debiased**
- Bias metrics are stored in structured JSON files
- Results are orchestrated, logged and monitored via **Apache Airflow**

---

## ğŸ§© Architecture

All components are orchestrated via Airflowâ€™s DAG:

[scrape_handbook] â†’ [transcribe_youtube] â†’ [validate_data] â†’ [bias_detection] â†’ [bias_mitigation] â†’ [notify_success]


---

## âš™ï¸ Pipeline Components

### 1ï¸âƒ£ **Data Acquisition**
**Scripts:**  
- `scraper.py` â€” Scrapes structured text content from [GitLabâ€™s Handbook](https://handbook.gitlab.com/).  
- `transcription.py` â€” Downloads and transcribes meeting videos from a YouTube playlist using **OpenAI Whisper**.

**Outputs:**  
- `data/handbook_paragraphs.json`  
- `data/meeting_transcripts/all_transcripts.json`

Both scripts integrate with the shared `ParagraphPreprocessor` for text normalization.

---

### 2ï¸âƒ£ **Data Validation**
**Script:** `validate_data.py`  
- Validates that key fields exist (`title`, `paragraph`, `transcript`, etc.)  
- Checks JSON structure and non-empty content  
- Exits with `code=1` if validation fails, so Airflow marks the DAG task as failed

**Output:**  
Validation summary logged to Airflow and console.

---

### 3ï¸âƒ£ **Bias Detection**
**Script:** `bias_detection.py`  
- Scans both datasets for sensitive or biased words using category-based lexicons  
- Categories: gender, ethnicity, age, ability, religion  
- Generates structured `bias_report.json` with per-record counts

**Output:**  
`data/bias_report.json`

---

### 4ï¸âƒ£ **Bias Mitigation**
**Script:** `bias_mitigation.py`  
- Reads the bias report and applies neutral replacements for biased terms  
- Creates clean, debiased versions of all datasets

**Output:**  
- `data/debiased_data/handbook_paragraphs_debiased.json`  
- `data/debiased_data/all_transcripts_debiased.json`

---

### 5ï¸âƒ£ **Pipeline Orchestration (Airflow)**
**File:** `data_pipeline_dag.py`  
- Defines the full DAG using BashOperators and EmailOperator  
- Automates end-to-end pipeline execution  
- Sends email notifications upon success/failure  
- Logs all stages centrally in Airflow UI  

**Task Order:**

scrape_handbook â†’ transcribe_youtube â†’ validate_data â†’ bias_detection â†’ bias_mitigation â†’ notify_success

## ğŸ§± Folder Structure

ğŸ“‚ Intelligent-Onboarding-Assistant
```
â”‚
â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ scripts/
â”‚ â”‚ â”œâ”€â”€ scraper.py
â”‚ â”‚ â”œâ”€â”€ transcription.py
â”‚ â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”‚ â”œâ”€â”€ validate_data.py
â”‚ â”‚ â”œâ”€â”€ bias_detection.py
â”‚ â”‚ â”œâ”€â”€ bias_mitigation.py
â”‚ â”‚ â”œâ”€â”€ logging_utils.py
â”‚ â”‚ â””â”€â”€ tests/
â”‚ â””â”€â”€ data_pipeline_dag.py
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ handbook_paragraphs.json
â”‚ â”œâ”€â”€ meeting_transcripts/all_transcripts.json
â”‚ â”œâ”€â”€ bias_report.json
â”‚ â””â”€â”€ debiased_data/
â”‚
â”œâ”€â”€ logs/
â”‚
â”œâ”€â”€ dvc.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md

```
---

## ğŸ§  Key Features
- âœ… **Automated ingestion** from multiple data sources (web + video)
- âœ… **Schema validation & anomaly detection**
- âœ… **Lexicon-based bias detection**
- âœ… **Bias mitigation via neutral replacements**
- âœ… **Version control with DVC**
- âœ… **Centralized logging**
- âœ… **Email alerting and failure handling**
- âœ… **Fully orchestrated Airflow DAG**

---

## ğŸ§© Technology Stack
| Layer | Tools Used |
|-------|-------------|
| **Orchestration** | Apache Airflow |
| **Data Versioning** | DVC |
| **Data Processing** | Python (BeautifulSoup, Whisper) |
| **Bias Analysis** | Custom lexicon-based detector |
| **Monitoring** | Airflow Logs, Email Alerts |
| **Deployment** | Dockerized environment |
| **Testing** | `unittest`, custom test scripts |

---

## ğŸ§¾ Evaluation Criteria Mapping

| **Criterion** | **How Itâ€™s Addressed** |
|----------------|------------------------|
| **Documentation** | Well-commented scripts, README, and logs |
| **Modularity** | Each step is an independent Python module |
| **Airflow DAG** | `data_pipeline_dag.py` with sequential dependencies |
| **Logging & Tracking** | Shared `logging_utils.py` across all scripts |
| **Data Version Control** | All datasets tracked via `.dvc` files |
| **Pipeline Optimization** | Lightweight, modular scripts with fail-fast validation |
| **Schema Validation** | Implemented in `validate_data.py` |
| **Anomaly & Alerting** | Airflow email alerts + validation exits |
| **Bias Detection & Mitigation** | Lexical scanning + replacements; report and debiased data generated |
| **Test Modules** | Unit tests under `/tests` |
| **Reproducibility** | Dockerized setup + relative paths |
| **Error Handling** | Try/except in all scripts, Airflow retries disabled for deterministic runs |

---

## ğŸ“¦ Setup & Execution

1. Clone Repository
```bash
git clone https://github.com/<your-username>/Intelligent-Onboarding-Assistant.git
cd Intelligent-Onboarding-Assistant
```
2. Install Dependencies
```
pip install -r requirements.txt
```
3. Initialize DVC
```
dvc init
dvc pull   # if remote data is configured
```
4. Start Airflow
```
docker-compose up
```
5. Trigger Pipeline

In the Airflow UI:

Navigate to DAGs â†’ data_pipeline_dag

Click Trigger DAG

Monitor progress in the Gantt view or logs
