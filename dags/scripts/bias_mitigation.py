"""
Bias Mitigation Module
======================

Uses the bias_report.json generated by bias_detection.py
and mitigates biased language in the text data by:
    - Replacing gendered or sensitive terms with neutral ones.
    - Creating a "debiased" version of the original JSON files.
"""

import os
import sys
import json
from pathlib import Path
from typing import Dict, List

# --- Logging Setup ---
CURRENT_DIR = Path(__file__).resolve().parent
if str(CURRENT_DIR) not in sys.path:
    sys.path.append(str(CURRENT_DIR))
from logging_utils import get_logger

logger = get_logger(__name__)

BASE_DIR = Path(__file__).resolve().parents[2] / "data"
REPORT_FILE = BASE_DIR / "bias_report.json"
OUTPUT_DIR = BASE_DIR / "debiased_data"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# --- Simple Replacement Dictionary (expandable) ---
REPLACEMENTS: Dict[str, str] = {
    # Gender-neutral terms
    "he": "they", "she": "they",
    "him": "them", "her": "them",
    "his": "their", "hers": "their",
    "man": "person", "woman": "person",
    "mankind": "humankind", "chairman": "chairperson",
    # Age & ability neutral terms
    "old": "experienced", "young": "early-career",
    "disabled": "person with disability",
}

def debias_text(text: str) -> str:
    """Replace biased terms with neutral alternatives."""
    words = text.split()
    return " ".join([REPLACEMENTS.get(w.lower(), w) for w in words])


def process_file(input_path: Path, output_path: Path, fields: List[str]):
    """Debias the given JSON file field-wise."""
    if not input_path.exists():
        logger.warning(f"File not found: {input_path}")
        return

    with open(input_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    for item in data:
        for field in fields:
            if field in item and isinstance(item[field], str):
                item[field] = debias_text(item[field])

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    logger.info(f"Debiased file saved â†’ {output_path}")


def run_bias_mitigation():
    """Run mitigation after bias detection."""
    logger.info("ðŸ§¹ Running bias mitigation...")

    handbook_path = BASE_DIR / "handbook_paragraphs.json"
    transcripts_path = BASE_DIR / "meeting_transcripts" / "all_transcripts.json"

    debiased_handbook = OUTPUT_DIR / "handbook_paragraphs_debiased.json"
    debiased_transcripts = OUTPUT_DIR / "all_transcripts_debiased.json"

    process_file(handbook_path, debiased_handbook, ["title", "paragraph"])
    process_file(transcripts_path, debiased_transcripts, ["title", "transcript"])

    logger.info("Bias mitigation complete. Debiased data ready for downstream tasks.")
    return OUTPUT_DIR


if __name__ == "__main__":
    run_bias_mitigation()
