{
  "content": "Recently, the GitLab Data team transformed scattered\nStreamlit\napplications into a unified, secure, and\nscalable solution for our Snowflake environment. To accomplish this, we\npacked Python, Snowflake, and Streamlit together with GitLab. Follow along\non this journey and discover the results we achieved, and learn how you can,\ntoo.\nThe challenge\nImagine this scenario: Your organization has dozens of Streamlit applications across different environments, running various Python versions, connecting to sensitive data with inconsistent security practices. Some apps work, others break mysteriously, and nobody knows who built what or how to maintain them.\nThis was exactly the challenge our data team faced. Applications were being created in isolation, with no standardization, no security oversight, and no clear deployment process. The result? A compliance nightmare and a maintenance burden that was growing exponentially.\nFunctional architectural design (high level)\nHow we started\nWe leveraged our unique position as customer zero by building this entire framework on GitLab's own CI/CD infrastructure and project management tools. Here are the ingredients we started with:\nGitLab\n(product)\nSnowflake\n- our single source of truth (SSOT) for the data warehouse activities (and more than that)\nStreamlit\n- an open-source tool for visual applications that has pure Python code under the hood\nThis provided us with immediate access to enterprise-grade DevSecOps capabilities, enabling us to implement automated testing, code review processes, and deployment pipelines from the outset. By utilizing GitLab's built-in features for issue tracking, merge requests, and automated deployments (CI/CD pipelines), we can iterate rapidly and validate the framework against real-world enterprise requirements. This internal-first approach ensured our solution was battle-tested on GitLab's own infrastructure before any external implementation.\nThe lessons we learned\nThe most critical lesson we learned from building the Streamlit Application Framework in Snowflake is that\nstructure beats chaos every time\nâ implement governance early rather than retrofitting it later when maintenance becomes exponential.\nYou also need to clearly define roles and responsibilities, separating infrastructure concerns from application development, so that each team can focus on its strengths.\nSecurity and compliance cannot be afterthoughts; they must be built into templates and automated processes from day one, as it's far easier to enforce consistent standards upfront than to force them after the fact. Invest heavily in automation and CI/CD pipelines, as manual processes don't scale and introduce human error.\nArchitecture of the framework (general overview)\nHow the Streamlit Application Framework changes everything\nThe Streamlit Application Framework turns a scattered approach into a structure. It gives developers freedom within secure guardrails, while automating deployment and eliminating maintenance complexity.\nThree clear roles, one unified process\nThe framework introduces a structured approach with three distinct roles:\nMaintainers\n(Data team members and contributors) handle the infrastructure, including CI/CD pipelines, security templates, and compliance rules. They ensure the framework runs smoothly and stays secure.\nCreators\n(those who need to build applications) can focus on what they do best: creating visualizations, connecting to Snowflake data, and building user experiences. They have full flexibility to create new applications from scratch, add new pages to existing apps, integrate additional Python libraries, and build complex data visualisations â all without worrying about deployment pipelines or security configurations.\nViewers\n(end users) access polished, secure applications without any technical overhead. All they need is Snowflake access.\nOverview of roles and their functions\nAutomate everything\nBy implementing CI/CD, days of manual deployments and configuration headaches are gone. The framework provides:\nOne-click environment preparation:\nWith a set of\nmake\ncommands, the environment is installed and ready in a few seconds.\n================================================================================\nâ Snowflake CLI successfully installed and configured!\nConnection: gitlab_streamlit\nUser:\n[email protected]\nAccount: gitlab\n================================================================================\nUsing virtualenv: /Users/YOU/repos/streamlit/.venv\nð Installing project dependencies...\nInstalling dependencies from lock file\nNo dependencies to install or update\nâ Streamlit environment prepared!\nAutomated CI/CD pipelines:\nHandle testing, code review, and deployment from development to production.\nSecure sandbox environments:\nProvide for safe development and testing before production deployment.\nâ°â$ make streamlit-rules\nð Running Streamlit compliance check...\n================================================================================\nCODE COMPLIANCE REPORT\n================================================================================\nGenerated: 2025-07-09 14:01:16\nFiles checked: 1\nSUMMARY:\nâ Passed: 1\nâ Failed: 0\nSuccess Rate: 100.0%\nAPPLICATION COMPLIANCE SUMMARY:\nð± Total Applications Checked: 1\nâ ï¸ Applications with Issues: 0\nð File Compliance Rate: 100.0%\nDETAILED RESULTS BY APPLICATION:\n...\nTemplate-based application creation:\nEnsures consistency across all applications and pages.\nâ°â$ make streamlit-new-page STREAMLIT_APP=sales_dashboard STREAMLIT_PAGE_NAME=analytics\nð Generating new Streamlit page: analytics for app: sales_dashboard\nð Create new page from template:\nPage name: analytics\nApp directory: sales_dashboard\nTemplate path: page_template.py\nâ Successfully created 'analytics.py' in 'sales_dashboard' directory from template\nPoetry-based dependency management:\nPrevents version conflicts and maintains clean environments.\nOrganized project structure:\nHas dedicated folders for applications, templates, compliance rules, and configuration management.\nâââ src/\nâ   âââ applications/     # Folder for Streamlit applications\nâ   â   âââ main_app/     # Main dashboard application\nâ   â   âââ components/   # Shared components\nâ   â   âââ <your_apps>/  # Your custom application\nâ   â   âââ <your_apps2>/ # Your 2nd custom application\nâ   âââ templates/        # Application and page templates\nâ   âââ compliance/       # Compliance rules and checks\nâ   âââ setup/            # Setup and configuration utilities\nâââ tests/                # Test files\nâââ config.yml            # Environment configuration\nâââ Makefile              # Build and deployment automation\nâââ README.md             # Main README.md file\nStreamlined workflow:\nTakes local development through testing schema to production, all automated through GitLab CI/CD pipelines.\nGitLab CI/CD pipelines for full automation of the process\nSecurity and compliance by design\nInstead of bolting on security as an afterthought, the structured Streamlit Application Framework builds it in from the ground up. Every application adheres to the same security standards, and compliance requirements are automatically enforced. Audit trails are maintained throughout the development lifecycle.\nWe introduce our compliance rules and verify them with a single command. For instance, we can list which classes and methods are mandatory to use, which files you should have, and which roles are allowed and which are forbidden to share the application with. The rules are flexible and descriptive; all you need to do is define them in a YAML file:\nclass_rules:\n- name: \"Inherit code for the page from GitLabDataStreamlitInit\"\ndescription: \"All Streamlit apps must inherit from GitLabDataStreamlitInit\"\nseverity: \"error\"\nrequired: true\nclass_name: \"*\"\nrequired_base_classes:\n- \"GitLabDataStreamlitInit\"\nrequired_methods:\n- \"__init__\"\n- \"set_page_layout\"\n- \"setup_ui\"\n- \"run\"\nfunction_rules:\n- name: \"Main function required\"\ndescription: \"Must have a main() function\"\nseverity: \"error\"\nrequired: true\nfunction_name: \"main\"\nimport_rules:\n- name: \"Import GitLabDataStreamlitInit\"\ndescription: \"Must import the mandatory base class\"\nseverity: \"error\"\nrequired: true\nmodule_name: \"gitlab_data_streamlit_init\"\nrequired_items:\n- \"GitLabDataStreamlitInit\"\n- name: \"Import streamlit\"\ndescription: \"Must import streamlit library\"\nseverity: \"error\"\nrequired: true\nmodule_name: \"streamlit\"\nfile_rules:\n- name: \"Snowflake configuration required (snowflake.yml)\"\ndescription: \"Each application must have a snowflake.yml configuration file\"\nseverity: \"error\"\nrequired: true\nfile_pattern: \"**/applications/**/snowflake.yml\"\nbase_path: \"\"\n- name: \"Snowflake environment required (environment.yml)\"\ndescription: \"Each application must have a environment.yml configuration file\"\nseverity: \"error\"\nrequired: true\nfile_pattern: \"**/applications/**/environment.yml\"\nbase_path: \"\"\n- name: \"Share specification required (share.yml)\"\ndescription: \"Each application must have a share.yml file\"\nseverity: \"warning\"\nrequired: true\nfile_pattern: \"**/applications/**/share.yml\"\nbase_path: \"\"\n- name: \"README.md required (README.md)\"\ndescription: \"Each application should have a README.md file with a proper documentation\"\nseverity: \"error\"\nrequired: true\nfile_pattern: \"**/applications/**/README.md\"\nbase_path: \"\"\n- name: \"Starting point recommended (dashboard.py)\"\ndescription: \"Each application must have a dashboard.py as a starting point\"\nseverity: \"warning\"\nrequired: true\nfile_pattern: \"**/applications/**/dashboard.py\"\nbase_path: \"\"\nsql_rules:\n- name: \"SQL files must contain only SELECT statements\"\ndescription: \"SQL files and SQL code in other files should only contain SELECT statements for data safety\"\nseverity: \"error\"\nrequired: true\nfile_extensions: [\".sql\", \".py\"]\nselect_only: true\nforbidden_statements:\n- ....\ncase_sensitive: false\n- name: \"SQL queries should include proper SELECT statements\"\ndescription: \"When SQL is present, it should contain proper SELECT statements\"\nseverity: \"warning\"\nrequired: false\nfile_extensions: [\".sql\", \".py\"]\nrequired_statements:\n- \"SELECT\"\ncase_sensitive: false\nshare_rules:\n- name: \"Valid functional roles in share.yml\"\ndescription: \"Share.yml files must contain only valid functional roles from the approved list\"\nseverity: \"error\"\nrequired: true\nfile_pattern: \"**/applications/**/share.yml\"\nvalid_roles:\n- ...\nsafe_data_roles:\n- ...\n- name: \"Share.yml file format validation\"\ndescription: \"Share.yml files must follow the correct YAML format structure\"\nseverity: \"error\"\nrequired: true\nfile_pattern: \"**/applications/**/share.yml\"\nrequired_keys:\n- \"share\"\nmin_roles: 1\nmax_roles: 10\nWith one command running:\nâ°â$ make streamlit-rules\nWe can verify all the rules we have created and validate that the developers (who are building a Streamlit application) are following the policy specified by the creators (who determine the policies and building blocks of the framework), and that all the building blocks are in the right place. This ensures consistent behavior across all Streamlit applications.\nð Running Streamlit compliance check...\n================================================================================\nCODE COMPLIANCE REPORT\n================================================================================\nGenerated: 2025-08-18 17:05:12\nFiles checked: 4\nSUMMARY:\nâ Passed: 4\nâ Failed: 0\nSuccess Rate: 100.0%\nAPPLICATION COMPLIANCE SUMMARY:\nð± Total Applications Checked: 1\nâ ï¸ Applications with Issues: 0\nð File Compliance Rate: 100.0%\nDETAILED RESULTS BY APPLICATION:\n================================================================================\nâ PASS APPLICATION: main_app\n------------------------------------------------------------\nð FILES ANALYZED (4):\nâ dashboard.py\nð¦ Classes: SnowflakeConnectionTester\nð§ Functions: main\nð¥ Imports: os, pwd, gitlab_data_streamlit_init, snowflake.snowpark.exceptions, streamlit\nâ show_streamlit_apps.py\nð¦ Classes: ShowStreamlitApps\nð§ Functions: main\nð¥ Imports: pandas, gitlab_data_streamlit_init, snowflake_session, streamlit\nâ available_packages.py\nð¦ Classes: AvailablePackages\nð§ Functions: main\nð¥ Imports: pandas, gitlab_data_streamlit_init, streamlit\nâ share.yml\nð¥ Share Roles: snowflake_analyst_safe\nð FILE COMPLIANCE FOR MAIN_APP:\nâ Required files found:\nâ snowflake.yml\nâ environment.yml\nâ share.yml\nâ README.md\nâ dashboard.py\nRULES CHECKED:\n----------------------------------------\nClass Rules (1):\n- Inherit code for the page from GitLabDataStreamlitInit (error)\nFunction Rules (1):\n- Main function required (error)\nImport Rules (2):\n- Import GitLabDataStreamlitInit (error)\n- Import streamlit (error)\nFile Rules (5):\n- Snowflake configuration required (snowflake.yml) (error)\n- Snowflake environment required (environment.yml) (error)\n- Share specification required (share.yml) (warning)\n- README.md required (README.md) (error)\n- Starting point recommended (dashboard.py) (warning)\nSQL Rules (2):\n- SQL files must contain only SELECT statements (error)\nð SELECT-only mode enabled\nð¨ Forbidden: INSERT, UPDATE, DELETE, DROP, ALTER...\n- SQL queries should include proper SELECT statements (warning)\nShare Rules (2):\n- Valid functional roles in share.yml (error)\nð¥ Valid roles: 15 roles defined\nð Safe data roles: 11 roles\n- Share.yml file format validation (error)\n------------------------------------------------------------\nâ Compliance check passed\n-----------------------------------------------------------\nDeveloper experience that works\nWhether you prefer your favorite IDE, a web-based development environment, or Snowflake Snowsight, the experience remains consistent. The framework provides:\nTemplate-driven development:\nNew applications and pages are created through standardized templates, ensuring consistency and best practices from day one. No more scattered design and elements.\nâ°â$ make streamlit-new-app NAME=sales_dashboard\nð§ Configuration Environment: TEST\nð Configuration File: config.yml\nð Config Loader Script: ./setup/get_config.sh\nð Python Version: 3.12\nð Applications Directory: ./src/applications\nð Database: ...\nð Schema: ...\nð Stage: ...\nð­ Warehouse: ...\nð Creating new Streamlit app: sales_dashboard\nInitialized the new project in ./src/applications/sales_dashboard\nPoetry package management:\nAll dependencies are managed through Poetry, creating isolated environments that won't disrupt your existing Python setup.\n[tool.poetry]\nname = \"GitLab Data Streamlit\"\nversion = \"0.1.1\"\ndescription = \"GitLab Data Team Streamlit project\"\nauthors = [\"GitLab Data Team <*****@gitlab.com>\"]\nreadme = \"README.md\"\n[tool.poetry.dependencies]\npython = \"<3.13,>=3.12\"\nsnowflake-snowpark-python = \"==1.32.0\"\nsnowflake-connector-python = {extras = [\"development\", \"pandas\", \"secure-local-storage\"], version = \"^3.15.0\"}\nstreamlit = \"==1.22.0\"\nwatchdog = \"^6.0.0\"\ntypes-toml = \"^0.10.8.20240310\"\npytest = \"==7.0.0\"\nblack = \"==25.1.0\"\nimportlib-metadata = \"==4.13.0\"\npyyaml = \"==6.0.2\"\npython-qualiter = \"*\"\nruff = \"^0.1.0\"\ntypes-pyyaml = \"^6.0.12.20250516\"\njinja2 = \"==3.1.6\"\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\nMulti-page application support:\nCreators can easily build complex applications with multiple pages and add new libraries as needed. Multi-page applications are part of the framework and a developer is focusing on the logic, not the design and structuring.\nMultipage application example (in Snowflake)\nSeamless Snowflake integration:\nBuilt-in connectors and authentication handling for secure data access provide the same experience, whether in local development or directly in Snowflake.\nmake streamlit-push-test APPLICATION_NAME=sales_dashboard\nð¤ Deploying Streamlit app to test environment: sales_dashboard\n...\n------------------------------------------------------------------------------------------------------------\nð Running share command for application: sales_dashboard\nRunning commands to grant shares\nð Executing: snow streamlit share sales_dashboard with SOME_NICE_ROLE\nâ Command executed successfully\nð Execution Summary: 1/1 commands succeeded\nComprehensive Makefile:\nAll common commands are wrapped in simple Makefile commands, from local development to testing and deployment, including CI/CD pipelines.\nSafe local development:\nEverything runs in isolated Poetry environments, protecting your system while providing production-like experiences.\nSame experience despite the environment (example of the local development)\nCollaboration via code:\nAll applications and components are wrapped up in one repository, which allows the entire organization to collaborate on the same resources and avoid double work and redundant setup.\nHow you can get started\nIf you're facing similar challenges with scattered Streamlit applications, here's how to begin and move quickly:\nAssess your current state:\nInventory your existing applications and identify pain points.\nDefine your roles:\nSeparate maintainer responsibilities from creator and end users' needs.\nStart with templates:\nCreate standardized application templates that enforce your security and compliance requirements.\nImplement CI/CD:\nAutomate your deployment pipeline to reduce manual errors and ensure consistency.\nThe application deployed in Snowflake\nThe bigger picture\nThis framework represents more than just a technical solution â it's a paradigm shift toward treating data applications as first-class citizens in your enterprise (data) architecture.\nBy providing structure without sacrificing flexibility, the GitLab Data team created an environment where anyone in the company with minimal technical knowledge can innovate rapidly while maintaining the highest standards of security and compliance.\nWhat's next?\nWe're continuing to enhance the framework based on user feedback and emerging needs. Future improvements include expanded template libraries, enhanced monitoring capabilities, more flexibility, and a smoother user experience.\nThe goal isn't just to solve today's problems, but to create a foundation that scales with your organization's growing data application needs.\nSummary\nThe GitLab Data Team\ntransformed dozens of scattered, insecure Streamlit applications with no standardization into a unified, enterprise-grade framework that separates roles cleanly:\nMaintainers\nhandle infrastructure and security.\nCreators\nfocus on building applications without deployment headaches.\nViewers\naccess polished, compliant apps.\nAnd we used these building blocks:\nAutomated\nCI/CD\npipelines\nFully collaborative and versioned code in\ngit\nTemplate-based\ndevelopment\nBuilt-in\nsecurity\ncompliance, testing\nPoetry-managed\nenvironments\nWe eliminated the maintenance nightmare while enabling rapid innovation â proving that you can have both structure and flexibility when you treat data applications as first-class enterprise assets rather than throwaway prototypes.",
  "metadata": {
    "title": "How we built a structured Streamlit Application Framework in Snowflake",
    "url": "https://about.gitlab.com/blog/how-we-built-a-structured-streamlit-application-framework-in-snowflake/",
    "published": "2025-10-10T00:00:00.000Z",
    "updated": "2025-10-10T00:00:00.000Z",
    "author": "Radovan Bacovic",
    "categories": [],
    "summary": "<p>Recently, the GitLab Data team transformed scattered\n<a href=\"https://streamlit.io/\">Streamlit</a> applications into a unified, secure, and\nscalable solution for our Snowflake environment. To accomplish this, we\npacked Python, Snowflake, and Streamlit together with GitLab. Follow along\non this journey and discover the results we achieved, and learn how you can,\ntoo.</p>\n<h2>The challenge</h2>\n<p>Imagine this scenario: Your organization has dozens of Streamlit applications across different env",
    "fetched_at": "2025-10-24T18:27:55.402742",
    "source": "gitlab_blog"
  },
  "processing": {
    "content_length": 19108,
    "word_count": 2337,
    "is_relevant": true
  }
}