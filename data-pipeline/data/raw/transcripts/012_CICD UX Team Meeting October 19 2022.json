{
  "title": "CI/CD UX Team Meeting: October 19, 2022",
  "video_id": "VoLkOz_F5oA",
  "url": "https://www.youtube.com/watch?v=VoLkOz_F5oA",
  "transcript": " Hello, everyone. This is the CICD UX team. We're meeting today on October 19th and there are some manager announcements in the beginning. I'll just go over and then we decided this meeting that we're going to switch up the order. So, there was a thread for OKR's progress. If there's anything blocked or at risk, Hianna was asking for you to list it, but it doesn't seem like anything's there. And then there's some upcoming family and friends days, dates that were released for November through January. And then the talent assessment officially kicked off today and it's open until November 4th to get that first. I think this is specifically to fill out the performance sheet that we were all given. Anything any questions or anything. All right. So then if we scroll all the way down, will do you want to start off and maybe if you know if Erica has anything you can go over that too. Yeah, sure. So I know that Erica is also going to be at QCon. I'll be there as well. Gina, I think you're also going to be there. So it'd be great to actually see a handful of people. I've met just a couple of GitLab team members before, but excited to actually meet people within the department. So we'll be out doing some research. I think she's doing Erica's doing like her own survey. Gina, you've been working on her with I'm doing something for a distribution team, like a survey and some interviews and then Eric and I are also teaming up with the market insights team to do some like buyer persona research, where we're trying to identify people that are likely to buy GitLab and then talk to them for a little bit and then see if they're open to like focus groups later in the week. So we're going to be quite busy with research next week. But when I have time, I'll be checking like messages and things to to keep up with stuff. Aside from that, about halfway through the benchmarking workshop that I'm doing with the release team. Basically, the team has come up with solutions to the identified pain points and is giving feedback on everyone's ideas at this point. And then tomorrow, I'm actually opening up a final part of that workshop where we'll essentially vote on the top solutions that we want to work on as a team. And then I'll create actual insight issues that will incorporate into the roadmap. And then I've been helping Emily out with some research that she's doing related to her CMS scorecard. So that's it for me. One other, the stuff that you were saying that Erica was doing for coupon. I only have insight into one of them, which is about secrets, but she's been there was like some previous work that she had piloted and ended up getting like a lot of data from around. I think that one was specifically secrets within the workflow. So kind of figuring out like what developers were expecting ideally for how that would work. And she's going to continue looking at that for Qcon, but focus on finding out metadata that's important around secrets. Okay. Yeah, thanks for the contacts. So Kevin, I think you're up next. Sure. Thanks. Yeah, for me, not a lot of dates, but mainly one of the issues that I've been working with and that I shared a last time was about them. And not revealing massed variables. And kind of what I've heard is after discussing with the team, we kind of agreed to take another path and kind of diverge on this and decorate secrets and variables. So I've kind of sketch out some really raw wire frames of what that would look like. If anyone has some thoughts, please weigh in, but essentially the next steps are going to be to live a bit deeper as to what this would look like, introducing a whole path for creating and managing secrets. And that is the first point. And the second point is you may have seen this in the UX ICD channel. But there is a proposal from an engineer Fred's to be designed the pipeline overview page. And I think it's a very good idea to have a look at the pipeline, I think it's a pipeline graph, you go with the different jobs and stages that would be a different visualization that kind of highlight more like the number of failed jobs and also like higher pipeline is doing. So I'll be helping him kind of isolating on this design, but potentially also good through research and validate it. Again, if you have any thoughts on that, feel free to weigh in the issue, I think there's a link to his video that he created in the issue, otherwise you might be able to find it in this like thread. So yeah, that's it. I was going through your proposal and like crunching the commit box to a small area and then landing straight on the summary tab. Did he also I haven't read through your comment, but was there a discussion around removing the failed jobs or that's something that's. The failed jobs, you mean yeah yeah yeah i kind of mentioned that we could instead of like showing all of the failed job just showing a bunch of them and then sending people to the failed job tabs, I think that's one direction. Instead yeah. All right. It's good. Sorry next is me. All right, so first of all, we had enabled tracking for a bunch of fire pendulated actions and now what we are doing is. I'll quickly find the size in sling. So we are able to get a lot of information about what are the actions that our users are performing more frequently and which are the links they're clicking on on the pipeline list view. So we had our monthly check in around that information here's the dashboard i'm linking it here. Yeah, this is the dashboard and we kind of sort of different ways in which we can act upon the information that we're getting from there. So for example, we already had a bunch of concerns related to speed. So what our front and team did was they used lighthouse runs to figure out like which are the areas which are costing us the most in terms of performance. And how can we tie in the insights, which are we are receiving through this set of data and come up with your proposals. So if you go down, I have proposed a new method to kind of just suggest a proposal and that will be broken into three parts like proposal, the assumptions that we are taking into account and the evidence to support the proposal, which can be a combination of both. So metrics were getting through data tracking as well as the insights from previous researchers. And at the end, like once we have a bunch of these we would do around a voting and so far my idea is that we would vote on the basis of like which one has the most least risky assumption associated with it and it would be most impactful to keeping those two parameters in mind. Yeah, and then we would just get started on the like design proposal for that particular proposal that kind of gets the highest number of words. Coming to the next point, which is the PNPS and Suss feedback assessment. So we revisited feedback from past four quarters, because we really wanted to get to work on such impacting issues that would have the highest impact. And we were desperate to take a different approach than just like going through like burning down through a list of S1 and S2s because we wanted this to align with what our users are feeling and how they are like sharing their experiences with us. Now this assessment, I was able to understand what the most frequently emerging teams across the feedback and the two that were most recurring were one was definitely around improvements to talks like adding more examples and improving the instructions around CACD. And the next one was reducing the number of steps for primary task. This was like a lot of users mentioned like share feed background. It taking a lot of time and a lot of number of clicks to get and to perform an action or to perform a task which we can say is primary to the area. So we want to make a collection of all the existing issues which are some impacting which relate to this insight and bring them together in an epic with a very clear exit criteria. So we are actually able to go through like one down all the issues inside the epic and also close it by the end of the quarter. So something very realistic. And that's the next step for me like I'll be creating that epic and adding issues to that. What next quarter? Yeah. Any comments, any feedback? Do you know do you want to voice? Yeah. I'll voice that one. This was related for your first topic. It was, it's just interesting that that that issue is more about like load performance, which makes perfect sense. And that we have a in pipeline insights, we have a feature around load performance and it's supposed to help track those types of things. But it's clear that the products that like that your team is using is showing results or data and much more depth than what our feature does. So it gives me some ideas of how we could improve that area. We're not even focused on performance testing as like a whole in pipeline insights, but something for the future at least that we could think of. I was aware of this so far and this is the first time looking at once it's proud of that provides these informations. Yeah, they do a good job. All right, so that was me passing it on to Emily. So last week I was kind of wrapping up our solution validation around pending deployment approvals into dues and just there was some interesting stuff that came out of the study that kind of correlated with some of the competitive reviews we've done. Slack seemed to be the most popular tool users we're using to notify each other since we didn't offer it. They were figuring out with bots are doing it manually through Slack channels. But interestingly enough, like users were looking for a way to integrate pending deploy and approvals with Slack. So they didn't have to depend on the GitLab UI. And we saw this when we reviewed harness as well harness was using Slack integrations for pending deployment approvals more so than their own notification system. So good takeaway of this is we were going to implement this within to do's and we think now a good MVC is just to allow users to kind of integrate these deployment pending deployment notifications within Slack and within their current workflow. So that's kind of the way we're going to take this. They did like the idea of being notified they thought to do's made sense, but there was warnings about how our to do's are pretty busy already. We have no way to prioritize to do's they kind of just land in the list. So I think there's additional work we'd have to do to get them in the to do's, but they would also see that workflow as being something useful just there's more work in there. So our MVC we're now landing on is focusing more on integrations. And yeah, I linked the research issue and dubs till study if you want to read more, but yeah, a big thanks to will he helped and supported with like all stages of this. So a big thank you for all that support. Cool. And then the second one is one of the bigger design initiatives we've had is supporting multiple approval rules and the project level protected environment settings. And then we've got a lot of different types of approval rules, which we're really excited about because this gives them a lot more configuration options within the UI, whereas before we only gave this through access with the API. And then we're going to have to come out as well. And then my last thing is I did mention this on Slack, but I will also be having lower availability next week. I'll be using my visiting grant. So I might be just lower availability for sink calls might be late responding to messages if you need me. So that's more of just an employee. And no one has questions I can pass it off to Gina. All right. The first both actually both of these items are around pipelining sites. I have work going on for runner to but I felt like these were more interesting. So the first one here is about the new artifacts browser design. So also kind of goes along with what Vica was saying about having basically like allowing for less clicks to get to the thing that you need to get to. So the browser right now if you were to go into a job and browse artifacts from there, you have to click into each folder. So it's so there can be so many nested folders to be able to get to that final file. So what I ended up doing if you look in the design there. I kind of consolidated all of those folders if they're empty into a single file path. And then I just indented the file with it like underneath there. So it's clear that it's still part of that folder. So I have any feedback on that design. I also linked video of me going through the proposal in the New York school working channel. If that helps as well. And the other thing I had here was we are. We did a bunch of research to understand for review apps. And we heard that the view app button wasn't prominent enough. People couldn't find it. So I wanted to understand really why and what was going on. And we found out that it's really just not integrated into the review workflow as much as people were expecting it to be. What we're planning on doing is adding the view app button into that code dropdown when you go to a MR. And this also allows it to kind of be like stuck to that global header because that heading is sticky when you scroll down the page. And it also is closely integrated into the review workflow there. And some specific things were like only certain projects have review apps enabled. So we won't be showing that many item all the time unless the review app is enabled for that project. I want to say I love this change because I don't know how many times I send trying to scroll down the page looking for that like view app button. So having it just in one place would be so nice. Thanks. Yeah, we're definitely I think it will definitely be better because like we were saying like people were having trouble finding it and said that it doesn't always show up in that widget. At the same time, so I think this will help. And then my last thing here is I'll be I think I might have done that with zeros. Why did they look like that I did all be out of office next week at coupon. But I'll probably be on I'll have my computer. So like if there's anything that you need just feel free to reach out. So 50% of the population here is going to be a coupon. Yes. Yes. So since Erica is back, maybe she wants to go through her items. No, did I miss Kevin? Yeah. Oh, okay. Okay. So yes, we're gearing up for coupon. And then just if my personal life, my child has been sick. And then yesterday we tested him for coven. Oh, no. We all have come in. So I'm like, oh, no, the conference. So I'm going to have to figure that out. So we'll engineer and I. So I just am like waking up because that's why I was a little late, but miraculously I woke up. Oh, there's a meeting. So I'm always just glad to see you guys. And I'm glad that I showed up because those were great updates. So we now have to kind of figure out what to do about my potential absence, but maybe I'll be healed. So what I can do is show share with you this deck. If I can do it. Well, let's see it. I can just give you the general updates. So we are going to be at coup con doing a lot of things. Will and I both have a survey that we're fielding. And we are going to be doing some interviews with buyer personas. The PMs from ops, especially have kind of come up with some questions. And so people will kind of come up to the booth. And if they're a buyer persona, they'll get put into this buyer persona interview round slash recruitment for focus groups. And if they are not a buyer, then they can either come to the area where we're going to have a station at the booths or there's actually two booths. They might also just complete these interviews from the PMs. And so it would be good to get your eyes on that stuff. So I'll link that issue. We have like seven questions that we're going to ask. And then we've set up. And then we've set up a list of questions that we're going to ask. So that all those questions and the questions for the buyers and all the other questions are in Qualtrics. And then that'll be a note taking mechanism. And then we'll have a list of questions that we'll ask like approach where he kind of summarizes it in an issue, the findings. And then we're going to invite people to follow up with those participants. So I'm sure it's all going to work out. And miraculously not have COVID in like a day. So besides that, we're working on the prioritization stuff for Q4. So if you haven't had a chance yet, it would be good to link the Q4 projects that you want. And we're going to put that through the resource prioritization. But because also our PMs are going to be at coupon. We're going to wait to finalize that until everyone gets back on November 8th. And another thing that I'm probably going to ping you about is, I'm going to try to do the research prioritization research sense of this. I forget we have like a longer name for it, but basically we're all go back through. And according to our research questions like summarize all the research we've found for this quarter. So that will be something I can link. So I'll just be asking you to include studies that you would like. Kind of included in that synthesis. And the idea is our great Jackie will return. And we want to like have that as a way of helping her come back is to kind of summarize the research so far. And if I don't go to Cucon, I'm going to be really bored. I don't know how I can help help me be asking you like please send me things to include. And I think another thing to put out there is I posted this on Slack. But to help us like digest the secrets findings. As a team, we've set up three meetings. The first is totally just optional and informal and will be me reading out the. The secret features prioritization survey responses with some pms like cross functionally pms so they'll be like in that report we can do like a Q and a. And then the second week of November, we have a think big set up. And so y'all should attend that. And I will. Maybe easier for me just to post the slack meetings, but there's two session the slack. Oh my gosh, the slack comment where I linked all of these things, which is in this yet to be channel. But there's two time zones, so that should hopefully work out for everyone. Hopefully you guys can attend that and hopefully we're getting this on your radars really enough so that you can plan around that. Okay, there's the slack ones. Sorry that I'm a little discombined really did. I'm going to have a long if there's anything that we can do to help for Qcon at the very least, let us know. And take time to rest. Sorry about the COVID situation. That's tough. That really bad timing. Oh my god, I know I was like, well, I'm going to have I'm looking to have a whole plan for like quarantine when I got back. I think even if you make it all three of us should be really cautious during the event. Yeah, at the at the last one, a lot of people kind of had it. I was like really like OCD about it and I did you know this story. I was I didn't get it. I coupon in traveling to Spain. And then I came home and my partner had it. Yeah, I remember that. So it's just you know, whatever we can do. But yes, so Gina, we're going to need to kind of decide today, like a backup plan for the, yeah, the interiors, the secrets stuff. Yeah. Okay. I probably need to meet and we just because I can scope down that whole project. Okay. If we want. And so it just depends on what you want to do. I had even talked to James about when we met to talk about the think big James and I had kind of talk about scoping that down anyway and just making the question, could we do this research. So it kind of scales it back. But yeah, hopefully we can find some time to meet today to go for that. Yeah, definitely. I'm around like all afternoon. My okay, it's fully fully available. So it's do that. Right. Well, I think that that was all of our items. Anybody else have anything that you wanted to talk about. No. All right. All right. We'll have a good rest of your week and talk again soon. Bye everybody.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 20.0,
      "text": " Hello, everyone. This is the CICD UX team. We're meeting today on October 19th and there are some manager announcements in the beginning. I'll just go over and then we decided this meeting that we're going to switch up the order.",
      "tokens": [
        50364,
        2425,
        11,
        1518,
        13,
        639,
        307,
        264,
        383,
        2532,
        35,
        40176,
        1469,
        13,
        492,
        434,
        3440,
        965,
        322,
        7617,
        1294,
        392,
        293,
        456,
        366,
        512,
        6598,
        23785,
        294,
        264,
        2863,
        13,
        286,
        603,
        445,
        352,
        670,
        293,
        550,
        321,
        3047,
        341,
        3440,
        300,
        321,
        434,
        516,
        281,
        3679,
        493,
        264,
        1668,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20460271835327148,
      "compression_ratio": 1.3712574850299402,
      "no_speech_prob": 0.035394519567489624
    },
    {
      "id": 1,
      "seek": 2000,
      "start": 20.0,
      "end": 35.0,
      "text": " So, there was a thread for OKR's progress. If there's anything blocked or at risk, Hianna was asking for you to list it, but it doesn't seem like anything's there.",
      "tokens": [
        50364,
        407,
        11,
        456,
        390,
        257,
        7207,
        337,
        2264,
        49,
        311,
        4205,
        13,
        759,
        456,
        311,
        1340,
        15470,
        420,
        412,
        3148,
        11,
        389,
        952,
        629,
        390,
        3365,
        337,
        291,
        281,
        1329,
        309,
        11,
        457,
        309,
        1177,
        380,
        1643,
        411,
        1340,
        311,
        456,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25690709843355064,
      "compression_ratio": 1.4574468085106382,
      "no_speech_prob": 0.3120737075805664
    },
    {
      "id": 2,
      "seek": 2000,
      "start": 35.0,
      "end": 43.0,
      "text": " And then there's some upcoming family and friends days, dates that were released for November through January.",
      "tokens": [
        51114,
        400,
        550,
        456,
        311,
        512,
        11500,
        1605,
        293,
        1855,
        1708,
        11,
        11691,
        300,
        645,
        4736,
        337,
        7674,
        807,
        7061,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25690709843355064,
      "compression_ratio": 1.4574468085106382,
      "no_speech_prob": 0.3120737075805664
    },
    {
      "id": 3,
      "seek": 4300,
      "start": 44.0,
      "end": 53.0,
      "text": " And then the talent assessment officially kicked off today and it's open until November 4th to get that first.",
      "tokens": [
        50414,
        400,
        550,
        264,
        8301,
        9687,
        12053,
        14609,
        766,
        965,
        293,
        309,
        311,
        1269,
        1826,
        7674,
        1017,
        392,
        281,
        483,
        300,
        700,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20876310456473873,
      "compression_ratio": 1.4382716049382716,
      "no_speech_prob": 0.08225371688604355
    },
    {
      "id": 4,
      "seek": 4300,
      "start": 53.0,
      "end": 61.0,
      "text": " I think this is specifically to fill out the performance sheet that we were all given.",
      "tokens": [
        50864,
        286,
        519,
        341,
        307,
        4682,
        281,
        2836,
        484,
        264,
        3389,
        8193,
        300,
        321,
        645,
        439,
        2212,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20876310456473873,
      "compression_ratio": 1.4382716049382716,
      "no_speech_prob": 0.08225371688604355
    },
    {
      "id": 5,
      "seek": 4300,
      "start": 61.0,
      "end": 68.0,
      "text": " Anything any questions or anything.",
      "tokens": [
        51264,
        11998,
        604,
        1651,
        420,
        1340,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20876310456473873,
      "compression_ratio": 1.4382716049382716,
      "no_speech_prob": 0.08225371688604355
    },
    {
      "id": 6,
      "seek": 6800,
      "start": 68.0,
      "end": 80.0,
      "text": " All right. So then if we scroll all the way down, will do you want to start off and maybe if you know if Erica has anything you can go over that too.",
      "tokens": [
        50364,
        1057,
        558,
        13,
        407,
        550,
        498,
        321,
        11369,
        439,
        264,
        636,
        760,
        11,
        486,
        360,
        291,
        528,
        281,
        722,
        766,
        293,
        1310,
        498,
        291,
        458,
        498,
        37429,
        575,
        1340,
        291,
        393,
        352,
        670,
        300,
        886,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17835924360487196,
      "compression_ratio": 1.532967032967033,
      "no_speech_prob": 0.07724250108003616
    },
    {
      "id": 7,
      "seek": 6800,
      "start": 80.0,
      "end": 82.0,
      "text": " Yeah, sure.",
      "tokens": [
        50964,
        865,
        11,
        988,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17835924360487196,
      "compression_ratio": 1.532967032967033,
      "no_speech_prob": 0.07724250108003616
    },
    {
      "id": 8,
      "seek": 6800,
      "start": 82.0,
      "end": 91.0,
      "text": " So I know that Erica is also going to be at QCon. I'll be there as well. Gina, I think you're also going to be there.",
      "tokens": [
        51064,
        407,
        286,
        458,
        300,
        37429,
        307,
        611,
        516,
        281,
        312,
        412,
        1249,
        9838,
        13,
        286,
        603,
        312,
        456,
        382,
        731,
        13,
        34711,
        11,
        286,
        519,
        291,
        434,
        611,
        516,
        281,
        312,
        456,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17835924360487196,
      "compression_ratio": 1.532967032967033,
      "no_speech_prob": 0.07724250108003616
    },
    {
      "id": 9,
      "seek": 9100,
      "start": 91.0,
      "end": 105.0,
      "text": " So it'd be great to actually see a handful of people. I've met just a couple of GitLab team members before, but excited to actually meet people within the department.",
      "tokens": [
        50364,
        407,
        309,
        1116,
        312,
        869,
        281,
        767,
        536,
        257,
        16458,
        295,
        561,
        13,
        286,
        600,
        1131,
        445,
        257,
        1916,
        295,
        16939,
        37880,
        1469,
        2679,
        949,
        11,
        457,
        2919,
        281,
        767,
        1677,
        561,
        1951,
        264,
        5882,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1295742243528366,
      "compression_ratio": 1.449438202247191,
      "no_speech_prob": 0.030347229912877083
    },
    {
      "id": 10,
      "seek": 9100,
      "start": 105.0,
      "end": 116.0,
      "text": " So we'll be out doing some research. I think she's doing Erica's doing like her own survey.",
      "tokens": [
        51064,
        407,
        321,
        603,
        312,
        484,
        884,
        512,
        2132,
        13,
        286,
        519,
        750,
        311,
        884,
        37429,
        311,
        884,
        411,
        720,
        1065,
        8984,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1295742243528366,
      "compression_ratio": 1.449438202247191,
      "no_speech_prob": 0.030347229912877083
    },
    {
      "id": 11,
      "seek": 11600,
      "start": 116.0,
      "end": 141.0,
      "text": " Gina, you've been working on her with I'm doing something for a distribution team, like a survey and some interviews and then Eric and I are also teaming up with the market insights team to do some like buyer persona research, where we're trying to identify people that are likely to buy GitLab",
      "tokens": [
        50364,
        34711,
        11,
        291,
        600,
        668,
        1364,
        322,
        720,
        365,
        286,
        478,
        884,
        746,
        337,
        257,
        7316,
        1469,
        11,
        411,
        257,
        8984,
        293,
        512,
        12318,
        293,
        550,
        9336,
        293,
        286,
        366,
        611,
        1469,
        278,
        493,
        365,
        264,
        2142,
        14310,
        1469,
        281,
        360,
        512,
        411,
        24645,
        12184,
        2132,
        11,
        689,
        321,
        434,
        1382,
        281,
        5876,
        561,
        300,
        366,
        3700,
        281,
        2256,
        16939,
        37880,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12151760688194861,
      "compression_ratio": 1.5233160621761659,
      "no_speech_prob": 0.011583358980715275
    },
    {
      "id": 12,
      "seek": 14100,
      "start": 141.0,
      "end": 160.0,
      "text": " and then talk to them for a little bit and then see if they're open to like focus groups later in the week. So we're going to be quite busy with research next week. But when I have time, I'll be checking like messages and things to to keep up with stuff.",
      "tokens": [
        50364,
        293,
        550,
        751,
        281,
        552,
        337,
        257,
        707,
        857,
        293,
        550,
        536,
        498,
        436,
        434,
        1269,
        281,
        411,
        1879,
        3935,
        1780,
        294,
        264,
        1243,
        13,
        407,
        321,
        434,
        516,
        281,
        312,
        1596,
        5856,
        365,
        2132,
        958,
        1243,
        13,
        583,
        562,
        286,
        362,
        565,
        11,
        286,
        603,
        312,
        8568,
        411,
        7897,
        293,
        721,
        281,
        281,
        1066,
        493,
        365,
        1507,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08951939414529239,
      "compression_ratio": 1.600896860986547,
      "no_speech_prob": 0.005347928032279015
    },
    {
      "id": 13,
      "seek": 14100,
      "start": 160.0,
      "end": 170.0,
      "text": " Aside from that, about halfway through the benchmarking workshop that I'm doing with the release team.",
      "tokens": [
        51314,
        33726,
        490,
        300,
        11,
        466,
        15461,
        807,
        264,
        18927,
        278,
        13541,
        300,
        286,
        478,
        884,
        365,
        264,
        4374,
        1469,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08951939414529239,
      "compression_ratio": 1.600896860986547,
      "no_speech_prob": 0.005347928032279015
    },
    {
      "id": 14,
      "seek": 17000,
      "start": 171.0,
      "end": 180.0,
      "text": " Basically, the team has come up with solutions to the identified pain points and is giving feedback on everyone's ideas at this point.",
      "tokens": [
        50414,
        8537,
        11,
        264,
        1469,
        575,
        808,
        493,
        365,
        6547,
        281,
        264,
        9234,
        1822,
        2793,
        293,
        307,
        2902,
        5824,
        322,
        1518,
        311,
        3487,
        412,
        341,
        935,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06805557193178119,
      "compression_ratio": 1.553191489361702,
      "no_speech_prob": 0.0038822577334940434
    },
    {
      "id": 15,
      "seek": 17000,
      "start": 180.0,
      "end": 192.0,
      "text": " And then tomorrow, I'm actually opening up a final part of that workshop where we'll essentially vote on the top solutions that we want to work on as a team.",
      "tokens": [
        50864,
        400,
        550,
        4153,
        11,
        286,
        478,
        767,
        5193,
        493,
        257,
        2572,
        644,
        295,
        300,
        13541,
        689,
        321,
        603,
        4476,
        4740,
        322,
        264,
        1192,
        6547,
        300,
        321,
        528,
        281,
        589,
        322,
        382,
        257,
        1469,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06805557193178119,
      "compression_ratio": 1.553191489361702,
      "no_speech_prob": 0.0038822577334940434
    },
    {
      "id": 16,
      "seek": 19200,
      "start": 193.0,
      "end": 207.0,
      "text": " And then I'll create actual insight issues that will incorporate into the roadmap. And then I've been helping Emily out with some research that she's doing related to her CMS scorecard.",
      "tokens": [
        50414,
        400,
        550,
        286,
        603,
        1884,
        3539,
        11269,
        2663,
        300,
        486,
        16091,
        666,
        264,
        35738,
        13,
        400,
        550,
        286,
        600,
        668,
        4315,
        15034,
        484,
        365,
        512,
        2132,
        300,
        750,
        311,
        884,
        4077,
        281,
        720,
        33124,
        6175,
        22259,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14173351287841796,
      "compression_ratio": 1.3825503355704698,
      "no_speech_prob": 0.040131110697984695
    },
    {
      "id": 17,
      "seek": 19200,
      "start": 208.0,
      "end": 210.0,
      "text": " So that's it for me.",
      "tokens": [
        51164,
        407,
        300,
        311,
        309,
        337,
        385,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14173351287841796,
      "compression_ratio": 1.3825503355704698,
      "no_speech_prob": 0.040131110697984695
    },
    {
      "id": 18,
      "seek": 21000,
      "start": 211.0,
      "end": 230.0,
      "text": " One other, the stuff that you were saying that Erica was doing for coupon. I only have insight into one of them, which is about secrets, but she's been there was like some previous work that she had piloted and ended up getting like a lot of data from around.",
      "tokens": [
        50414,
        1485,
        661,
        11,
        264,
        1507,
        300,
        291,
        645,
        1566,
        300,
        37429,
        390,
        884,
        337,
        33390,
        13,
        286,
        787,
        362,
        11269,
        666,
        472,
        295,
        552,
        11,
        597,
        307,
        466,
        14093,
        11,
        457,
        750,
        311,
        668,
        456,
        390,
        411,
        512,
        3894,
        589,
        300,
        750,
        632,
        9691,
        292,
        293,
        4590,
        493,
        1242,
        411,
        257,
        688,
        295,
        1412,
        490,
        926,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13004678194640112,
      "compression_ratio": 1.463276836158192,
      "no_speech_prob": 0.013843518681824207
    },
    {
      "id": 19,
      "seek": 23000,
      "start": 231.0,
      "end": 242.0,
      "text": " I think that one was specifically secrets within the workflow. So kind of figuring out like what developers were expecting ideally for how that would work.",
      "tokens": [
        50414,
        286,
        519,
        300,
        472,
        390,
        4682,
        14093,
        1951,
        264,
        20993,
        13,
        407,
        733,
        295,
        15213,
        484,
        411,
        437,
        8849,
        645,
        9650,
        22915,
        337,
        577,
        300,
        576,
        589,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16573174340384347,
      "compression_ratio": 1.526829268292683,
      "no_speech_prob": 0.00944395549595356
    },
    {
      "id": 20,
      "seek": 23000,
      "start": 242.0,
      "end": 253.0,
      "text": " And she's going to continue looking at that for Qcon, but focus on finding out metadata that's important around secrets.",
      "tokens": [
        50964,
        400,
        750,
        311,
        516,
        281,
        2354,
        1237,
        412,
        300,
        337,
        1249,
        1671,
        11,
        457,
        1879,
        322,
        5006,
        484,
        26603,
        300,
        311,
        1021,
        926,
        14093,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16573174340384347,
      "compression_ratio": 1.526829268292683,
      "no_speech_prob": 0.00944395549595356
    },
    {
      "id": 21,
      "seek": 23000,
      "start": 253.0,
      "end": 256.0,
      "text": " Okay. Yeah, thanks for the contacts.",
      "tokens": [
        51514,
        1033,
        13,
        865,
        11,
        3231,
        337,
        264,
        15836,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16573174340384347,
      "compression_ratio": 1.526829268292683,
      "no_speech_prob": 0.00944395549595356
    },
    {
      "id": 22,
      "seek": 25600,
      "start": 257.0,
      "end": 261.0,
      "text": " So Kevin, I think you're up next.",
      "tokens": [
        50414,
        407,
        9954,
        11,
        286,
        519,
        291,
        434,
        493,
        958,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25835821363661027,
      "compression_ratio": 1.3580246913580247,
      "no_speech_prob": 0.01487328577786684
    },
    {
      "id": 23,
      "seek": 25600,
      "start": 261.0,
      "end": 272.0,
      "text": " Sure. Thanks. Yeah, for me, not a lot of dates, but mainly one of the issues that I've been working with and that I shared a last time was about them.",
      "tokens": [
        50614,
        4894,
        13,
        2561,
        13,
        865,
        11,
        337,
        385,
        11,
        406,
        257,
        688,
        295,
        11691,
        11,
        457,
        8704,
        472,
        295,
        264,
        2663,
        300,
        286,
        600,
        668,
        1364,
        365,
        293,
        300,
        286,
        5507,
        257,
        1036,
        565,
        390,
        466,
        552,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25835821363661027,
      "compression_ratio": 1.3580246913580247,
      "no_speech_prob": 0.01487328577786684
    },
    {
      "id": 24,
      "seek": 25600,
      "start": 272.0,
      "end": 276.0,
      "text": " And not revealing massed variables.",
      "tokens": [
        51164,
        400,
        406,
        23983,
        2758,
        292,
        9102,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25835821363661027,
      "compression_ratio": 1.3580246913580247,
      "no_speech_prob": 0.01487328577786684
    },
    {
      "id": 25,
      "seek": 27600,
      "start": 277.0,
      "end": 291.0,
      "text": " And kind of what I've heard is after discussing with the team, we kind of agreed to take another path and kind of diverge on this and decorate secrets and variables.",
      "tokens": [
        50414,
        400,
        733,
        295,
        437,
        286,
        600,
        2198,
        307,
        934,
        10850,
        365,
        264,
        1469,
        11,
        321,
        733,
        295,
        9166,
        281,
        747,
        1071,
        3100,
        293,
        733,
        295,
        18558,
        432,
        322,
        341,
        293,
        979,
        284,
        473,
        14093,
        293,
        9102,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24879272522464876,
      "compression_ratio": 1.5337423312883436,
      "no_speech_prob": 0.014588000252842903
    },
    {
      "id": 26,
      "seek": 27600,
      "start": 291.0,
      "end": 298.0,
      "text": " So I've kind of sketch out some really raw wire frames of what that would look like.",
      "tokens": [
        51114,
        407,
        286,
        600,
        733,
        295,
        12325,
        484,
        512,
        534,
        8936,
        6234,
        12083,
        295,
        437,
        300,
        576,
        574,
        411,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24879272522464876,
      "compression_ratio": 1.5337423312883436,
      "no_speech_prob": 0.014588000252842903
    },
    {
      "id": 27,
      "seek": 29800,
      "start": 298.0,
      "end": 312.0,
      "text": " If anyone has some thoughts, please weigh in, but essentially the next steps are going to be to live a bit deeper as to what this would look like, introducing a whole path for creating and managing secrets.",
      "tokens": [
        50364,
        759,
        2878,
        575,
        512,
        4598,
        11,
        1767,
        13843,
        294,
        11,
        457,
        4476,
        264,
        958,
        4439,
        366,
        516,
        281,
        312,
        281,
        1621,
        257,
        857,
        7731,
        382,
        281,
        437,
        341,
        576,
        574,
        411,
        11,
        15424,
        257,
        1379,
        3100,
        337,
        4084,
        293,
        11642,
        14093,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14118179841475054,
      "compression_ratio": 1.4417177914110428,
      "no_speech_prob": 0.0039274548180401325
    },
    {
      "id": 28,
      "seek": 29800,
      "start": 312.0,
      "end": 315.0,
      "text": " And that is the first point.",
      "tokens": [
        51064,
        400,
        300,
        307,
        264,
        700,
        935,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14118179841475054,
      "compression_ratio": 1.4417177914110428,
      "no_speech_prob": 0.0039274548180401325
    },
    {
      "id": 29,
      "seek": 31500,
      "start": 315.0,
      "end": 322.0,
      "text": " And the second point is you may have seen this in the UX ICD channel.",
      "tokens": [
        50364,
        400,
        264,
        1150,
        935,
        307,
        291,
        815,
        362,
        1612,
        341,
        294,
        264,
        40176,
        286,
        16508,
        2269,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3669872516539039,
      "compression_ratio": 1.25,
      "no_speech_prob": 0.01382068358361721
    },
    {
      "id": 30,
      "seek": 31500,
      "start": 322.0,
      "end": 333.0,
      "text": " But there is a proposal from an engineer Fred's to be designed the pipeline overview page.",
      "tokens": [
        50714,
        583,
        456,
        307,
        257,
        11494,
        490,
        364,
        11403,
        10112,
        311,
        281,
        312,
        4761,
        264,
        15517,
        12492,
        3028,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3669872516539039,
      "compression_ratio": 1.25,
      "no_speech_prob": 0.01382068358361721
    },
    {
      "id": 31,
      "seek": 33300,
      "start": 333.0,
      "end": 352.0,
      "text": " And I think it's a very good idea to have a look at the pipeline, I think it's a pipeline graph, you go with the different jobs and stages that would be a different visualization that kind of highlight more like the number of failed jobs and also like higher pipeline is doing.",
      "tokens": [
        50364,
        400,
        286,
        519,
        309,
        311,
        257,
        588,
        665,
        1558,
        281,
        362,
        257,
        574,
        412,
        264,
        15517,
        11,
        286,
        519,
        309,
        311,
        257,
        15517,
        4295,
        11,
        291,
        352,
        365,
        264,
        819,
        4782,
        293,
        10232,
        300,
        576,
        312,
        257,
        819,
        25801,
        300,
        733,
        295,
        5078,
        544,
        411,
        264,
        1230,
        295,
        7612,
        4782,
        293,
        611,
        411,
        2946,
        15517,
        307,
        884,
        13,
        51314
      ],
      "temperature": 0.2,
      "avg_logprob": -0.4800431262487653,
      "compression_ratio": 1.6909871244635193,
      "no_speech_prob": 0.18335679173469543
    },
    {
      "id": 32,
      "seek": 33300,
      "start": 352.0,
      "end": 361.0,
      "text": " So I'll be helping him kind of isolating on this design, but potentially also good through research and validate it.",
      "tokens": [
        51314,
        407,
        286,
        603,
        312,
        4315,
        796,
        733,
        295,
        48912,
        322,
        341,
        1715,
        11,
        457,
        7263,
        611,
        665,
        807,
        2132,
        293,
        29562,
        309,
        13,
        51764
      ],
      "temperature": 0.2,
      "avg_logprob": -0.4800431262487653,
      "compression_ratio": 1.6909871244635193,
      "no_speech_prob": 0.18335679173469543
    },
    {
      "id": 33,
      "seek": 36100,
      "start": 361.0,
      "end": 375.0,
      "text": " Again, if you have any thoughts on that, feel free to weigh in the issue, I think there's a link to his video that he created in the issue, otherwise you might be able to find it in this like thread.",
      "tokens": [
        50364,
        3764,
        11,
        498,
        291,
        362,
        604,
        4598,
        322,
        300,
        11,
        841,
        1737,
        281,
        13843,
        294,
        264,
        2734,
        11,
        286,
        519,
        456,
        311,
        257,
        2113,
        281,
        702,
        960,
        300,
        415,
        2942,
        294,
        264,
        2734,
        11,
        5911,
        291,
        1062,
        312,
        1075,
        281,
        915,
        309,
        294,
        341,
        411,
        7207,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17944852511088052,
      "compression_ratio": 1.489795918367347,
      "no_speech_prob": 0.009900788776576519
    },
    {
      "id": 34,
      "seek": 36100,
      "start": 375.0,
      "end": 379.0,
      "text": " So yeah, that's it.",
      "tokens": [
        51064,
        407,
        1338,
        11,
        300,
        311,
        309,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17944852511088052,
      "compression_ratio": 1.489795918367347,
      "no_speech_prob": 0.009900788776576519
    },
    {
      "id": 35,
      "seek": 37900,
      "start": 379.0,
      "end": 391.0,
      "text": " I was going through your proposal and like crunching the commit box to a small area and then landing straight on the summary tab.",
      "tokens": [
        50364,
        286,
        390,
        516,
        807,
        428,
        11494,
        293,
        411,
        13386,
        278,
        264,
        5599,
        2424,
        281,
        257,
        1359,
        1859,
        293,
        550,
        11202,
        2997,
        322,
        264,
        12691,
        4421,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20185128847757974,
      "compression_ratio": 1.5317919075144508,
      "no_speech_prob": 0.3763468563556671
    },
    {
      "id": 36,
      "seek": 37900,
      "start": 391.0,
      "end": 401.0,
      "text": " Did he also I haven't read through your comment, but was there a discussion around removing the failed jobs or that's something that's.",
      "tokens": [
        50964,
        2589,
        415,
        611,
        286,
        2378,
        380,
        1401,
        807,
        428,
        2871,
        11,
        457,
        390,
        456,
        257,
        5017,
        926,
        12720,
        264,
        7612,
        4782,
        420,
        300,
        311,
        746,
        300,
        311,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20185128847757974,
      "compression_ratio": 1.5317919075144508,
      "no_speech_prob": 0.3763468563556671
    },
    {
      "id": 37,
      "seek": 40100,
      "start": 401.0,
      "end": 416.0,
      "text": " The failed jobs, you mean yeah yeah yeah i kind of mentioned that we could instead of like showing all of the failed job just showing a bunch of them and then sending people to the failed job tabs, I think that's one direction.",
      "tokens": [
        50364,
        440,
        7612,
        4782,
        11,
        291,
        914,
        1338,
        1338,
        1338,
        741,
        733,
        295,
        2835,
        300,
        321,
        727,
        2602,
        295,
        411,
        4099,
        439,
        295,
        264,
        7612,
        1691,
        445,
        4099,
        257,
        3840,
        295,
        552,
        293,
        550,
        7750,
        561,
        281,
        264,
        7612,
        1691,
        20743,
        11,
        286,
        519,
        300,
        311,
        472,
        3513,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3021074725735572,
      "compression_ratio": 1.6153846153846154,
      "no_speech_prob": 0.06741189956665039
    },
    {
      "id": 38,
      "seek": 40100,
      "start": 416.0,
      "end": 421.0,
      "text": " Instead yeah.",
      "tokens": [
        51114,
        7156,
        1338,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3021074725735572,
      "compression_ratio": 1.6153846153846154,
      "no_speech_prob": 0.06741189956665039
    },
    {
      "id": 39,
      "seek": 40100,
      "start": 421.0,
      "end": 425.0,
      "text": " All right.",
      "tokens": [
        51364,
        1057,
        558,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3021074725735572,
      "compression_ratio": 1.6153846153846154,
      "no_speech_prob": 0.06741189956665039
    },
    {
      "id": 40,
      "seek": 42500,
      "start": 425.0,
      "end": 430.0,
      "text": " It's good.",
      "tokens": [
        50364,
        467,
        311,
        665,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579045680531284,
      "compression_ratio": 1.3191489361702127,
      "no_speech_prob": 0.006359345279633999
    },
    {
      "id": 41,
      "seek": 42500,
      "start": 430.0,
      "end": 435.0,
      "text": " Sorry next is me.",
      "tokens": [
        50614,
        4919,
        958,
        307,
        385,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579045680531284,
      "compression_ratio": 1.3191489361702127,
      "no_speech_prob": 0.006359345279633999
    },
    {
      "id": 42,
      "seek": 42500,
      "start": 435.0,
      "end": 446.0,
      "text": " All right, so first of all, we had enabled tracking for a bunch of fire pendulated actions and now what we are doing is.",
      "tokens": [
        50864,
        1057,
        558,
        11,
        370,
        700,
        295,
        439,
        11,
        321,
        632,
        15172,
        11603,
        337,
        257,
        3840,
        295,
        2610,
        12179,
        6987,
        5909,
        293,
        586,
        437,
        321,
        366,
        884,
        307,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579045680531284,
      "compression_ratio": 1.3191489361702127,
      "no_speech_prob": 0.006359345279633999
    },
    {
      "id": 43,
      "seek": 42500,
      "start": 446.0,
      "end": 449.0,
      "text": " I'll quickly find the size in sling.",
      "tokens": [
        51414,
        286,
        603,
        2661,
        915,
        264,
        2744,
        294,
        1061,
        278,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3579045680531284,
      "compression_ratio": 1.3191489361702127,
      "no_speech_prob": 0.006359345279633999
    },
    {
      "id": 44,
      "seek": 44900,
      "start": 449.0,
      "end": 463.0,
      "text": " So we are able to get a lot of information about what are the actions that our users are performing more frequently and which are the links they're clicking on on the pipeline list view.",
      "tokens": [
        50364,
        407,
        321,
        366,
        1075,
        281,
        483,
        257,
        688,
        295,
        1589,
        466,
        437,
        366,
        264,
        5909,
        300,
        527,
        5022,
        366,
        10205,
        544,
        10374,
        293,
        597,
        366,
        264,
        6123,
        436,
        434,
        9697,
        322,
        322,
        264,
        15517,
        1329,
        1910,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0978388786315918,
      "compression_ratio": 1.5988700564971752,
      "no_speech_prob": 0.012010936625301838
    },
    {
      "id": 45,
      "seek": 44900,
      "start": 463.0,
      "end": 471.0,
      "text": " So we had our monthly check in around that information here's the dashboard i'm linking it here.",
      "tokens": [
        51064,
        407,
        321,
        632,
        527,
        12878,
        1520,
        294,
        926,
        300,
        1589,
        510,
        311,
        264,
        18342,
        741,
        478,
        25775,
        309,
        510,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0978388786315918,
      "compression_ratio": 1.5988700564971752,
      "no_speech_prob": 0.012010936625301838
    },
    {
      "id": 46,
      "seek": 47100,
      "start": 471.0,
      "end": 482.0,
      "text": " Yeah, this is the dashboard and we kind of sort of different ways in which we can act upon the information that we're getting from there.",
      "tokens": [
        50364,
        865,
        11,
        341,
        307,
        264,
        18342,
        293,
        321,
        733,
        295,
        1333,
        295,
        819,
        2098,
        294,
        597,
        321,
        393,
        605,
        3564,
        264,
        1589,
        300,
        321,
        434,
        1242,
        490,
        456,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1067896808486387,
      "compression_ratio": 1.6044444444444443,
      "no_speech_prob": 0.024812281131744385
    },
    {
      "id": 47,
      "seek": 47100,
      "start": 482.0,
      "end": 487.0,
      "text": " So for example, we already had a bunch of concerns related to speed.",
      "tokens": [
        50914,
        407,
        337,
        1365,
        11,
        321,
        1217,
        632,
        257,
        3840,
        295,
        7389,
        4077,
        281,
        3073,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1067896808486387,
      "compression_ratio": 1.6044444444444443,
      "no_speech_prob": 0.024812281131744385
    },
    {
      "id": 48,
      "seek": 47100,
      "start": 487.0,
      "end": 496.0,
      "text": " So what our front and team did was they used lighthouse runs to figure out like which are the areas which are costing us the most in terms of performance.",
      "tokens": [
        51164,
        407,
        437,
        527,
        1868,
        293,
        1469,
        630,
        390,
        436,
        1143,
        47481,
        6676,
        281,
        2573,
        484,
        411,
        597,
        366,
        264,
        3179,
        597,
        366,
        37917,
        505,
        264,
        881,
        294,
        2115,
        295,
        3389,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1067896808486387,
      "compression_ratio": 1.6044444444444443,
      "no_speech_prob": 0.024812281131744385
    },
    {
      "id": 49,
      "seek": 49600,
      "start": 496.0,
      "end": 504.0,
      "text": " And how can we tie in the insights, which are we are receiving through this set of data and come up with your proposals.",
      "tokens": [
        50364,
        400,
        577,
        393,
        321,
        7582,
        294,
        264,
        14310,
        11,
        597,
        366,
        321,
        366,
        10040,
        807,
        341,
        992,
        295,
        1412,
        293,
        808,
        493,
        365,
        428,
        20198,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13875981264336165,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.12324177473783493
    },
    {
      "id": 50,
      "seek": 49600,
      "start": 504.0,
      "end": 522.0,
      "text": " So if you go down, I have proposed a new method to kind of just suggest a proposal and that will be broken into three parts like proposal, the assumptions that we are taking into account and the evidence to support the proposal, which can be a combination of both.",
      "tokens": [
        50764,
        407,
        498,
        291,
        352,
        760,
        11,
        286,
        362,
        10348,
        257,
        777,
        3170,
        281,
        733,
        295,
        445,
        3402,
        257,
        11494,
        293,
        300,
        486,
        312,
        5463,
        666,
        1045,
        3166,
        411,
        11494,
        11,
        264,
        17695,
        300,
        321,
        366,
        1940,
        666,
        2696,
        293,
        264,
        4467,
        281,
        1406,
        264,
        11494,
        11,
        597,
        393,
        312,
        257,
        6562,
        295,
        1293,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13875981264336165,
      "compression_ratio": 1.6666666666666667,
      "no_speech_prob": 0.12324177473783493
    },
    {
      "id": 51,
      "seek": 52200,
      "start": 522.0,
      "end": 527.0,
      "text": " So metrics were getting through data tracking as well as the insights from previous researchers.",
      "tokens": [
        50364,
        407,
        16367,
        645,
        1242,
        807,
        1412,
        11603,
        382,
        731,
        382,
        264,
        14310,
        490,
        3894,
        10309,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13646308286690417,
      "compression_ratio": 1.6331877729257642,
      "no_speech_prob": 0.17067712545394897
    },
    {
      "id": 52,
      "seek": 52200,
      "start": 527.0,
      "end": 545.0,
      "text": " And at the end, like once we have a bunch of these we would do around a voting and so far my idea is that we would vote on the basis of like which one has the most least risky assumption associated with it and it would be most impactful to keeping those two parameters in mind.",
      "tokens": [
        50614,
        400,
        412,
        264,
        917,
        11,
        411,
        1564,
        321,
        362,
        257,
        3840,
        295,
        613,
        321,
        576,
        360,
        926,
        257,
        10419,
        293,
        370,
        1400,
        452,
        1558,
        307,
        300,
        321,
        576,
        4740,
        322,
        264,
        5143,
        295,
        411,
        597,
        472,
        575,
        264,
        881,
        1935,
        21137,
        15302,
        6615,
        365,
        309,
        293,
        309,
        576,
        312,
        881,
        30842,
        281,
        5145,
        729,
        732,
        9834,
        294,
        1575,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13646308286690417,
      "compression_ratio": 1.6331877729257642,
      "no_speech_prob": 0.17067712545394897
    },
    {
      "id": 53,
      "seek": 54500,
      "start": 545.0,
      "end": 556.0,
      "text": " Yeah, and then we would just get started on the like design proposal for that particular proposal that kind of gets the highest number of words.",
      "tokens": [
        50364,
        865,
        11,
        293,
        550,
        321,
        576,
        445,
        483,
        1409,
        322,
        264,
        411,
        1715,
        11494,
        337,
        300,
        1729,
        11494,
        300,
        733,
        295,
        2170,
        264,
        6343,
        1230,
        295,
        2283,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14913224585262347,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.07388125360012054
    },
    {
      "id": 54,
      "seek": 54500,
      "start": 556.0,
      "end": 574.0,
      "text": " Coming to the next point, which is the PNPS and Suss feedback assessment. So we revisited feedback from past four quarters, because we really wanted to get to work on such impacting issues that would have the highest impact.",
      "tokens": [
        50914,
        12473,
        281,
        264,
        958,
        935,
        11,
        597,
        307,
        264,
        430,
        45,
        6273,
        293,
        318,
        2023,
        5824,
        9687,
        13,
        407,
        321,
        20767,
        1226,
        5824,
        490,
        1791,
        1451,
        20612,
        11,
        570,
        321,
        534,
        1415,
        281,
        483,
        281,
        589,
        322,
        1270,
        29963,
        2663,
        300,
        576,
        362,
        264,
        6343,
        2712,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14913224585262347,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.07388125360012054
    },
    {
      "id": 55,
      "seek": 57400,
      "start": 574.0,
      "end": 593.0,
      "text": " And we were desperate to take a different approach than just like going through like burning down through a list of S1 and S2s because we wanted this to align with what our users are feeling and how they are like sharing their experiences with us.",
      "tokens": [
        50364,
        400,
        321,
        645,
        17601,
        281,
        747,
        257,
        819,
        3109,
        813,
        445,
        411,
        516,
        807,
        411,
        9488,
        760,
        807,
        257,
        1329,
        295,
        318,
        16,
        293,
        318,
        17,
        82,
        570,
        321,
        1415,
        341,
        281,
        7975,
        365,
        437,
        527,
        5022,
        366,
        2633,
        293,
        577,
        436,
        366,
        411,
        5414,
        641,
        5235,
        365,
        505,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12545795793886538,
      "compression_ratio": 1.5246913580246915,
      "no_speech_prob": 0.014214581809937954
    },
    {
      "id": 56,
      "seek": 59300,
      "start": 593.0,
      "end": 613.0,
      "text": " Now this assessment, I was able to understand what the most frequently emerging teams across the feedback and the two that were most recurring were one was definitely around improvements to talks like adding more examples and improving the instructions around CACD.",
      "tokens": [
        50364,
        823,
        341,
        9687,
        11,
        286,
        390,
        1075,
        281,
        1223,
        437,
        264,
        881,
        10374,
        14989,
        5491,
        2108,
        264,
        5824,
        293,
        264,
        732,
        300,
        645,
        881,
        32279,
        645,
        472,
        390,
        2138,
        926,
        13797,
        281,
        6686,
        411,
        5127,
        544,
        5110,
        293,
        11470,
        264,
        9415,
        926,
        383,
        4378,
        35,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2015542984008789,
      "compression_ratio": 1.4887640449438202,
      "no_speech_prob": 0.040057722479104996
    },
    {
      "id": 57,
      "seek": 61300,
      "start": 613.0,
      "end": 622.0,
      "text": " And the next one was reducing the number of steps for primary task. This was like a lot of users mentioned like share feed background.",
      "tokens": [
        50364,
        400,
        264,
        958,
        472,
        390,
        12245,
        264,
        1230,
        295,
        4439,
        337,
        6194,
        5633,
        13,
        639,
        390,
        411,
        257,
        688,
        295,
        5022,
        2835,
        411,
        2073,
        3154,
        3678,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10560996392193962,
      "compression_ratio": 1.6395348837209303,
      "no_speech_prob": 0.5901187658309937
    },
    {
      "id": 58,
      "seek": 61300,
      "start": 622.0,
      "end": 637.0,
      "text": " It taking a lot of time and a lot of number of clicks to get and to perform an action or to perform a task which we can say is primary to the area.",
      "tokens": [
        50814,
        467,
        1940,
        257,
        688,
        295,
        565,
        293,
        257,
        688,
        295,
        1230,
        295,
        18521,
        281,
        483,
        293,
        281,
        2042,
        364,
        3069,
        420,
        281,
        2042,
        257,
        5633,
        597,
        321,
        393,
        584,
        307,
        6194,
        281,
        264,
        1859,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10560996392193962,
      "compression_ratio": 1.6395348837209303,
      "no_speech_prob": 0.5901187658309937
    },
    {
      "id": 59,
      "seek": 63700,
      "start": 637.0,
      "end": 656.0,
      "text": " So we want to make a collection of all the existing issues which are some impacting which relate to this insight and bring them together in an epic with a very clear exit criteria. So we are actually able to go through like one down all the issues inside the epic and also close it by the end of the quarter.",
      "tokens": [
        50364,
        407,
        321,
        528,
        281,
        652,
        257,
        5765,
        295,
        439,
        264,
        6741,
        2663,
        597,
        366,
        512,
        29963,
        597,
        10961,
        281,
        341,
        11269,
        293,
        1565,
        552,
        1214,
        294,
        364,
        13581,
        365,
        257,
        588,
        1850,
        11043,
        11101,
        13,
        407,
        321,
        366,
        767,
        1075,
        281,
        352,
        807,
        411,
        472,
        760,
        439,
        264,
        2663,
        1854,
        264,
        13581,
        293,
        611,
        1998,
        309,
        538,
        264,
        917,
        295,
        264,
        6555,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15012240655643425,
      "compression_ratio": 1.7188755020080322,
      "no_speech_prob": 0.0744926929473877
    },
    {
      "id": 60,
      "seek": 63700,
      "start": 656.0,
      "end": 658.0,
      "text": " So something very realistic.",
      "tokens": [
        51314,
        407,
        746,
        588,
        12465,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15012240655643425,
      "compression_ratio": 1.7188755020080322,
      "no_speech_prob": 0.0744926929473877
    },
    {
      "id": 61,
      "seek": 63700,
      "start": 658.0,
      "end": 664.0,
      "text": " And that's the next step for me like I'll be creating that epic and adding issues to that.",
      "tokens": [
        51414,
        400,
        300,
        311,
        264,
        958,
        1823,
        337,
        385,
        411,
        286,
        603,
        312,
        4084,
        300,
        13581,
        293,
        5127,
        2663,
        281,
        300,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15012240655643425,
      "compression_ratio": 1.7188755020080322,
      "no_speech_prob": 0.0744926929473877
    },
    {
      "id": 62,
      "seek": 66400,
      "start": 664.0,
      "end": 667.0,
      "text": " What next quarter?",
      "tokens": [
        50364,
        708,
        958,
        6555,
        30,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29504417728733373,
      "compression_ratio": 1.435483870967742,
      "no_speech_prob": 0.013876763172447681
    },
    {
      "id": 63,
      "seek": 66400,
      "start": 667.0,
      "end": 670.0,
      "text": " Yeah.",
      "tokens": [
        50514,
        865,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29504417728733373,
      "compression_ratio": 1.435483870967742,
      "no_speech_prob": 0.013876763172447681
    },
    {
      "id": 64,
      "seek": 66400,
      "start": 670.0,
      "end": 673.0,
      "text": " Any comments, any feedback?",
      "tokens": [
        50664,
        2639,
        3053,
        11,
        604,
        5824,
        30,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29504417728733373,
      "compression_ratio": 1.435483870967742,
      "no_speech_prob": 0.013876763172447681
    },
    {
      "id": 65,
      "seek": 66400,
      "start": 673.0,
      "end": 675.0,
      "text": " Do you know do you want to voice?",
      "tokens": [
        50814,
        1144,
        291,
        458,
        360,
        291,
        528,
        281,
        3177,
        30,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29504417728733373,
      "compression_ratio": 1.435483870967742,
      "no_speech_prob": 0.013876763172447681
    },
    {
      "id": 66,
      "seek": 66400,
      "start": 675.0,
      "end": 676.0,
      "text": " Yeah.",
      "tokens": [
        50914,
        865,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29504417728733373,
      "compression_ratio": 1.435483870967742,
      "no_speech_prob": 0.013876763172447681
    },
    {
      "id": 67,
      "seek": 66400,
      "start": 676.0,
      "end": 688.0,
      "text": " I'll voice that one. This was related for your first topic. It was, it's just interesting that that that issue is more about like load performance, which makes perfect sense.",
      "tokens": [
        50964,
        286,
        603,
        3177,
        300,
        472,
        13,
        639,
        390,
        4077,
        337,
        428,
        700,
        4829,
        13,
        467,
        390,
        11,
        309,
        311,
        445,
        1880,
        300,
        300,
        300,
        2734,
        307,
        544,
        466,
        411,
        3677,
        3389,
        11,
        597,
        1669,
        2176,
        2020,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29504417728733373,
      "compression_ratio": 1.435483870967742,
      "no_speech_prob": 0.013876763172447681
    },
    {
      "id": 68,
      "seek": 68800,
      "start": 688.0,
      "end": 697.0,
      "text": " And that we have a in pipeline insights, we have a feature around load performance and it's supposed to help track those types of things.",
      "tokens": [
        50364,
        400,
        300,
        321,
        362,
        257,
        294,
        15517,
        14310,
        11,
        321,
        362,
        257,
        4111,
        926,
        3677,
        3389,
        293,
        309,
        311,
        3442,
        281,
        854,
        2837,
        729,
        3467,
        295,
        721,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09985763307601686,
      "compression_ratio": 1.558659217877095,
      "no_speech_prob": 0.0014562044525519013
    },
    {
      "id": 69,
      "seek": 68800,
      "start": 697.0,
      "end": 709.0,
      "text": " But it's clear that the products that like that your team is using is showing results or data and much more depth than what our feature does.",
      "tokens": [
        50814,
        583,
        309,
        311,
        1850,
        300,
        264,
        3383,
        300,
        411,
        300,
        428,
        1469,
        307,
        1228,
        307,
        4099,
        3542,
        420,
        1412,
        293,
        709,
        544,
        7161,
        813,
        437,
        527,
        4111,
        775,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09985763307601686,
      "compression_ratio": 1.558659217877095,
      "no_speech_prob": 0.0014562044525519013
    },
    {
      "id": 70,
      "seek": 70900,
      "start": 709.0,
      "end": 724.0,
      "text": " So it gives me some ideas of how we could improve that area. We're not even focused on performance testing as like a whole in pipeline insights, but something for the future at least that we could think of.",
      "tokens": [
        50364,
        407,
        309,
        2709,
        385,
        512,
        3487,
        295,
        577,
        321,
        727,
        3470,
        300,
        1859,
        13,
        492,
        434,
        406,
        754,
        5178,
        322,
        3389,
        4997,
        382,
        411,
        257,
        1379,
        294,
        15517,
        14310,
        11,
        457,
        746,
        337,
        264,
        2027,
        412,
        1935,
        300,
        321,
        727,
        519,
        295,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17269659042358398,
      "compression_ratio": 1.5695067264573992,
      "no_speech_prob": 0.3245064914226532
    },
    {
      "id": 71,
      "seek": 70900,
      "start": 724.0,
      "end": 732.0,
      "text": " I was aware of this so far and this is the first time looking at once it's proud of that provides these informations.",
      "tokens": [
        51114,
        286,
        390,
        3650,
        295,
        341,
        370,
        1400,
        293,
        341,
        307,
        264,
        700,
        565,
        1237,
        412,
        1564,
        309,
        311,
        4570,
        295,
        300,
        6417,
        613,
        38855,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17269659042358398,
      "compression_ratio": 1.5695067264573992,
      "no_speech_prob": 0.3245064914226532
    },
    {
      "id": 72,
      "seek": 70900,
      "start": 732.0,
      "end": 735.0,
      "text": " Yeah, they do a good job.",
      "tokens": [
        51514,
        865,
        11,
        436,
        360,
        257,
        665,
        1691,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17269659042358398,
      "compression_ratio": 1.5695067264573992,
      "no_speech_prob": 0.3245064914226532
    },
    {
      "id": 73,
      "seek": 73500,
      "start": 735.0,
      "end": 741.0,
      "text": " All right, so that was me passing it on to Emily.",
      "tokens": [
        50364,
        1057,
        558,
        11,
        370,
        300,
        390,
        385,
        8437,
        309,
        322,
        281,
        15034,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1455093970665565,
      "compression_ratio": 1.530612244897959,
      "no_speech_prob": 0.013139414601027966
    },
    {
      "id": 74,
      "seek": 73500,
      "start": 741.0,
      "end": 757.0,
      "text": " So last week I was kind of wrapping up our solution validation around pending deployment approvals into dues and just there was some interesting stuff that came out of the study that kind of correlated with some of the competitive reviews we've done.",
      "tokens": [
        50664,
        407,
        1036,
        1243,
        286,
        390,
        733,
        295,
        21993,
        493,
        527,
        3827,
        24071,
        926,
        32110,
        19317,
        2075,
        19778,
        666,
        41753,
        293,
        445,
        456,
        390,
        512,
        1880,
        1507,
        300,
        1361,
        484,
        295,
        264,
        2979,
        300,
        733,
        295,
        38574,
        365,
        512,
        295,
        264,
        10043,
        10229,
        321,
        600,
        1096,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1455093970665565,
      "compression_ratio": 1.530612244897959,
      "no_speech_prob": 0.013139414601027966
    },
    {
      "id": 75,
      "seek": 75700,
      "start": 757.0,
      "end": 763.0,
      "text": " Slack seemed to be the most popular tool users we're using to notify each other since we didn't offer it.",
      "tokens": [
        50364,
        37211,
        6576,
        281,
        312,
        264,
        881,
        3743,
        2290,
        5022,
        321,
        434,
        1228,
        281,
        36560,
        1184,
        661,
        1670,
        321,
        994,
        380,
        2626,
        309,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1340431911604745,
      "compression_ratio": 1.7080536912751678,
      "no_speech_prob": 0.022790398448705673
    },
    {
      "id": 76,
      "seek": 75700,
      "start": 763.0,
      "end": 767.0,
      "text": " They were figuring out with bots are doing it manually through Slack channels.",
      "tokens": [
        50664,
        814,
        645,
        15213,
        484,
        365,
        35410,
        366,
        884,
        309,
        16945,
        807,
        37211,
        9235,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1340431911604745,
      "compression_ratio": 1.7080536912751678,
      "no_speech_prob": 0.022790398448705673
    },
    {
      "id": 77,
      "seek": 75700,
      "start": 767.0,
      "end": 774.0,
      "text": " But interestingly enough, like users were looking for a way to integrate pending deploy and approvals with Slack.",
      "tokens": [
        50864,
        583,
        25873,
        1547,
        11,
        411,
        5022,
        645,
        1237,
        337,
        257,
        636,
        281,
        13365,
        32110,
        7274,
        293,
        2075,
        19778,
        365,
        37211,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1340431911604745,
      "compression_ratio": 1.7080536912751678,
      "no_speech_prob": 0.022790398448705673
    },
    {
      "id": 78,
      "seek": 75700,
      "start": 774.0,
      "end": 778.0,
      "text": " So they didn't have to depend on the GitLab UI.",
      "tokens": [
        51214,
        407,
        436,
        994,
        380,
        362,
        281,
        5672,
        322,
        264,
        16939,
        37880,
        15682,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1340431911604745,
      "compression_ratio": 1.7080536912751678,
      "no_speech_prob": 0.022790398448705673
    },
    {
      "id": 79,
      "seek": 75700,
      "start": 778.0,
      "end": 786.0,
      "text": " And we saw this when we reviewed harness as well harness was using Slack integrations for pending deployment approvals more so than their own notification system.",
      "tokens": [
        51414,
        400,
        321,
        1866,
        341,
        562,
        321,
        18429,
        19700,
        382,
        731,
        19700,
        390,
        1228,
        37211,
        3572,
        763,
        337,
        32110,
        19317,
        2075,
        19778,
        544,
        370,
        813,
        641,
        1065,
        11554,
        1185,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1340431911604745,
      "compression_ratio": 1.7080536912751678,
      "no_speech_prob": 0.022790398448705673
    },
    {
      "id": 80,
      "seek": 78600,
      "start": 786.0,
      "end": 799.0,
      "text": " So good takeaway of this is we were going to implement this within to do's and we think now a good MVC is just to allow users to kind of integrate these deployment pending deployment notifications within Slack and within their current workflow.",
      "tokens": [
        50364,
        407,
        665,
        30681,
        295,
        341,
        307,
        321,
        645,
        516,
        281,
        4445,
        341,
        1951,
        281,
        360,
        311,
        293,
        321,
        519,
        586,
        257,
        665,
        17663,
        34,
        307,
        445,
        281,
        2089,
        5022,
        281,
        733,
        295,
        13365,
        613,
        19317,
        32110,
        19317,
        13426,
        1951,
        37211,
        293,
        1951,
        641,
        2190,
        20993,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1027517607717803,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.0018395972438156605
    },
    {
      "id": 81,
      "seek": 78600,
      "start": 799.0,
      "end": 803.0,
      "text": " So that's kind of the way we're going to take this.",
      "tokens": [
        51014,
        407,
        300,
        311,
        733,
        295,
        264,
        636,
        321,
        434,
        516,
        281,
        747,
        341,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1027517607717803,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.0018395972438156605
    },
    {
      "id": 82,
      "seek": 80300,
      "start": 803.0,
      "end": 811.0,
      "text": " They did like the idea of being notified they thought to do's made sense, but there was warnings about how our to do's are pretty busy already.",
      "tokens": [
        50364,
        814,
        630,
        411,
        264,
        1558,
        295,
        885,
        18013,
        436,
        1194,
        281,
        360,
        311,
        1027,
        2020,
        11,
        457,
        456,
        390,
        30009,
        466,
        577,
        527,
        281,
        360,
        311,
        366,
        1238,
        5856,
        1217,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09533737016760785,
      "compression_ratio": 1.7348484848484849,
      "no_speech_prob": 0.010289420373737812
    },
    {
      "id": 83,
      "seek": 80300,
      "start": 811.0,
      "end": 816.0,
      "text": " We have no way to prioritize to do's they kind of just land in the list.",
      "tokens": [
        50764,
        492,
        362,
        572,
        636,
        281,
        25164,
        281,
        360,
        311,
        436,
        733,
        295,
        445,
        2117,
        294,
        264,
        1329,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09533737016760785,
      "compression_ratio": 1.7348484848484849,
      "no_speech_prob": 0.010289420373737812
    },
    {
      "id": 84,
      "seek": 80300,
      "start": 816.0,
      "end": 825.0,
      "text": " So I think there's additional work we'd have to do to get them in the to do's, but they would also see that workflow as being something useful just there's more work in there.",
      "tokens": [
        51014,
        407,
        286,
        519,
        456,
        311,
        4497,
        589,
        321,
        1116,
        362,
        281,
        360,
        281,
        483,
        552,
        294,
        264,
        281,
        360,
        311,
        11,
        457,
        436,
        576,
        611,
        536,
        300,
        20993,
        382,
        885,
        746,
        4420,
        445,
        456,
        311,
        544,
        589,
        294,
        456,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09533737016760785,
      "compression_ratio": 1.7348484848484849,
      "no_speech_prob": 0.010289420373737812
    },
    {
      "id": 85,
      "seek": 80300,
      "start": 825.0,
      "end": 830.0,
      "text": " So our MVC we're now landing on is focusing more on integrations.",
      "tokens": [
        51464,
        407,
        527,
        17663,
        34,
        321,
        434,
        586,
        11202,
        322,
        307,
        8416,
        544,
        322,
        3572,
        763,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09533737016760785,
      "compression_ratio": 1.7348484848484849,
      "no_speech_prob": 0.010289420373737812
    },
    {
      "id": 86,
      "seek": 83000,
      "start": 830.0,
      "end": 847.0,
      "text": " And yeah, I linked the research issue and dubs till study if you want to read more, but yeah, a big thanks to will he helped and supported with like all stages of this. So a big thank you for all that support.",
      "tokens": [
        50364,
        400,
        1338,
        11,
        286,
        9408,
        264,
        2132,
        2734,
        293,
        274,
        5432,
        4288,
        2979,
        498,
        291,
        528,
        281,
        1401,
        544,
        11,
        457,
        1338,
        11,
        257,
        955,
        3231,
        281,
        486,
        415,
        4254,
        293,
        8104,
        365,
        411,
        439,
        10232,
        295,
        341,
        13,
        407,
        257,
        955,
        1309,
        291,
        337,
        439,
        300,
        1406,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1944655368202611,
      "compression_ratio": 1.4527027027027026,
      "no_speech_prob": 0.006374698132276535
    },
    {
      "id": 87,
      "seek": 83000,
      "start": 847.0,
      "end": 849.0,
      "text": " Cool.",
      "tokens": [
        51214,
        8561,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1944655368202611,
      "compression_ratio": 1.4527027027027026,
      "no_speech_prob": 0.006374698132276535
    },
    {
      "id": 88,
      "seek": 84900,
      "start": 849.0,
      "end": 859.0,
      "text": " And then the second one is one of the bigger design initiatives we've had is supporting multiple approval rules and the project level protected environment settings.",
      "tokens": [
        50364,
        400,
        550,
        264,
        1150,
        472,
        307,
        472,
        295,
        264,
        3801,
        1715,
        16194,
        321,
        600,
        632,
        307,
        7231,
        3866,
        13317,
        4474,
        293,
        264,
        1716,
        1496,
        10594,
        2823,
        6257,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16652683913707733,
      "compression_ratio": 1.3636363636363635,
      "no_speech_prob": 0.04395826905965805
    },
    {
      "id": 89,
      "seek": 85900,
      "start": 859.0,
      "end": 884.0,
      "text": " And then we've got a lot of different types of approval rules, which we're really excited about because this gives them a lot more configuration options within the UI, whereas before we only gave this through access with the API.",
      "tokens": [
        50364,
        400,
        550,
        321,
        600,
        658,
        257,
        688,
        295,
        819,
        3467,
        295,
        13317,
        4474,
        11,
        597,
        321,
        434,
        534,
        2919,
        466,
        570,
        341,
        2709,
        552,
        257,
        688,
        544,
        11694,
        3956,
        1951,
        264,
        15682,
        11,
        9735,
        949,
        321,
        787,
        2729,
        341,
        807,
        2105,
        365,
        264,
        9362,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49421750282754706,
      "compression_ratio": 1.4135802469135803,
      "no_speech_prob": 0.24965988099575043
    },
    {
      "id": 90,
      "seek": 88400,
      "start": 884.0,
      "end": 889.0,
      "text": " And then we're going to have to come out as well.",
      "tokens": [
        50364,
        400,
        550,
        321,
        434,
        516,
        281,
        362,
        281,
        808,
        484,
        382,
        731,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30198276473815183,
      "compression_ratio": 1.5952380952380953,
      "no_speech_prob": 0.07673686742782593
    },
    {
      "id": 91,
      "seek": 88400,
      "start": 889.0,
      "end": 905.0,
      "text": " And then my last thing is I did mention this on Slack, but I will also be having lower availability next week. I'll be using my visiting grant. So I might be just lower availability for sink calls might be late responding to messages if you need me.",
      "tokens": [
        50614,
        400,
        550,
        452,
        1036,
        551,
        307,
        286,
        630,
        2152,
        341,
        322,
        37211,
        11,
        457,
        286,
        486,
        611,
        312,
        1419,
        3126,
        17945,
        958,
        1243,
        13,
        286,
        603,
        312,
        1228,
        452,
        11700,
        6386,
        13,
        407,
        286,
        1062,
        312,
        445,
        3126,
        17945,
        337,
        9500,
        5498,
        1062,
        312,
        3469,
        16670,
        281,
        7897,
        498,
        291,
        643,
        385,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30198276473815183,
      "compression_ratio": 1.5952380952380953,
      "no_speech_prob": 0.07673686742782593
    },
    {
      "id": 92,
      "seek": 88400,
      "start": 905.0,
      "end": 910.0,
      "text": " So that's more of just an employee.",
      "tokens": [
        51414,
        407,
        300,
        311,
        544,
        295,
        445,
        364,
        10738,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30198276473815183,
      "compression_ratio": 1.5952380952380953,
      "no_speech_prob": 0.07673686742782593
    },
    {
      "id": 93,
      "seek": 91000,
      "start": 910.0,
      "end": 919.0,
      "text": " And no one has questions I can pass it off to Gina.",
      "tokens": [
        50364,
        400,
        572,
        472,
        575,
        1651,
        286,
        393,
        1320,
        309,
        766,
        281,
        34711,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20971740995134627,
      "compression_ratio": 1.396103896103896,
      "no_speech_prob": 0.007917472161352634
    },
    {
      "id": 94,
      "seek": 91000,
      "start": 919.0,
      "end": 921.0,
      "text": " All right.",
      "tokens": [
        50814,
        1057,
        558,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20971740995134627,
      "compression_ratio": 1.396103896103896,
      "no_speech_prob": 0.007917472161352634
    },
    {
      "id": 95,
      "seek": 91000,
      "start": 921.0,
      "end": 931.0,
      "text": " The first both actually both of these items are around pipelining sites. I have work going on for runner to but I felt like these were more interesting.",
      "tokens": [
        50914,
        440,
        700,
        1293,
        767,
        1293,
        295,
        613,
        4754,
        366,
        926,
        8489,
        338,
        1760,
        7533,
        13,
        286,
        362,
        589,
        516,
        322,
        337,
        24376,
        281,
        457,
        286,
        2762,
        411,
        613,
        645,
        544,
        1880,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20971740995134627,
      "compression_ratio": 1.396103896103896,
      "no_speech_prob": 0.007917472161352634
    },
    {
      "id": 96,
      "seek": 93100,
      "start": 931.0,
      "end": 937.0,
      "text": " So the first one here is about the new artifacts browser design.",
      "tokens": [
        50364,
        407,
        264,
        700,
        472,
        510,
        307,
        466,
        264,
        777,
        24617,
        11185,
        1715,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16185150146484376,
      "compression_ratio": 1.681592039800995,
      "no_speech_prob": 0.014231161214411259
    },
    {
      "id": 97,
      "seek": 93100,
      "start": 937.0,
      "end": 947.0,
      "text": " So also kind of goes along with what Vica was saying about having basically like allowing for less clicks to get to the thing that you need to get to.",
      "tokens": [
        50664,
        407,
        611,
        733,
        295,
        1709,
        2051,
        365,
        437,
        691,
        2262,
        390,
        1566,
        466,
        1419,
        1936,
        411,
        8293,
        337,
        1570,
        18521,
        281,
        483,
        281,
        264,
        551,
        300,
        291,
        643,
        281,
        483,
        281,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16185150146484376,
      "compression_ratio": 1.681592039800995,
      "no_speech_prob": 0.014231161214411259
    },
    {
      "id": 98,
      "seek": 93100,
      "start": 947.0,
      "end": 956.0,
      "text": " So the browser right now if you were to go into a job and browse artifacts from there, you have to click into each folder.",
      "tokens": [
        51164,
        407,
        264,
        11185,
        558,
        586,
        498,
        291,
        645,
        281,
        352,
        666,
        257,
        1691,
        293,
        31442,
        24617,
        490,
        456,
        11,
        291,
        362,
        281,
        2052,
        666,
        1184,
        10820,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16185150146484376,
      "compression_ratio": 1.681592039800995,
      "no_speech_prob": 0.014231161214411259
    },
    {
      "id": 99,
      "seek": 95600,
      "start": 956.0,
      "end": 962.0,
      "text": " So it's so there can be so many nested folders to be able to get to that final file.",
      "tokens": [
        50364,
        407,
        309,
        311,
        370,
        456,
        393,
        312,
        370,
        867,
        15646,
        292,
        31082,
        281,
        312,
        1075,
        281,
        483,
        281,
        300,
        2572,
        3991,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.127276806349165,
      "compression_ratio": 1.6150234741784038,
      "no_speech_prob": 0.014756967313587666
    },
    {
      "id": 100,
      "seek": 95600,
      "start": 962.0,
      "end": 968.0,
      "text": " So what I ended up doing if you look in the design there.",
      "tokens": [
        50664,
        407,
        437,
        286,
        4590,
        493,
        884,
        498,
        291,
        574,
        294,
        264,
        1715,
        456,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.127276806349165,
      "compression_ratio": 1.6150234741784038,
      "no_speech_prob": 0.014756967313587666
    },
    {
      "id": 101,
      "seek": 95600,
      "start": 968.0,
      "end": 982.0,
      "text": " I kind of consolidated all of those folders if they're empty into a single file path. And then I just indented the file with it like underneath there. So it's clear that it's still part of that folder.",
      "tokens": [
        50964,
        286,
        733,
        295,
        49008,
        439,
        295,
        729,
        31082,
        498,
        436,
        434,
        6707,
        666,
        257,
        2167,
        3991,
        3100,
        13,
        400,
        550,
        286,
        445,
        1016,
        6003,
        264,
        3991,
        365,
        309,
        411,
        7223,
        456,
        13,
        407,
        309,
        311,
        1850,
        300,
        309,
        311,
        920,
        644,
        295,
        300,
        10820,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.127276806349165,
      "compression_ratio": 1.6150234741784038,
      "no_speech_prob": 0.014756967313587666
    },
    {
      "id": 102,
      "seek": 98200,
      "start": 982.0,
      "end": 995.0,
      "text": " So I have any feedback on that design. I also linked video of me going through the proposal in the New York school working channel. If that helps as well.",
      "tokens": [
        50364,
        407,
        286,
        362,
        604,
        5824,
        322,
        300,
        1715,
        13,
        286,
        611,
        9408,
        960,
        295,
        385,
        516,
        807,
        264,
        11494,
        294,
        264,
        1873,
        3609,
        1395,
        1364,
        2269,
        13,
        759,
        300,
        3665,
        382,
        731,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1984984427690506,
      "compression_ratio": 1.457142857142857,
      "no_speech_prob": 0.018345318734645844
    },
    {
      "id": 103,
      "seek": 98200,
      "start": 995.0,
      "end": 999.0,
      "text": " And the other thing I had here was we are.",
      "tokens": [
        51014,
        400,
        264,
        661,
        551,
        286,
        632,
        510,
        390,
        321,
        366,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1984984427690506,
      "compression_ratio": 1.457142857142857,
      "no_speech_prob": 0.018345318734645844
    },
    {
      "id": 104,
      "seek": 98200,
      "start": 999.0,
      "end": 1004.0,
      "text": " We did a bunch of research to understand for review apps.",
      "tokens": [
        51214,
        492,
        630,
        257,
        3840,
        295,
        2132,
        281,
        1223,
        337,
        3131,
        7733,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1984984427690506,
      "compression_ratio": 1.457142857142857,
      "no_speech_prob": 0.018345318734645844
    },
    {
      "id": 105,
      "seek": 100400,
      "start": 1004.0,
      "end": 1014.0,
      "text": " And we heard that the view app button wasn't prominent enough. People couldn't find it. So I wanted to understand really why and what was going on.",
      "tokens": [
        50364,
        400,
        321,
        2198,
        300,
        264,
        1910,
        724,
        2960,
        2067,
        380,
        17034,
        1547,
        13,
        3432,
        2809,
        380,
        915,
        309,
        13,
        407,
        286,
        1415,
        281,
        1223,
        534,
        983,
        293,
        437,
        390,
        516,
        322,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11164900613209558,
      "compression_ratio": 1.469945355191257,
      "no_speech_prob": 0.020545637235045433
    },
    {
      "id": 106,
      "seek": 100400,
      "start": 1014.0,
      "end": 1022.0,
      "text": " And we found out that it's really just not integrated into the review workflow as much as people were expecting it to be.",
      "tokens": [
        50864,
        400,
        321,
        1352,
        484,
        300,
        309,
        311,
        534,
        445,
        406,
        10919,
        666,
        264,
        3131,
        20993,
        382,
        709,
        382,
        561,
        645,
        9650,
        309,
        281,
        312,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11164900613209558,
      "compression_ratio": 1.469945355191257,
      "no_speech_prob": 0.020545637235045433
    },
    {
      "id": 107,
      "seek": 102200,
      "start": 1022.0,
      "end": 1037.0,
      "text": " What we're planning on doing is adding the view app button into that code dropdown when you go to a MR. And this also allows it to kind of be like stuck to that global header because that heading is sticky when you scroll down the page.",
      "tokens": [
        50364,
        708,
        321,
        434,
        5038,
        322,
        884,
        307,
        5127,
        264,
        1910,
        724,
        2960,
        666,
        300,
        3089,
        47599,
        562,
        291,
        352,
        281,
        257,
        9808,
        13,
        400,
        341,
        611,
        4045,
        309,
        281,
        733,
        295,
        312,
        411,
        5541,
        281,
        300,
        4338,
        23117,
        570,
        300,
        9864,
        307,
        14470,
        562,
        291,
        11369,
        760,
        264,
        3028,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15611891185536103,
      "compression_ratio": 1.5729166666666667,
      "no_speech_prob": 0.01826193556189537
    },
    {
      "id": 108,
      "seek": 102200,
      "start": 1037.0,
      "end": 1043.0,
      "text": " And it also is closely integrated into the review workflow there.",
      "tokens": [
        51114,
        400,
        309,
        611,
        307,
        8185,
        10919,
        666,
        264,
        3131,
        20993,
        456,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15611891185536103,
      "compression_ratio": 1.5729166666666667,
      "no_speech_prob": 0.01826193556189537
    },
    {
      "id": 109,
      "seek": 104300,
      "start": 1043.0,
      "end": 1059.0,
      "text": " And some specific things were like only certain projects have review apps enabled. So we won't be showing that many item all the time unless the review app is enabled for that project.",
      "tokens": [
        50364,
        400,
        512,
        2685,
        721,
        645,
        411,
        787,
        1629,
        4455,
        362,
        3131,
        7733,
        15172,
        13,
        407,
        321,
        1582,
        380,
        312,
        4099,
        300,
        867,
        3174,
        439,
        264,
        565,
        5969,
        264,
        3131,
        724,
        307,
        15172,
        337,
        300,
        1716,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21085238456726074,
      "compression_ratio": 1.4153846153846155,
      "no_speech_prob": 0.01316566951572895
    },
    {
      "id": 110,
      "seek": 105900,
      "start": 1059.0,
      "end": 1073.0,
      "text": " I want to say I love this change because I don't know how many times I send trying to scroll down the page looking for that like view app button. So having it just in one place would be so nice.",
      "tokens": [
        50364,
        286,
        528,
        281,
        584,
        286,
        959,
        341,
        1319,
        570,
        286,
        500,
        380,
        458,
        577,
        867,
        1413,
        286,
        2845,
        1382,
        281,
        11369,
        760,
        264,
        3028,
        1237,
        337,
        300,
        411,
        1910,
        724,
        2960,
        13,
        407,
        1419,
        309,
        445,
        294,
        472,
        1081,
        576,
        312,
        370,
        1481,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10806210835774739,
      "compression_ratio": 1.3566433566433567,
      "no_speech_prob": 0.04847743734717369
    },
    {
      "id": 111,
      "seek": 107300,
      "start": 1073.0,
      "end": 1084.0,
      "text": " Thanks. Yeah, we're definitely I think it will definitely be better because like we were saying like people were having trouble finding it and said that it doesn't always show up in that widget.",
      "tokens": [
        50364,
        2561,
        13,
        865,
        11,
        321,
        434,
        2138,
        286,
        519,
        309,
        486,
        2138,
        312,
        1101,
        570,
        411,
        321,
        645,
        1566,
        411,
        561,
        645,
        1419,
        5253,
        5006,
        309,
        293,
        848,
        300,
        309,
        1177,
        380,
        1009,
        855,
        493,
        294,
        300,
        34047,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12163039257651881,
      "compression_ratio": 1.49375,
      "no_speech_prob": 0.07891800999641418
    },
    {
      "id": 112,
      "seek": 107300,
      "start": 1084.0,
      "end": 1091.0,
      "text": " At the same time, so I think this will help.",
      "tokens": [
        50914,
        1711,
        264,
        912,
        565,
        11,
        370,
        286,
        519,
        341,
        486,
        854,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12163039257651881,
      "compression_ratio": 1.49375,
      "no_speech_prob": 0.07891800999641418
    },
    {
      "id": 113,
      "seek": 109100,
      "start": 1091.0,
      "end": 1101.0,
      "text": " And then my last thing here is I'll be I think I might have done that with zeros. Why did they look like that I did all be out of office next week at coupon.",
      "tokens": [
        50364,
        400,
        550,
        452,
        1036,
        551,
        510,
        307,
        286,
        603,
        312,
        286,
        519,
        286,
        1062,
        362,
        1096,
        300,
        365,
        35193,
        13,
        1545,
        630,
        436,
        574,
        411,
        300,
        286,
        630,
        439,
        312,
        484,
        295,
        3398,
        958,
        1243,
        412,
        33390,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1596319571785305,
      "compression_ratio": 1.5509259259259258,
      "no_speech_prob": 0.022156579419970512
    },
    {
      "id": 114,
      "seek": 109100,
      "start": 1101.0,
      "end": 1109.0,
      "text": " But I'll probably be on I'll have my computer. So like if there's anything that you need just feel free to reach out.",
      "tokens": [
        50864,
        583,
        286,
        603,
        1391,
        312,
        322,
        286,
        603,
        362,
        452,
        3820,
        13,
        407,
        411,
        498,
        456,
        311,
        1340,
        300,
        291,
        643,
        445,
        841,
        1737,
        281,
        2524,
        484,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1596319571785305,
      "compression_ratio": 1.5509259259259258,
      "no_speech_prob": 0.022156579419970512
    },
    {
      "id": 115,
      "seek": 109100,
      "start": 1109.0,
      "end": 1114.0,
      "text": " So 50% of the population here is going to be a coupon.",
      "tokens": [
        51264,
        407,
        2625,
        4,
        295,
        264,
        4415,
        510,
        307,
        516,
        281,
        312,
        257,
        33390,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1596319571785305,
      "compression_ratio": 1.5509259259259258,
      "no_speech_prob": 0.022156579419970512
    },
    {
      "id": 116,
      "seek": 109100,
      "start": 1114.0,
      "end": 1117.0,
      "text": " Yes.",
      "tokens": [
        51514,
        1079,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1596319571785305,
      "compression_ratio": 1.5509259259259258,
      "no_speech_prob": 0.022156579419970512
    },
    {
      "id": 117,
      "seek": 111700,
      "start": 1117.0,
      "end": 1122.0,
      "text": " Yes.",
      "tokens": [
        50364,
        1079,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3881284622918992,
      "compression_ratio": 1.0594059405940595,
      "no_speech_prob": 0.013831157237291336
    },
    {
      "id": 118,
      "seek": 111700,
      "start": 1122.0,
      "end": 1132.0,
      "text": " So since Erica is back, maybe she wants to go through her items.",
      "tokens": [
        50614,
        407,
        1670,
        37429,
        307,
        646,
        11,
        1310,
        750,
        2738,
        281,
        352,
        807,
        720,
        4754,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3881284622918992,
      "compression_ratio": 1.0594059405940595,
      "no_speech_prob": 0.013831157237291336
    },
    {
      "id": 119,
      "seek": 111700,
      "start": 1132.0,
      "end": 1135.0,
      "text": " No, did I miss Kevin?",
      "tokens": [
        51114,
        883,
        11,
        630,
        286,
        1713,
        9954,
        30,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3881284622918992,
      "compression_ratio": 1.0594059405940595,
      "no_speech_prob": 0.013831157237291336
    },
    {
      "id": 120,
      "seek": 111700,
      "start": 1135.0,
      "end": 1137.0,
      "text": " Yeah.",
      "tokens": [
        51264,
        865,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3881284622918992,
      "compression_ratio": 1.0594059405940595,
      "no_speech_prob": 0.013831157237291336
    },
    {
      "id": 121,
      "seek": 111700,
      "start": 1137.0,
      "end": 1141.0,
      "text": " Oh, okay.",
      "tokens": [
        51364,
        876,
        11,
        1392,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3881284622918992,
      "compression_ratio": 1.0594059405940595,
      "no_speech_prob": 0.013831157237291336
    },
    {
      "id": 122,
      "seek": 114100,
      "start": 1141.0,
      "end": 1153.0,
      "text": " Okay. So yes, we're gearing up for coupon. And then just if my personal life, my child has been sick. And then yesterday we tested him for coven.",
      "tokens": [
        50364,
        1033,
        13,
        407,
        2086,
        11,
        321,
        434,
        1519,
        1921,
        493,
        337,
        33390,
        13,
        400,
        550,
        445,
        498,
        452,
        2973,
        993,
        11,
        452,
        1440,
        575,
        668,
        4998,
        13,
        400,
        550,
        5186,
        321,
        8246,
        796,
        337,
        598,
        553,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3198590860134218,
      "compression_ratio": 1.44,
      "no_speech_prob": 0.010964294895529747
    },
    {
      "id": 123,
      "seek": 114100,
      "start": 1153.0,
      "end": 1154.0,
      "text": " Oh, no.",
      "tokens": [
        50964,
        876,
        11,
        572,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3198590860134218,
      "compression_ratio": 1.44,
      "no_speech_prob": 0.010964294895529747
    },
    {
      "id": 124,
      "seek": 114100,
      "start": 1154.0,
      "end": 1157.0,
      "text": " We all have come in.",
      "tokens": [
        51014,
        492,
        439,
        362,
        808,
        294,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3198590860134218,
      "compression_ratio": 1.44,
      "no_speech_prob": 0.010964294895529747
    },
    {
      "id": 125,
      "seek": 114100,
      "start": 1157.0,
      "end": 1162.0,
      "text": " So I'm like, oh, no, the conference.",
      "tokens": [
        51164,
        407,
        286,
        478,
        411,
        11,
        1954,
        11,
        572,
        11,
        264,
        7586,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3198590860134218,
      "compression_ratio": 1.44,
      "no_speech_prob": 0.010964294895529747
    },
    {
      "id": 126,
      "seek": 114100,
      "start": 1162.0,
      "end": 1165.0,
      "text": " So I'm going to have to figure that out.",
      "tokens": [
        51414,
        407,
        286,
        478,
        516,
        281,
        362,
        281,
        2573,
        300,
        484,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3198590860134218,
      "compression_ratio": 1.44,
      "no_speech_prob": 0.010964294895529747
    },
    {
      "id": 127,
      "seek": 116500,
      "start": 1165.0,
      "end": 1173.0,
      "text": " So we'll engineer and I. So I just am like waking up because that's why I was a little late, but miraculously I woke up.",
      "tokens": [
        50364,
        407,
        321,
        603,
        11403,
        293,
        286,
        13,
        407,
        286,
        445,
        669,
        411,
        20447,
        493,
        570,
        300,
        311,
        983,
        286,
        390,
        257,
        707,
        3469,
        11,
        457,
        30686,
        25038,
        286,
        12852,
        493,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17911034023638853,
      "compression_ratio": 1.5486725663716814,
      "no_speech_prob": 0.04595118761062622
    },
    {
      "id": 128,
      "seek": 116500,
      "start": 1173.0,
      "end": 1175.0,
      "text": " Oh, there's a meeting.",
      "tokens": [
        50764,
        876,
        11,
        456,
        311,
        257,
        3440,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17911034023638853,
      "compression_ratio": 1.5486725663716814,
      "no_speech_prob": 0.04595118761062622
    },
    {
      "id": 129,
      "seek": 116500,
      "start": 1175.0,
      "end": 1182.0,
      "text": " So I'm always just glad to see you guys. And I'm glad that I showed up because those were great updates.",
      "tokens": [
        50864,
        407,
        286,
        478,
        1009,
        445,
        5404,
        281,
        536,
        291,
        1074,
        13,
        400,
        286,
        478,
        5404,
        300,
        286,
        4712,
        493,
        570,
        729,
        645,
        869,
        9205,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17911034023638853,
      "compression_ratio": 1.5486725663716814,
      "no_speech_prob": 0.04595118761062622
    },
    {
      "id": 130,
      "seek": 116500,
      "start": 1182.0,
      "end": 1194.0,
      "text": " So we now have to kind of figure out what to do about my potential absence, but maybe I'll be healed.",
      "tokens": [
        51214,
        407,
        321,
        586,
        362,
        281,
        733,
        295,
        2573,
        484,
        437,
        281,
        360,
        466,
        452,
        3995,
        17145,
        11,
        457,
        1310,
        286,
        603,
        312,
        20482,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17911034023638853,
      "compression_ratio": 1.5486725663716814,
      "no_speech_prob": 0.04595118761062622
    },
    {
      "id": 131,
      "seek": 119400,
      "start": 1194.0,
      "end": 1199.0,
      "text": " So what I can do is show share with you this deck.",
      "tokens": [
        50364,
        407,
        437,
        286,
        393,
        360,
        307,
        855,
        2073,
        365,
        291,
        341,
        9341,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184094746907552,
      "compression_ratio": 1.4506172839506173,
      "no_speech_prob": 0.003175269113853574
    },
    {
      "id": 132,
      "seek": 119400,
      "start": 1199.0,
      "end": 1201.0,
      "text": " If I can do it.",
      "tokens": [
        50614,
        759,
        286,
        393,
        360,
        309,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184094746907552,
      "compression_ratio": 1.4506172839506173,
      "no_speech_prob": 0.003175269113853574
    },
    {
      "id": 133,
      "seek": 119400,
      "start": 1201.0,
      "end": 1204.0,
      "text": " Well, let's see it.",
      "tokens": [
        50714,
        1042,
        11,
        718,
        311,
        536,
        309,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184094746907552,
      "compression_ratio": 1.4506172839506173,
      "no_speech_prob": 0.003175269113853574
    },
    {
      "id": 134,
      "seek": 119400,
      "start": 1204.0,
      "end": 1211.0,
      "text": " I can just give you the general updates. So we are going to be at coup con doing a lot of things.",
      "tokens": [
        50864,
        286,
        393,
        445,
        976,
        291,
        264,
        2674,
        9205,
        13,
        407,
        321,
        366,
        516,
        281,
        312,
        412,
        8682,
        416,
        884,
        257,
        688,
        295,
        721,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184094746907552,
      "compression_ratio": 1.4506172839506173,
      "no_speech_prob": 0.003175269113853574
    },
    {
      "id": 135,
      "seek": 119400,
      "start": 1211.0,
      "end": 1217.0,
      "text": " Will and I both have a survey that we're fielding.",
      "tokens": [
        51214,
        3099,
        293,
        286,
        1293,
        362,
        257,
        8984,
        300,
        321,
        434,
        2519,
        278,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17184094746907552,
      "compression_ratio": 1.4506172839506173,
      "no_speech_prob": 0.003175269113853574
    },
    {
      "id": 136,
      "seek": 121700,
      "start": 1217.0,
      "end": 1225.0,
      "text": " And we are going to be doing some interviews with buyer personas.",
      "tokens": [
        50364,
        400,
        321,
        366,
        516,
        281,
        312,
        884,
        512,
        12318,
        365,
        24645,
        12019,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11836098988850911,
      "compression_ratio": 1.617801047120419,
      "no_speech_prob": 0.0064567867666482925
    },
    {
      "id": 137,
      "seek": 121700,
      "start": 1225.0,
      "end": 1233.0,
      "text": " The PMs from ops, especially have kind of come up with some questions.",
      "tokens": [
        50764,
        440,
        12499,
        82,
        490,
        44663,
        11,
        2318,
        362,
        733,
        295,
        808,
        493,
        365,
        512,
        1651,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11836098988850911,
      "compression_ratio": 1.617801047120419,
      "no_speech_prob": 0.0064567867666482925
    },
    {
      "id": 138,
      "seek": 121700,
      "start": 1233.0,
      "end": 1236.0,
      "text": " And so people will kind of come up to the booth.",
      "tokens": [
        51164,
        400,
        370,
        561,
        486,
        733,
        295,
        808,
        493,
        281,
        264,
        20912,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11836098988850911,
      "compression_ratio": 1.617801047120419,
      "no_speech_prob": 0.0064567867666482925
    },
    {
      "id": 139,
      "seek": 121700,
      "start": 1236.0,
      "end": 1244.0,
      "text": " And if they're a buyer persona, they'll get put into this buyer persona interview round slash recruitment for focus groups.",
      "tokens": [
        51314,
        400,
        498,
        436,
        434,
        257,
        24645,
        12184,
        11,
        436,
        603,
        483,
        829,
        666,
        341,
        24645,
        12184,
        4049,
        3098,
        17330,
        28240,
        337,
        1879,
        3935,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11836098988850911,
      "compression_ratio": 1.617801047120419,
      "no_speech_prob": 0.0064567867666482925
    },
    {
      "id": 140,
      "seek": 124400,
      "start": 1244.0,
      "end": 1260.0,
      "text": " And if they are not a buyer, then they can either come to the area where we're going to have a station at the booths or there's actually two booths.",
      "tokens": [
        50364,
        400,
        498,
        436,
        366,
        406,
        257,
        24645,
        11,
        550,
        436,
        393,
        2139,
        808,
        281,
        264,
        1859,
        689,
        321,
        434,
        516,
        281,
        362,
        257,
        5214,
        412,
        264,
        20912,
        82,
        420,
        456,
        311,
        767,
        732,
        20912,
        82,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1243283572020354,
      "compression_ratio": 1.4026845637583893,
      "no_speech_prob": 0.0014001709641888738
    },
    {
      "id": 141,
      "seek": 124400,
      "start": 1260.0,
      "end": 1265.0,
      "text": " They might also just complete these interviews from the PMs.",
      "tokens": [
        51164,
        814,
        1062,
        611,
        445,
        3566,
        613,
        12318,
        490,
        264,
        12499,
        82,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1243283572020354,
      "compression_ratio": 1.4026845637583893,
      "no_speech_prob": 0.0014001709641888738
    },
    {
      "id": 142,
      "seek": 126500,
      "start": 1265.0,
      "end": 1270.0,
      "text": " And so it would be good to get your eyes on that stuff.",
      "tokens": [
        50364,
        400,
        370,
        309,
        576,
        312,
        665,
        281,
        483,
        428,
        2575,
        322,
        300,
        1507,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21028395493825278,
      "compression_ratio": 1.2975206611570247,
      "no_speech_prob": 0.00586283253505826
    },
    {
      "id": 143,
      "seek": 126500,
      "start": 1270.0,
      "end": 1284.0,
      "text": " So I'll link that issue. We have like seven questions that we're going to ask.",
      "tokens": [
        50614,
        407,
        286,
        603,
        2113,
        300,
        2734,
        13,
        492,
        362,
        411,
        3407,
        1651,
        300,
        321,
        434,
        516,
        281,
        1029,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21028395493825278,
      "compression_ratio": 1.2975206611570247,
      "no_speech_prob": 0.00586283253505826
    },
    {
      "id": 144,
      "seek": 126500,
      "start": 1284.0,
      "end": 1288.0,
      "text": " And then we've set up.",
      "tokens": [
        51314,
        400,
        550,
        321,
        600,
        992,
        493,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21028395493825278,
      "compression_ratio": 1.2975206611570247,
      "no_speech_prob": 0.00586283253505826
    },
    {
      "id": 145,
      "seek": 128800,
      "start": 1288.0,
      "end": 1298.0,
      "text": " And then we've set up a list of questions that we're going to ask.",
      "tokens": [
        50364,
        400,
        550,
        321,
        600,
        992,
        493,
        257,
        1329,
        295,
        1651,
        300,
        321,
        434,
        516,
        281,
        1029,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49869641086511446,
      "compression_ratio": 1.5683453237410072,
      "no_speech_prob": 0.0034696508664637804
    },
    {
      "id": 146,
      "seek": 128800,
      "start": 1298.0,
      "end": 1307.0,
      "text": " So that all those questions and the questions for the buyers and all the other questions are in Qualtrics.",
      "tokens": [
        50864,
        407,
        300,
        439,
        729,
        1651,
        293,
        264,
        1651,
        337,
        264,
        23465,
        293,
        439,
        264,
        661,
        1651,
        366,
        294,
        13616,
        6903,
        1167,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49869641086511446,
      "compression_ratio": 1.5683453237410072,
      "no_speech_prob": 0.0034696508664637804
    },
    {
      "id": 147,
      "seek": 128800,
      "start": 1307.0,
      "end": 1310.0,
      "text": " And then that'll be a note taking mechanism.",
      "tokens": [
        51314,
        400,
        550,
        300,
        603,
        312,
        257,
        3637,
        1940,
        7513,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49869641086511446,
      "compression_ratio": 1.5683453237410072,
      "no_speech_prob": 0.0034696508664637804
    },
    {
      "id": 148,
      "seek": 131000,
      "start": 1310.0,
      "end": 1317.0,
      "text": " And then we'll have a list of questions that we'll ask like approach where he kind of summarizes it in an issue, the findings.",
      "tokens": [
        50364,
        400,
        550,
        321,
        603,
        362,
        257,
        1329,
        295,
        1651,
        300,
        321,
        603,
        1029,
        411,
        3109,
        689,
        415,
        733,
        295,
        14611,
        5660,
        309,
        294,
        364,
        2734,
        11,
        264,
        16483,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35418306986490883,
      "compression_ratio": 1.4820512820512821,
      "no_speech_prob": 0.028357094153761864
    },
    {
      "id": 149,
      "seek": 131000,
      "start": 1317.0,
      "end": 1324.0,
      "text": " And then we're going to invite people to follow up with those participants.",
      "tokens": [
        50714,
        400,
        550,
        321,
        434,
        516,
        281,
        7980,
        561,
        281,
        1524,
        493,
        365,
        729,
        10503,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35418306986490883,
      "compression_ratio": 1.4820512820512821,
      "no_speech_prob": 0.028357094153761864
    },
    {
      "id": 150,
      "seek": 131000,
      "start": 1324.0,
      "end": 1333.0,
      "text": " So I'm sure it's all going to work out. And miraculously not have COVID in like a day.",
      "tokens": [
        51064,
        407,
        286,
        478,
        988,
        309,
        311,
        439,
        516,
        281,
        589,
        484,
        13,
        400,
        30686,
        25038,
        406,
        362,
        4566,
        294,
        411,
        257,
        786,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35418306986490883,
      "compression_ratio": 1.4820512820512821,
      "no_speech_prob": 0.028357094153761864
    },
    {
      "id": 151,
      "seek": 133300,
      "start": 1333.0,
      "end": 1341.0,
      "text": " So besides that, we're working on the prioritization stuff for Q4.",
      "tokens": [
        50364,
        407,
        11868,
        300,
        11,
        321,
        434,
        1364,
        322,
        264,
        14846,
        2144,
        1507,
        337,
        1249,
        19,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13520661338430937,
      "compression_ratio": 1.4294871794871795,
      "no_speech_prob": 0.0011288325767964125
    },
    {
      "id": 152,
      "seek": 133300,
      "start": 1341.0,
      "end": 1351.0,
      "text": " So if you haven't had a chance yet, it would be good to link the Q4 projects that you want.",
      "tokens": [
        50764,
        407,
        498,
        291,
        2378,
        380,
        632,
        257,
        2931,
        1939,
        11,
        309,
        576,
        312,
        665,
        281,
        2113,
        264,
        1249,
        19,
        4455,
        300,
        291,
        528,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13520661338430937,
      "compression_ratio": 1.4294871794871795,
      "no_speech_prob": 0.0011288325767964125
    },
    {
      "id": 153,
      "seek": 133300,
      "start": 1351.0,
      "end": 1354.0,
      "text": " And we're going to put that through the resource prioritization.",
      "tokens": [
        51264,
        400,
        321,
        434,
        516,
        281,
        829,
        300,
        807,
        264,
        7684,
        14846,
        2144,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13520661338430937,
      "compression_ratio": 1.4294871794871795,
      "no_speech_prob": 0.0011288325767964125
    },
    {
      "id": 154,
      "seek": 135400,
      "start": 1354.0,
      "end": 1359.0,
      "text": " But because also our PMs are going to be at coupon.",
      "tokens": [
        50364,
        583,
        570,
        611,
        527,
        12499,
        82,
        366,
        516,
        281,
        312,
        412,
        33390,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13564424929411514,
      "compression_ratio": 1.5027932960893855,
      "no_speech_prob": 0.002190337050706148
    },
    {
      "id": 155,
      "seek": 135400,
      "start": 1359.0,
      "end": 1366.0,
      "text": " We're going to wait to finalize that until everyone gets back on November 8th.",
      "tokens": [
        50614,
        492,
        434,
        516,
        281,
        1699,
        281,
        2572,
        1125,
        300,
        1826,
        1518,
        2170,
        646,
        322,
        7674,
        1649,
        392,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13564424929411514,
      "compression_ratio": 1.5027932960893855,
      "no_speech_prob": 0.002190337050706148
    },
    {
      "id": 156,
      "seek": 135400,
      "start": 1366.0,
      "end": 1377.0,
      "text": " And another thing that I'm probably going to ping you about is, I'm going to try to do the research prioritization research sense of this.",
      "tokens": [
        50964,
        400,
        1071,
        551,
        300,
        286,
        478,
        1391,
        516,
        281,
        26151,
        291,
        466,
        307,
        11,
        286,
        478,
        516,
        281,
        853,
        281,
        360,
        264,
        2132,
        14846,
        2144,
        2132,
        2020,
        295,
        341,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13564424929411514,
      "compression_ratio": 1.5027932960893855,
      "no_speech_prob": 0.002190337050706148
    },
    {
      "id": 157,
      "seek": 137700,
      "start": 1377.0,
      "end": 1382.0,
      "text": " I forget we have like a longer name for it, but basically we're all go back through.",
      "tokens": [
        50364,
        286,
        2870,
        321,
        362,
        411,
        257,
        2854,
        1315,
        337,
        309,
        11,
        457,
        1936,
        321,
        434,
        439,
        352,
        646,
        807,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16764889487737342,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.004676308017224073
    },
    {
      "id": 158,
      "seek": 137700,
      "start": 1382.0,
      "end": 1389.0,
      "text": " And according to our research questions like summarize all the research we've found for this quarter.",
      "tokens": [
        50614,
        400,
        4650,
        281,
        527,
        2132,
        1651,
        411,
        20858,
        439,
        264,
        2132,
        321,
        600,
        1352,
        337,
        341,
        6555,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16764889487737342,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.004676308017224073
    },
    {
      "id": 159,
      "seek": 137700,
      "start": 1389.0,
      "end": 1396.0,
      "text": " So that will be something I can link. So I'll just be asking you to include studies that you would like.",
      "tokens": [
        50964,
        407,
        300,
        486,
        312,
        746,
        286,
        393,
        2113,
        13,
        407,
        286,
        603,
        445,
        312,
        3365,
        291,
        281,
        4090,
        5313,
        300,
        291,
        576,
        411,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16764889487737342,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.004676308017224073
    },
    {
      "id": 160,
      "seek": 137700,
      "start": 1396.0,
      "end": 1399.0,
      "text": " Kind of included in that synthesis.",
      "tokens": [
        51314,
        9242,
        295,
        5556,
        294,
        300,
        30252,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16764889487737342,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.004676308017224073
    },
    {
      "id": 161,
      "seek": 139900,
      "start": 1399.0,
      "end": 1413.0,
      "text": " And the idea is our great Jackie will return. And we want to like have that as a way of helping her come back is to kind of summarize the research so far.",
      "tokens": [
        50364,
        400,
        264,
        1558,
        307,
        527,
        869,
        23402,
        486,
        2736,
        13,
        400,
        321,
        528,
        281,
        411,
        362,
        300,
        382,
        257,
        636,
        295,
        4315,
        720,
        808,
        646,
        307,
        281,
        733,
        295,
        20858,
        264,
        2132,
        370,
        1400,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2959333672580949,
      "compression_ratio": 1.5125628140703518,
      "no_speech_prob": 0.0022237328812479973
    },
    {
      "id": 162,
      "seek": 139900,
      "start": 1413.0,
      "end": 1417.0,
      "text": " And if I don't go to Cucon, I'm going to be really bored.",
      "tokens": [
        51064,
        400,
        498,
        286,
        500,
        380,
        352,
        281,
        383,
        1311,
        266,
        11,
        286,
        478,
        516,
        281,
        312,
        534,
        13521,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2959333672580949,
      "compression_ratio": 1.5125628140703518,
      "no_speech_prob": 0.0022237328812479973
    },
    {
      "id": 163,
      "seek": 139900,
      "start": 1417.0,
      "end": 1425.0,
      "text": " I don't know how I can help help me be asking you like please send me things to include.",
      "tokens": [
        51264,
        286,
        500,
        380,
        458,
        577,
        286,
        393,
        854,
        854,
        385,
        312,
        3365,
        291,
        411,
        1767,
        2845,
        385,
        721,
        281,
        4090,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2959333672580949,
      "compression_ratio": 1.5125628140703518,
      "no_speech_prob": 0.0022237328812479973
    },
    {
      "id": 164,
      "seek": 142500,
      "start": 1425.0,
      "end": 1431.0,
      "text": " And I think another thing to put out there is I posted this on Slack.",
      "tokens": [
        50364,
        400,
        286,
        519,
        1071,
        551,
        281,
        829,
        484,
        456,
        307,
        286,
        9437,
        341,
        322,
        37211,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17624718802315847,
      "compression_ratio": 1.451219512195122,
      "no_speech_prob": 0.0008237295551225543
    },
    {
      "id": 165,
      "seek": 142500,
      "start": 1431.0,
      "end": 1436.0,
      "text": " But to help us like digest the secrets findings.",
      "tokens": [
        50664,
        583,
        281,
        854,
        505,
        411,
        13884,
        264,
        14093,
        16483,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17624718802315847,
      "compression_ratio": 1.451219512195122,
      "no_speech_prob": 0.0008237295551225543
    },
    {
      "id": 166,
      "seek": 142500,
      "start": 1436.0,
      "end": 1441.0,
      "text": " As a team, we've set up three meetings.",
      "tokens": [
        50914,
        1018,
        257,
        1469,
        11,
        321,
        600,
        992,
        493,
        1045,
        8410,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17624718802315847,
      "compression_ratio": 1.451219512195122,
      "no_speech_prob": 0.0008237295551225543
    },
    {
      "id": 167,
      "seek": 142500,
      "start": 1441.0,
      "end": 1448.0,
      "text": " The first is totally just optional and informal and will be me reading out the.",
      "tokens": [
        51164,
        440,
        700,
        307,
        3879,
        445,
        17312,
        293,
        24342,
        293,
        486,
        312,
        385,
        3760,
        484,
        264,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17624718802315847,
      "compression_ratio": 1.451219512195122,
      "no_speech_prob": 0.0008237295551225543
    },
    {
      "id": 168,
      "seek": 144800,
      "start": 1448.0,
      "end": 1459.0,
      "text": " The secret features prioritization survey responses with some pms like cross functionally pms so they'll be like in that report we can do like a Q and a.",
      "tokens": [
        50364,
        440,
        4054,
        4122,
        14846,
        2144,
        8984,
        13019,
        365,
        512,
        280,
        2592,
        411,
        3278,
        2445,
        379,
        280,
        2592,
        370,
        436,
        603,
        312,
        411,
        294,
        300,
        2275,
        321,
        393,
        360,
        411,
        257,
        1249,
        293,
        257,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2131626703967787,
      "compression_ratio": 1.4505494505494505,
      "no_speech_prob": 0.002201412571594119
    },
    {
      "id": 169,
      "seek": 144800,
      "start": 1459.0,
      "end": 1466.0,
      "text": " And then the second week of November, we have a think big set up.",
      "tokens": [
        50914,
        400,
        550,
        264,
        1150,
        1243,
        295,
        7674,
        11,
        321,
        362,
        257,
        519,
        955,
        992,
        493,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2131626703967787,
      "compression_ratio": 1.4505494505494505,
      "no_speech_prob": 0.002201412571594119
    },
    {
      "id": 170,
      "seek": 144800,
      "start": 1466.0,
      "end": 1469.0,
      "text": " And so y'all should attend that.",
      "tokens": [
        51264,
        400,
        370,
        288,
        6,
        336,
        820,
        6888,
        300,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2131626703967787,
      "compression_ratio": 1.4505494505494505,
      "no_speech_prob": 0.002201412571594119
    },
    {
      "id": 171,
      "seek": 144800,
      "start": 1469.0,
      "end": 1471.0,
      "text": " And I will.",
      "tokens": [
        51414,
        400,
        286,
        486,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2131626703967787,
      "compression_ratio": 1.4505494505494505,
      "no_speech_prob": 0.002201412571594119
    },
    {
      "id": 172,
      "seek": 147100,
      "start": 1471.0,
      "end": 1485.0,
      "text": " Maybe easier for me just to post the slack meetings, but there's two session the slack. Oh my gosh, the slack comment where I linked all of these things, which is in this yet to be channel.",
      "tokens": [
        50364,
        2704,
        3571,
        337,
        385,
        445,
        281,
        2183,
        264,
        29767,
        8410,
        11,
        457,
        456,
        311,
        732,
        5481,
        264,
        29767,
        13,
        876,
        452,
        6502,
        11,
        264,
        29767,
        2871,
        689,
        286,
        9408,
        439,
        295,
        613,
        721,
        11,
        597,
        307,
        294,
        341,
        1939,
        281,
        312,
        2269,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2811427776630108,
      "compression_ratio": 1.5142857142857142,
      "no_speech_prob": 0.017945177853107452
    },
    {
      "id": 173,
      "seek": 147100,
      "start": 1485.0,
      "end": 1494.0,
      "text": " But there's two time zones, so that should hopefully work out for everyone.",
      "tokens": [
        51064,
        583,
        456,
        311,
        732,
        565,
        16025,
        11,
        370,
        300,
        820,
        4696,
        589,
        484,
        337,
        1518,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2811427776630108,
      "compression_ratio": 1.5142857142857142,
      "no_speech_prob": 0.017945177853107452
    },
    {
      "id": 174,
      "seek": 149400,
      "start": 1494.0,
      "end": 1504.0,
      "text": " Hopefully you guys can attend that and hopefully we're getting this on your radars really enough so that you can plan around that.",
      "tokens": [
        50364,
        10429,
        291,
        1074,
        393,
        6888,
        300,
        293,
        4696,
        321,
        434,
        1242,
        341,
        322,
        428,
        2843,
        685,
        534,
        1547,
        370,
        300,
        291,
        393,
        1393,
        926,
        300,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2139711026792173,
      "compression_ratio": 1.4444444444444444,
      "no_speech_prob": 0.07533689588308334
    },
    {
      "id": 175,
      "seek": 149400,
      "start": 1504.0,
      "end": 1508.0,
      "text": " Okay, there's the slack ones.",
      "tokens": [
        50864,
        1033,
        11,
        456,
        311,
        264,
        29767,
        2306,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2139711026792173,
      "compression_ratio": 1.4444444444444444,
      "no_speech_prob": 0.07533689588308334
    },
    {
      "id": 176,
      "seek": 149400,
      "start": 1508.0,
      "end": 1514.0,
      "text": " Sorry that I'm a little discombined really did.",
      "tokens": [
        51064,
        4919,
        300,
        286,
        478,
        257,
        707,
        717,
        38763,
        2001,
        534,
        630,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2139711026792173,
      "compression_ratio": 1.4444444444444444,
      "no_speech_prob": 0.07533689588308334
    },
    {
      "id": 177,
      "seek": 151400,
      "start": 1514.0,
      "end": 1522.0,
      "text": " I'm going to have a long if there's anything that we can do to help for Qcon at the very least, let us know.",
      "tokens": [
        50364,
        286,
        478,
        516,
        281,
        362,
        257,
        938,
        498,
        456,
        311,
        1340,
        300,
        321,
        393,
        360,
        281,
        854,
        337,
        1249,
        1671,
        412,
        264,
        588,
        1935,
        11,
        718,
        505,
        458,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2973118443642893,
      "compression_ratio": 1.5305164319248827,
      "no_speech_prob": 0.30837756395339966
    },
    {
      "id": 178,
      "seek": 151400,
      "start": 1522.0,
      "end": 1525.0,
      "text": " And take time to rest.",
      "tokens": [
        50764,
        400,
        747,
        565,
        281,
        1472,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2973118443642893,
      "compression_ratio": 1.5305164319248827,
      "no_speech_prob": 0.30837756395339966
    },
    {
      "id": 179,
      "seek": 151400,
      "start": 1525.0,
      "end": 1530.0,
      "text": " Sorry about the COVID situation. That's tough. That really bad timing.",
      "tokens": [
        50914,
        4919,
        466,
        264,
        4566,
        2590,
        13,
        663,
        311,
        4930,
        13,
        663,
        534,
        1578,
        10822,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2973118443642893,
      "compression_ratio": 1.5305164319248827,
      "no_speech_prob": 0.30837756395339966
    },
    {
      "id": 180,
      "seek": 151400,
      "start": 1530.0,
      "end": 1539.0,
      "text": " Oh my god, I know I was like, well, I'm going to have I'm looking to have a whole plan for like quarantine when I got back.",
      "tokens": [
        51164,
        876,
        452,
        3044,
        11,
        286,
        458,
        286,
        390,
        411,
        11,
        731,
        11,
        286,
        478,
        516,
        281,
        362,
        286,
        478,
        1237,
        281,
        362,
        257,
        1379,
        1393,
        337,
        411,
        18138,
        562,
        286,
        658,
        646,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2973118443642893,
      "compression_ratio": 1.5305164319248827,
      "no_speech_prob": 0.30837756395339966
    },
    {
      "id": 181,
      "seek": 153900,
      "start": 1539.0,
      "end": 1548.0,
      "text": " I think even if you make it all three of us should be really cautious during the event.",
      "tokens": [
        50364,
        286,
        519,
        754,
        498,
        291,
        652,
        309,
        439,
        1045,
        295,
        505,
        820,
        312,
        534,
        25278,
        1830,
        264,
        2280,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24867209959565922,
      "compression_ratio": 1.5594059405940595,
      "no_speech_prob": 0.07043851166963577
    },
    {
      "id": 182,
      "seek": 153900,
      "start": 1548.0,
      "end": 1554.0,
      "text": " Yeah, at the at the last one, a lot of people kind of had it.",
      "tokens": [
        50814,
        865,
        11,
        412,
        264,
        412,
        264,
        1036,
        472,
        11,
        257,
        688,
        295,
        561,
        733,
        295,
        632,
        309,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24867209959565922,
      "compression_ratio": 1.5594059405940595,
      "no_speech_prob": 0.07043851166963577
    },
    {
      "id": 183,
      "seek": 153900,
      "start": 1554.0,
      "end": 1567.0,
      "text": " I was like really like OCD about it and I did you know this story. I was I didn't get it. I coupon in traveling to Spain. And then I came home and my partner had it.",
      "tokens": [
        51114,
        286,
        390,
        411,
        534,
        411,
        422,
        16508,
        466,
        309,
        293,
        286,
        630,
        291,
        458,
        341,
        1657,
        13,
        286,
        390,
        286,
        994,
        380,
        483,
        309,
        13,
        286,
        8682,
        266,
        294,
        9712,
        281,
        12838,
        13,
        400,
        550,
        286,
        1361,
        1280,
        293,
        452,
        4975,
        632,
        309,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24867209959565922,
      "compression_ratio": 1.5594059405940595,
      "no_speech_prob": 0.07043851166963577
    },
    {
      "id": 184,
      "seek": 156700,
      "start": 1567.0,
      "end": 1571.0,
      "text": " Yeah, I remember that.",
      "tokens": [
        50364,
        865,
        11,
        286,
        1604,
        300,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556281870061701,
      "compression_ratio": 1.3164556962025316,
      "no_speech_prob": 0.009749045595526695
    },
    {
      "id": 185,
      "seek": 156700,
      "start": 1571.0,
      "end": 1578.0,
      "text": " So it's just you know, whatever we can do.",
      "tokens": [
        50564,
        407,
        309,
        311,
        445,
        291,
        458,
        11,
        2035,
        321,
        393,
        360,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556281870061701,
      "compression_ratio": 1.3164556962025316,
      "no_speech_prob": 0.009749045595526695
    },
    {
      "id": 186,
      "seek": 156700,
      "start": 1578.0,
      "end": 1588.0,
      "text": " But yes, so Gina, we're going to need to kind of decide today, like a backup plan for the, yeah, the interiors, the secrets stuff.",
      "tokens": [
        50914,
        583,
        2086,
        11,
        370,
        34711,
        11,
        321,
        434,
        516,
        281,
        643,
        281,
        733,
        295,
        4536,
        965,
        11,
        411,
        257,
        14807,
        1393,
        337,
        264,
        11,
        1338,
        11,
        264,
        728,
        9337,
        11,
        264,
        14093,
        1507,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556281870061701,
      "compression_ratio": 1.3164556962025316,
      "no_speech_prob": 0.009749045595526695
    },
    {
      "id": 187,
      "seek": 156700,
      "start": 1588.0,
      "end": 1590.0,
      "text": " Yeah. Okay.",
      "tokens": [
        51414,
        865,
        13,
        1033,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3556281870061701,
      "compression_ratio": 1.3164556962025316,
      "no_speech_prob": 0.009749045595526695
    },
    {
      "id": 188,
      "seek": 159000,
      "start": 1590.0,
      "end": 1596.0,
      "text": " I probably need to meet and we just because I can scope down that whole project.",
      "tokens": [
        50364,
        286,
        1391,
        643,
        281,
        1677,
        293,
        321,
        445,
        570,
        286,
        393,
        11923,
        760,
        300,
        1379,
        1716,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19271464574904668,
      "compression_ratio": 1.6183574879227054,
      "no_speech_prob": 0.015519709326326847
    },
    {
      "id": 189,
      "seek": 159000,
      "start": 1596.0,
      "end": 1597.0,
      "text": " Okay.",
      "tokens": [
        50664,
        1033,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19271464574904668,
      "compression_ratio": 1.6183574879227054,
      "no_speech_prob": 0.015519709326326847
    },
    {
      "id": 190,
      "seek": 159000,
      "start": 1597.0,
      "end": 1616.0,
      "text": " If we want. And so it just depends on what you want to do. I had even talked to James about when we met to talk about the think big James and I had kind of talk about scoping that down anyway and just making the question, could we do this research.",
      "tokens": [
        50714,
        759,
        321,
        528,
        13,
        400,
        370,
        309,
        445,
        5946,
        322,
        437,
        291,
        528,
        281,
        360,
        13,
        286,
        632,
        754,
        2825,
        281,
        5678,
        466,
        562,
        321,
        1131,
        281,
        751,
        466,
        264,
        519,
        955,
        5678,
        293,
        286,
        632,
        733,
        295,
        751,
        466,
        795,
        26125,
        300,
        760,
        4033,
        293,
        445,
        1455,
        264,
        1168,
        11,
        727,
        321,
        360,
        341,
        2132,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19271464574904668,
      "compression_ratio": 1.6183574879227054,
      "no_speech_prob": 0.015519709326326847
    },
    {
      "id": 191,
      "seek": 161600,
      "start": 1616.0,
      "end": 1619.0,
      "text": " So it kind of scales it back.",
      "tokens": [
        50364,
        407,
        309,
        733,
        295,
        17408,
        309,
        646,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2558680640326606,
      "compression_ratio": 1.3877551020408163,
      "no_speech_prob": 0.0054826997220516205
    },
    {
      "id": 192,
      "seek": 161600,
      "start": 1619.0,
      "end": 1624.0,
      "text": " But yeah, hopefully we can find some time to meet today to go for that.",
      "tokens": [
        50514,
        583,
        1338,
        11,
        4696,
        321,
        393,
        915,
        512,
        565,
        281,
        1677,
        965,
        281,
        352,
        337,
        300,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2558680640326606,
      "compression_ratio": 1.3877551020408163,
      "no_speech_prob": 0.0054826997220516205
    },
    {
      "id": 193,
      "seek": 161600,
      "start": 1624.0,
      "end": 1626.0,
      "text": " Yeah, definitely.",
      "tokens": [
        50764,
        865,
        11,
        2138,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2558680640326606,
      "compression_ratio": 1.3877551020408163,
      "no_speech_prob": 0.0054826997220516205
    },
    {
      "id": 194,
      "seek": 161600,
      "start": 1626.0,
      "end": 1628.0,
      "text": " I'm around like all afternoon.",
      "tokens": [
        50864,
        286,
        478,
        926,
        411,
        439,
        6499,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2558680640326606,
      "compression_ratio": 1.3877551020408163,
      "no_speech_prob": 0.0054826997220516205
    },
    {
      "id": 195,
      "seek": 161600,
      "start": 1628.0,
      "end": 1637.0,
      "text": " My okay, it's fully fully available. So it's do that.",
      "tokens": [
        50964,
        1222,
        1392,
        11,
        309,
        311,
        4498,
        4498,
        2435,
        13,
        407,
        309,
        311,
        360,
        300,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2558680640326606,
      "compression_ratio": 1.3877551020408163,
      "no_speech_prob": 0.0054826997220516205
    },
    {
      "id": 196,
      "seek": 163700,
      "start": 1637.0,
      "end": 1649.0,
      "text": " Right. Well, I think that that was all of our items. Anybody else have anything that you wanted to talk about.",
      "tokens": [
        50364,
        1779,
        13,
        1042,
        11,
        286,
        519,
        300,
        300,
        390,
        439,
        295,
        527,
        4754,
        13,
        19082,
        1646,
        362,
        1340,
        300,
        291,
        1415,
        281,
        751,
        466,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20928039885403818,
      "compression_ratio": 1.4444444444444444,
      "no_speech_prob": 0.019368067383766174
    },
    {
      "id": 197,
      "seek": 163700,
      "start": 1649.0,
      "end": 1657.0,
      "text": " No. All right. All right. We'll have a good rest of your week and talk again soon.",
      "tokens": [
        50964,
        883,
        13,
        1057,
        558,
        13,
        1057,
        558,
        13,
        492,
        603,
        362,
        257,
        665,
        1472,
        295,
        428,
        1243,
        293,
        751,
        797,
        2321,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20928039885403818,
      "compression_ratio": 1.4444444444444444,
      "no_speech_prob": 0.019368067383766174
    },
    {
      "id": 198,
      "seek": 163700,
      "start": 1657.0,
      "end": 1659.0,
      "text": " Bye everybody.",
      "tokens": [
        51364,
        4621,
        2201,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20928039885403818,
      "compression_ratio": 1.4444444444444444,
      "no_speech_prob": 0.019368067383766174
    }
  ]
}