{
  "title": "ci/cd ux meeting APAC 2022-06-15",
  "video_id": "exTwAR4PeFY",
  "url": "https://www.youtube.com/watch?v=exTwAR4PeFY",
  "transcript": " Hi everyone and welcome to the CICD UX Sync for June 14th or 15th depending on where you are in the world. To start with I'll go through the general slash manager announcements. Hi, I'm put here to review the the OKR's progress and asks if anything is blocked or at risk and no one has written anything so that's good. There's a reminder that there's a family and friends day on June 24th and also a reminder that we're going to be doing mid year check ins and hyenas created a tracking issue. So this is team member lead check ins to assess how things are going from both the team member and managers point of view to share feedback and help improve performance and development plans. So make sure to dedicate an upcoming one on one with hyena and do this before July 22nd. And another announcement is welcome to Emily who is going to be the product designer on the release team. So get welcome Emily or really happy that you're here. And I just added a small notes I will be in Europe for two months starting next week. I'll be taking a couple days off to deal with the jet lag some of those fall on public holidays and family and friends days, but I might ask the channel to cover for me. But I'm not expecting anything major. Cool, I'll just quickly go over Gina's items. So Gina says that the artifacts page research is complete and that they're going to move forward with the page but have gotten a lot of great feedback that will be incorporated into the NBC. So she's working on updating the list now. And Gina is also working on a survey to validate artifacts jobs we've done and has collected about 80 responses and going to be analyzing the data in 15 to air cuts. Did you want to voice your comment? Yeah, I just wanted to ask you know the question of there was some difference that Jackie was talking about between self manage and SAS users. And I was just very curious. So if she could respond there that would be awesome. Next from Gina is the new runner list for your research, which is in progress. So she's done unmoderated research and it was purely on quantitative data on the usability of the new view versus the old view and she's holding sessions with customers to get qualitative feedback in a couple of weeks as well. And last thing from Gina is John's update if you're working with upgrades at all upgrading get lab runner, for example, we now have an icon to represent them. So that's cool. Sweet, I'll move on to my stuff. So I recently completed the analysis for solution validation for the container registry cleanup policies. This feature allows you to set policies to automatically remove items from the registry to save storage space. And this is very similar to previous solution validation I've done for the packet registry. They're not super surprising, but one thing that I didn't anticipate is that users want to make a template of their policies and apply them to other projects. Erica, you had a comment. I think that's so awesome. And I want us to be able to elevate that in a report brief way. That's just what I would have done in a previous role would be to make a really quick summary. You have that actionable insight. And maybe we should just think through like how we bring together all the work around the library. Like we could link it to that foundational research issue I had or whatever you... Yeah, but we should elevate it. Yeah, yeah, hi Nadia. We've already started going through the agenda just so you know. Sure. When you say, Erica, when you say pull that out into a separate report brief, what exactly does that mean? It would be like instead of the lead, instead of you leading with like we did this study on that, it would be like here's the highlight of a learning related to templates that might be helpful for us to keep in mind as we think about a shared resource library. Yeah, that makes sense. I'm just wondering would that be in Dovetail or would that be on an issue? I don't think we would put it in Dovetail because I think we want to get engineers engaging with it more. And maybe you could take the lead in thinking through the things that we would want. As each of us discovered that the things that we would want to report out, but I looked at it briefly and it was like, I noticed you asked about which level, like project team or group, if they had feedback like that or just sort of this general idea that they love infrastructure as code. Yeah, I'm wondering how, because this kind of fits in with the resource library stuff as you were mentioning before. And I'm just wondering like, yeah, how do I socialize that? What's the best way? Maybe we make an epic and then everyone can link to that. I don't know, a meta issue so that it doesn't get swamped. We can think about it. Yeah, we don't have to solve it on this call, but that is maybe an action item. So I'll mark that after this. My next item is in 152, we're going to be implementing a feature that we're going to release with a small subset of users and monitor with snowplow tracking. And the reason is we've done two rounds of validation, but we're still not certain if this is disruptive to people's workflows. So we're taking a pretty cautious approach. I've done this at other companies, but I've never done it at GitLab. So and my front-end engineer is also new to GitLab. So we're going to figure out this together. But yeah, I'll let you all know how that goes. My next point, I've been doing the touchpoints interviews for a package and I consistently am hearing from customers that the integration with package and release could be better. So I had a one hour call yesterday and I captured the feedback on an internal note. So I'm not sure if you all are going to be able to see it. But basically, I would really like to work with Emily when she's maybe a little bit more on boarded to improve this. Nadia, do you want to voice your question? Yeah, I'm curious to hear if you're already seeing some opportunities there. Do you have any ideas for how we could better integrate those two areas? Yeah, totally. Basically, it's quite a lot of manual process and a lot of boilerplate code that people need in the pipeline and what people are actually expecting is that they couldn't create a package in the pipeline and just mark the package as a release and they don't need to do extra steps. And for the more people want to be able to see that a release like the actual artifact of the release comes from the package registry and a link to that because the package registry has a lot more in-depth information for auditing and stuff. And at the moment, when you're going on the release page, you download the artifact and that's it. You don't even know necessarily that it came from the package registry and there's this whole wealth of information. So it seems like ignoring the technical side, the opportunity is quite clear, but I'm sure there's probably some technical reasons why it is the way it is. Yeah, thanks, Anne. Thank you. My next item, I'm starting to plan for 15-2 and I think there's some opportunities to start getting some of these research projects that we had in the validation backlog moving again. Specifically, we want to improve the package detail page because there's a lot more features we want to add to it. But we kind of want to do like some problem validation to understand what workflows people are. Why are the reasons that they're coming there? What are they trying to achieve? What's missing? What's painful? Just kind of some foundational problem validation research before we start thinking about features. And my last point is continuing on my journey with data. I'm going to try to implement the missing front end events tracking, so that's click tracking for package. We are only tracking like 20% of the things that people click on at the moment. So we have all these beautiful size and stashboards, but they're not painting a really good picture because we're missing a lot of the tracking. So I'm going to attempt that. I think it's going to be easy because I can just copy it from the code, but famous last words, I guess. And that's it for me. I see. Are you guys writing something or do you want to keep the tree don't we? OK. All right. So in 15.3 and this milestone as well, like the remaining week, I'll be focusing on the pipeline components and the solution validation. Currently, I'm finishing up the interviews with internal users. And I've been talking to a lot of the members of our productivity engineering team. And so far, the feedback that we've been getting has been very positive on our proposal. We are getting lots of ideas for improving the further iteration of the future. But it seems like our direction, a lot of the choices that we've made so far are on track and seem like the desired behavior. And also, there's a lot of interest from the engineering productivity team to dog food or product. We already have an issue where we will be tracking that. So we expect that we'll start the implementation in 15.4. If everything goes well, depends on how quickly we can go through the planning breakdown. Of course, there can be an first-seen challenges. But let's hope. And then, yeah, and then we'll be able to dog food it with our productivity engineering team. So they want to kind of move to our new system for creating pipeline components and use our feature to standardize their components or CI templates. So yeah, all of this is very exciting because we can really see how we'll be getting this into the actual product and dog fooding it with our own team. I can't not have been there. So I wonder if you could think about setting up a quick and just real quick lightweight diary study for them or like a Slack bot where you ask them, like, what did you use it for today? Or like, what went well? What could have gone better? Just to stream my in that feedback and make less work for you? I really like the idea of a Slack bot. It hasn't occurred to me to do something like that. My initial idea was to just have an issue, but I see how having something Slack like that would be much easier for the engineers to kind of just type their feedback in. So maybe there's a way to somehow connect it. Maybe have a Slack bot and then somehow pull all of that into the issue because I want to make sure I can actually like grab all of that information that is coming in and have a document is somewhere. But yeah, I think it's a really good idea. Yeah, just like yeah, what went well? What didn't go well? What was your goal? Awesome. Thanks, Erica. Always with your nuggets of wisdom. I love it. Okay. Another thing I wanted to share is around the recently edited guidelines for in product reference information using drawers. So with edits and really basic guidelines, I was lining what kind of content you should put into the drawers, what kind of content you shouldn't put into the drawers and how all of that can be implemented either by pulling in the documentation directly to the drawer or you can also have your own custom content that you write, but it still has to adhere to the content guidelines for our documentation. And we want to actually store it in a markdown file in the docs repository. That is being done to ensure that we can actually test the changes to help content using the documentation pipeline because it does all kinds of helpful waiting and whatnot. So following up on that, I'm revisiting the pipeline editor drawer to make it more helpful to our users. So there's been a lot of hype around the pipeline editor drawer. I feel like like so many people were interested in it like, oh, it's so nice. It's this help info and then we start tracking it. It's youthish. And honestly, it's very low compared to the oral pipeline editor usage. And I think there could be like many different ways to interpret it. Like maybe our users just those toggle when they're going through the flow, which I don't think is the case. Or also maybe it's not very discoverable. It's not tied to a piece of the cat. I mean, maybe it's not tied to a specific task that they're working on. So there's, yeah, we're kind of like not helping them with something specific. It's very generic. And if you look at the guidelines that we put in place, we're saying that we shouldn't create generic health drawers. Like here's help on all kinds of topics that you might think of. Instead, it should be tied to helping the user perform a very specific task. So, yeah, basically I want to like take a deeper dive on the metrics that we've got. Because we also start getting metrics and all of the links inside the drawer. So we can see when the user clicks into the drawer itself, what are they reading about? And so far, it looks like the leading links are CI example. And also the YAML reference, which is something that we would expect. Let's start it. I have to repair off. It's my first step on you, Cat. I can't discipline her. She's just climbing a lottery. Yeah, so I want to take all of this data. And I don't know, maybe we could do some additional solution validation as well together some qualitative data around this. But my next step I think would be to do some experimentation there with the content and try different ways of surfacing different information. Yeah, so basically we learned that it seems like it's not. It's probably not helping our users as much as we thought it were. So I will be looking into it and be able to do that. Hopefully we can improve it from there. Cool. Do we want to move on to the research section? Yeah, so just a general update. There have been no shows. People are not showing to sessions. And it's actually just a larger trend. We think related to the changing of seasons. It's not you or our recruitment, it's just a general trend across all studies. So I thought that would be helpful. And then I have just a couple of check ins. There are, oh, Nadia, do you want to talk? No, I'm just making a joke. Maybe it's not a career retrograde or something. Exactly. Okay. And then, and then if you guys could go into and link the research, the studies that you've been doing, yeah, the research studies you've been doing that I should include in the registry and synthesis. I'm still really wanting to do that to kind of go through. So if you have them and you link them in that issue, that's where I go back through and do like a, like a crosswalk of all the findings for the studies in terms of our big research questions. We like put those together when I first started. And then because we validated our product direction with the, the KUMKON survey, we're like good with those questions. So it's just, if you have other studies that you've completed or when you do, just a reminder, because I was kind of thinking about it. And then if you can go back through and just take out the studies or either delete them from those tables or just say finished, that'd be good. Not, not. I won't beg you, but that'd be awesome, but it's not that great. I mean, you know, I can try to figure it out. And then just also that our team looked just really great. So good job, everyone with the OptiProduction Survey. If you look in that async issue, you can see that we're getting like all this cross-functional feedback. And people are just saying like, great job. You're, you're team did a great job on this. So, okay. Nice. Anyone have anything else they want to chat about? No? Okay, great. Well, thank you both. And yeah, speak to you soon. All right. Bye.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 10.0,
      "text": " Hi everyone and welcome to the CICD UX Sync for June 14th or 15th depending on where you are in the world.",
      "tokens": [
        50364,
        2421,
        1518,
        293,
        2928,
        281,
        264,
        383,
        2532,
        35,
        40176,
        26155,
        66,
        337,
        6928,
        3499,
        392,
        420,
        2119,
        392,
        5413,
        322,
        689,
        291,
        366,
        294,
        264,
        1002,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25030108532273626,
      "compression_ratio": 1.4324324324324325,
      "no_speech_prob": 0.04055153951048851
    },
    {
      "id": 1,
      "seek": 0,
      "start": 10.0,
      "end": 15.0,
      "text": " To start with I'll go through the general slash manager announcements.",
      "tokens": [
        50864,
        1407,
        722,
        365,
        286,
        603,
        352,
        807,
        264,
        2674,
        17330,
        6598,
        23785,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25030108532273626,
      "compression_ratio": 1.4324324324324325,
      "no_speech_prob": 0.04055153951048851
    },
    {
      "id": 2,
      "seek": 0,
      "start": 15.0,
      "end": 24.0,
      "text": " Hi, I'm put here to review the the OKR's progress and asks if anything is blocked or at risk and no one has written anything so that's good.",
      "tokens": [
        51114,
        2421,
        11,
        286,
        478,
        829,
        510,
        281,
        3131,
        264,
        264,
        2264,
        49,
        311,
        4205,
        293,
        8962,
        498,
        1340,
        307,
        15470,
        420,
        412,
        3148,
        293,
        572,
        472,
        575,
        3720,
        1340,
        370,
        300,
        311,
        665,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25030108532273626,
      "compression_ratio": 1.4324324324324325,
      "no_speech_prob": 0.04055153951048851
    },
    {
      "id": 3,
      "seek": 2400,
      "start": 24.0,
      "end": 36.0,
      "text": " There's a reminder that there's a family and friends day on June 24th and also a reminder that we're going to be doing mid year check ins and hyenas created a tracking issue.",
      "tokens": [
        50364,
        821,
        311,
        257,
        13548,
        300,
        456,
        311,
        257,
        1605,
        293,
        1855,
        786,
        322,
        6928,
        4022,
        392,
        293,
        611,
        257,
        13548,
        300,
        321,
        434,
        516,
        281,
        312,
        884,
        2062,
        1064,
        1520,
        1028,
        293,
        2477,
        11581,
        2942,
        257,
        11603,
        2734,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15671378374099731,
      "compression_ratio": 1.6636363636363636,
      "no_speech_prob": 0.0515674389898777
    },
    {
      "id": 4,
      "seek": 2400,
      "start": 36.0,
      "end": 47.0,
      "text": " So this is team member lead check ins to assess how things are going from both the team member and managers point of view to share feedback and help improve performance and development plans.",
      "tokens": [
        50964,
        407,
        341,
        307,
        1469,
        4006,
        1477,
        1520,
        1028,
        281,
        5877,
        577,
        721,
        366,
        516,
        490,
        1293,
        264,
        1469,
        4006,
        293,
        14084,
        935,
        295,
        1910,
        281,
        2073,
        5824,
        293,
        854,
        3470,
        3389,
        293,
        3250,
        5482,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15671378374099731,
      "compression_ratio": 1.6636363636363636,
      "no_speech_prob": 0.0515674389898777
    },
    {
      "id": 5,
      "seek": 4700,
      "start": 47.0,
      "end": 54.0,
      "text": " So make sure to dedicate an upcoming one on one with hyena and do this before July 22nd.",
      "tokens": [
        50364,
        407,
        652,
        988,
        281,
        30718,
        364,
        11500,
        472,
        322,
        472,
        365,
        2477,
        4118,
        293,
        360,
        341,
        949,
        7370,
        5853,
        273,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14823969856637423,
      "compression_ratio": 1.439306358381503,
      "no_speech_prob": 0.4783554971218109
    },
    {
      "id": 6,
      "seek": 4700,
      "start": 54.0,
      "end": 62.0,
      "text": " And another announcement is welcome to Emily who is going to be the product designer on the release team.",
      "tokens": [
        50714,
        400,
        1071,
        12847,
        307,
        2928,
        281,
        15034,
        567,
        307,
        516,
        281,
        312,
        264,
        1674,
        11795,
        322,
        264,
        4374,
        1469,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14823969856637423,
      "compression_ratio": 1.439306358381503,
      "no_speech_prob": 0.4783554971218109
    },
    {
      "id": 7,
      "seek": 4700,
      "start": 62.0,
      "end": 65.0,
      "text": " So get welcome Emily or really happy that you're here.",
      "tokens": [
        51114,
        407,
        483,
        2928,
        15034,
        420,
        534,
        2055,
        300,
        291,
        434,
        510,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14823969856637423,
      "compression_ratio": 1.439306358381503,
      "no_speech_prob": 0.4783554971218109
    },
    {
      "id": 8,
      "seek": 6500,
      "start": 65.0,
      "end": 80.0,
      "text": " And I just added a small notes I will be in Europe for two months starting next week. I'll be taking a couple days off to deal with the jet lag some of those fall on public holidays and family and friends days, but I might ask the channel to cover for me.",
      "tokens": [
        50364,
        400,
        286,
        445,
        3869,
        257,
        1359,
        5570,
        286,
        486,
        312,
        294,
        3315,
        337,
        732,
        2493,
        2891,
        958,
        1243,
        13,
        286,
        603,
        312,
        1940,
        257,
        1916,
        1708,
        766,
        281,
        2028,
        365,
        264,
        14452,
        8953,
        512,
        295,
        729,
        2100,
        322,
        1908,
        15734,
        293,
        1605,
        293,
        1855,
        1708,
        11,
        457,
        286,
        1062,
        1029,
        264,
        2269,
        281,
        2060,
        337,
        385,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12482373143585634,
      "compression_ratio": 1.47979797979798,
      "no_speech_prob": 0.08268973976373672
    },
    {
      "id": 9,
      "seek": 6500,
      "start": 80.0,
      "end": 83.0,
      "text": " But I'm not expecting anything major.",
      "tokens": [
        51114,
        583,
        286,
        478,
        406,
        9650,
        1340,
        2563,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12482373143585634,
      "compression_ratio": 1.47979797979798,
      "no_speech_prob": 0.08268973976373672
    },
    {
      "id": 10,
      "seek": 8300,
      "start": 84.0,
      "end": 99.0,
      "text": " Cool, I'll just quickly go over Gina's items. So Gina says that the artifacts page research is complete and that they're going to move forward with the page but have gotten a lot of great feedback that will be incorporated into the NBC.",
      "tokens": [
        50414,
        8561,
        11,
        286,
        603,
        445,
        2661,
        352,
        670,
        34711,
        311,
        4754,
        13,
        407,
        34711,
        1619,
        300,
        264,
        24617,
        3028,
        2132,
        307,
        3566,
        293,
        300,
        436,
        434,
        516,
        281,
        1286,
        2128,
        365,
        264,
        3028,
        457,
        362,
        5768,
        257,
        688,
        295,
        869,
        5824,
        300,
        486,
        312,
        21654,
        666,
        264,
        31504,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10546622643103966,
      "compression_ratio": 1.416243654822335,
      "no_speech_prob": 0.03193831443786621
    },
    {
      "id": 11,
      "seek": 8300,
      "start": 99.0,
      "end": 103.0,
      "text": " So she's working on updating the list now.",
      "tokens": [
        51164,
        407,
        750,
        311,
        1364,
        322,
        25113,
        264,
        1329,
        586,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10546622643103966,
      "compression_ratio": 1.416243654822335,
      "no_speech_prob": 0.03193831443786621
    },
    {
      "id": 12,
      "seek": 10300,
      "start": 103.0,
      "end": 116.0,
      "text": " And Gina is also working on a survey to validate artifacts jobs we've done and has collected about 80 responses and going to be analyzing the data in 15 to air cuts. Did you want to voice your comment?",
      "tokens": [
        50364,
        400,
        34711,
        307,
        611,
        1364,
        322,
        257,
        8984,
        281,
        29562,
        24617,
        4782,
        321,
        600,
        1096,
        293,
        575,
        11087,
        466,
        4688,
        13019,
        293,
        516,
        281,
        312,
        23663,
        264,
        1412,
        294,
        2119,
        281,
        1988,
        9992,
        13,
        2589,
        291,
        528,
        281,
        3177,
        428,
        2871,
        30,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22816067156584366,
      "compression_ratio": 1.3311258278145695,
      "no_speech_prob": 0.017038509249687195
    },
    {
      "id": 13,
      "seek": 11600,
      "start": 116.0,
      "end": 126.0,
      "text": " Yeah, I just wanted to ask you know the question of there was some difference that Jackie was talking about between self manage and SAS users.",
      "tokens": [
        50364,
        865,
        11,
        286,
        445,
        1415,
        281,
        1029,
        291,
        458,
        264,
        1168,
        295,
        456,
        390,
        512,
        2649,
        300,
        23402,
        390,
        1417,
        466,
        1296,
        2698,
        3067,
        293,
        33441,
        5022,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2181514043074388,
      "compression_ratio": 1.4177215189873418,
      "no_speech_prob": 0.008575363084673882
    },
    {
      "id": 14,
      "seek": 11600,
      "start": 126.0,
      "end": 132.0,
      "text": " And I was just very curious. So if she could respond there that would be awesome.",
      "tokens": [
        50864,
        400,
        286,
        390,
        445,
        588,
        6369,
        13,
        407,
        498,
        750,
        727,
        4196,
        456,
        300,
        576,
        312,
        3476,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2181514043074388,
      "compression_ratio": 1.4177215189873418,
      "no_speech_prob": 0.008575363084673882
    },
    {
      "id": 15,
      "seek": 13200,
      "start": 133.0,
      "end": 154.0,
      "text": " Next from Gina is the new runner list for your research, which is in progress. So she's done unmoderated research and it was purely on quantitative data on the usability of the new view versus the old view and she's holding sessions with customers to get qualitative feedback in a couple of weeks as well.",
      "tokens": [
        50414,
        3087,
        490,
        34711,
        307,
        264,
        777,
        24376,
        1329,
        337,
        428,
        2132,
        11,
        597,
        307,
        294,
        4205,
        13,
        407,
        750,
        311,
        1096,
        517,
        8014,
        260,
        770,
        2132,
        293,
        309,
        390,
        17491,
        322,
        27778,
        1412,
        322,
        264,
        46878,
        295,
        264,
        777,
        1910,
        5717,
        264,
        1331,
        1910,
        293,
        750,
        311,
        5061,
        11081,
        365,
        4581,
        281,
        483,
        31312,
        5824,
        294,
        257,
        1916,
        295,
        3259,
        382,
        731,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12027441565670184,
      "compression_ratio": 1.5482233502538072,
      "no_speech_prob": 0.02902856469154358
    },
    {
      "id": 16,
      "seek": 15400,
      "start": 154.0,
      "end": 167.0,
      "text": " And last thing from Gina is John's update if you're working with upgrades at all upgrading get lab runner, for example, we now have an icon to represent them. So that's cool.",
      "tokens": [
        50364,
        400,
        1036,
        551,
        490,
        34711,
        307,
        2619,
        311,
        5623,
        498,
        291,
        434,
        1364,
        365,
        24868,
        412,
        439,
        36249,
        483,
        2715,
        24376,
        11,
        337,
        1365,
        11,
        321,
        586,
        362,
        364,
        6528,
        281,
        2906,
        552,
        13,
        407,
        300,
        311,
        1627,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19800467057661578,
      "compression_ratio": 1.361842105263158,
      "no_speech_prob": 0.004784320015460253
    },
    {
      "id": 17,
      "seek": 15400,
      "start": 167.0,
      "end": 171.0,
      "text": " Sweet, I'll move on to my stuff.",
      "tokens": [
        51014,
        14653,
        11,
        286,
        603,
        1286,
        322,
        281,
        452,
        1507,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19800467057661578,
      "compression_ratio": 1.361842105263158,
      "no_speech_prob": 0.004784320015460253
    },
    {
      "id": 18,
      "seek": 17100,
      "start": 171.0,
      "end": 178.0,
      "text": " So I recently completed the analysis for solution validation for the container registry cleanup policies.",
      "tokens": [
        50364,
        407,
        286,
        3938,
        7365,
        264,
        5215,
        337,
        3827,
        24071,
        337,
        264,
        10129,
        36468,
        40991,
        7657,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11218203347304771,
      "compression_ratio": 1.6559139784946237,
      "no_speech_prob": 0.025154439732432365
    },
    {
      "id": 19,
      "seek": 17100,
      "start": 178.0,
      "end": 190.0,
      "text": " This feature allows you to set policies to automatically remove items from the registry to save storage space. And this is very similar to previous solution validation I've done for the packet registry.",
      "tokens": [
        50714,
        639,
        4111,
        4045,
        291,
        281,
        992,
        7657,
        281,
        6772,
        4159,
        4754,
        490,
        264,
        36468,
        281,
        3155,
        6725,
        1901,
        13,
        400,
        341,
        307,
        588,
        2531,
        281,
        3894,
        3827,
        24071,
        286,
        600,
        1096,
        337,
        264,
        20300,
        36468,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11218203347304771,
      "compression_ratio": 1.6559139784946237,
      "no_speech_prob": 0.025154439732432365
    },
    {
      "id": 20,
      "seek": 19000,
      "start": 190.0,
      "end": 202.0,
      "text": " They're not super surprising, but one thing that I didn't anticipate is that users want to make a template of their policies and apply them to other projects. Erica, you had a comment.",
      "tokens": [
        50364,
        814,
        434,
        406,
        1687,
        8830,
        11,
        457,
        472,
        551,
        300,
        286,
        994,
        380,
        21685,
        307,
        300,
        5022,
        528,
        281,
        652,
        257,
        12379,
        295,
        641,
        7657,
        293,
        3079,
        552,
        281,
        661,
        4455,
        13,
        37429,
        11,
        291,
        632,
        257,
        2871,
        13,
        50964
      ],
      "temperature": 0.6,
      "avg_logprob": -0.29937870557918106,
      "compression_ratio": 1.3430656934306568,
      "no_speech_prob": 0.15883666276931763
    },
    {
      "id": 21,
      "seek": 20200,
      "start": 202.0,
      "end": 203.72,
      "text": " I think that's so awesome.",
      "tokens": [
        50364,
        286,
        519,
        300,
        311,
        370,
        3476,
        13,
        50450
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 22,
      "seek": 20200,
      "start": 203.72,
      "end": 206.92,
      "text": " And I want us to be able to elevate that",
      "tokens": [
        50450,
        400,
        286,
        528,
        505,
        281,
        312,
        1075,
        281,
        33054,
        300,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 23,
      "seek": 20200,
      "start": 206.92,
      "end": 209.08,
      "text": " in a report brief way.",
      "tokens": [
        50610,
        294,
        257,
        2275,
        5353,
        636,
        13,
        50718
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 24,
      "seek": 20200,
      "start": 209.08,
      "end": 212.8,
      "text": " That's just what I would have done in a previous role",
      "tokens": [
        50718,
        663,
        311,
        445,
        437,
        286,
        576,
        362,
        1096,
        294,
        257,
        3894,
        3090,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 25,
      "seek": 20200,
      "start": 212.8,
      "end": 214.4,
      "text": " would be to make a really quick summary.",
      "tokens": [
        50904,
        576,
        312,
        281,
        652,
        257,
        534,
        1702,
        12691,
        13,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 26,
      "seek": 20200,
      "start": 214.4,
      "end": 216.48,
      "text": " You have that actionable insight.",
      "tokens": [
        50984,
        509,
        362,
        300,
        45098,
        11269,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 27,
      "seek": 20200,
      "start": 216.48,
      "end": 218.44,
      "text": " And maybe we should just think through",
      "tokens": [
        51088,
        400,
        1310,
        321,
        820,
        445,
        519,
        807,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 28,
      "seek": 20200,
      "start": 218.44,
      "end": 222.96,
      "text": " like how we bring together all the work around the library.",
      "tokens": [
        51186,
        411,
        577,
        321,
        1565,
        1214,
        439,
        264,
        589,
        926,
        264,
        6405,
        13,
        51412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 29,
      "seek": 20200,
      "start": 222.96,
      "end": 227.48,
      "text": " Like we could link it to that foundational research issue",
      "tokens": [
        51412,
        1743,
        321,
        727,
        2113,
        309,
        281,
        300,
        32195,
        2132,
        2734,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 30,
      "seek": 20200,
      "start": 227.48,
      "end": 231.0,
      "text": " I had or whatever you...",
      "tokens": [
        51638,
        286,
        632,
        420,
        2035,
        291,
        485,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19291863486031505,
      "compression_ratio": 1.6434426229508197,
      "no_speech_prob": 0.009025981649756432
    },
    {
      "id": 31,
      "seek": 23100,
      "start": 231.0,
      "end": 233.16,
      "text": " Yeah, but we should elevate it.",
      "tokens": [
        50364,
        865,
        11,
        457,
        321,
        820,
        33054,
        309,
        13,
        50472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 32,
      "seek": 23100,
      "start": 233.16,
      "end": 235.24,
      "text": " Yeah, yeah, hi Nadia.",
      "tokens": [
        50472,
        865,
        11,
        1338,
        11,
        4879,
        23269,
        654,
        13,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 33,
      "seek": 23100,
      "start": 235.24,
      "end": 237.32,
      "text": " We've already started going through the agenda",
      "tokens": [
        50576,
        492,
        600,
        1217,
        1409,
        516,
        807,
        264,
        9829,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 34,
      "seek": 23100,
      "start": 237.32,
      "end": 238.16,
      "text": " just so you know.",
      "tokens": [
        50680,
        445,
        370,
        291,
        458,
        13,
        50722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 35,
      "seek": 23100,
      "start": 238.16,
      "end": 239.84,
      "text": " Sure.",
      "tokens": [
        50722,
        4894,
        13,
        50806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 36,
      "seek": 23100,
      "start": 239.84,
      "end": 242.6,
      "text": " When you say, Erica, when you say pull that out",
      "tokens": [
        50806,
        1133,
        291,
        584,
        11,
        37429,
        11,
        562,
        291,
        584,
        2235,
        300,
        484,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 37,
      "seek": 23100,
      "start": 242.6,
      "end": 246.64,
      "text": " into a separate report brief, what exactly does that mean?",
      "tokens": [
        50944,
        666,
        257,
        4994,
        2275,
        5353,
        11,
        437,
        2293,
        775,
        300,
        914,
        30,
        51146
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 38,
      "seek": 23100,
      "start": 248.64,
      "end": 251.24,
      "text": " It would be like instead of the lead,",
      "tokens": [
        51246,
        467,
        576,
        312,
        411,
        2602,
        295,
        264,
        1477,
        11,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 39,
      "seek": 23100,
      "start": 251.24,
      "end": 254.6,
      "text": " instead of you leading with like we did this study on that,",
      "tokens": [
        51376,
        2602,
        295,
        291,
        5775,
        365,
        411,
        321,
        630,
        341,
        2979,
        322,
        300,
        11,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 40,
      "seek": 23100,
      "start": 254.6,
      "end": 258.52,
      "text": " it would be like here's the highlight of a learning",
      "tokens": [
        51544,
        309,
        576,
        312,
        411,
        510,
        311,
        264,
        5078,
        295,
        257,
        2539,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2256823626431552,
      "compression_ratio": 1.6212765957446809,
      "no_speech_prob": 0.0008374006138183177
    },
    {
      "id": 41,
      "seek": 25852,
      "start": 258.52,
      "end": 263.76,
      "text": " related to templates that might be helpful for us",
      "tokens": [
        50364,
        4077,
        281,
        21165,
        300,
        1062,
        312,
        4961,
        337,
        505,
        50626
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1879581069946289,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.00012880518625024706
    },
    {
      "id": 42,
      "seek": 25852,
      "start": 263.76,
      "end": 268.76,
      "text": " to keep in mind as we think about a shared resource library.",
      "tokens": [
        50626,
        281,
        1066,
        294,
        1575,
        382,
        321,
        519,
        466,
        257,
        5507,
        7684,
        6405,
        13,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1879581069946289,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.00012880518625024706
    },
    {
      "id": 43,
      "seek": 25852,
      "start": 269.71999999999997,
      "end": 271.32,
      "text": " Yeah, that makes sense.",
      "tokens": [
        50924,
        865,
        11,
        300,
        1669,
        2020,
        13,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1879581069946289,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.00012880518625024706
    },
    {
      "id": 44,
      "seek": 25852,
      "start": 271.32,
      "end": 273.56,
      "text": " I'm just wondering would that be in Dovetail",
      "tokens": [
        51004,
        286,
        478,
        445,
        6359,
        576,
        300,
        312,
        294,
        1144,
        9771,
        864,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1879581069946289,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.00012880518625024706
    },
    {
      "id": 45,
      "seek": 25852,
      "start": 273.56,
      "end": 274.76,
      "text": " or would that be on an issue?",
      "tokens": [
        51116,
        420,
        576,
        300,
        312,
        322,
        364,
        2734,
        30,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1879581069946289,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.00012880518625024706
    },
    {
      "id": 46,
      "seek": 25852,
      "start": 274.76,
      "end": 277.32,
      "text": " I don't think we would put it in Dovetail",
      "tokens": [
        51176,
        286,
        500,
        380,
        519,
        321,
        576,
        829,
        309,
        294,
        1144,
        9771,
        864,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1879581069946289,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.00012880518625024706
    },
    {
      "id": 47,
      "seek": 25852,
      "start": 277.32,
      "end": 282.32,
      "text": " because I think we want to get engineers engaging with it more.",
      "tokens": [
        51304,
        570,
        286,
        519,
        321,
        528,
        281,
        483,
        11955,
        11268,
        365,
        309,
        544,
        13,
        51554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1879581069946289,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.00012880518625024706
    },
    {
      "id": 48,
      "seek": 25852,
      "start": 282.32,
      "end": 286.03999999999996,
      "text": " And maybe you could take the lead in thinking through",
      "tokens": [
        51554,
        400,
        1310,
        291,
        727,
        747,
        264,
        1477,
        294,
        1953,
        807,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1879581069946289,
      "compression_ratio": 1.6327433628318584,
      "no_speech_prob": 0.00012880518625024706
    },
    {
      "id": 49,
      "seek": 28604,
      "start": 287.0,
      "end": 289.36,
      "text": " the things that we would want.",
      "tokens": [
        50412,
        264,
        721,
        300,
        321,
        576,
        528,
        13,
        50530
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 50,
      "seek": 28604,
      "start": 289.36,
      "end": 292.64000000000004,
      "text": " As each of us discovered that the things",
      "tokens": [
        50530,
        1018,
        1184,
        295,
        505,
        6941,
        300,
        264,
        721,
        50694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 51,
      "seek": 28604,
      "start": 292.64000000000004,
      "end": 294.24,
      "text": " that we would want to report out,",
      "tokens": [
        50694,
        300,
        321,
        576,
        528,
        281,
        2275,
        484,
        11,
        50774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 52,
      "seek": 28604,
      "start": 294.24,
      "end": 297.44,
      "text": " but I looked at it briefly and it was like,",
      "tokens": [
        50774,
        457,
        286,
        2956,
        412,
        309,
        10515,
        293,
        309,
        390,
        411,
        11,
        50934
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 53,
      "seek": 28604,
      "start": 297.44,
      "end": 299.72,
      "text": " I noticed you asked about which level,",
      "tokens": [
        50934,
        286,
        5694,
        291,
        2351,
        466,
        597,
        1496,
        11,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 54,
      "seek": 28604,
      "start": 299.72,
      "end": 302.16,
      "text": " like project team or group,",
      "tokens": [
        51048,
        411,
        1716,
        1469,
        420,
        1594,
        11,
        51170
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 55,
      "seek": 28604,
      "start": 302.16,
      "end": 304.16,
      "text": " if they had feedback like that",
      "tokens": [
        51170,
        498,
        436,
        632,
        5824,
        411,
        300,
        51270
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 56,
      "seek": 28604,
      "start": 304.16,
      "end": 306.76,
      "text": " or just sort of this general idea",
      "tokens": [
        51270,
        420,
        445,
        1333,
        295,
        341,
        2674,
        1558,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 57,
      "seek": 28604,
      "start": 306.76,
      "end": 309.32000000000005,
      "text": " that they love infrastructure as code.",
      "tokens": [
        51400,
        300,
        436,
        959,
        6896,
        382,
        3089,
        13,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 58,
      "seek": 28604,
      "start": 312.68,
      "end": 315.04,
      "text": " Yeah, I'm wondering how,",
      "tokens": [
        51696,
        865,
        11,
        286,
        478,
        6359,
        577,
        11,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25088516707272873,
      "compression_ratio": 1.6121495327102804,
      "no_speech_prob": 0.0012303065741434693
    },
    {
      "id": 59,
      "seek": 31504,
      "start": 315.04,
      "end": 320.56,
      "text": " because this kind of fits in with the resource library stuff",
      "tokens": [
        50364,
        570,
        341,
        733,
        295,
        9001,
        294,
        365,
        264,
        7684,
        6405,
        1507,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 60,
      "seek": 31504,
      "start": 320.56,
      "end": 321.88,
      "text": " as you were mentioning before.",
      "tokens": [
        50640,
        382,
        291,
        645,
        18315,
        949,
        13,
        50706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 61,
      "seek": 31504,
      "start": 321.88,
      "end": 322.96000000000004,
      "text": " And I'm just wondering like,",
      "tokens": [
        50706,
        400,
        286,
        478,
        445,
        6359,
        411,
        11,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 62,
      "seek": 31504,
      "start": 322.96000000000004,
      "end": 324.76000000000005,
      "text": " yeah, how do I socialize that?",
      "tokens": [
        50760,
        1338,
        11,
        577,
        360,
        286,
        2093,
        1125,
        300,
        30,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 63,
      "seek": 31504,
      "start": 324.76000000000005,
      "end": 325.8,
      "text": " What's the best way?",
      "tokens": [
        50850,
        708,
        311,
        264,
        1151,
        636,
        30,
        50902
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 64,
      "seek": 31504,
      "start": 327.68,
      "end": 330.72,
      "text": " Maybe we make an epic and then everyone can link to that.",
      "tokens": [
        50996,
        2704,
        321,
        652,
        364,
        13581,
        293,
        550,
        1518,
        393,
        2113,
        281,
        300,
        13,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 65,
      "seek": 31504,
      "start": 330.72,
      "end": 335.08000000000004,
      "text": " I don't know, a meta issue so that it doesn't get swamped.",
      "tokens": [
        51148,
        286,
        500,
        380,
        458,
        11,
        257,
        19616,
        2734,
        370,
        300,
        309,
        1177,
        380,
        483,
        31724,
        292,
        13,
        51366
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 66,
      "seek": 31504,
      "start": 335.08000000000004,
      "end": 336.48,
      "text": " We can think about it.",
      "tokens": [
        51366,
        492,
        393,
        519,
        466,
        309,
        13,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 67,
      "seek": 31504,
      "start": 336.48,
      "end": 339.6,
      "text": " Yeah, we don't have to solve it on this call,",
      "tokens": [
        51436,
        865,
        11,
        321,
        500,
        380,
        362,
        281,
        5039,
        309,
        322,
        341,
        818,
        11,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 68,
      "seek": 31504,
      "start": 339.6,
      "end": 342.32000000000005,
      "text": " but that is maybe an action item.",
      "tokens": [
        51592,
        457,
        300,
        307,
        1310,
        364,
        3069,
        3174,
        13,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20981956740557137,
      "compression_ratio": 1.5433070866141732,
      "no_speech_prob": 8.934531797422096e-05
    },
    {
      "id": 69,
      "seek": 34232,
      "start": 342.32,
      "end": 344.04,
      "text": " So I'll mark that after this.",
      "tokens": [
        50364,
        407,
        286,
        603,
        1491,
        300,
        934,
        341,
        13,
        50450
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 70,
      "seek": 34232,
      "start": 347.76,
      "end": 349.59999999999997,
      "text": " My next item is in 152,",
      "tokens": [
        50636,
        1222,
        958,
        3174,
        307,
        294,
        2119,
        17,
        11,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 71,
      "seek": 34232,
      "start": 349.59999999999997,
      "end": 351.4,
      "text": " we're going to be implementing a feature",
      "tokens": [
        50728,
        321,
        434,
        516,
        281,
        312,
        18114,
        257,
        4111,
        50818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 72,
      "seek": 34232,
      "start": 351.4,
      "end": 353.96,
      "text": " that we're going to release with a small subset of users",
      "tokens": [
        50818,
        300,
        321,
        434,
        516,
        281,
        4374,
        365,
        257,
        1359,
        25993,
        295,
        5022,
        50946
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 73,
      "seek": 34232,
      "start": 353.96,
      "end": 355.84,
      "text": " and monitor with snowplow tracking.",
      "tokens": [
        50946,
        293,
        6002,
        365,
        5756,
        564,
        305,
        11603,
        13,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 74,
      "seek": 34232,
      "start": 355.84,
      "end": 358.48,
      "text": " And the reason is we've done two rounds of validation,",
      "tokens": [
        51040,
        400,
        264,
        1778,
        307,
        321,
        600,
        1096,
        732,
        13757,
        295,
        24071,
        11,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 75,
      "seek": 34232,
      "start": 358.48,
      "end": 359.68,
      "text": " but we're still not certain",
      "tokens": [
        51172,
        457,
        321,
        434,
        920,
        406,
        1629,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 76,
      "seek": 34232,
      "start": 359.68,
      "end": 361.71999999999997,
      "text": " if this is disruptive to people's workflows.",
      "tokens": [
        51232,
        498,
        341,
        307,
        37865,
        281,
        561,
        311,
        43461,
        13,
        51334
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 77,
      "seek": 34232,
      "start": 361.71999999999997,
      "end": 364.52,
      "text": " So we're taking a pretty cautious approach.",
      "tokens": [
        51334,
        407,
        321,
        434,
        1940,
        257,
        1238,
        25278,
        3109,
        13,
        51474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 78,
      "seek": 34232,
      "start": 364.52,
      "end": 365.71999999999997,
      "text": " I've done this at other companies,",
      "tokens": [
        51474,
        286,
        600,
        1096,
        341,
        412,
        661,
        3431,
        11,
        51534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 79,
      "seek": 34232,
      "start": 365.71999999999997,
      "end": 367.2,
      "text": " but I've never done it at GitLab.",
      "tokens": [
        51534,
        457,
        286,
        600,
        1128,
        1096,
        309,
        412,
        16939,
        37880,
        13,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 80,
      "seek": 34232,
      "start": 367.2,
      "end": 370.28,
      "text": " So and my front-end engineer is also new to GitLab.",
      "tokens": [
        51608,
        407,
        293,
        452,
        1868,
        12,
        521,
        11403,
        307,
        611,
        777,
        281,
        16939,
        37880,
        13,
        51762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16144630874412647,
      "compression_ratio": 1.6326530612244898,
      "no_speech_prob": 0.0005327537073753774
    },
    {
      "id": 81,
      "seek": 37028,
      "start": 370.28,
      "end": 372.91999999999996,
      "text": " So we're going to figure out this together.",
      "tokens": [
        50364,
        407,
        321,
        434,
        516,
        281,
        2573,
        484,
        341,
        1214,
        13,
        50496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15614640175759256,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.0005100707639940083
    },
    {
      "id": 82,
      "seek": 37028,
      "start": 372.91999999999996,
      "end": 376.2,
      "text": " But yeah, I'll let you all know how that goes.",
      "tokens": [
        50496,
        583,
        1338,
        11,
        286,
        603,
        718,
        291,
        439,
        458,
        577,
        300,
        1709,
        13,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15614640175759256,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.0005100707639940083
    },
    {
      "id": 83,
      "seek": 37028,
      "start": 379.23999999999995,
      "end": 382.96,
      "text": " My next point, I've been doing the touchpoints interviews",
      "tokens": [
        50812,
        1222,
        958,
        935,
        11,
        286,
        600,
        668,
        884,
        264,
        2557,
        20552,
        12318,
        50998
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15614640175759256,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.0005100707639940083
    },
    {
      "id": 84,
      "seek": 37028,
      "start": 382.96,
      "end": 386.76,
      "text": " for a package and I consistently am hearing from customers",
      "tokens": [
        50998,
        337,
        257,
        7372,
        293,
        286,
        14961,
        669,
        4763,
        490,
        4581,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15614640175759256,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.0005100707639940083
    },
    {
      "id": 85,
      "seek": 37028,
      "start": 386.76,
      "end": 388.64,
      "text": " that the integration with package and release",
      "tokens": [
        51188,
        300,
        264,
        10980,
        365,
        7372,
        293,
        4374,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15614640175759256,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.0005100707639940083
    },
    {
      "id": 86,
      "seek": 37028,
      "start": 388.64,
      "end": 390.2,
      "text": " could be better.",
      "tokens": [
        51282,
        727,
        312,
        1101,
        13,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15614640175759256,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.0005100707639940083
    },
    {
      "id": 87,
      "seek": 37028,
      "start": 390.2,
      "end": 392.91999999999996,
      "text": " So I had a one hour call yesterday",
      "tokens": [
        51360,
        407,
        286,
        632,
        257,
        472,
        1773,
        818,
        5186,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15614640175759256,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.0005100707639940083
    },
    {
      "id": 88,
      "seek": 37028,
      "start": 392.91999999999996,
      "end": 396.0,
      "text": " and I captured the feedback on an internal note.",
      "tokens": [
        51496,
        293,
        286,
        11828,
        264,
        5824,
        322,
        364,
        6920,
        3637,
        13,
        51650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15614640175759256,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.0005100707639940083
    },
    {
      "id": 89,
      "seek": 37028,
      "start": 396.0,
      "end": 398.59999999999997,
      "text": " So I'm not sure if you all are going to be able to see it.",
      "tokens": [
        51650,
        407,
        286,
        478,
        406,
        988,
        498,
        291,
        439,
        366,
        516,
        281,
        312,
        1075,
        281,
        536,
        309,
        13,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15614640175759256,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.0005100707639940083
    },
    {
      "id": 90,
      "seek": 39860,
      "start": 399.6,
      "end": 404.32000000000005,
      "text": " But basically, I would really like to work with Emily",
      "tokens": [
        50414,
        583,
        1936,
        11,
        286,
        576,
        534,
        411,
        281,
        589,
        365,
        15034,
        50650
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20018478468352674,
      "compression_ratio": 1.510204081632653,
      "no_speech_prob": 0.0022699469700455666
    },
    {
      "id": 91,
      "seek": 39860,
      "start": 404.32000000000005,
      "end": 408.32000000000005,
      "text": " when she's maybe a little bit more on boarded to improve this.",
      "tokens": [
        50650,
        562,
        750,
        311,
        1310,
        257,
        707,
        857,
        544,
        322,
        3150,
        292,
        281,
        3470,
        341,
        13,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20018478468352674,
      "compression_ratio": 1.510204081632653,
      "no_speech_prob": 0.0022699469700455666
    },
    {
      "id": 92,
      "seek": 39860,
      "start": 409.52000000000004,
      "end": 412.20000000000005,
      "text": " Nadia, do you want to voice your question?",
      "tokens": [
        50910,
        23269,
        654,
        11,
        360,
        291,
        528,
        281,
        3177,
        428,
        1168,
        30,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20018478468352674,
      "compression_ratio": 1.510204081632653,
      "no_speech_prob": 0.0022699469700455666
    },
    {
      "id": 93,
      "seek": 39860,
      "start": 412.20000000000005,
      "end": 414.88,
      "text": " Yeah, I'm curious to hear if you're already seeing",
      "tokens": [
        51044,
        865,
        11,
        286,
        478,
        6369,
        281,
        1568,
        498,
        291,
        434,
        1217,
        2577,
        51178
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20018478468352674,
      "compression_ratio": 1.510204081632653,
      "no_speech_prob": 0.0022699469700455666
    },
    {
      "id": 94,
      "seek": 39860,
      "start": 414.88,
      "end": 416.48,
      "text": " some opportunities there.",
      "tokens": [
        51178,
        512,
        4786,
        456,
        13,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20018478468352674,
      "compression_ratio": 1.510204081632653,
      "no_speech_prob": 0.0022699469700455666
    },
    {
      "id": 95,
      "seek": 39860,
      "start": 416.48,
      "end": 418.84000000000003,
      "text": " Do you have any ideas for how we could",
      "tokens": [
        51258,
        1144,
        291,
        362,
        604,
        3487,
        337,
        577,
        321,
        727,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20018478468352674,
      "compression_ratio": 1.510204081632653,
      "no_speech_prob": 0.0022699469700455666
    },
    {
      "id": 96,
      "seek": 39860,
      "start": 418.84000000000003,
      "end": 421.32000000000005,
      "text": " better integrate those two areas?",
      "tokens": [
        51376,
        1101,
        13365,
        729,
        732,
        3179,
        30,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20018478468352674,
      "compression_ratio": 1.510204081632653,
      "no_speech_prob": 0.0022699469700455666
    },
    {
      "id": 97,
      "seek": 39860,
      "start": 421.32000000000005,
      "end": 422.16,
      "text": " Yeah, totally.",
      "tokens": [
        51500,
        865,
        11,
        3879,
        13,
        51542
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20018478468352674,
      "compression_ratio": 1.510204081632653,
      "no_speech_prob": 0.0022699469700455666
    },
    {
      "id": 98,
      "seek": 39860,
      "start": 423.12,
      "end": 426.84000000000003,
      "text": " Basically, it's quite a lot of manual process",
      "tokens": [
        51590,
        8537,
        11,
        309,
        311,
        1596,
        257,
        688,
        295,
        9688,
        1399,
        51776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20018478468352674,
      "compression_ratio": 1.510204081632653,
      "no_speech_prob": 0.0022699469700455666
    },
    {
      "id": 99,
      "seek": 42684,
      "start": 426.84,
      "end": 431.08,
      "text": " and a lot of boilerplate code that people need in the pipeline",
      "tokens": [
        50364,
        293,
        257,
        688,
        295,
        39228,
        37008,
        3089,
        300,
        561,
        643,
        294,
        264,
        15517,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 100,
      "seek": 42684,
      "start": 431.08,
      "end": 433.2,
      "text": " and what people are actually expecting",
      "tokens": [
        50576,
        293,
        437,
        561,
        366,
        767,
        9650,
        50682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 101,
      "seek": 42684,
      "start": 433.2,
      "end": 436.28,
      "text": " is that they couldn't create a package in the pipeline",
      "tokens": [
        50682,
        307,
        300,
        436,
        2809,
        380,
        1884,
        257,
        7372,
        294,
        264,
        15517,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 102,
      "seek": 42684,
      "start": 436.28,
      "end": 438.79999999999995,
      "text": " and just mark the package as a release",
      "tokens": [
        50836,
        293,
        445,
        1491,
        264,
        7372,
        382,
        257,
        4374,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 103,
      "seek": 42684,
      "start": 438.79999999999995,
      "end": 440.88,
      "text": " and they don't need to do extra steps.",
      "tokens": [
        50962,
        293,
        436,
        500,
        380,
        643,
        281,
        360,
        2857,
        4439,
        13,
        51066
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 104,
      "seek": 42684,
      "start": 441.88,
      "end": 446.88,
      "text": " And for the more people want to be able to see that a release",
      "tokens": [
        51116,
        400,
        337,
        264,
        544,
        561,
        528,
        281,
        312,
        1075,
        281,
        536,
        300,
        257,
        4374,
        51366
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 105,
      "seek": 42684,
      "start": 447.12,
      "end": 448.88,
      "text": " like the actual artifact of the release",
      "tokens": [
        51378,
        411,
        264,
        3539,
        34806,
        295,
        264,
        4374,
        51466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 106,
      "seek": 42684,
      "start": 448.88,
      "end": 451.28,
      "text": " comes from the package registry and a link to that",
      "tokens": [
        51466,
        1487,
        490,
        264,
        7372,
        36468,
        293,
        257,
        2113,
        281,
        300,
        51586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 107,
      "seek": 42684,
      "start": 451.28,
      "end": 455.08,
      "text": " because the package registry has a lot more in-depth information",
      "tokens": [
        51586,
        570,
        264,
        7372,
        36468,
        575,
        257,
        688,
        544,
        294,
        12,
        25478,
        1589,
        51776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 108,
      "seek": 42684,
      "start": 455.08,
      "end": 456.79999999999995,
      "text": " for auditing and stuff.",
      "tokens": [
        51776,
        337,
        2379,
        1748,
        293,
        1507,
        13,
        51862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10813386901086118,
      "compression_ratio": 1.9193548387096775,
      "no_speech_prob": 0.003915054257959127
    },
    {
      "id": 109,
      "seek": 45680,
      "start": 456.8,
      "end": 458.92,
      "text": " And at the moment, when you're going on the release page,",
      "tokens": [
        50364,
        400,
        412,
        264,
        1623,
        11,
        562,
        291,
        434,
        516,
        322,
        264,
        4374,
        3028,
        11,
        50470
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 110,
      "seek": 45680,
      "start": 458.92,
      "end": 461.32,
      "text": " you download the artifact and that's it.",
      "tokens": [
        50470,
        291,
        5484,
        264,
        34806,
        293,
        300,
        311,
        309,
        13,
        50590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 111,
      "seek": 45680,
      "start": 461.32,
      "end": 464.2,
      "text": " You don't even know necessarily that it came from the package registry",
      "tokens": [
        50590,
        509,
        500,
        380,
        754,
        458,
        4725,
        300,
        309,
        1361,
        490,
        264,
        7372,
        36468,
        50734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 112,
      "seek": 45680,
      "start": 464.2,
      "end": 466.52000000000004,
      "text": " and there's this whole wealth of information.",
      "tokens": [
        50734,
        293,
        456,
        311,
        341,
        1379,
        7203,
        295,
        1589,
        13,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 113,
      "seek": 45680,
      "start": 466.52000000000004,
      "end": 470.0,
      "text": " So it seems like ignoring the technical side,",
      "tokens": [
        50850,
        407,
        309,
        2544,
        411,
        26258,
        264,
        6191,
        1252,
        11,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 114,
      "seek": 45680,
      "start": 470.0,
      "end": 472.48,
      "text": " the opportunity is quite clear,",
      "tokens": [
        51024,
        264,
        2650,
        307,
        1596,
        1850,
        11,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 115,
      "seek": 45680,
      "start": 472.48,
      "end": 475.28000000000003,
      "text": " but I'm sure there's probably some technical reasons",
      "tokens": [
        51148,
        457,
        286,
        478,
        988,
        456,
        311,
        1391,
        512,
        6191,
        4112,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 116,
      "seek": 45680,
      "start": 475.28000000000003,
      "end": 476.44,
      "text": " why it is the way it is.",
      "tokens": [
        51288,
        983,
        309,
        307,
        264,
        636,
        309,
        307,
        13,
        51346
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 117,
      "seek": 45680,
      "start": 478.0,
      "end": 478.84000000000003,
      "text": " Yeah, thanks, Anne.",
      "tokens": [
        51424,
        865,
        11,
        3231,
        11,
        13706,
        13,
        51466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 118,
      "seek": 45680,
      "start": 478.84000000000003,
      "end": 479.68,
      "text": " Thank you.",
      "tokens": [
        51466,
        1044,
        291,
        13,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 119,
      "seek": 45680,
      "start": 482.52,
      "end": 486.28000000000003,
      "text": " My next item, I'm starting to plan for 15-2",
      "tokens": [
        51650,
        1222,
        958,
        3174,
        11,
        286,
        478,
        2891,
        281,
        1393,
        337,
        2119,
        12,
        17,
        51838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17255221643755514,
      "compression_ratio": 1.5928571428571427,
      "no_speech_prob": 0.00017218828725162894
    },
    {
      "id": 120,
      "seek": 48628,
      "start": 486.28,
      "end": 488.4,
      "text": " and I think there's some opportunities",
      "tokens": [
        50364,
        293,
        286,
        519,
        456,
        311,
        512,
        4786,
        50470
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 121,
      "seek": 48628,
      "start": 488.4,
      "end": 491.76,
      "text": " to start getting some of these research projects",
      "tokens": [
        50470,
        281,
        722,
        1242,
        512,
        295,
        613,
        2132,
        4455,
        50638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 122,
      "seek": 48628,
      "start": 491.76,
      "end": 494.44,
      "text": " that we had in the validation backlog moving again.",
      "tokens": [
        50638,
        300,
        321,
        632,
        294,
        264,
        24071,
        47364,
        2684,
        797,
        13,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 123,
      "seek": 48628,
      "start": 495.52,
      "end": 499.84,
      "text": " Specifically, we want to improve the package detail page",
      "tokens": [
        50826,
        26058,
        11,
        321,
        528,
        281,
        3470,
        264,
        7372,
        2607,
        3028,
        51042
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 124,
      "seek": 48628,
      "start": 499.84,
      "end": 502.71999999999997,
      "text": " because there's a lot more features we want to add to it.",
      "tokens": [
        51042,
        570,
        456,
        311,
        257,
        688,
        544,
        4122,
        321,
        528,
        281,
        909,
        281,
        309,
        13,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 125,
      "seek": 48628,
      "start": 503.71999999999997,
      "end": 506.4,
      "text": " But we kind of want to do like some problem validation",
      "tokens": [
        51236,
        583,
        321,
        733,
        295,
        528,
        281,
        360,
        411,
        512,
        1154,
        24071,
        51370
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 126,
      "seek": 48628,
      "start": 506.4,
      "end": 509.2,
      "text": " to understand what workflows people are.",
      "tokens": [
        51370,
        281,
        1223,
        437,
        43461,
        561,
        366,
        13,
        51510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 127,
      "seek": 48628,
      "start": 510.2,
      "end": 511.64,
      "text": " Why are the reasons that they're coming there?",
      "tokens": [
        51560,
        1545,
        366,
        264,
        4112,
        300,
        436,
        434,
        1348,
        456,
        30,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 128,
      "seek": 48628,
      "start": 511.64,
      "end": 513.16,
      "text": " What are they trying to achieve?",
      "tokens": [
        51632,
        708,
        366,
        436,
        1382,
        281,
        4584,
        30,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 129,
      "seek": 48628,
      "start": 513.16,
      "end": 514.0,
      "text": " What's missing?",
      "tokens": [
        51708,
        708,
        311,
        5361,
        30,
        51750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 130,
      "seek": 48628,
      "start": 514.0,
      "end": 514.92,
      "text": " What's painful?",
      "tokens": [
        51750,
        708,
        311,
        11697,
        30,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17553321246443124,
      "compression_ratio": 1.7047970479704797,
      "no_speech_prob": 0.0006469875224865973
    },
    {
      "id": 131,
      "seek": 51492,
      "start": 514.92,
      "end": 517.64,
      "text": " Just kind of some foundational problem validation research",
      "tokens": [
        50364,
        1449,
        733,
        295,
        512,
        32195,
        1154,
        24071,
        2132,
        50500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17972808414035374,
      "compression_ratio": 1.5935251798561152,
      "no_speech_prob": 0.0008304227376356721
    },
    {
      "id": 132,
      "seek": 51492,
      "start": 517.64,
      "end": 520.12,
      "text": " before we start thinking about features.",
      "tokens": [
        50500,
        949,
        321,
        722,
        1953,
        466,
        4122,
        13,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17972808414035374,
      "compression_ratio": 1.5935251798561152,
      "no_speech_prob": 0.0008304227376356721
    },
    {
      "id": 133,
      "seek": 51492,
      "start": 522.88,
      "end": 527.4,
      "text": " And my last point is continuing on my journey with data.",
      "tokens": [
        50762,
        400,
        452,
        1036,
        935,
        307,
        9289,
        322,
        452,
        4671,
        365,
        1412,
        13,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17972808414035374,
      "compression_ratio": 1.5935251798561152,
      "no_speech_prob": 0.0008304227376356721
    },
    {
      "id": 134,
      "seek": 51492,
      "start": 528.24,
      "end": 531.64,
      "text": " I'm going to try to implement the missing front end events",
      "tokens": [
        51030,
        286,
        478,
        516,
        281,
        853,
        281,
        4445,
        264,
        5361,
        1868,
        917,
        3931,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17972808414035374,
      "compression_ratio": 1.5935251798561152,
      "no_speech_prob": 0.0008304227376356721
    },
    {
      "id": 135,
      "seek": 51492,
      "start": 531.64,
      "end": 534.56,
      "text": " tracking, so that's click tracking for package.",
      "tokens": [
        51200,
        11603,
        11,
        370,
        300,
        311,
        2052,
        11603,
        337,
        7372,
        13,
        51346
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17972808414035374,
      "compression_ratio": 1.5935251798561152,
      "no_speech_prob": 0.0008304227376356721
    },
    {
      "id": 136,
      "seek": 51492,
      "start": 534.56,
      "end": 537.12,
      "text": " We are only tracking like 20% of the things",
      "tokens": [
        51346,
        492,
        366,
        787,
        11603,
        411,
        945,
        4,
        295,
        264,
        721,
        51474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17972808414035374,
      "compression_ratio": 1.5935251798561152,
      "no_speech_prob": 0.0008304227376356721
    },
    {
      "id": 137,
      "seek": 51492,
      "start": 537.12,
      "end": 539.8,
      "text": " that people click on at the moment.",
      "tokens": [
        51474,
        300,
        561,
        2052,
        322,
        412,
        264,
        1623,
        13,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17972808414035374,
      "compression_ratio": 1.5935251798561152,
      "no_speech_prob": 0.0008304227376356721
    },
    {
      "id": 138,
      "seek": 51492,
      "start": 539.8,
      "end": 542.88,
      "text": " So we have all these beautiful size and stashboards,",
      "tokens": [
        51608,
        407,
        321,
        362,
        439,
        613,
        2238,
        2744,
        293,
        342,
        1299,
        17228,
        11,
        51762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17972808414035374,
      "compression_ratio": 1.5935251798561152,
      "no_speech_prob": 0.0008304227376356721
    },
    {
      "id": 139,
      "seek": 51492,
      "start": 542.88,
      "end": 544.4399999999999,
      "text": " but they're not painting a really good picture",
      "tokens": [
        51762,
        457,
        436,
        434,
        406,
        5370,
        257,
        534,
        665,
        3036,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17972808414035374,
      "compression_ratio": 1.5935251798561152,
      "no_speech_prob": 0.0008304227376356721
    },
    {
      "id": 140,
      "seek": 54444,
      "start": 544.44,
      "end": 546.0,
      "text": " because we're missing a lot of the tracking.",
      "tokens": [
        50364,
        570,
        321,
        434,
        5361,
        257,
        688,
        295,
        264,
        11603,
        13,
        50442
      ],
      "temperature": 0.0,
      "avg_logprob": -0.347256266552469,
      "compression_ratio": 1.4947368421052631,
      "no_speech_prob": 0.00031533840228803456
    },
    {
      "id": 141,
      "seek": 54444,
      "start": 546.0,
      "end": 549.08,
      "text": " So I'm going to attempt that.",
      "tokens": [
        50442,
        407,
        286,
        478,
        516,
        281,
        5217,
        300,
        13,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.347256266552469,
      "compression_ratio": 1.4947368421052631,
      "no_speech_prob": 0.00031533840228803456
    },
    {
      "id": 142,
      "seek": 54444,
      "start": 549.08,
      "end": 552.48,
      "text": " I think it's going to be easy because I can just copy it",
      "tokens": [
        50596,
        286,
        519,
        309,
        311,
        516,
        281,
        312,
        1858,
        570,
        286,
        393,
        445,
        5055,
        309,
        50766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.347256266552469,
      "compression_ratio": 1.4947368421052631,
      "no_speech_prob": 0.00031533840228803456
    },
    {
      "id": 143,
      "seek": 54444,
      "start": 552.48,
      "end": 555.5200000000001,
      "text": " from the code, but famous last words, I guess.",
      "tokens": [
        50766,
        490,
        264,
        3089,
        11,
        457,
        4618,
        1036,
        2283,
        11,
        286,
        2041,
        13,
        50918
      ],
      "temperature": 0.0,
      "avg_logprob": -0.347256266552469,
      "compression_ratio": 1.4947368421052631,
      "no_speech_prob": 0.00031533840228803456
    },
    {
      "id": 144,
      "seek": 54444,
      "start": 558.12,
      "end": 559.0,
      "text": " And that's it for me.",
      "tokens": [
        51048,
        400,
        300,
        311,
        309,
        337,
        385,
        13,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.347256266552469,
      "compression_ratio": 1.4947368421052631,
      "no_speech_prob": 0.00031533840228803456
    },
    {
      "id": 145,
      "seek": 54444,
      "start": 566.9200000000001,
      "end": 567.24,
      "text": " I see.",
      "tokens": [
        51488,
        286,
        536,
        13,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.347256266552469,
      "compression_ratio": 1.4947368421052631,
      "no_speech_prob": 0.00031533840228803456
    },
    {
      "id": 146,
      "seek": 54444,
      "start": 567.24,
      "end": 569.8000000000001,
      "text": " Are you guys writing something or do you want to keep the tree",
      "tokens": [
        51504,
        2014,
        291,
        1074,
        3579,
        746,
        420,
        360,
        291,
        528,
        281,
        1066,
        264,
        4230,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.347256266552469,
      "compression_ratio": 1.4947368421052631,
      "no_speech_prob": 0.00031533840228803456
    },
    {
      "id": 147,
      "seek": 54444,
      "start": 569.8000000000001,
      "end": 570.24,
      "text": " don't we?",
      "tokens": [
        51632,
        500,
        380,
        321,
        30,
        51654
      ],
      "temperature": 0.0,
      "avg_logprob": -0.347256266552469,
      "compression_ratio": 1.4947368421052631,
      "no_speech_prob": 0.00031533840228803456
    },
    {
      "id": 148,
      "seek": 54444,
      "start": 572.2800000000001,
      "end": 572.6400000000001,
      "text": " OK.",
      "tokens": [
        51756,
        2264,
        13,
        51774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.347256266552469,
      "compression_ratio": 1.4947368421052631,
      "no_speech_prob": 0.00031533840228803456
    },
    {
      "id": 149,
      "seek": 57444,
      "start": 574.8800000000001,
      "end": 575.6800000000001,
      "text": " All right.",
      "tokens": [
        50386,
        1057,
        558,
        13,
        50426
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 150,
      "seek": 57444,
      "start": 575.6800000000001,
      "end": 580.48,
      "text": " So in 15.3 and this milestone as well,",
      "tokens": [
        50426,
        407,
        294,
        2119,
        13,
        18,
        293,
        341,
        28048,
        382,
        731,
        11,
        50666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 151,
      "seek": 57444,
      "start": 580.48,
      "end": 582.8000000000001,
      "text": " like the remaining week, I'll be focusing",
      "tokens": [
        50666,
        411,
        264,
        8877,
        1243,
        11,
        286,
        603,
        312,
        8416,
        50782
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 152,
      "seek": 57444,
      "start": 582.8000000000001,
      "end": 586.4000000000001,
      "text": " on the pipeline components and the solution validation.",
      "tokens": [
        50782,
        322,
        264,
        15517,
        6677,
        293,
        264,
        3827,
        24071,
        13,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 153,
      "seek": 57444,
      "start": 586.4000000000001,
      "end": 588.48,
      "text": " Currently, I'm finishing up the interviews",
      "tokens": [
        50962,
        19964,
        11,
        286,
        478,
        12693,
        493,
        264,
        12318,
        51066
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 154,
      "seek": 57444,
      "start": 588.48,
      "end": 590.36,
      "text": " with internal users.",
      "tokens": [
        51066,
        365,
        6920,
        5022,
        13,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 155,
      "seek": 57444,
      "start": 590.36,
      "end": 593.6800000000001,
      "text": " And I've been talking to a lot of the members",
      "tokens": [
        51160,
        400,
        286,
        600,
        668,
        1417,
        281,
        257,
        688,
        295,
        264,
        2679,
        51326
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 156,
      "seek": 57444,
      "start": 593.6800000000001,
      "end": 595.84,
      "text": " of our productivity engineering team.",
      "tokens": [
        51326,
        295,
        527,
        15604,
        7043,
        1469,
        13,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 157,
      "seek": 57444,
      "start": 595.84,
      "end": 598.32,
      "text": " And so far, the feedback that we've been getting",
      "tokens": [
        51434,
        400,
        370,
        1400,
        11,
        264,
        5824,
        300,
        321,
        600,
        668,
        1242,
        51558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 158,
      "seek": 57444,
      "start": 598.32,
      "end": 602.5600000000001,
      "text": " has been very positive on our proposal.",
      "tokens": [
        51558,
        575,
        668,
        588,
        3353,
        322,
        527,
        11494,
        13,
        51770
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19213379130643957,
      "compression_ratio": 1.5609756097560976,
      "no_speech_prob": 0.004961566999554634
    },
    {
      "id": 159,
      "seek": 60256,
      "start": 602.56,
      "end": 606.2399999999999,
      "text": " We are getting lots of ideas for improving",
      "tokens": [
        50364,
        492,
        366,
        1242,
        3195,
        295,
        3487,
        337,
        11470,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18730567603982906,
      "compression_ratio": 1.6261261261261262,
      "no_speech_prob": 0.0007007511449046433
    },
    {
      "id": 160,
      "seek": 60256,
      "start": 606.2399999999999,
      "end": 608.68,
      "text": " the further iteration of the future.",
      "tokens": [
        50548,
        264,
        3052,
        24784,
        295,
        264,
        2027,
        13,
        50670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18730567603982906,
      "compression_ratio": 1.6261261261261262,
      "no_speech_prob": 0.0007007511449046433
    },
    {
      "id": 161,
      "seek": 60256,
      "start": 608.68,
      "end": 614.8399999999999,
      "text": " But it seems like our direction, a lot of the choices",
      "tokens": [
        50670,
        583,
        309,
        2544,
        411,
        527,
        3513,
        11,
        257,
        688,
        295,
        264,
        7994,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18730567603982906,
      "compression_ratio": 1.6261261261261262,
      "no_speech_prob": 0.0007007511449046433
    },
    {
      "id": 162,
      "seek": 60256,
      "start": 614.8399999999999,
      "end": 619.0799999999999,
      "text": " that we've made so far are on track and seem",
      "tokens": [
        50978,
        300,
        321,
        600,
        1027,
        370,
        1400,
        366,
        322,
        2837,
        293,
        1643,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18730567603982906,
      "compression_ratio": 1.6261261261261262,
      "no_speech_prob": 0.0007007511449046433
    },
    {
      "id": 163,
      "seek": 60256,
      "start": 619.0799999999999,
      "end": 620.88,
      "text": " like the desired behavior.",
      "tokens": [
        51190,
        411,
        264,
        14721,
        5223,
        13,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18730567603982906,
      "compression_ratio": 1.6261261261261262,
      "no_speech_prob": 0.0007007511449046433
    },
    {
      "id": 164,
      "seek": 60256,
      "start": 620.88,
      "end": 622.4799999999999,
      "text": " And also, there's a lot of interest",
      "tokens": [
        51280,
        400,
        611,
        11,
        456,
        311,
        257,
        688,
        295,
        1179,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18730567603982906,
      "compression_ratio": 1.6261261261261262,
      "no_speech_prob": 0.0007007511449046433
    },
    {
      "id": 165,
      "seek": 60256,
      "start": 622.4799999999999,
      "end": 625.64,
      "text": " from the engineering productivity team to dog food or product.",
      "tokens": [
        51360,
        490,
        264,
        7043,
        15604,
        1469,
        281,
        3000,
        1755,
        420,
        1674,
        13,
        51518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18730567603982906,
      "compression_ratio": 1.6261261261261262,
      "no_speech_prob": 0.0007007511449046433
    },
    {
      "id": 166,
      "seek": 60256,
      "start": 625.64,
      "end": 628.04,
      "text": " We already have an issue where we will be tracking that.",
      "tokens": [
        51518,
        492,
        1217,
        362,
        364,
        2734,
        689,
        321,
        486,
        312,
        11603,
        300,
        13,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18730567603982906,
      "compression_ratio": 1.6261261261261262,
      "no_speech_prob": 0.0007007511449046433
    },
    {
      "id": 167,
      "seek": 62804,
      "start": 628.04,
      "end": 632.9599999999999,
      "text": " So we expect that we'll start the implementation in 15.4.",
      "tokens": [
        50364,
        407,
        321,
        2066,
        300,
        321,
        603,
        722,
        264,
        11420,
        294,
        2119,
        13,
        19,
        13,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22471160155076247,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0005973740480840206
    },
    {
      "id": 168,
      "seek": 62804,
      "start": 632.9599999999999,
      "end": 635.64,
      "text": " If everything goes well, depends on how quickly",
      "tokens": [
        50610,
        759,
        1203,
        1709,
        731,
        11,
        5946,
        322,
        577,
        2661,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22471160155076247,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0005973740480840206
    },
    {
      "id": 169,
      "seek": 62804,
      "start": 635.64,
      "end": 638.0,
      "text": " we can go through the planning breakdown.",
      "tokens": [
        50744,
        321,
        393,
        352,
        807,
        264,
        5038,
        18188,
        13,
        50862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22471160155076247,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0005973740480840206
    },
    {
      "id": 170,
      "seek": 62804,
      "start": 638.0,
      "end": 639.88,
      "text": " Of course, there can be an first-seen challenges.",
      "tokens": [
        50862,
        2720,
        1164,
        11,
        456,
        393,
        312,
        364,
        700,
        12,
        22008,
        4759,
        13,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22471160155076247,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0005973740480840206
    },
    {
      "id": 171,
      "seek": 62804,
      "start": 639.88,
      "end": 641.56,
      "text": " But let's hope.",
      "tokens": [
        50956,
        583,
        718,
        311,
        1454,
        13,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22471160155076247,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0005973740480840206
    },
    {
      "id": 172,
      "seek": 62804,
      "start": 641.56,
      "end": 644.92,
      "text": " And then, yeah, and then we'll be able to dog food it",
      "tokens": [
        51040,
        400,
        550,
        11,
        1338,
        11,
        293,
        550,
        321,
        603,
        312,
        1075,
        281,
        3000,
        1755,
        309,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22471160155076247,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0005973740480840206
    },
    {
      "id": 173,
      "seek": 62804,
      "start": 644.92,
      "end": 647.04,
      "text": " with our productivity engineering team.",
      "tokens": [
        51208,
        365,
        527,
        15604,
        7043,
        1469,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22471160155076247,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0005973740480840206
    },
    {
      "id": 174,
      "seek": 62804,
      "start": 647.04,
      "end": 651.7199999999999,
      "text": " So they want to kind of move to our new system",
      "tokens": [
        51314,
        407,
        436,
        528,
        281,
        733,
        295,
        1286,
        281,
        527,
        777,
        1185,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22471160155076247,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0005973740480840206
    },
    {
      "id": 175,
      "seek": 62804,
      "start": 651.7199999999999,
      "end": 653.68,
      "text": " for creating pipeline components",
      "tokens": [
        51548,
        337,
        4084,
        15517,
        6677,
        51646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22471160155076247,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0005973740480840206
    },
    {
      "id": 176,
      "seek": 65368,
      "start": 653.76,
      "end": 660.1999999999999,
      "text": " and use our feature to standardize their components",
      "tokens": [
        50368,
        293,
        764,
        527,
        4111,
        281,
        3832,
        1125,
        641,
        6677,
        50690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19353466723338666,
      "compression_ratio": 1.4805825242718447,
      "no_speech_prob": 0.0008390908478759229
    },
    {
      "id": 177,
      "seek": 65368,
      "start": 660.1999999999999,
      "end": 662.28,
      "text": " or CI templates.",
      "tokens": [
        50690,
        420,
        37777,
        21165,
        13,
        50794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19353466723338666,
      "compression_ratio": 1.4805825242718447,
      "no_speech_prob": 0.0008390908478759229
    },
    {
      "id": 178,
      "seek": 65368,
      "start": 662.28,
      "end": 664.2399999999999,
      "text": " So yeah, all of this is very exciting",
      "tokens": [
        50794,
        407,
        1338,
        11,
        439,
        295,
        341,
        307,
        588,
        4670,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19353466723338666,
      "compression_ratio": 1.4805825242718447,
      "no_speech_prob": 0.0008390908478759229
    },
    {
      "id": 179,
      "seek": 65368,
      "start": 664.2399999999999,
      "end": 667.2399999999999,
      "text": " because we can really see how we'll be getting this",
      "tokens": [
        50892,
        570,
        321,
        393,
        534,
        536,
        577,
        321,
        603,
        312,
        1242,
        341,
        51042
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19353466723338666,
      "compression_ratio": 1.4805825242718447,
      "no_speech_prob": 0.0008390908478759229
    },
    {
      "id": 180,
      "seek": 65368,
      "start": 667.2399999999999,
      "end": 671.16,
      "text": " into the actual product and dog fooding it with our own team.",
      "tokens": [
        51042,
        666,
        264,
        3539,
        1674,
        293,
        3000,
        1755,
        278,
        309,
        365,
        527,
        1065,
        1469,
        13,
        51238
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19353466723338666,
      "compression_ratio": 1.4805825242718447,
      "no_speech_prob": 0.0008390908478759229
    },
    {
      "id": 181,
      "seek": 65368,
      "start": 674.7199999999999,
      "end": 676.3599999999999,
      "text": " I can't not have been there.",
      "tokens": [
        51416,
        286,
        393,
        380,
        406,
        362,
        668,
        456,
        13,
        51498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19353466723338666,
      "compression_ratio": 1.4805825242718447,
      "no_speech_prob": 0.0008390908478759229
    },
    {
      "id": 182,
      "seek": 65368,
      "start": 676.3599999999999,
      "end": 680.3199999999999,
      "text": " So I wonder if you could think about setting up a quick",
      "tokens": [
        51498,
        407,
        286,
        2441,
        498,
        291,
        727,
        519,
        466,
        3287,
        493,
        257,
        1702,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19353466723338666,
      "compression_ratio": 1.4805825242718447,
      "no_speech_prob": 0.0008390908478759229
    },
    {
      "id": 183,
      "seek": 68032,
      "start": 680.32,
      "end": 685.2800000000001,
      "text": " and just real quick lightweight diary study for them",
      "tokens": [
        50364,
        293,
        445,
        957,
        1702,
        22052,
        26492,
        2979,
        337,
        552,
        50612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 184,
      "seek": 68032,
      "start": 685.2800000000001,
      "end": 688.4000000000001,
      "text": " or like a Slack bot where you ask them,",
      "tokens": [
        50612,
        420,
        411,
        257,
        37211,
        10592,
        689,
        291,
        1029,
        552,
        11,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 185,
      "seek": 68032,
      "start": 688.4000000000001,
      "end": 691.1600000000001,
      "text": " like, what did you use it for today?",
      "tokens": [
        50768,
        411,
        11,
        437,
        630,
        291,
        764,
        309,
        337,
        965,
        30,
        50906
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 186,
      "seek": 68032,
      "start": 691.1600000000001,
      "end": 693.2,
      "text": " Or like, what went well?",
      "tokens": [
        50906,
        1610,
        411,
        11,
        437,
        1437,
        731,
        30,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 187,
      "seek": 68032,
      "start": 693.2,
      "end": 694.84,
      "text": " What could have gone better?",
      "tokens": [
        51008,
        708,
        727,
        362,
        2780,
        1101,
        30,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 188,
      "seek": 68032,
      "start": 694.84,
      "end": 696.9200000000001,
      "text": " Just to stream my in that feedback",
      "tokens": [
        51090,
        1449,
        281,
        4309,
        452,
        294,
        300,
        5824,
        51194
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 189,
      "seek": 68032,
      "start": 696.9200000000001,
      "end": 698.96,
      "text": " and make less work for you?",
      "tokens": [
        51194,
        293,
        652,
        1570,
        589,
        337,
        291,
        30,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 190,
      "seek": 68032,
      "start": 700.12,
      "end": 702.72,
      "text": " I really like the idea of a Slack bot.",
      "tokens": [
        51354,
        286,
        534,
        411,
        264,
        1558,
        295,
        257,
        37211,
        10592,
        13,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 191,
      "seek": 68032,
      "start": 702.72,
      "end": 705.0,
      "text": " It hasn't occurred to me to do something like that.",
      "tokens": [
        51484,
        467,
        6132,
        380,
        11068,
        281,
        385,
        281,
        360,
        746,
        411,
        300,
        13,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 192,
      "seek": 68032,
      "start": 705.0,
      "end": 708.8000000000001,
      "text": " My initial idea was to just have an issue,",
      "tokens": [
        51598,
        1222,
        5883,
        1558,
        390,
        281,
        445,
        362,
        364,
        2734,
        11,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22523202029141512,
      "compression_ratio": 1.6101694915254237,
      "no_speech_prob": 0.01188565045595169
    },
    {
      "id": 193,
      "seek": 70880,
      "start": 708.8,
      "end": 712.0,
      "text": " but I see how having something Slack like that",
      "tokens": [
        50364,
        457,
        286,
        536,
        577,
        1419,
        746,
        37211,
        411,
        300,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 194,
      "seek": 70880,
      "start": 712.0,
      "end": 714.3199999999999,
      "text": " would be much easier for the engineers",
      "tokens": [
        50524,
        576,
        312,
        709,
        3571,
        337,
        264,
        11955,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 195,
      "seek": 70880,
      "start": 714.3199999999999,
      "end": 716.4799999999999,
      "text": " to kind of just type their feedback in.",
      "tokens": [
        50640,
        281,
        733,
        295,
        445,
        2010,
        641,
        5824,
        294,
        13,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 196,
      "seek": 70880,
      "start": 716.4799999999999,
      "end": 718.24,
      "text": " So maybe there's a way to somehow connect it.",
      "tokens": [
        50748,
        407,
        1310,
        456,
        311,
        257,
        636,
        281,
        6063,
        1745,
        309,
        13,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 197,
      "seek": 70880,
      "start": 718.24,
      "end": 722.0799999999999,
      "text": " Maybe have a Slack bot and then somehow pull all of that",
      "tokens": [
        50836,
        2704,
        362,
        257,
        37211,
        10592,
        293,
        550,
        6063,
        2235,
        439,
        295,
        300,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 198,
      "seek": 70880,
      "start": 722.0799999999999,
      "end": 724.8399999999999,
      "text": " into the issue because I want to make sure I can actually",
      "tokens": [
        51028,
        666,
        264,
        2734,
        570,
        286,
        528,
        281,
        652,
        988,
        286,
        393,
        767,
        51166
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 199,
      "seek": 70880,
      "start": 724.8399999999999,
      "end": 727.76,
      "text": " like grab all of that information that is coming in",
      "tokens": [
        51166,
        411,
        4444,
        439,
        295,
        300,
        1589,
        300,
        307,
        1348,
        294,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 200,
      "seek": 70880,
      "start": 727.76,
      "end": 730.9599999999999,
      "text": " and have a document is somewhere.",
      "tokens": [
        51312,
        293,
        362,
        257,
        4166,
        307,
        4079,
        13,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 201,
      "seek": 70880,
      "start": 730.9599999999999,
      "end": 733.4399999999999,
      "text": " But yeah, I think it's a really good idea.",
      "tokens": [
        51472,
        583,
        1338,
        11,
        286,
        519,
        309,
        311,
        257,
        534,
        665,
        1558,
        13,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 202,
      "seek": 70880,
      "start": 735.16,
      "end": 737.4,
      "text": " Yeah, just like yeah, what went well?",
      "tokens": [
        51682,
        865,
        11,
        445,
        411,
        1338,
        11,
        437,
        1437,
        731,
        30,
        51794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16576697609641336,
      "compression_ratio": 1.6715867158671587,
      "no_speech_prob": 0.00018884535529650748
    },
    {
      "id": 203,
      "seek": 73740,
      "start": 737.4,
      "end": 738.36,
      "text": " What didn't go well?",
      "tokens": [
        50364,
        708,
        994,
        380,
        352,
        731,
        30,
        50412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 204,
      "seek": 73740,
      "start": 738.36,
      "end": 739.28,
      "text": " What was your goal?",
      "tokens": [
        50412,
        708,
        390,
        428,
        3387,
        30,
        50458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 205,
      "seek": 73740,
      "start": 742.12,
      "end": 742.88,
      "text": " Awesome.",
      "tokens": [
        50600,
        10391,
        13,
        50638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 206,
      "seek": 73740,
      "start": 742.88,
      "end": 743.9599999999999,
      "text": " Thanks, Erica.",
      "tokens": [
        50638,
        2561,
        11,
        37429,
        13,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 207,
      "seek": 73740,
      "start": 743.9599999999999,
      "end": 746.3199999999999,
      "text": " Always with your nuggets of wisdom.",
      "tokens": [
        50692,
        11270,
        365,
        428,
        42663,
        295,
        10712,
        13,
        50810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 208,
      "seek": 73740,
      "start": 746.3199999999999,
      "end": 747.16,
      "text": " I love it.",
      "tokens": [
        50810,
        286,
        959,
        309,
        13,
        50852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 209,
      "seek": 73740,
      "start": 747.16,
      "end": 748.16,
      "text": " Okay.",
      "tokens": [
        50852,
        1033,
        13,
        50902
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 210,
      "seek": 73740,
      "start": 751.4,
      "end": 754.1999999999999,
      "text": " Another thing I wanted to share is around",
      "tokens": [
        51064,
        3996,
        551,
        286,
        1415,
        281,
        2073,
        307,
        926,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 211,
      "seek": 73740,
      "start": 754.1999999999999,
      "end": 757.24,
      "text": " the recently edited guidelines for in product reference",
      "tokens": [
        51204,
        264,
        3938,
        23016,
        12470,
        337,
        294,
        1674,
        6408,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 212,
      "seek": 73740,
      "start": 757.24,
      "end": 759.28,
      "text": " information using drawers.",
      "tokens": [
        51356,
        1589,
        1228,
        38302,
        13,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 213,
      "seek": 73740,
      "start": 759.28,
      "end": 761.6,
      "text": " So with edits and really basic guidelines,",
      "tokens": [
        51458,
        407,
        365,
        41752,
        293,
        534,
        3875,
        12470,
        11,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 214,
      "seek": 73740,
      "start": 761.6,
      "end": 765.0,
      "text": " I was lining what kind of content you should put",
      "tokens": [
        51574,
        286,
        390,
        19628,
        437,
        733,
        295,
        2701,
        291,
        820,
        829,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 215,
      "seek": 73740,
      "start": 765.0,
      "end": 766.68,
      "text": " into the drawers, what kind of content",
      "tokens": [
        51744,
        666,
        264,
        38302,
        11,
        437,
        733,
        295,
        2701,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33514763758732724,
      "compression_ratio": 1.5805084745762712,
      "no_speech_prob": 0.0005015358910895884
    },
    {
      "id": 216,
      "seek": 76668,
      "start": 766.68,
      "end": 768.8,
      "text": " you shouldn't put into the drawers",
      "tokens": [
        50364,
        291,
        4659,
        380,
        829,
        666,
        264,
        38302,
        50470
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 217,
      "seek": 76668,
      "start": 768.8,
      "end": 772.04,
      "text": " and how all of that can be implemented",
      "tokens": [
        50470,
        293,
        577,
        439,
        295,
        300,
        393,
        312,
        12270,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 218,
      "seek": 76668,
      "start": 772.04,
      "end": 775.56,
      "text": " either by pulling in the documentation directly",
      "tokens": [
        50632,
        2139,
        538,
        8407,
        294,
        264,
        14333,
        3838,
        50808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 219,
      "seek": 76668,
      "start": 775.56,
      "end": 779.4399999999999,
      "text": " to the drawer or you can also have your own custom content",
      "tokens": [
        50808,
        281,
        264,
        24039,
        420,
        291,
        393,
        611,
        362,
        428,
        1065,
        2375,
        2701,
        51002
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 220,
      "seek": 76668,
      "start": 779.4399999999999,
      "end": 780.28,
      "text": " that you write,",
      "tokens": [
        51002,
        300,
        291,
        2464,
        11,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 221,
      "seek": 76668,
      "start": 780.28,
      "end": 783.68,
      "text": " but it still has to adhere to the content guidelines",
      "tokens": [
        51044,
        457,
        309,
        920,
        575,
        281,
        33584,
        281,
        264,
        2701,
        12470,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 222,
      "seek": 76668,
      "start": 783.68,
      "end": 785.2399999999999,
      "text": " for our documentation.",
      "tokens": [
        51214,
        337,
        527,
        14333,
        13,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 223,
      "seek": 76668,
      "start": 786.16,
      "end": 790.52,
      "text": " And we want to actually store it in a markdown file",
      "tokens": [
        51338,
        400,
        321,
        528,
        281,
        767,
        3531,
        309,
        294,
        257,
        1491,
        5093,
        3991,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 224,
      "seek": 76668,
      "start": 790.52,
      "end": 792.7199999999999,
      "text": " in the docs repository.",
      "tokens": [
        51556,
        294,
        264,
        45623,
        25841,
        13,
        51666
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 225,
      "seek": 76668,
      "start": 792.7199999999999,
      "end": 795.92,
      "text": " That is being done to ensure that we can actually test",
      "tokens": [
        51666,
        663,
        307,
        885,
        1096,
        281,
        5586,
        300,
        321,
        393,
        767,
        1500,
        51826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1855452668433096,
      "compression_ratio": 1.7370689655172413,
      "no_speech_prob": 0.00020234171824995428
    },
    {
      "id": 226,
      "seek": 79592,
      "start": 795.92,
      "end": 800.0799999999999,
      "text": " the changes to help content using the documentation pipeline",
      "tokens": [
        50364,
        264,
        2962,
        281,
        854,
        2701,
        1228,
        264,
        14333,
        15517,
        50572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 227,
      "seek": 79592,
      "start": 800.0799999999999,
      "end": 803.4799999999999,
      "text": " because it does all kinds of helpful waiting and whatnot.",
      "tokens": [
        50572,
        570,
        309,
        775,
        439,
        3685,
        295,
        4961,
        3806,
        293,
        25882,
        13,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 228,
      "seek": 79592,
      "start": 804.7199999999999,
      "end": 806.68,
      "text": " So following up on that,",
      "tokens": [
        50804,
        407,
        3480,
        493,
        322,
        300,
        11,
        50902
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 229,
      "seek": 79592,
      "start": 806.68,
      "end": 808.8399999999999,
      "text": " I'm revisiting the pipeline editor drawer",
      "tokens": [
        50902,
        286,
        478,
        20767,
        1748,
        264,
        15517,
        9839,
        24039,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 230,
      "seek": 79592,
      "start": 808.8399999999999,
      "end": 811.1999999999999,
      "text": " to make it more helpful to our users.",
      "tokens": [
        51010,
        281,
        652,
        309,
        544,
        4961,
        281,
        527,
        5022,
        13,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 231,
      "seek": 79592,
      "start": 811.1999999999999,
      "end": 814.3199999999999,
      "text": " So there's been a lot of hype around the pipeline editor drawer.",
      "tokens": [
        51128,
        407,
        456,
        311,
        668,
        257,
        688,
        295,
        24144,
        926,
        264,
        15517,
        9839,
        24039,
        13,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 232,
      "seek": 79592,
      "start": 814.3199999999999,
      "end": 817.64,
      "text": " I feel like like so many people were interested in it",
      "tokens": [
        51284,
        286,
        841,
        411,
        411,
        370,
        867,
        561,
        645,
        3102,
        294,
        309,
        51450
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 233,
      "seek": 79592,
      "start": 817.64,
      "end": 819.5999999999999,
      "text": " like, oh, it's so nice.",
      "tokens": [
        51450,
        411,
        11,
        1954,
        11,
        309,
        311,
        370,
        1481,
        13,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 234,
      "seek": 79592,
      "start": 819.5999999999999,
      "end": 822.16,
      "text": " It's this help info and then we start tracking it.",
      "tokens": [
        51548,
        467,
        311,
        341,
        854,
        13614,
        293,
        550,
        321,
        722,
        11603,
        309,
        13,
        51676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 235,
      "seek": 79592,
      "start": 822.16,
      "end": 823.28,
      "text": " It's youthish.",
      "tokens": [
        51676,
        467,
        311,
        7503,
        742,
        13,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18117501817900558,
      "compression_ratio": 1.728,
      "no_speech_prob": 7.062785152811557e-05
    },
    {
      "id": 236,
      "seek": 82328,
      "start": 823.28,
      "end": 829.76,
      "text": " And honestly, it's very low compared to the oral pipeline editor usage.",
      "tokens": [
        50364,
        400,
        6095,
        11,
        309,
        311,
        588,
        2295,
        5347,
        281,
        264,
        19338,
        15517,
        9839,
        14924,
        13,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3488713370429145,
      "compression_ratio": 1.539906103286385,
      "no_speech_prob": 0.001571837579831481
    },
    {
      "id": 237,
      "seek": 82328,
      "start": 829.76,
      "end": 833.64,
      "text": " And I think there could be like many different ways to interpret it.",
      "tokens": [
        50688,
        400,
        286,
        519,
        456,
        727,
        312,
        411,
        867,
        819,
        2098,
        281,
        7302,
        309,
        13,
        50882
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3488713370429145,
      "compression_ratio": 1.539906103286385,
      "no_speech_prob": 0.001571837579831481
    },
    {
      "id": 238,
      "seek": 82328,
      "start": 833.64,
      "end": 835.64,
      "text": " Like maybe our users just those toggle",
      "tokens": [
        50882,
        1743,
        1310,
        527,
        5022,
        445,
        729,
        31225,
        50982
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3488713370429145,
      "compression_ratio": 1.539906103286385,
      "no_speech_prob": 0.001571837579831481
    },
    {
      "id": 239,
      "seek": 82328,
      "start": 835.64,
      "end": 839.12,
      "text": " when they're going through the flow,",
      "tokens": [
        50982,
        562,
        436,
        434,
        516,
        807,
        264,
        3095,
        11,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3488713370429145,
      "compression_ratio": 1.539906103286385,
      "no_speech_prob": 0.001571837579831481
    },
    {
      "id": 240,
      "seek": 82328,
      "start": 839.12,
      "end": 841.88,
      "text": " which I don't think is the case.",
      "tokens": [
        51156,
        597,
        286,
        500,
        380,
        519,
        307,
        264,
        1389,
        13,
        51294
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3488713370429145,
      "compression_ratio": 1.539906103286385,
      "no_speech_prob": 0.001571837579831481
    },
    {
      "id": 241,
      "seek": 82328,
      "start": 841.88,
      "end": 844.1999999999999,
      "text": " Or also maybe it's not very discoverable.",
      "tokens": [
        51294,
        1610,
        611,
        1310,
        309,
        311,
        406,
        588,
        4411,
        712,
        13,
        51410
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3488713370429145,
      "compression_ratio": 1.539906103286385,
      "no_speech_prob": 0.001571837579831481
    },
    {
      "id": 242,
      "seek": 82328,
      "start": 844.1999999999999,
      "end": 847.9599999999999,
      "text": " It's not tied to a piece of the cat.",
      "tokens": [
        51410,
        467,
        311,
        406,
        9601,
        281,
        257,
        2522,
        295,
        264,
        3857,
        13,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3488713370429145,
      "compression_ratio": 1.539906103286385,
      "no_speech_prob": 0.001571837579831481
    },
    {
      "id": 243,
      "seek": 84796,
      "start": 848.2800000000001,
      "end": 854.88,
      "text": " I mean, maybe it's not tied to a specific task that they're working on.",
      "tokens": [
        50380,
        286,
        914,
        11,
        1310,
        309,
        311,
        406,
        9601,
        281,
        257,
        2685,
        5633,
        300,
        436,
        434,
        1364,
        322,
        13,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18125898648152308,
      "compression_ratio": 1.716,
      "no_speech_prob": 0.0006536489236168563
    },
    {
      "id": 244,
      "seek": 84796,
      "start": 854.88,
      "end": 859.48,
      "text": " So there's, yeah, we're kind of like not helping them with something specific.",
      "tokens": [
        50710,
        407,
        456,
        311,
        11,
        1338,
        11,
        321,
        434,
        733,
        295,
        411,
        406,
        4315,
        552,
        365,
        746,
        2685,
        13,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18125898648152308,
      "compression_ratio": 1.716,
      "no_speech_prob": 0.0006536489236168563
    },
    {
      "id": 245,
      "seek": 84796,
      "start": 859.48,
      "end": 860.6,
      "text": " It's very generic.",
      "tokens": [
        50940,
        467,
        311,
        588,
        19577,
        13,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18125898648152308,
      "compression_ratio": 1.716,
      "no_speech_prob": 0.0006536489236168563
    },
    {
      "id": 246,
      "seek": 84796,
      "start": 860.6,
      "end": 863.48,
      "text": " And if you look at the guidelines that we put in place,",
      "tokens": [
        50996,
        400,
        498,
        291,
        574,
        412,
        264,
        12470,
        300,
        321,
        829,
        294,
        1081,
        11,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18125898648152308,
      "compression_ratio": 1.716,
      "no_speech_prob": 0.0006536489236168563
    },
    {
      "id": 247,
      "seek": 84796,
      "start": 863.48,
      "end": 866.96,
      "text": " we're saying that we shouldn't create generic health drawers.",
      "tokens": [
        51140,
        321,
        434,
        1566,
        300,
        321,
        4659,
        380,
        1884,
        19577,
        1585,
        38302,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18125898648152308,
      "compression_ratio": 1.716,
      "no_speech_prob": 0.0006536489236168563
    },
    {
      "id": 248,
      "seek": 84796,
      "start": 866.96,
      "end": 870.9200000000001,
      "text": " Like here's help on all kinds of topics that you might think of.",
      "tokens": [
        51314,
        1743,
        510,
        311,
        854,
        322,
        439,
        3685,
        295,
        8378,
        300,
        291,
        1062,
        519,
        295,
        13,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18125898648152308,
      "compression_ratio": 1.716,
      "no_speech_prob": 0.0006536489236168563
    },
    {
      "id": 249,
      "seek": 84796,
      "start": 870.9200000000001,
      "end": 876.2800000000001,
      "text": " Instead, it should be tied to helping the user perform a very specific task.",
      "tokens": [
        51512,
        7156,
        11,
        309,
        820,
        312,
        9601,
        281,
        4315,
        264,
        4195,
        2042,
        257,
        588,
        2685,
        5633,
        13,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18125898648152308,
      "compression_ratio": 1.716,
      "no_speech_prob": 0.0006536489236168563
    },
    {
      "id": 250,
      "seek": 87628,
      "start": 876.28,
      "end": 882.76,
      "text": " So, yeah, basically I want to like take a deeper dive on the metrics that we've got.",
      "tokens": [
        50364,
        407,
        11,
        1338,
        11,
        1936,
        286,
        528,
        281,
        411,
        747,
        257,
        7731,
        9192,
        322,
        264,
        16367,
        300,
        321,
        600,
        658,
        13,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26108405516319666,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.0001396875159116462
    },
    {
      "id": 251,
      "seek": 87628,
      "start": 882.76,
      "end": 886.68,
      "text": " Because we also start getting metrics and all of the links inside the drawer.",
      "tokens": [
        50688,
        1436,
        321,
        611,
        722,
        1242,
        16367,
        293,
        439,
        295,
        264,
        6123,
        1854,
        264,
        24039,
        13,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26108405516319666,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.0001396875159116462
    },
    {
      "id": 252,
      "seek": 87628,
      "start": 886.68,
      "end": 893.8399999999999,
      "text": " So we can see when the user clicks into the drawer itself, what are they reading about?",
      "tokens": [
        50884,
        407,
        321,
        393,
        536,
        562,
        264,
        4195,
        18521,
        666,
        264,
        24039,
        2564,
        11,
        437,
        366,
        436,
        3760,
        466,
        30,
        51242
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26108405516319666,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.0001396875159116462
    },
    {
      "id": 253,
      "seek": 87628,
      "start": 893.8399999999999,
      "end": 898.8,
      "text": " And so far, it looks like the leading links are CI example.",
      "tokens": [
        51242,
        400,
        370,
        1400,
        11,
        309,
        1542,
        411,
        264,
        5775,
        6123,
        366,
        37777,
        1365,
        13,
        51490
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26108405516319666,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.0001396875159116462
    },
    {
      "id": 254,
      "seek": 87628,
      "start": 898.8,
      "end": 904.76,
      "text": " And also the YAML reference, which is something that we would expect.",
      "tokens": [
        51490,
        400,
        611,
        264,
        398,
        2865,
        43,
        6408,
        11,
        597,
        307,
        746,
        300,
        321,
        576,
        2066,
        13,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26108405516319666,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.0001396875159116462
    },
    {
      "id": 255,
      "seek": 90476,
      "start": 904.76,
      "end": 909.76,
      "text": " Let's start it. I have to repair off.",
      "tokens": [
        50364,
        961,
        311,
        722,
        309,
        13,
        286,
        362,
        281,
        10535,
        766,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29633331298828125,
      "compression_ratio": 1.45,
      "no_speech_prob": 0.00041276332922279835
    },
    {
      "id": 256,
      "seek": 90476,
      "start": 909.76,
      "end": 911.0,
      "text": " It's my first step on you, Cat.",
      "tokens": [
        50614,
        467,
        311,
        452,
        700,
        1823,
        322,
        291,
        11,
        9565,
        13,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29633331298828125,
      "compression_ratio": 1.45,
      "no_speech_prob": 0.00041276332922279835
    },
    {
      "id": 257,
      "seek": 90476,
      "start": 911.0,
      "end": 912.52,
      "text": " I can't discipline her.",
      "tokens": [
        50676,
        286,
        393,
        380,
        13635,
        720,
        13,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29633331298828125,
      "compression_ratio": 1.45,
      "no_speech_prob": 0.00041276332922279835
    },
    {
      "id": 258,
      "seek": 90476,
      "start": 912.52,
      "end": 916.92,
      "text": " She's just climbing a lottery.",
      "tokens": [
        50752,
        1240,
        311,
        445,
        14780,
        257,
        27391,
        13,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29633331298828125,
      "compression_ratio": 1.45,
      "no_speech_prob": 0.00041276332922279835
    },
    {
      "id": 259,
      "seek": 90476,
      "start": 916.92,
      "end": 920.3199999999999,
      "text": " Yeah, so I want to take all of this data.",
      "tokens": [
        50972,
        865,
        11,
        370,
        286,
        528,
        281,
        747,
        439,
        295,
        341,
        1412,
        13,
        51142
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29633331298828125,
      "compression_ratio": 1.45,
      "no_speech_prob": 0.00041276332922279835
    },
    {
      "id": 260,
      "seek": 90476,
      "start": 920.3199999999999,
      "end": 925.36,
      "text": " And I don't know, maybe we could do some additional solution validation as well",
      "tokens": [
        51142,
        400,
        286,
        500,
        380,
        458,
        11,
        1310,
        321,
        727,
        360,
        512,
        4497,
        3827,
        24071,
        382,
        731,
        51394
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29633331298828125,
      "compression_ratio": 1.45,
      "no_speech_prob": 0.00041276332922279835
    },
    {
      "id": 261,
      "seek": 90476,
      "start": 925.36,
      "end": 928.56,
      "text": " together some qualitative data around this.",
      "tokens": [
        51394,
        1214,
        512,
        31312,
        1412,
        926,
        341,
        13,
        51554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29633331298828125,
      "compression_ratio": 1.45,
      "no_speech_prob": 0.00041276332922279835
    },
    {
      "id": 262,
      "seek": 92856,
      "start": 928.64,
      "end": 937.16,
      "text": " But my next step I think would be to do some experimentation there with the content",
      "tokens": [
        50368,
        583,
        452,
        958,
        1823,
        286,
        519,
        576,
        312,
        281,
        360,
        512,
        37142,
        456,
        365,
        264,
        2701,
        50794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23774706033559945,
      "compression_ratio": 1.46448087431694,
      "no_speech_prob": 0.000183525204192847
    },
    {
      "id": 263,
      "seek": 92856,
      "start": 937.16,
      "end": 942.4799999999999,
      "text": " and try different ways of surfacing different information.",
      "tokens": [
        50794,
        293,
        853,
        819,
        2098,
        295,
        9684,
        5615,
        819,
        1589,
        13,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23774706033559945,
      "compression_ratio": 1.46448087431694,
      "no_speech_prob": 0.000183525204192847
    },
    {
      "id": 264,
      "seek": 92856,
      "start": 944.64,
      "end": 948.3199999999999,
      "text": " Yeah, so basically we learned that it seems like it's not.",
      "tokens": [
        51168,
        865,
        11,
        370,
        1936,
        321,
        3264,
        300,
        309,
        2544,
        411,
        309,
        311,
        406,
        13,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23774706033559945,
      "compression_ratio": 1.46448087431694,
      "no_speech_prob": 0.000183525204192847
    },
    {
      "id": 265,
      "seek": 92856,
      "start": 950.1199999999999,
      "end": 954.92,
      "text": " It's probably not helping our users as much as we thought it were.",
      "tokens": [
        51442,
        467,
        311,
        1391,
        406,
        4315,
        527,
        5022,
        382,
        709,
        382,
        321,
        1194,
        309,
        645,
        13,
        51682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23774706033559945,
      "compression_ratio": 1.46448087431694,
      "no_speech_prob": 0.000183525204192847
    },
    {
      "id": 266,
      "seek": 95492,
      "start": 954.92,
      "end": 958.4399999999999,
      "text": " So I will be looking into it and be able to do that.",
      "tokens": [
        50364,
        407,
        286,
        486,
        312,
        1237,
        666,
        309,
        293,
        312,
        1075,
        281,
        360,
        300,
        13,
        50540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3885995168534536,
      "compression_ratio": 1.3443708609271523,
      "no_speech_prob": 0.0008574872626923025
    },
    {
      "id": 267,
      "seek": 95492,
      "start": 958.4399999999999,
      "end": 960.04,
      "text": " Hopefully we can improve it from there.",
      "tokens": [
        50540,
        10429,
        321,
        393,
        3470,
        309,
        490,
        456,
        13,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3885995168534536,
      "compression_ratio": 1.3443708609271523,
      "no_speech_prob": 0.0008574872626923025
    },
    {
      "id": 268,
      "seek": 95492,
      "start": 969.76,
      "end": 970.76,
      "text": " Cool.",
      "tokens": [
        51106,
        8561,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3885995168534536,
      "compression_ratio": 1.3443708609271523,
      "no_speech_prob": 0.0008574872626923025
    },
    {
      "id": 269,
      "seek": 95492,
      "start": 970.76,
      "end": 974.56,
      "text": " Do we want to move on to the research section?",
      "tokens": [
        51156,
        1144,
        321,
        528,
        281,
        1286,
        322,
        281,
        264,
        2132,
        3541,
        30,
        51346
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3885995168534536,
      "compression_ratio": 1.3443708609271523,
      "no_speech_prob": 0.0008574872626923025
    },
    {
      "id": 270,
      "seek": 95492,
      "start": 978.8,
      "end": 981.48,
      "text": " Yeah, so just a general update.",
      "tokens": [
        51558,
        865,
        11,
        370,
        445,
        257,
        2674,
        5623,
        13,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3885995168534536,
      "compression_ratio": 1.3443708609271523,
      "no_speech_prob": 0.0008574872626923025
    },
    {
      "id": 271,
      "seek": 95492,
      "start": 981.48,
      "end": 982.64,
      "text": " There have been no shows.",
      "tokens": [
        51692,
        821,
        362,
        668,
        572,
        3110,
        13,
        51750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3885995168534536,
      "compression_ratio": 1.3443708609271523,
      "no_speech_prob": 0.0008574872626923025
    },
    {
      "id": 272,
      "seek": 98264,
      "start": 982.64,
      "end": 985.0,
      "text": " People are not showing to sessions.",
      "tokens": [
        50364,
        3432,
        366,
        406,
        4099,
        281,
        11081,
        13,
        50482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3107876410851112,
      "compression_ratio": 1.5070422535211268,
      "no_speech_prob": 0.0011507365852594376
    },
    {
      "id": 273,
      "seek": 98264,
      "start": 985.0,
      "end": 987.4,
      "text": " And it's actually just a larger trend.",
      "tokens": [
        50482,
        400,
        309,
        311,
        767,
        445,
        257,
        4833,
        6028,
        13,
        50602
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3107876410851112,
      "compression_ratio": 1.5070422535211268,
      "no_speech_prob": 0.0011507365852594376
    },
    {
      "id": 274,
      "seek": 98264,
      "start": 987.4,
      "end": 990.0,
      "text": " We think related to the changing of seasons.",
      "tokens": [
        50602,
        492,
        519,
        4077,
        281,
        264,
        4473,
        295,
        15050,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3107876410851112,
      "compression_ratio": 1.5070422535211268,
      "no_speech_prob": 0.0011507365852594376
    },
    {
      "id": 275,
      "seek": 98264,
      "start": 990.0,
      "end": 997.16,
      "text": " It's not you or our recruitment, it's just a general trend across all studies.",
      "tokens": [
        50732,
        467,
        311,
        406,
        291,
        420,
        527,
        28240,
        11,
        309,
        311,
        445,
        257,
        2674,
        6028,
        2108,
        439,
        5313,
        13,
        51090
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3107876410851112,
      "compression_ratio": 1.5070422535211268,
      "no_speech_prob": 0.0011507365852594376
    },
    {
      "id": 276,
      "seek": 98264,
      "start": 997.16,
      "end": 998.68,
      "text": " So I thought that would be helpful.",
      "tokens": [
        51090,
        407,
        286,
        1194,
        300,
        576,
        312,
        4961,
        13,
        51166
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3107876410851112,
      "compression_ratio": 1.5070422535211268,
      "no_speech_prob": 0.0011507365852594376
    },
    {
      "id": 277,
      "seek": 98264,
      "start": 1000.52,
      "end": 1004.52,
      "text": " And then I have just a couple of check ins.",
      "tokens": [
        51258,
        400,
        550,
        286,
        362,
        445,
        257,
        1916,
        295,
        1520,
        1028,
        13,
        51458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3107876410851112,
      "compression_ratio": 1.5070422535211268,
      "no_speech_prob": 0.0011507365852594376
    },
    {
      "id": 278,
      "seek": 98264,
      "start": 1005.52,
      "end": 1010.3199999999999,
      "text": " There are, oh, Nadia, do you want to talk?",
      "tokens": [
        51508,
        821,
        366,
        11,
        1954,
        11,
        23269,
        654,
        11,
        360,
        291,
        528,
        281,
        751,
        30,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3107876410851112,
      "compression_ratio": 1.5070422535211268,
      "no_speech_prob": 0.0011507365852594376
    },
    {
      "id": 279,
      "seek": 101264,
      "start": 1013.64,
      "end": 1015.64,
      "text": " No, I'm just making a joke.",
      "tokens": [
        50414,
        883,
        11,
        286,
        478,
        445,
        1455,
        257,
        7647,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45698841508612575,
      "compression_ratio": 1.5585106382978724,
      "no_speech_prob": 0.001466273213736713
    },
    {
      "id": 280,
      "seek": 101264,
      "start": 1015.64,
      "end": 1018.84,
      "text": " Maybe it's not a career retrograde or something.",
      "tokens": [
        50514,
        2704,
        309,
        311,
        406,
        257,
        3988,
        18820,
        8692,
        420,
        746,
        13,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45698841508612575,
      "compression_ratio": 1.5585106382978724,
      "no_speech_prob": 0.001466273213736713
    },
    {
      "id": 281,
      "seek": 101264,
      "start": 1018.84,
      "end": 1020.4399999999999,
      "text": " Exactly.",
      "tokens": [
        50674,
        7587,
        13,
        50754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45698841508612575,
      "compression_ratio": 1.5585106382978724,
      "no_speech_prob": 0.001466273213736713
    },
    {
      "id": 282,
      "seek": 101264,
      "start": 1024.44,
      "end": 1025.44,
      "text": " Okay.",
      "tokens": [
        50954,
        1033,
        13,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45698841508612575,
      "compression_ratio": 1.5585106382978724,
      "no_speech_prob": 0.001466273213736713
    },
    {
      "id": 283,
      "seek": 101264,
      "start": 1025.44,
      "end": 1032.6399999999999,
      "text": " And then, and then if you guys could go into and link the research,",
      "tokens": [
        51004,
        400,
        550,
        11,
        293,
        550,
        498,
        291,
        1074,
        727,
        352,
        666,
        293,
        2113,
        264,
        2132,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45698841508612575,
      "compression_ratio": 1.5585106382978724,
      "no_speech_prob": 0.001466273213736713
    },
    {
      "id": 284,
      "seek": 101264,
      "start": 1032.6399999999999,
      "end": 1036.24,
      "text": " the studies that you've been doing, yeah, the research studies you've been doing",
      "tokens": [
        51364,
        264,
        5313,
        300,
        291,
        600,
        668,
        884,
        11,
        1338,
        11,
        264,
        2132,
        5313,
        291,
        600,
        668,
        884,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45698841508612575,
      "compression_ratio": 1.5585106382978724,
      "no_speech_prob": 0.001466273213736713
    },
    {
      "id": 285,
      "seek": 101264,
      "start": 1036.24,
      "end": 1039.16,
      "text": " that I should include in the registry and synthesis.",
      "tokens": [
        51544,
        300,
        286,
        820,
        4090,
        294,
        264,
        36468,
        293,
        30252,
        13,
        51690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45698841508612575,
      "compression_ratio": 1.5585106382978724,
      "no_speech_prob": 0.001466273213736713
    },
    {
      "id": 286,
      "seek": 103916,
      "start": 1039.16,
      "end": 1043.3600000000001,
      "text": " I'm still really wanting to do that to kind of go through.",
      "tokens": [
        50364,
        286,
        478,
        920,
        534,
        7935,
        281,
        360,
        300,
        281,
        733,
        295,
        352,
        807,
        13,
        50574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2422172196057378,
      "compression_ratio": 1.5510204081632653,
      "no_speech_prob": 0.0004872648569289595
    },
    {
      "id": 287,
      "seek": 103916,
      "start": 1043.3600000000001,
      "end": 1050.44,
      "text": " So if you have them and you link them in that issue, that's where I go back through",
      "tokens": [
        50574,
        407,
        498,
        291,
        362,
        552,
        293,
        291,
        2113,
        552,
        294,
        300,
        2734,
        11,
        300,
        311,
        689,
        286,
        352,
        646,
        807,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2422172196057378,
      "compression_ratio": 1.5510204081632653,
      "no_speech_prob": 0.0004872648569289595
    },
    {
      "id": 288,
      "seek": 103916,
      "start": 1050.44,
      "end": 1058.44,
      "text": " and do like a, like a crosswalk of all the findings for the studies in terms of our big research questions.",
      "tokens": [
        50928,
        293,
        360,
        411,
        257,
        11,
        411,
        257,
        3278,
        12490,
        295,
        439,
        264,
        16483,
        337,
        264,
        5313,
        294,
        2115,
        295,
        527,
        955,
        2132,
        1651,
        13,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2422172196057378,
      "compression_ratio": 1.5510204081632653,
      "no_speech_prob": 0.0004872648569289595
    },
    {
      "id": 289,
      "seek": 103916,
      "start": 1058.44,
      "end": 1060.64,
      "text": " We like put those together when I first started.",
      "tokens": [
        51328,
        492,
        411,
        829,
        729,
        1214,
        562,
        286,
        700,
        1409,
        13,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2422172196057378,
      "compression_ratio": 1.5510204081632653,
      "no_speech_prob": 0.0004872648569289595
    },
    {
      "id": 290,
      "seek": 103916,
      "start": 1060.64,
      "end": 1066.52,
      "text": " And then because we validated our product direction with the, the KUMKON survey,",
      "tokens": [
        51438,
        400,
        550,
        570,
        321,
        40693,
        527,
        1674,
        3513,
        365,
        264,
        11,
        264,
        591,
        14340,
        42,
        1928,
        8984,
        11,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2422172196057378,
      "compression_ratio": 1.5510204081632653,
      "no_speech_prob": 0.0004872648569289595
    },
    {
      "id": 291,
      "seek": 106652,
      "start": 1066.52,
      "end": 1069.32,
      "text": " we're like good with those questions.",
      "tokens": [
        50364,
        321,
        434,
        411,
        665,
        365,
        729,
        1651,
        13,
        50504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891078391771636,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.0003764276916626841
    },
    {
      "id": 292,
      "seek": 106652,
      "start": 1069.32,
      "end": 1075.96,
      "text": " So it's just, if you have other studies that you've completed or when you do, just a reminder,",
      "tokens": [
        50504,
        407,
        309,
        311,
        445,
        11,
        498,
        291,
        362,
        661,
        5313,
        300,
        291,
        600,
        7365,
        420,
        562,
        291,
        360,
        11,
        445,
        257,
        13548,
        11,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891078391771636,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.0003764276916626841
    },
    {
      "id": 293,
      "seek": 106652,
      "start": 1075.96,
      "end": 1078.44,
      "text": " because I was kind of thinking about it.",
      "tokens": [
        50836,
        570,
        286,
        390,
        733,
        295,
        1953,
        466,
        309,
        13,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891078391771636,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.0003764276916626841
    },
    {
      "id": 294,
      "seek": 106652,
      "start": 1078.44,
      "end": 1086.12,
      "text": " And then if you can go back through and just take out the studies or either delete them from those tables",
      "tokens": [
        50960,
        400,
        550,
        498,
        291,
        393,
        352,
        646,
        807,
        293,
        445,
        747,
        484,
        264,
        5313,
        420,
        2139,
        12097,
        552,
        490,
        729,
        8020,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891078391771636,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.0003764276916626841
    },
    {
      "id": 295,
      "seek": 106652,
      "start": 1086.12,
      "end": 1089.6399999999999,
      "text": " or just say finished, that'd be good.",
      "tokens": [
        51344,
        420,
        445,
        584,
        4335,
        11,
        300,
        1116,
        312,
        665,
        13,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891078391771636,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.0003764276916626841
    },
    {
      "id": 296,
      "seek": 106652,
      "start": 1090.6,
      "end": 1092.08,
      "text": " Not, not.",
      "tokens": [
        51568,
        1726,
        11,
        406,
        13,
        51642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29891078391771636,
      "compression_ratio": 1.5497630331753554,
      "no_speech_prob": 0.0003764276916626841
    },
    {
      "id": 297,
      "seek": 109208,
      "start": 1093.04,
      "end": 1096.32,
      "text": " I won't beg you, but that'd be awesome, but it's not that great.",
      "tokens": [
        50412,
        286,
        1582,
        380,
        4612,
        291,
        11,
        457,
        300,
        1116,
        312,
        3476,
        11,
        457,
        309,
        311,
        406,
        300,
        869,
        13,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.259921992590668,
      "compression_ratio": 1.617391304347826,
      "no_speech_prob": 0.00037512017297558486
    },
    {
      "id": 298,
      "seek": 109208,
      "start": 1096.32,
      "end": 1099.12,
      "text": " I mean, you know, I can try to figure it out.",
      "tokens": [
        50576,
        286,
        914,
        11,
        291,
        458,
        11,
        286,
        393,
        853,
        281,
        2573,
        309,
        484,
        13,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.259921992590668,
      "compression_ratio": 1.617391304347826,
      "no_speech_prob": 0.00037512017297558486
    },
    {
      "id": 299,
      "seek": 109208,
      "start": 1100.3999999999999,
      "end": 1105.9199999999998,
      "text": " And then just also that our team looked just really great.",
      "tokens": [
        50780,
        400,
        550,
        445,
        611,
        300,
        527,
        1469,
        2956,
        445,
        534,
        869,
        13,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.259921992590668,
      "compression_ratio": 1.617391304347826,
      "no_speech_prob": 0.00037512017297558486
    },
    {
      "id": 300,
      "seek": 109208,
      "start": 1105.9199999999998,
      "end": 1109.9199999999998,
      "text": " So good job, everyone with the OptiProduction Survey.",
      "tokens": [
        51056,
        407,
        665,
        1691,
        11,
        1518,
        365,
        264,
        21455,
        72,
        47,
        2323,
        349,
        313,
        33365,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.259921992590668,
      "compression_ratio": 1.617391304347826,
      "no_speech_prob": 0.00037512017297558486
    },
    {
      "id": 301,
      "seek": 109208,
      "start": 1110.72,
      "end": 1115.4399999999998,
      "text": " If you look in that async issue, you can see that we're getting like all this cross-functional",
      "tokens": [
        51296,
        759,
        291,
        574,
        294,
        300,
        382,
        34015,
        2734,
        11,
        291,
        393,
        536,
        300,
        321,
        434,
        1242,
        411,
        439,
        341,
        3278,
        12,
        22845,
        304,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.259921992590668,
      "compression_ratio": 1.617391304347826,
      "no_speech_prob": 0.00037512017297558486
    },
    {
      "id": 302,
      "seek": 109208,
      "start": 1115.4399999999998,
      "end": 1119.04,
      "text": " feedback. And people are just saying like, great job.",
      "tokens": [
        51532,
        5824,
        13,
        400,
        561,
        366,
        445,
        1566,
        411,
        11,
        869,
        1691,
        13,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.259921992590668,
      "compression_ratio": 1.617391304347826,
      "no_speech_prob": 0.00037512017297558486
    },
    {
      "id": 303,
      "seek": 111904,
      "start": 1119.04,
      "end": 1123.84,
      "text": " You're, you're team did a great job on this. So, okay.",
      "tokens": [
        50364,
        509,
        434,
        11,
        291,
        434,
        1469,
        630,
        257,
        869,
        1691,
        322,
        341,
        13,
        407,
        11,
        1392,
        13,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3207676161581011,
      "compression_ratio": 1.308724832214765,
      "no_speech_prob": 0.0029604288283735514
    },
    {
      "id": 304,
      "seek": 111904,
      "start": 1129.84,
      "end": 1131.12,
      "text": " Nice.",
      "tokens": [
        50904,
        5490,
        13,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3207676161581011,
      "compression_ratio": 1.308724832214765,
      "no_speech_prob": 0.0029604288283735514
    },
    {
      "id": 305,
      "seek": 111904,
      "start": 1131.76,
      "end": 1134.56,
      "text": " Anyone have anything else they want to chat about?",
      "tokens": [
        51000,
        14643,
        362,
        1340,
        1646,
        436,
        528,
        281,
        5081,
        466,
        30,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3207676161581011,
      "compression_ratio": 1.308724832214765,
      "no_speech_prob": 0.0029604288283735514
    },
    {
      "id": 306,
      "seek": 111904,
      "start": 1138.6399999999999,
      "end": 1142.3999999999999,
      "text": " No? Okay, great. Well, thank you both.",
      "tokens": [
        51344,
        883,
        30,
        1033,
        11,
        869,
        13,
        1042,
        11,
        1309,
        291,
        1293,
        13,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3207676161581011,
      "compression_ratio": 1.308724832214765,
      "no_speech_prob": 0.0029604288283735514
    },
    {
      "id": 307,
      "seek": 111904,
      "start": 1143.12,
      "end": 1144.48,
      "text": " And yeah, speak to you soon.",
      "tokens": [
        51568,
        400,
        1338,
        11,
        1710,
        281,
        291,
        2321,
        13,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3207676161581011,
      "compression_ratio": 1.308724832214765,
      "no_speech_prob": 0.0029604288283735514
    },
    {
      "id": 308,
      "seek": 111904,
      "start": 1146.08,
      "end": 1147.2,
      "text": " All right. Bye.",
      "tokens": [
        51716,
        1057,
        558,
        13,
        4621,
        13,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3207676161581011,
      "compression_ratio": 1.308724832214765,
      "no_speech_prob": 0.0029604288283735514
    }
  ]
}