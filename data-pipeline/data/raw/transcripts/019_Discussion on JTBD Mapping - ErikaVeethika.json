{
  "title": "Discussion on JTBD Mapping - Erika/Veethika",
  "video_id": "-ff-yAFjFOE",
  "url": "https://www.youtube.com/watch?v=-ff-yAFjFOE",
  "transcript": " All right, so today, Erica and I are going to the process of mapping jobs. And I am taking the reference of the old mapping that I had done about one and a half years ago, which might not be perfect, but this is what we are going to base our discussion on. How I started with this mapping is I'm not sharing my screen and I totally should. All right, is it. Visible enough? Okay, great. So I started off with the kind of making a note of the core functional jobs that users come to perform when we are talking about all things verify. So at this stage, I was not even like focusing a lot on just pipe and execution or just continuous integration. I was thinking of everything that users would want to do with the features that we kind of group under verify. And from there, I consolidated the core jobs into this one particular statement and this statement says to standardize an automate tests builds and deploy process across organization to allow easy contribution while keeping them. The main branch screen, which is main branch, healthy. And I like kept this as a reference for the core job that we are going to be referring to. The next part was thinking of who would be executing the jobs. The circles in the innermost circle are the core executors. So for core executors, I thought of personas that we very frequently refer to like the DevOps engineers, the software engineer, the developer. And a little outside that circle on its periphery, I was imagining personnel such as system administrator compliance manager, release manager development team lead because in the process that release managers follow and compliance managers follow the processes, they are very much kind of around pipelines because pipelines enables the release process and. Following the compliance guidelines and then who else can use pipelines and related features. The idea is anybody can because taking a reference of a company like get love where we work. Everybody runs pipelines, everybody merges their changes, so everybody kind of interacts with that in their day to day job. I kind of skipped this part because I was not able to get a very good hang of like what's the value that this adding and I'm not saying that that was really great step on my part, but just stating that it wasn't. Coming to the job map part, so we have these stages which come predefined and I tried to segregate all the primary not primary, although jobs that were kind of that were documented here earlier into these buckets into these different stages, let's say. And I started off like if we talk about defining and we talk about pipelines, then what are the jobs, which are relevant at that stage and of course what's relevant is defining a new pipeline but to put it in a more functional way without. So focusing a lot on the tool and the exact mechanisms that we are providing today, so I wrote that defining standard standards tests and commands for organizations to test for the deploy. And as written keeping in mind that users have to author the pipeline before they can even like before they can do anything else for that then comes the part of locating so make a aware of available test suite or explain the process for using existing pipeline. And so on, so what I saw was since we had made this division in the responsibilities of the two stage groups, by the not string and by an execution and we mentioned that everything that relates to defining the pipeline or editing the pipeline it's under the purview of type and altering and by the pipe and is running that's when. It is like it comes under the categories under higher than execution so. It starts with like where would be make the like this option available to users to. Avail the automated tests and processes that's where we are talking about the discovery of all features which are related to our current execution or continuous integration next was just confirming like enable using environment specific process so this particular stage we are only talking about like maybe. Confirming the action and next was when pipe and has already started to execute so when the. I'm using the term pipeline here which is not ideal and I just want to make a note that we are still talking about those automated tests but since it's just like i'm going through the process i'm just using terms which are not very well caught off. And so when we come to the execute stage this is exactly what pipeline execution category stick care of like when the pipeline is running when the runner is picking up jobs executing those. What is the job what what is the real job that we are referring to here what is. What is it what is it that users have come to do on get lab that we are making happen through these through the set of feature and the next was. Yeah. That note and so this is perfect but where do the devs come in like and so so is this execute the between the handoff between stage four and stage five is that how we distinguish authoring from. From execution. Not really so I think that defining. Is apart that's mostly played by DevOps engineers or the time leads and it kind of i mean it's not something very. But it's not a hard and fast because it totally depends on the composition of the teams like if it's a very short team then maybe there's one developer who's responsible for the pipeline as well apart from the day to day job of writing a software but in like big enterprise teams there would be a dedicated DevOps engineer or they might even be an s re who's going to take. Or read responsibility of all things that relates to defining or writing the pipeline or editing the pipeline so whether handoff really happens is. I would say. Not even look it prepare. Because when developers are merging their changes. They are looking for initiating these. automated tests and once they initiate that and confirm, this is actually the part where their role kicks in. Okay. And then, to some degree, the people upstream are defining the tests or do we think as define the tests? Are they just running them? They're just running them because they cannot define anymore. The definition of the pipeline has already been written and they only can avail what's already there. Okay, got it. Thank you, Tony. Yeah. And the next part is of course, monitor because when the jobs are being executed, at that time, there would be some degree of anxiety among the developers. Like, I initiated this. I have other things to look at. How is this progressing? Would I have to come back and dedicate more time to this? So they want some sort of piece of mind. And that's where the monitoring part comes in. They want to easily be able to examine and monitor the running pipeline and observe if like the safety measures are in place. For example, they want to be assured that the variables that they're passing through the jobs, they're not getting leaked anywhere. There's no security threat that's underway. And in case something goes here and there, like, not as expected, then there is a chance of modifying. Like, there's a scope to modify the definition, but again, one has to have the proper, the right access to make those modifications. And here the same person who can define can also modify. So maybe this, this is a reverse handoff. Like where the developers are communicating with the demo sentinus. Okay, cool. Good. And then stage seven, and then tell me a little bit about stage four, or stage five. Are they in? What do we think they're doing in stage five? Yeah, so stage four, if I talk to you in terms of like the exact action that you are performing on the product. So when you, when you click on like creating the merge request, when the creation of MR is initiated, at the same time, the pipeline also gets started. So that's one. And then another option to do this is when you go to your pipeline page, pipeline index page, and you click on the blue button, which is on the top right corner, that's his run pipeline. That's when you're confirming that action, which is initiating a pipeline. So that's where the execution begins. Okay. And then devs do that for sure. Yes, yes, devs do that. Okay. Okay, cool. And then five. Okay, my God. Yeah, five is monitoring. So this can be targeting like both the personas. I know that jobs have to be person-agnostic, but talking in terms of like who's doing the who the, who the main executor here is. Developers are expecting different things when they are talking about monitoring the pipelines and the devops engineers or someone sitting like at the very top at the director level, they're expecting something very different from monitoring. They want to see like in terms of usage, how things are probably. Go back to execute, because even execute looks like in this version of the world that execute is running the tests. Yes. So all of that seems like really security-based. And I think that's right in this job, agnostic way, but I think that one way we could frame that so that it would kind of cover like kind of what you're saying about that coming from other people. And I am in this study where we're looking at the product, the life cycle for infrastructure resources and talking about those different components and who and also for secrets and who's in charge of those systems. It's not, it's sometimes the dev ops people, but it's coming from the CTO or like a security officer or like there so they're doing that in coordination. So one thing we could do is frame that stage in terms of like what I work with my needs to align with our security standards. Yes. Yeah, that's a really great point. That's something that I definitely missed like noting here that even though like the executor, especially in the context of the execute state, it's it might be the developer, but the job that the job the user who the job should target might be some entirely different the compliance manager or the release manager or who's our concern. Yes, it's teamwork. Yeah. Yeah. So one thing that I saw in the video today, in one of the videos that I was watching is so there the person talked about that let's say you're working for a B2B company and you have a buyer, but the buyer is not your user. The buyer is like of course purchasing from you, but you should never like build the persona, build the jobs to be done targeting the buyer because it has to be about the user or the user is trying to accomplish. So even though we're not talking about the buyer here, but in terms of who the jobs to be done should target like the end user of that, I think in this case it's different set of people. Yeah, or at least they're in control and the developers are working within those. Yes, how it bar rails. Yeah. Okay. And then stage six, six, six, yes. So like I had mentioned that from stage six, different kind of personas would have different expectations. Here, it's feared because now when I think of it that even though this involves like defining the core executors at the very beginning, I think the core executors for every stage is different. Yeah, because I'm thinking that yeah, the stage six, the devs are hands on again, right? Yes. Okay. Yeah, but should it matter like who's the most hands on? Should it matter like who's concern is this particular stage attendant to? Well, I think that's why the jobs to be done, at least this is the page, this is the like handbook page with Jackie's video that like I can understand it. So because the job can be anybody that does it, but eventually the person when it becomes a jobs to be done, the persona steps in. Because it says in this handbook, a page says job, deploy and build into place offer and then job performer is an element of jobs to be done and that brings in the persona. Which is part of the circumstance. Yes, but I could get us in a lot of trouble because I'm not sure that I'm tracking how we do it here, but that's how I think it that's that's what I mean, like we want to just be able to pull out not the jobs to be done, but even just the job. But I think the job is more about like kind of how we said, making the releases more efficient in a way that is secure. Yeah. For that meets the security requirements. We did within my company. Yeah, I think thinking in the constraint, only thinking in the constraint of the executive person, as that we shortly start at the beginning, I think that's a wrong approach. That kind of limits in some way, like how we are defining the job should be done and it might not be because a developer would never be too concerned about the compliance standards or the security standards. It would always be somebody else, but if I only think of like what the developer is trying to achieve here, I might get things wrong. What do you think? Yeah, I mean, I think we want to just talk to them about these about what they're trying to do, because some of them I've talked to are in charge of security stuff, but they're not like the author, kind of how we're doing it. We can also have a discussion around this. Yeah. No, and I think that I mean, even now, one question I have is just like, where does Nadi has work stop up and then your work pick up? I mean, I'm not even sure there. So this modified part where I talked about a reverse handover, this is Nadi's, and then this is Nadi's define and to some extent locate. Okay, I think that's what I think I'm always wanting to make it like a literal break off, but that's good. Okay. Yeah. Yeah. And then I did this small exercise of prioritization. At this point, I couldn't tell like what the colors denote, because I was smart enough not to make an index for that. But yeah, we had a synchronous session, B and the PM, and we talked about like which are the most important and most important personas, but we satisfy it, so we mark them as opportunities for ourselves. Like this is the area where we should be thinking of making improvements in our future of plans for categories. And then yeah, I mean, it feels like we're implicitly mapping the personas to the stages. But what if we just make the job, making the release, making the releases, is it of my software, more efficient in a way that meets the security requirements of the software, which didn't say mine, that making the releases of software more efficient in a way that meets the security requirements of our company, our company, in the way that meets company security requirements. Because that will cover this whole flow. That's also what confuses me is whether or not the job needs to cover a whole flow or yeah, that's where the elevation and the granularity that mapping comes into picture. So we can like if you map it as a reverse triangle, then what you're saying, that can totally be the core jobs to be done, which is at the highest level. And then when we try to like break it further, it would be, it would cover the flow. Okay. I love that reverse triangle. Yep. Okay, and then okay, let's talk about a little bit about where the merge trains come in. So let me tell you. And then I think the merge trains come in at five stage five. Yes, they do. That's right. Okay. And then the, what was that other thing? Yeah. So I think, so because we were talking about combining those two studies. Mm-hmm. So I think that's how we can kind of think about it is like mapping out. Can we think about it like mapping out the jobs to be done across this one job workflow? Merge trains execute. I'm going to enter the note for the one job workflow. The one that you mentioned about the one that you had framed. Yeah. That can be, so in my case, I had something for the core job. And like for the new mapping, what you mentioned could be our core job. I think so. Yeah, the top of the triangle one. And then I think is what our main research goal can be. Or where I mean research question can be would be to figure out. Where did I write it? I wrote it. Yeah, how do we help developers to. How do we? Yeah, here it is. How do we help developers? Oh no, how do we help users? Because we don't want to say users to make their releases more efficient. So that could be of this combined research study. We can say that's our primary goal. Like that could be the name of the research study. And then kind of our approach could be. We could even have we could even have these stages here and then say like walk us through your process with these stages. Like ideally they would show us in the tool, but they are sometimes not what they don't want to do that. So we could just put this in a deck and then have them talk through like first to say where are you involved in this flow, right? Yeah. And then say, okay, now unpack what are your goals here? What are you trying to do and what are your key tasks? So that's. I think that sounds good. Yeah. It would be critical though. Yeah, because my current plan was kind of to create the initial mapping by myself and then go to validation, but this is so much better because we won't have to like take a U-turn at any part of the process. Yeah, I think so. And then we just get them to kind of tell us. And it's like ideally we wouldn't do that, but this is such a technical space that I think it's defensible. Hold it. We're not asking me. Yeah, I think it's right. So, okay. So the method would be to interview to work through. The different stages involved in pipelines. To see where our users. Working and what their goals are. Do you think they'll recognize these parks or it doesn't matter. We can even just say, um, we can even just say this is how we're defining this isn't in define, locate, prepare, confirm. Is that coming from us in any way or that's not coming from us that's actually coming from the uh, job, stability and templates. If you think like changing this to and even combining a few stages would help, which I think would help. For example, I don't see like very clear differentiation between prepare and confirm here. It's kind of. Maybe that's an idea too is maybe what we do first is just say from your perspective, let's map out. What are the different stages. Like card sorting sort of without providing cards. Well, yeah. Like what I end up doing, I'll show you one of these sessions, but what I end up doing is like just like making shapes with them and like having them talk about it. Like, so what we're doing right now with the, um, the secrets lifecycle is just to be like, tell me about a secret. Where's the beginning. What's the middle. What's the end. And then they kind of articulated there. But in that one, we're like, who what where when. But I think in this one, we would just be like, so where does your process start. But I'm not the only thing I'm not sure about there is like how we frame it. Yeah. So keeping it open ended, but uh, kind of nudging them to define those stages themselves. Yeah. And what's what do we say this? What is at the stages of. What is that? What do we, how do we say it? Uh, how do you. Your perspective, what are the stages of a pipeline. Of pipeline execution of pipeline. Um, the stages of. How you were. Oh, should we like keep it a little more generic and talk about what are the stages of verifying your code. Got it. Yeah. And you know what we can say to like we can say like not from your perspective or like what I mean, that's fine too, but we could just say tell us how your teams are breaking up the process of verifying your code into stages. I'm liking where this is going. Yeah. Yeah. This is the kind of information that uh, they never asked for. Mm-hmm. I think we want to step back. Tell us how your team, especially if you have the bandwidth. Tell us how your teams are breaking up the process of verifying your code. Mm-hmm. And the good part is the same set of information can also be useful for Gina and Nadia. Yeah. Um, uh, yeah, because they're in this flow too, right? Yeah. Yeah. Okay. At some point we'll need to put, where is, can we do it now really quickly? To help my brain? What stage is Gina doing? Uh, pipe and insights and runner. But in this, I like these stages. Okay. All right. I thought stage groups. That's what was going on in the mind. So here we should call them, maybe we should call them steps so we don't confuse ourselves. Uh, I think execute. Execute is where both the stage groups are genius working with would very well fit. And sorry, the pipeline insights can be more about monitor, I guess. Stage six. Yes. And runner is of course execute because when the, uh, jobs are being executed, that's when the role of runner kicks in. Okay. Okay. So it's a look up here. So stage one, so stage five is Gina when she's doing runners. Yes. Right. How does one day we'll talk about how runners and merge trains interact? It's all in that. It's hopefully in that blog post. Uh, okay. Cool. Uh, yeah. Okay. Well, it seems like, um, maybe let's start recording when we recording still. Yes. We are recording still. No, let's talk. Let's talk calendars now. Okay, we can stop. That's a brilliant. Yeah, yeah. That was so good. Yeah, that was so fun too. Okay. So that's stuff now? Yeah, yeah, yeah. Okay. All right. I'm stopping.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 11.0,
      "text": " All right, so today, Erica and I are going to the process of mapping jobs.",
      "tokens": [
        50364,
        1057,
        558,
        11,
        370,
        965,
        11,
        37429,
        293,
        286,
        366,
        516,
        281,
        264,
        1399,
        295,
        18350,
        4782,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23093929290771484,
      "compression_ratio": 1.4970760233918128,
      "no_speech_prob": 0.06278952211141586
    },
    {
      "id": 1,
      "seek": 0,
      "start": 11.0,
      "end": 23.0,
      "text": " And I am taking the reference of the old mapping that I had done about one and a half years ago, which might not be perfect, but this is what we are going to base our discussion on.",
      "tokens": [
        50914,
        400,
        286,
        669,
        1940,
        264,
        6408,
        295,
        264,
        1331,
        18350,
        300,
        286,
        632,
        1096,
        466,
        472,
        293,
        257,
        1922,
        924,
        2057,
        11,
        597,
        1062,
        406,
        312,
        2176,
        11,
        457,
        341,
        307,
        437,
        321,
        366,
        516,
        281,
        3096,
        527,
        5017,
        322,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23093929290771484,
      "compression_ratio": 1.4970760233918128,
      "no_speech_prob": 0.06278952211141586
    },
    {
      "id": 2,
      "seek": 2300,
      "start": 23.0,
      "end": 35.0,
      "text": " How I started with this mapping is I'm not sharing my screen and I totally should.",
      "tokens": [
        50364,
        1012,
        286,
        1409,
        365,
        341,
        18350,
        307,
        286,
        478,
        406,
        5414,
        452,
        2568,
        293,
        286,
        3879,
        820,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18905107180277506,
      "compression_ratio": 1.4427083333333333,
      "no_speech_prob": 0.0360947847366333
    },
    {
      "id": 3,
      "seek": 2300,
      "start": 35.0,
      "end": 38.0,
      "text": " All right, is it.",
      "tokens": [
        50964,
        1057,
        558,
        11,
        307,
        309,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18905107180277506,
      "compression_ratio": 1.4427083333333333,
      "no_speech_prob": 0.0360947847366333
    },
    {
      "id": 4,
      "seek": 2300,
      "start": 38.0,
      "end": 40.0,
      "text": " Visible enough? Okay, great.",
      "tokens": [
        51114,
        10410,
        964,
        1547,
        30,
        1033,
        11,
        869,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18905107180277506,
      "compression_ratio": 1.4427083333333333,
      "no_speech_prob": 0.0360947847366333
    },
    {
      "id": 5,
      "seek": 2300,
      "start": 40.0,
      "end": 51.0,
      "text": " So I started off with the kind of making a note of the core functional jobs that users come to perform when we are talking about all things verify.",
      "tokens": [
        51214,
        407,
        286,
        1409,
        766,
        365,
        264,
        733,
        295,
        1455,
        257,
        3637,
        295,
        264,
        4965,
        11745,
        4782,
        300,
        5022,
        808,
        281,
        2042,
        562,
        321,
        366,
        1417,
        466,
        439,
        721,
        16888,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18905107180277506,
      "compression_ratio": 1.4427083333333333,
      "no_speech_prob": 0.0360947847366333
    },
    {
      "id": 6,
      "seek": 5100,
      "start": 51.0,
      "end": 57.0,
      "text": " So at this stage, I was not even like focusing a lot on just pipe and execution or just continuous integration.",
      "tokens": [
        50364,
        407,
        412,
        341,
        3233,
        11,
        286,
        390,
        406,
        754,
        411,
        8416,
        257,
        688,
        322,
        445,
        11240,
        293,
        15058,
        420,
        445,
        10957,
        10980,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16600026141156207,
      "compression_ratio": 1.661764705882353,
      "no_speech_prob": 0.00954668503254652
    },
    {
      "id": 7,
      "seek": 5100,
      "start": 57.0,
      "end": 64.0,
      "text": " I was thinking of everything that users would want to do with the features that we kind of group under verify.",
      "tokens": [
        50664,
        286,
        390,
        1953,
        295,
        1203,
        300,
        5022,
        576,
        528,
        281,
        360,
        365,
        264,
        4122,
        300,
        321,
        733,
        295,
        1594,
        833,
        16888,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16600026141156207,
      "compression_ratio": 1.661764705882353,
      "no_speech_prob": 0.00954668503254652
    },
    {
      "id": 8,
      "seek": 5100,
      "start": 64.0,
      "end": 80.0,
      "text": " And from there, I consolidated the core jobs into this one particular statement and this statement says to standardize an automate tests builds and deploy process across organization to allow easy contribution while keeping them.",
      "tokens": [
        51014,
        400,
        490,
        456,
        11,
        286,
        49008,
        264,
        4965,
        4782,
        666,
        341,
        472,
        1729,
        5629,
        293,
        341,
        5629,
        1619,
        281,
        3832,
        1125,
        364,
        31605,
        6921,
        15182,
        293,
        7274,
        1399,
        2108,
        4475,
        281,
        2089,
        1858,
        13150,
        1339,
        5145,
        552,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16600026141156207,
      "compression_ratio": 1.661764705882353,
      "no_speech_prob": 0.00954668503254652
    },
    {
      "id": 9,
      "seek": 8000,
      "start": 80.0,
      "end": 85.0,
      "text": " The main branch screen, which is main branch, healthy.",
      "tokens": [
        50364,
        440,
        2135,
        9819,
        2568,
        11,
        597,
        307,
        2135,
        9819,
        11,
        4627,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23400384408456307,
      "compression_ratio": 1.4444444444444444,
      "no_speech_prob": 0.041134607046842575
    },
    {
      "id": 10,
      "seek": 8000,
      "start": 85.0,
      "end": 93.0,
      "text": " And I like kept this as a reference for the core job that we are going to be referring to.",
      "tokens": [
        50614,
        400,
        286,
        411,
        4305,
        341,
        382,
        257,
        6408,
        337,
        264,
        4965,
        1691,
        300,
        321,
        366,
        516,
        281,
        312,
        13761,
        281,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23400384408456307,
      "compression_ratio": 1.4444444444444444,
      "no_speech_prob": 0.041134607046842575
    },
    {
      "id": 11,
      "seek": 8000,
      "start": 93.0,
      "end": 98.0,
      "text": " The next part was thinking of who would be executing the jobs.",
      "tokens": [
        51014,
        440,
        958,
        644,
        390,
        1953,
        295,
        567,
        576,
        312,
        32368,
        264,
        4782,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23400384408456307,
      "compression_ratio": 1.4444444444444444,
      "no_speech_prob": 0.041134607046842575
    },
    {
      "id": 12,
      "seek": 9800,
      "start": 99.0,
      "end": 115.0,
      "text": " The circles in the innermost circle are the core executors. So for core executors, I thought of personas that we very frequently refer to like the DevOps engineers, the software engineer, the developer.",
      "tokens": [
        50414,
        440,
        13040,
        294,
        264,
        7714,
        966,
        555,
        6329,
        366,
        264,
        4965,
        7568,
        830,
        13,
        407,
        337,
        4965,
        7568,
        830,
        11,
        286,
        1194,
        295,
        12019,
        300,
        321,
        588,
        10374,
        2864,
        281,
        411,
        264,
        43051,
        11955,
        11,
        264,
        4722,
        11403,
        11,
        264,
        10754,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2292573762976605,
      "compression_ratio": 1.463768115942029,
      "no_speech_prob": 0.14904876053333282
    },
    {
      "id": 13,
      "seek": 11500,
      "start": 116.0,
      "end": 144.0,
      "text": " And a little outside that circle on its periphery, I was imagining personnel such as system administrator compliance manager, release manager development team lead because in the process that release managers follow and compliance managers follow the processes, they are very much kind of around pipelines because pipelines enables the release process and.",
      "tokens": [
        50414,
        400,
        257,
        707,
        2380,
        300,
        6329,
        322,
        1080,
        26807,
        88,
        11,
        286,
        390,
        27798,
        14988,
        1270,
        382,
        1185,
        25529,
        15882,
        6598,
        11,
        4374,
        6598,
        3250,
        1469,
        1477,
        570,
        294,
        264,
        1399,
        300,
        4374,
        14084,
        1524,
        293,
        15882,
        14084,
        1524,
        264,
        7555,
        11,
        436,
        366,
        588,
        709,
        733,
        295,
        926,
        40168,
        570,
        40168,
        17077,
        264,
        4374,
        1399,
        293,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23304508578392766,
      "compression_ratio": 1.7889447236180904,
      "no_speech_prob": 0.15147320926189423
    },
    {
      "id": 14,
      "seek": 14400,
      "start": 144.0,
      "end": 153.0,
      "text": " Following the compliance guidelines and then who else can use pipelines and related features.",
      "tokens": [
        50364,
        19192,
        264,
        15882,
        12470,
        293,
        550,
        567,
        1646,
        393,
        764,
        40168,
        293,
        4077,
        4122,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22668462811094342,
      "compression_ratio": 1.6230366492146597,
      "no_speech_prob": 0.027208494022488594
    },
    {
      "id": 15,
      "seek": 14400,
      "start": 153.0,
      "end": 159.0,
      "text": " The idea is anybody can because taking a reference of a company like get love where we work.",
      "tokens": [
        50814,
        440,
        1558,
        307,
        4472,
        393,
        570,
        1940,
        257,
        6408,
        295,
        257,
        2237,
        411,
        483,
        959,
        689,
        321,
        589,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22668462811094342,
      "compression_ratio": 1.6230366492146597,
      "no_speech_prob": 0.027208494022488594
    },
    {
      "id": 16,
      "seek": 14400,
      "start": 159.0,
      "end": 167.0,
      "text": " Everybody runs pipelines, everybody merges their changes, so everybody kind of interacts with that in their day to day job.",
      "tokens": [
        51114,
        7646,
        6676,
        40168,
        11,
        2201,
        3551,
        2880,
        641,
        2962,
        11,
        370,
        2201,
        733,
        295,
        43582,
        365,
        300,
        294,
        641,
        786,
        281,
        786,
        1691,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22668462811094342,
      "compression_ratio": 1.6230366492146597,
      "no_speech_prob": 0.027208494022488594
    },
    {
      "id": 17,
      "seek": 16700,
      "start": 168.0,
      "end": 185.0,
      "text": " I kind of skipped this part because I was not able to get a very good hang of like what's the value that this adding and I'm not saying that that was really great step on my part, but just stating that it wasn't.",
      "tokens": [
        50414,
        286,
        733,
        295,
        30193,
        341,
        644,
        570,
        286,
        390,
        406,
        1075,
        281,
        483,
        257,
        588,
        665,
        3967,
        295,
        411,
        437,
        311,
        264,
        2158,
        300,
        341,
        5127,
        293,
        286,
        478,
        406,
        1566,
        300,
        300,
        390,
        534,
        869,
        1823,
        322,
        452,
        644,
        11,
        457,
        445,
        26688,
        300,
        309,
        2067,
        380,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1283394345697367,
      "compression_ratio": 1.452054794520548,
      "no_speech_prob": 0.13049301505088806
    },
    {
      "id": 18,
      "seek": 18500,
      "start": 186.0,
      "end": 212.0,
      "text": " Coming to the job map part, so we have these stages which come predefined and I tried to segregate all the primary not primary, although jobs that were kind of that were documented here earlier into these buckets into these different stages, let's say.",
      "tokens": [
        50414,
        12473,
        281,
        264,
        1691,
        4471,
        644,
        11,
        370,
        321,
        362,
        613,
        10232,
        597,
        808,
        659,
        37716,
        293,
        286,
        3031,
        281,
        37630,
        473,
        439,
        264,
        6194,
        406,
        6194,
        11,
        4878,
        4782,
        300,
        645,
        733,
        295,
        300,
        645,
        23007,
        510,
        3071,
        666,
        613,
        32191,
        666,
        613,
        819,
        10232,
        11,
        718,
        311,
        584,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2110926021229137,
      "compression_ratio": 1.5180722891566265,
      "no_speech_prob": 0.1255134642124176
    },
    {
      "id": 19,
      "seek": 21200,
      "start": 212.0,
      "end": 232.0,
      "text": " And I started off like if we talk about defining and we talk about pipelines, then what are the jobs, which are relevant at that stage and of course what's relevant is defining a new pipeline but to put it in a more functional way without.",
      "tokens": [
        50364,
        400,
        286,
        1409,
        766,
        411,
        498,
        321,
        751,
        466,
        17827,
        293,
        321,
        751,
        466,
        40168,
        11,
        550,
        437,
        366,
        264,
        4782,
        11,
        597,
        366,
        7340,
        412,
        300,
        3233,
        293,
        295,
        1164,
        437,
        311,
        7340,
        307,
        17827,
        257,
        777,
        15517,
        457,
        281,
        829,
        309,
        294,
        257,
        544,
        11745,
        636,
        1553,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11791905650386104,
      "compression_ratio": 1.5620915032679739,
      "no_speech_prob": 0.027787478640675545
    },
    {
      "id": 20,
      "seek": 23200,
      "start": 232.0,
      "end": 249.0,
      "text": " So focusing a lot on the tool and the exact mechanisms that we are providing today, so I wrote that defining standard standards tests and commands for organizations to test for the deploy.",
      "tokens": [
        50364,
        407,
        8416,
        257,
        688,
        322,
        264,
        2290,
        293,
        264,
        1900,
        15902,
        300,
        321,
        366,
        6530,
        965,
        11,
        370,
        286,
        4114,
        300,
        17827,
        3832,
        7787,
        6921,
        293,
        16901,
        337,
        6150,
        281,
        1500,
        337,
        264,
        7274,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3138885008983123,
      "compression_ratio": 1.413533834586466,
      "no_speech_prob": 0.09465125948190689
    },
    {
      "id": 21,
      "seek": 24900,
      "start": 249.0,
      "end": 267.0,
      "text": " And as written keeping in mind that users have to author the pipeline before they can even like before they can do anything else for that then comes the part of locating so make a aware of available test suite or explain the process for using existing pipeline.",
      "tokens": [
        50364,
        400,
        382,
        3720,
        5145,
        294,
        1575,
        300,
        5022,
        362,
        281,
        3793,
        264,
        15517,
        949,
        436,
        393,
        754,
        411,
        949,
        436,
        393,
        360,
        1340,
        1646,
        337,
        300,
        550,
        1487,
        264,
        644,
        295,
        1628,
        990,
        370,
        652,
        257,
        3650,
        295,
        2435,
        1500,
        14205,
        420,
        2903,
        264,
        1399,
        337,
        1228,
        6741,
        15517,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19808523743240922,
      "compression_ratio": 1.6211180124223603,
      "no_speech_prob": 0.1326366513967514
    },
    {
      "id": 22,
      "seek": 26700,
      "start": 267.4,
      "end": 291.0,
      "text": " And so on, so what I saw was since we had made this division in the responsibilities of the two stage groups, by the not string and by an execution and we mentioned that everything that relates to defining the pipeline or editing the pipeline it's under the purview of type and altering and by the pipe and is running that's when.",
      "tokens": [
        50384,
        400,
        370,
        322,
        11,
        370,
        437,
        286,
        1866,
        390,
        1670,
        321,
        632,
        1027,
        341,
        10044,
        294,
        264,
        16190,
        295,
        264,
        732,
        3233,
        3935,
        11,
        538,
        264,
        406,
        6798,
        293,
        538,
        364,
        15058,
        293,
        321,
        2835,
        300,
        1203,
        300,
        16155,
        281,
        17827,
        264,
        15517,
        420,
        10000,
        264,
        15517,
        309,
        311,
        833,
        264,
        1864,
        1759,
        295,
        2010,
        293,
        11337,
        278,
        293,
        538,
        264,
        11240,
        293,
        307,
        2614,
        300,
        311,
        562,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.361198947854238,
      "compression_ratio": 1.683673469387755,
      "no_speech_prob": 0.10202856361865997
    },
    {
      "id": 23,
      "seek": 29100,
      "start": 292.0,
      "end": 298.0,
      "text": " It is like it comes under the categories under higher than execution so.",
      "tokens": [
        50414,
        467,
        307,
        411,
        309,
        1487,
        833,
        264,
        10479,
        833,
        2946,
        813,
        15058,
        370,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23033845746839368,
      "compression_ratio": 1.3805309734513274,
      "no_speech_prob": 0.022136123850941658
    },
    {
      "id": 24,
      "seek": 29100,
      "start": 300.0,
      "end": 308.0,
      "text": " It starts with like where would be make the like this option available to users to.",
      "tokens": [
        50814,
        467,
        3719,
        365,
        411,
        689,
        576,
        312,
        652,
        264,
        411,
        341,
        3614,
        2435,
        281,
        5022,
        281,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23033845746839368,
      "compression_ratio": 1.3805309734513274,
      "no_speech_prob": 0.022136123850941658
    },
    {
      "id": 25,
      "seek": 30800,
      "start": 309.0,
      "end": 333.0,
      "text": " Avail the automated tests and processes that's where we are talking about the discovery of all features which are related to our current execution or continuous integration next was just confirming like enable using environment specific process so this particular stage we are only talking about like maybe.",
      "tokens": [
        50414,
        11667,
        864,
        264,
        18473,
        6921,
        293,
        7555,
        300,
        311,
        689,
        321,
        366,
        1417,
        466,
        264,
        12114,
        295,
        439,
        4122,
        597,
        366,
        4077,
        281,
        527,
        2190,
        15058,
        420,
        10957,
        10980,
        958,
        390,
        445,
        42861,
        411,
        9528,
        1228,
        2823,
        2685,
        1399,
        370,
        341,
        1729,
        3233,
        321,
        366,
        787,
        1417,
        466,
        411,
        1310,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20388504375110972,
      "compression_ratio": 1.6157894736842104,
      "no_speech_prob": 0.04222002625465393
    },
    {
      "id": 26,
      "seek": 33300,
      "start": 334.0,
      "end": 343.0,
      "text": " Confirming the action and next was when pipe and has already started to execute so when the.",
      "tokens": [
        50414,
        11701,
        347,
        2810,
        264,
        3069,
        293,
        958,
        390,
        562,
        11240,
        293,
        575,
        1217,
        1409,
        281,
        14483,
        370,
        562,
        264,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1549043413958972,
      "compression_ratio": 1.6394230769230769,
      "no_speech_prob": 0.029457826167345047
    },
    {
      "id": 27,
      "seek": 33300,
      "start": 344.0,
      "end": 360.0,
      "text": " I'm using the term pipeline here which is not ideal and I just want to make a note that we are still talking about those automated tests but since it's just like i'm going through the process i'm just using terms which are not very well caught off.",
      "tokens": [
        50914,
        286,
        478,
        1228,
        264,
        1433,
        15517,
        510,
        597,
        307,
        406,
        7157,
        293,
        286,
        445,
        528,
        281,
        652,
        257,
        3637,
        300,
        321,
        366,
        920,
        1417,
        466,
        729,
        18473,
        6921,
        457,
        1670,
        309,
        311,
        445,
        411,
        741,
        478,
        516,
        807,
        264,
        1399,
        741,
        478,
        445,
        1228,
        2115,
        597,
        366,
        406,
        588,
        731,
        5415,
        766,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1549043413958972,
      "compression_ratio": 1.6394230769230769,
      "no_speech_prob": 0.029457826167345047
    },
    {
      "id": 28,
      "seek": 36000,
      "start": 361.0,
      "end": 373.0,
      "text": " And so when we come to the execute stage this is exactly what pipeline execution category stick care of like when the pipeline is running when the runner is picking up jobs executing those.",
      "tokens": [
        50414,
        400,
        370,
        562,
        321,
        808,
        281,
        264,
        14483,
        3233,
        341,
        307,
        2293,
        437,
        15517,
        15058,
        7719,
        2897,
        1127,
        295,
        411,
        562,
        264,
        15517,
        307,
        2614,
        562,
        264,
        24376,
        307,
        8867,
        493,
        4782,
        32368,
        729,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25996753374735515,
      "compression_ratio": 1.7088607594936709,
      "no_speech_prob": 0.016236964613199234
    },
    {
      "id": 29,
      "seek": 36000,
      "start": 374.0,
      "end": 379.0,
      "text": " What is the job what what is the real job that we are referring to here what is.",
      "tokens": [
        51064,
        708,
        307,
        264,
        1691,
        437,
        437,
        307,
        264,
        957,
        1691,
        300,
        321,
        366,
        13761,
        281,
        510,
        437,
        307,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25996753374735515,
      "compression_ratio": 1.7088607594936709,
      "no_speech_prob": 0.016236964613199234
    },
    {
      "id": 30,
      "seek": 37900,
      "start": 380.0,
      "end": 392.0,
      "text": " What is it what is it that users have come to do on get lab that we are making happen through these through the set of feature and the next was.",
      "tokens": [
        50414,
        708,
        307,
        309,
        437,
        307,
        309,
        300,
        5022,
        362,
        808,
        281,
        360,
        322,
        483,
        2715,
        300,
        321,
        366,
        1455,
        1051,
        807,
        613,
        807,
        264,
        992,
        295,
        4111,
        293,
        264,
        958,
        390,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27505532230239316,
      "compression_ratio": 1.7164179104477613,
      "no_speech_prob": 0.0017030616290867329
    },
    {
      "id": 31,
      "seek": 37900,
      "start": 393.0,
      "end": 394.0,
      "text": " Yeah.",
      "tokens": [
        51064,
        865,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27505532230239316,
      "compression_ratio": 1.7164179104477613,
      "no_speech_prob": 0.0017030616290867329
    },
    {
      "id": 32,
      "seek": 37900,
      "start": 395.0,
      "end": 407.0,
      "text": " That note and so this is perfect but where do the devs come in like and so so is this execute the between the handoff between stage four and stage five is that how we distinguish authoring from.",
      "tokens": [
        51164,
        663,
        3637,
        293,
        370,
        341,
        307,
        2176,
        457,
        689,
        360,
        264,
        1905,
        82,
        808,
        294,
        411,
        293,
        370,
        370,
        307,
        341,
        14483,
        264,
        1296,
        264,
        1011,
        4506,
        1296,
        3233,
        1451,
        293,
        3233,
        1732,
        307,
        300,
        577,
        321,
        20206,
        3793,
        278,
        490,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27505532230239316,
      "compression_ratio": 1.7164179104477613,
      "no_speech_prob": 0.0017030616290867329
    },
    {
      "id": 33,
      "seek": 40900,
      "start": 409.0,
      "end": 411.0,
      "text": " From execution.",
      "tokens": [
        50364,
        3358,
        15058,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25805542685768823,
      "compression_ratio": 1.2846153846153847,
      "no_speech_prob": 0.01212086621671915
    },
    {
      "id": 34,
      "seek": 40900,
      "start": 411.0,
      "end": 415.0,
      "text": " Not really so I think that defining.",
      "tokens": [
        50464,
        1726,
        534,
        370,
        286,
        519,
        300,
        17827,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25805542685768823,
      "compression_ratio": 1.2846153846153847,
      "no_speech_prob": 0.01212086621671915
    },
    {
      "id": 35,
      "seek": 40900,
      "start": 415.0,
      "end": 427.0,
      "text": " Is apart that's mostly played by DevOps engineers or the time leads and it kind of i mean it's not something very.",
      "tokens": [
        50664,
        1119,
        4936,
        300,
        311,
        5240,
        3737,
        538,
        43051,
        11955,
        420,
        264,
        565,
        6689,
        293,
        309,
        733,
        295,
        741,
        914,
        309,
        311,
        406,
        746,
        588,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25805542685768823,
      "compression_ratio": 1.2846153846153847,
      "no_speech_prob": 0.01212086621671915
    },
    {
      "id": 36,
      "seek": 42700,
      "start": 427.0,
      "end": 451.0,
      "text": " But it's not a hard and fast because it totally depends on the composition of the teams like if it's a very short team then maybe there's one developer who's responsible for the pipeline as well apart from the day to day job of writing a software but in like big enterprise teams there would be a dedicated DevOps engineer or they might even be an s re who's going to take.",
      "tokens": [
        50364,
        583,
        309,
        311,
        406,
        257,
        1152,
        293,
        2370,
        570,
        309,
        3879,
        5946,
        322,
        264,
        12686,
        295,
        264,
        5491,
        411,
        498,
        309,
        311,
        257,
        588,
        2099,
        1469,
        550,
        1310,
        456,
        311,
        472,
        10754,
        567,
        311,
        6250,
        337,
        264,
        15517,
        382,
        731,
        4936,
        490,
        264,
        786,
        281,
        786,
        1691,
        295,
        3579,
        257,
        4722,
        457,
        294,
        411,
        955,
        14132,
        5491,
        456,
        576,
        312,
        257,
        8374,
        43051,
        11403,
        420,
        436,
        1062,
        754,
        312,
        364,
        262,
        319,
        567,
        311,
        516,
        281,
        747,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26191220632413537,
      "compression_ratio": 1.6147186147186148,
      "no_speech_prob": 0.7082715034484863
    },
    {
      "id": 37,
      "seek": 45100,
      "start": 451.0,
      "end": 463.0,
      "text": " Or read responsibility of all things that relates to defining or writing the pipeline or editing the pipeline so whether handoff really happens is.",
      "tokens": [
        50364,
        1610,
        1401,
        6357,
        295,
        439,
        721,
        300,
        16155,
        281,
        17827,
        420,
        3579,
        264,
        15517,
        420,
        10000,
        264,
        15517,
        370,
        1968,
        1011,
        4506,
        534,
        2314,
        307,
        13,
        50964
      ],
      "temperature": 0.6,
      "avg_logprob": -0.42395728826522827,
      "compression_ratio": 1.550561797752809,
      "no_speech_prob": 0.28660809993743896
    },
    {
      "id": 38,
      "seek": 45100,
      "start": 463.0,
      "end": 466.0,
      "text": " I would say.",
      "tokens": [
        50964,
        286,
        576,
        584,
        13,
        51114
      ],
      "temperature": 0.6,
      "avg_logprob": -0.42395728826522827,
      "compression_ratio": 1.550561797752809,
      "no_speech_prob": 0.28660809993743896
    },
    {
      "id": 39,
      "seek": 45100,
      "start": 466.0,
      "end": 469.0,
      "text": " Not even look it prepare.",
      "tokens": [
        51114,
        1726,
        754,
        574,
        309,
        5940,
        13,
        51264
      ],
      "temperature": 0.6,
      "avg_logprob": -0.42395728826522827,
      "compression_ratio": 1.550561797752809,
      "no_speech_prob": 0.28660809993743896
    },
    {
      "id": 40,
      "seek": 45100,
      "start": 469.0,
      "end": 474.0,
      "text": " Because when developers are merging their changes.",
      "tokens": [
        51264,
        1436,
        562,
        8849,
        366,
        44559,
        641,
        2962,
        13,
        51514
      ],
      "temperature": 0.6,
      "avg_logprob": -0.42395728826522827,
      "compression_ratio": 1.550561797752809,
      "no_speech_prob": 0.28660809993743896
    },
    {
      "id": 41,
      "seek": 45100,
      "start": 474.0,
      "end": 477.0,
      "text": " They are looking for initiating these.",
      "tokens": [
        51514,
        814,
        366,
        1237,
        337,
        6265,
        990,
        613,
        13,
        51664
      ],
      "temperature": 0.6,
      "avg_logprob": -0.42395728826522827,
      "compression_ratio": 1.550561797752809,
      "no_speech_prob": 0.28660809993743896
    },
    {
      "id": 42,
      "seek": 47700,
      "start": 477.0,
      "end": 483.48,
      "text": " automated tests and once they initiate that and confirm, this is actually the part where",
      "tokens": [
        50364,
        18473,
        6921,
        293,
        1564,
        436,
        31574,
        300,
        293,
        9064,
        11,
        341,
        307,
        767,
        264,
        644,
        689,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38071587506462545,
      "compression_ratio": 1.4316546762589928,
      "no_speech_prob": 0.058242786675691605
    },
    {
      "id": 43,
      "seek": 47700,
      "start": 484.52,
      "end": 485.88,
      "text": " their role kicks in.",
      "tokens": [
        50740,
        641,
        3090,
        21293,
        294,
        13,
        50808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38071587506462545,
      "compression_ratio": 1.4316546762589928,
      "no_speech_prob": 0.058242786675691605
    },
    {
      "id": 44,
      "seek": 47700,
      "start": 487.32,
      "end": 487.8,
      "text": " Okay.",
      "tokens": [
        50880,
        1033,
        13,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38071587506462545,
      "compression_ratio": 1.4316546762589928,
      "no_speech_prob": 0.058242786675691605
    },
    {
      "id": 45,
      "seek": 47700,
      "start": 493.4,
      "end": 502.84,
      "text": " And then, to some degree, the people upstream are defining the tests or do we think",
      "tokens": [
        51184,
        400,
        550,
        11,
        281,
        512,
        4314,
        11,
        264,
        561,
        33915,
        366,
        17827,
        264,
        6921,
        420,
        360,
        321,
        519,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38071587506462545,
      "compression_ratio": 1.4316546762589928,
      "no_speech_prob": 0.058242786675691605
    },
    {
      "id": 46,
      "seek": 50284,
      "start": 502.91999999999996,
      "end": 506.35999999999996,
      "text": " as define the tests? Are they just running them?",
      "tokens": [
        50368,
        382,
        6964,
        264,
        6921,
        30,
        2014,
        436,
        445,
        2614,
        552,
        30,
        50540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2404021762666248,
      "compression_ratio": 1.6067961165048543,
      "no_speech_prob": 0.01682143285870552
    },
    {
      "id": 47,
      "seek": 50284,
      "start": 507.88,
      "end": 511.96,
      "text": " They're just running them because they cannot define anymore. The definition of the",
      "tokens": [
        50616,
        814,
        434,
        445,
        2614,
        552,
        570,
        436,
        2644,
        6964,
        3602,
        13,
        440,
        7123,
        295,
        264,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2404021762666248,
      "compression_ratio": 1.6067961165048543,
      "no_speech_prob": 0.01682143285870552
    },
    {
      "id": 48,
      "seek": 50284,
      "start": 511.96,
      "end": 518.68,
      "text": " pipeline has already been written and they only can avail what's already there.",
      "tokens": [
        50820,
        15517,
        575,
        1217,
        668,
        3720,
        293,
        436,
        787,
        393,
        2327,
        437,
        311,
        1217,
        456,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2404021762666248,
      "compression_ratio": 1.6067961165048543,
      "no_speech_prob": 0.01682143285870552
    },
    {
      "id": 49,
      "seek": 50284,
      "start": 520.12,
      "end": 521.3199999999999,
      "text": " Okay, got it.",
      "tokens": [
        51228,
        1033,
        11,
        658,
        309,
        13,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2404021762666248,
      "compression_ratio": 1.6067961165048543,
      "no_speech_prob": 0.01682143285870552
    },
    {
      "id": 50,
      "seek": 50284,
      "start": 521.3199999999999,
      "end": 522.12,
      "text": " Thank you, Tony.",
      "tokens": [
        51288,
        1044,
        291,
        11,
        10902,
        13,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2404021762666248,
      "compression_ratio": 1.6067961165048543,
      "no_speech_prob": 0.01682143285870552
    },
    {
      "id": 51,
      "seek": 50284,
      "start": 523.3199999999999,
      "end": 527.8,
      "text": " Yeah. And the next part is of course, monitor because when the jobs are being executed,",
      "tokens": [
        51388,
        865,
        13,
        400,
        264,
        958,
        644,
        307,
        295,
        1164,
        11,
        6002,
        570,
        562,
        264,
        4782,
        366,
        885,
        17577,
        11,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2404021762666248,
      "compression_ratio": 1.6067961165048543,
      "no_speech_prob": 0.01682143285870552
    },
    {
      "id": 52,
      "seek": 52780,
      "start": 528.52,
      "end": 534.28,
      "text": " at that time, there would be some degree of anxiety among the developers.",
      "tokens": [
        50400,
        412,
        300,
        565,
        11,
        456,
        576,
        312,
        512,
        4314,
        295,
        9119,
        3654,
        264,
        8849,
        13,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11957138575864641,
      "compression_ratio": 1.5921052631578947,
      "no_speech_prob": 0.03340333327651024
    },
    {
      "id": 53,
      "seek": 52780,
      "start": 534.28,
      "end": 541.0799999999999,
      "text": " Like, I initiated this. I have other things to look at. How is this progressing? Would I have to come",
      "tokens": [
        50688,
        1743,
        11,
        286,
        28578,
        341,
        13,
        286,
        362,
        661,
        721,
        281,
        574,
        412,
        13,
        1012,
        307,
        341,
        36305,
        30,
        6068,
        286,
        362,
        281,
        808,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11957138575864641,
      "compression_ratio": 1.5921052631578947,
      "no_speech_prob": 0.03340333327651024
    },
    {
      "id": 54,
      "seek": 52780,
      "start": 541.0799999999999,
      "end": 546.4399999999999,
      "text": " back and dedicate more time to this? So they want some sort of piece of mind. And that's where",
      "tokens": [
        51028,
        646,
        293,
        30718,
        544,
        565,
        281,
        341,
        30,
        407,
        436,
        528,
        512,
        1333,
        295,
        2522,
        295,
        1575,
        13,
        400,
        300,
        311,
        689,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11957138575864641,
      "compression_ratio": 1.5921052631578947,
      "no_speech_prob": 0.03340333327651024
    },
    {
      "id": 55,
      "seek": 52780,
      "start": 546.4399999999999,
      "end": 551.88,
      "text": " the monitoring part comes in. They want to easily be able to examine and monitor the running",
      "tokens": [
        51296,
        264,
        11028,
        644,
        1487,
        294,
        13,
        814,
        528,
        281,
        3612,
        312,
        1075,
        281,
        17496,
        293,
        6002,
        264,
        2614,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11957138575864641,
      "compression_ratio": 1.5921052631578947,
      "no_speech_prob": 0.03340333327651024
    },
    {
      "id": 56,
      "seek": 55188,
      "start": 551.88,
      "end": 561.8,
      "text": " pipeline and observe if like the safety measures are in place. For example, they want to be",
      "tokens": [
        50364,
        15517,
        293,
        11441,
        498,
        411,
        264,
        4514,
        8000,
        366,
        294,
        1081,
        13,
        1171,
        1365,
        11,
        436,
        528,
        281,
        312,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18147199153900145,
      "compression_ratio": 1.5570776255707763,
      "no_speech_prob": 0.009618852287530899
    },
    {
      "id": 57,
      "seek": 55188,
      "start": 563.0,
      "end": 567.0,
      "text": " assured that the variables that they're passing through the jobs, they're not getting",
      "tokens": [
        50920,
        23426,
        300,
        264,
        9102,
        300,
        436,
        434,
        8437,
        807,
        264,
        4782,
        11,
        436,
        434,
        406,
        1242,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18147199153900145,
      "compression_ratio": 1.5570776255707763,
      "no_speech_prob": 0.009618852287530899
    },
    {
      "id": 58,
      "seek": 55188,
      "start": 567.0,
      "end": 574.92,
      "text": " leaked anywhere. There's no security threat that's underway. And in case something goes",
      "tokens": [
        51120,
        31779,
        4992,
        13,
        821,
        311,
        572,
        3825,
        4734,
        300,
        311,
        27534,
        13,
        400,
        294,
        1389,
        746,
        1709,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18147199153900145,
      "compression_ratio": 1.5570776255707763,
      "no_speech_prob": 0.009618852287530899
    },
    {
      "id": 59,
      "seek": 55188,
      "start": 575.72,
      "end": 580.2,
      "text": " here and there, like, not as expected, then there is a chance of modifying.",
      "tokens": [
        51556,
        510,
        293,
        456,
        11,
        411,
        11,
        406,
        382,
        5176,
        11,
        550,
        456,
        307,
        257,
        2931,
        295,
        42626,
        13,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18147199153900145,
      "compression_ratio": 1.5570776255707763,
      "no_speech_prob": 0.009618852287530899
    },
    {
      "id": 60,
      "seek": 58020,
      "start": 580.84,
      "end": 586.44,
      "text": " Like, there's a scope to modify the definition, but again, one has to have the proper,",
      "tokens": [
        50396,
        1743,
        11,
        456,
        311,
        257,
        11923,
        281,
        16927,
        264,
        7123,
        11,
        457,
        797,
        11,
        472,
        575,
        281,
        362,
        264,
        2296,
        11,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20807612643522375,
      "compression_ratio": 1.5865921787709498,
      "no_speech_prob": 0.010758684948086739
    },
    {
      "id": 61,
      "seek": 58020,
      "start": 586.44,
      "end": 593.24,
      "text": " the right access to make those modifications. And here the same person who can define can also modify.",
      "tokens": [
        50676,
        264,
        558,
        2105,
        281,
        652,
        729,
        26881,
        13,
        400,
        510,
        264,
        912,
        954,
        567,
        393,
        6964,
        393,
        611,
        16927,
        13,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20807612643522375,
      "compression_ratio": 1.5865921787709498,
      "no_speech_prob": 0.010758684948086739
    },
    {
      "id": 62,
      "seek": 58020,
      "start": 594.12,
      "end": 598.6,
      "text": " So maybe this, this is a reverse handoff. Like where the developers are communicating with the",
      "tokens": [
        51060,
        407,
        1310,
        341,
        11,
        341,
        307,
        257,
        9943,
        1011,
        4506,
        13,
        1743,
        689,
        264,
        8849,
        366,
        17559,
        365,
        264,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20807612643522375,
      "compression_ratio": 1.5865921787709498,
      "no_speech_prob": 0.010758684948086739
    },
    {
      "id": 63,
      "seek": 59860,
      "start": 598.6800000000001,
      "end": 614.0400000000001,
      "text": " demo sentinus. Okay, cool. Good. And then stage seven, and then tell me a little bit about stage four,",
      "tokens": [
        50368,
        10723,
        2279,
        259,
        301,
        13,
        1033,
        11,
        1627,
        13,
        2205,
        13,
        400,
        550,
        3233,
        3407,
        11,
        293,
        550,
        980,
        385,
        257,
        707,
        857,
        466,
        3233,
        1451,
        11,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39040352462174055,
      "compression_ratio": 1.5277777777777777,
      "no_speech_prob": 0.011036437004804611
    },
    {
      "id": 64,
      "seek": 59860,
      "start": 614.0400000000001,
      "end": 618.84,
      "text": " or stage five. Are they in? What do we think they're doing in stage five?",
      "tokens": [
        51136,
        420,
        3233,
        1732,
        13,
        2014,
        436,
        294,
        30,
        708,
        360,
        321,
        519,
        436,
        434,
        884,
        294,
        3233,
        1732,
        30,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39040352462174055,
      "compression_ratio": 1.5277777777777777,
      "no_speech_prob": 0.011036437004804611
    },
    {
      "id": 65,
      "seek": 59860,
      "start": 619.88,
      "end": 627.32,
      "text": " Yeah, so stage four, if I talk to you in terms of like the exact action that you are performing on",
      "tokens": [
        51428,
        865,
        11,
        370,
        3233,
        1451,
        11,
        498,
        286,
        751,
        281,
        291,
        294,
        2115,
        295,
        411,
        264,
        1900,
        3069,
        300,
        291,
        366,
        10205,
        322,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39040352462174055,
      "compression_ratio": 1.5277777777777777,
      "no_speech_prob": 0.011036437004804611
    },
    {
      "id": 66,
      "seek": 62732,
      "start": 627.4000000000001,
      "end": 639.8000000000001,
      "text": " the product. So when you, when you click on like creating the merge request, when the creation",
      "tokens": [
        50368,
        264,
        1674,
        13,
        407,
        562,
        291,
        11,
        562,
        291,
        2052,
        322,
        411,
        4084,
        264,
        22183,
        5308,
        11,
        562,
        264,
        8016,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1511095232433743,
      "compression_ratio": 1.6589595375722543,
      "no_speech_prob": 0.002719864947721362
    },
    {
      "id": 67,
      "seek": 62732,
      "start": 639.8000000000001,
      "end": 647.6400000000001,
      "text": " of MR is initiated, at the same time, the pipeline also gets started. So that's one. And then",
      "tokens": [
        50988,
        295,
        9808,
        307,
        28578,
        11,
        412,
        264,
        912,
        565,
        11,
        264,
        15517,
        611,
        2170,
        1409,
        13,
        407,
        300,
        311,
        472,
        13,
        400,
        550,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1511095232433743,
      "compression_ratio": 1.6589595375722543,
      "no_speech_prob": 0.002719864947721362
    },
    {
      "id": 68,
      "seek": 62732,
      "start": 647.6400000000001,
      "end": 653.4000000000001,
      "text": " another option to do this is when you go to your pipeline page, pipeline index page, and you click",
      "tokens": [
        51380,
        1071,
        3614,
        281,
        360,
        341,
        307,
        562,
        291,
        352,
        281,
        428,
        15517,
        3028,
        11,
        15517,
        8186,
        3028,
        11,
        293,
        291,
        2052,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1511095232433743,
      "compression_ratio": 1.6589595375722543,
      "no_speech_prob": 0.002719864947721362
    },
    {
      "id": 69,
      "seek": 65340,
      "start": 653.48,
      "end": 657.9599999999999,
      "text": " on the blue button, which is on the top right corner, that's his run pipeline. That's when you're",
      "tokens": [
        50368,
        322,
        264,
        3344,
        2960,
        11,
        597,
        307,
        322,
        264,
        1192,
        558,
        4538,
        11,
        300,
        311,
        702,
        1190,
        15517,
        13,
        663,
        311,
        562,
        291,
        434,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23481040403067346,
      "compression_ratio": 1.653179190751445,
      "no_speech_prob": 0.0044767349027097225
    },
    {
      "id": 70,
      "seek": 65340,
      "start": 657.9599999999999,
      "end": 663.8,
      "text": " confirming that action, which is initiating a pipeline. So that's where the execution begins.",
      "tokens": [
        50592,
        42861,
        300,
        3069,
        11,
        597,
        307,
        6265,
        990,
        257,
        15517,
        13,
        407,
        300,
        311,
        689,
        264,
        15058,
        7338,
        13,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23481040403067346,
      "compression_ratio": 1.653179190751445,
      "no_speech_prob": 0.0044767349027097225
    },
    {
      "id": 71,
      "seek": 65340,
      "start": 667.56,
      "end": 674.36,
      "text": " Okay. And then devs do that for sure. Yes, yes, devs do that. Okay.",
      "tokens": [
        51072,
        1033,
        13,
        400,
        550,
        1905,
        82,
        360,
        300,
        337,
        988,
        13,
        1079,
        11,
        2086,
        11,
        1905,
        82,
        360,
        300,
        13,
        1033,
        13,
        51412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23481040403067346,
      "compression_ratio": 1.653179190751445,
      "no_speech_prob": 0.0044767349027097225
    },
    {
      "id": 72,
      "seek": 65340,
      "start": 677.16,
      "end": 679.88,
      "text": " Okay, cool. And then five.",
      "tokens": [
        51552,
        1033,
        11,
        1627,
        13,
        400,
        550,
        1732,
        13,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23481040403067346,
      "compression_ratio": 1.653179190751445,
      "no_speech_prob": 0.0044767349027097225
    },
    {
      "id": 73,
      "seek": 67988,
      "start": 680.28,
      "end": 682.04,
      "text": " Okay, my God.",
      "tokens": [
        50384,
        1033,
        11,
        452,
        1265,
        13,
        50472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28892913231482875,
      "compression_ratio": 1.5974025974025974,
      "no_speech_prob": 0.011394387111067772
    },
    {
      "id": 74,
      "seek": 67988,
      "start": 685.24,
      "end": 691.0,
      "text": " Yeah, five is monitoring. So this can be targeting like both the personas.",
      "tokens": [
        50632,
        865,
        11,
        1732,
        307,
        11028,
        13,
        407,
        341,
        393,
        312,
        17918,
        411,
        1293,
        264,
        12019,
        13,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28892913231482875,
      "compression_ratio": 1.5974025974025974,
      "no_speech_prob": 0.011394387111067772
    },
    {
      "id": 75,
      "seek": 67988,
      "start": 692.2,
      "end": 696.76,
      "text": " I know that jobs have to be person-agnostic, but talking in terms of like who's doing the",
      "tokens": [
        50980,
        286,
        458,
        300,
        4782,
        362,
        281,
        312,
        954,
        12,
        4535,
        19634,
        11,
        457,
        1417,
        294,
        2115,
        295,
        411,
        567,
        311,
        884,
        264,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28892913231482875,
      "compression_ratio": 1.5974025974025974,
      "no_speech_prob": 0.011394387111067772
    },
    {
      "id": 76,
      "seek": 67988,
      "start": 696.76,
      "end": 703.08,
      "text": " who the, who the main executor here is. Developers are expecting different things when they",
      "tokens": [
        51208,
        567,
        264,
        11,
        567,
        264,
        2135,
        7568,
        284,
        510,
        307,
        13,
        11442,
        433,
        366,
        9650,
        819,
        721,
        562,
        436,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28892913231482875,
      "compression_ratio": 1.5974025974025974,
      "no_speech_prob": 0.011394387111067772
    },
    {
      "id": 77,
      "seek": 67988,
      "start": 703.08,
      "end": 707.56,
      "text": " are talking about monitoring the pipelines and the devops engineers or someone sitting like at the",
      "tokens": [
        51524,
        366,
        1417,
        466,
        11028,
        264,
        40168,
        293,
        264,
        1905,
        3370,
        11955,
        420,
        1580,
        3798,
        411,
        412,
        264,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28892913231482875,
      "compression_ratio": 1.5974025974025974,
      "no_speech_prob": 0.011394387111067772
    },
    {
      "id": 78,
      "seek": 70756,
      "start": 707.56,
      "end": 712.52,
      "text": " very top at the director level, they're expecting something very different from monitoring. They want",
      "tokens": [
        50364,
        588,
        1192,
        412,
        264,
        5391,
        1496,
        11,
        436,
        434,
        9650,
        746,
        588,
        819,
        490,
        11028,
        13,
        814,
        528,
        50612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23881930112838745,
      "compression_ratio": 1.616326530612245,
      "no_speech_prob": 0.0005579522112384439
    },
    {
      "id": 79,
      "seek": 70756,
      "start": 712.52,
      "end": 721.0799999999999,
      "text": " to see like in terms of usage, how things are probably. Go back to execute, because even execute",
      "tokens": [
        50612,
        281,
        536,
        411,
        294,
        2115,
        295,
        14924,
        11,
        577,
        721,
        366,
        1391,
        13,
        1037,
        646,
        281,
        14483,
        11,
        570,
        754,
        14483,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23881930112838745,
      "compression_ratio": 1.616326530612245,
      "no_speech_prob": 0.0005579522112384439
    },
    {
      "id": 80,
      "seek": 70756,
      "start": 721.0799999999999,
      "end": 729.7199999999999,
      "text": " looks like in this version of the world that execute is running the tests. Yes. So all of that seems",
      "tokens": [
        51040,
        1542,
        411,
        294,
        341,
        3037,
        295,
        264,
        1002,
        300,
        14483,
        307,
        2614,
        264,
        6921,
        13,
        1079,
        13,
        407,
        439,
        295,
        300,
        2544,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23881930112838745,
      "compression_ratio": 1.616326530612245,
      "no_speech_prob": 0.0005579522112384439
    },
    {
      "id": 81,
      "seek": 70756,
      "start": 729.7199999999999,
      "end": 736.76,
      "text": " like really security-based. And I think that's right in this job, agnostic way, but I think that",
      "tokens": [
        51472,
        411,
        534,
        3825,
        12,
        6032,
        13,
        400,
        286,
        519,
        300,
        311,
        558,
        294,
        341,
        1691,
        11,
        623,
        77,
        19634,
        636,
        11,
        457,
        286,
        519,
        300,
        51824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23881930112838745,
      "compression_ratio": 1.616326530612245,
      "no_speech_prob": 0.0005579522112384439
    },
    {
      "id": 82,
      "seek": 73676,
      "start": 736.76,
      "end": 744.68,
      "text": " one way we could frame that so that it would kind of cover like kind of what you're saying about",
      "tokens": [
        50364,
        472,
        636,
        321,
        727,
        3920,
        300,
        370,
        300,
        309,
        576,
        733,
        295,
        2060,
        411,
        733,
        295,
        437,
        291,
        434,
        1566,
        466,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1204930517408583,
      "compression_ratio": 1.6753246753246753,
      "no_speech_prob": 7.329994696192443e-05
    },
    {
      "id": 83,
      "seek": 73676,
      "start": 744.68,
      "end": 749.48,
      "text": " that coming from other people. And I am in this study where we're looking at the product, the",
      "tokens": [
        50760,
        300,
        1348,
        490,
        661,
        561,
        13,
        400,
        286,
        669,
        294,
        341,
        2979,
        689,
        321,
        434,
        1237,
        412,
        264,
        1674,
        11,
        264,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1204930517408583,
      "compression_ratio": 1.6753246753246753,
      "no_speech_prob": 7.329994696192443e-05
    },
    {
      "id": 84,
      "seek": 73676,
      "start": 749.48,
      "end": 756.36,
      "text": " life cycle for infrastructure resources and talking about those different components and who",
      "tokens": [
        51000,
        993,
        6586,
        337,
        6896,
        3593,
        293,
        1417,
        466,
        729,
        819,
        6677,
        293,
        567,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1204930517408583,
      "compression_ratio": 1.6753246753246753,
      "no_speech_prob": 7.329994696192443e-05
    },
    {
      "id": 85,
      "seek": 73676,
      "start": 756.36,
      "end": 763.3199999999999,
      "text": " and also for secrets and who's in charge of those systems. It's not, it's sometimes the dev ops people,",
      "tokens": [
        51344,
        293,
        611,
        337,
        14093,
        293,
        567,
        311,
        294,
        4602,
        295,
        729,
        3652,
        13,
        467,
        311,
        406,
        11,
        309,
        311,
        2171,
        264,
        1905,
        44663,
        561,
        11,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1204930517408583,
      "compression_ratio": 1.6753246753246753,
      "no_speech_prob": 7.329994696192443e-05
    },
    {
      "id": 86,
      "seek": 76332,
      "start": 763.32,
      "end": 770.44,
      "text": " but it's coming from the CTO or like a security officer or like there so they're doing that in",
      "tokens": [
        50364,
        457,
        309,
        311,
        1348,
        490,
        264,
        383,
        15427,
        420,
        411,
        257,
        3825,
        8456,
        420,
        411,
        456,
        370,
        436,
        434,
        884,
        300,
        294,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18531602049527102,
      "compression_ratio": 1.547872340425532,
      "no_speech_prob": 0.0006314321071840823
    },
    {
      "id": 87,
      "seek": 76332,
      "start": 770.44,
      "end": 779.32,
      "text": " coordination. So one thing we could do is frame that stage in terms of like what I work with my",
      "tokens": [
        50720,
        21252,
        13,
        407,
        472,
        551,
        321,
        727,
        360,
        307,
        3920,
        300,
        3233,
        294,
        2115,
        295,
        411,
        437,
        286,
        589,
        365,
        452,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18531602049527102,
      "compression_ratio": 1.547872340425532,
      "no_speech_prob": 0.0006314321071840823
    },
    {
      "id": 88,
      "seek": 76332,
      "start": 779.32,
      "end": 786.36,
      "text": " needs to align with our security standards. Yes. Yeah, that's a really great point. That's something",
      "tokens": [
        51164,
        2203,
        281,
        7975,
        365,
        527,
        3825,
        7787,
        13,
        1079,
        13,
        865,
        11,
        300,
        311,
        257,
        534,
        869,
        935,
        13,
        663,
        311,
        746,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18531602049527102,
      "compression_ratio": 1.547872340425532,
      "no_speech_prob": 0.0006314321071840823
    },
    {
      "id": 89,
      "seek": 78636,
      "start": 786.44,
      "end": 795.24,
      "text": " that I definitely missed like noting here that even though like the executor, especially in the context",
      "tokens": [
        50368,
        300,
        286,
        2138,
        6721,
        411,
        26801,
        510,
        300,
        754,
        1673,
        411,
        264,
        7568,
        284,
        11,
        2318,
        294,
        264,
        4319,
        50808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20878621303673947,
      "compression_ratio": 1.7085714285714286,
      "no_speech_prob": 0.010584245435893536
    },
    {
      "id": 90,
      "seek": 78636,
      "start": 795.24,
      "end": 803.88,
      "text": " of the execute state, it's it might be the developer, but the job that the job the user who the job",
      "tokens": [
        50808,
        295,
        264,
        14483,
        1785,
        11,
        309,
        311,
        309,
        1062,
        312,
        264,
        10754,
        11,
        457,
        264,
        1691,
        300,
        264,
        1691,
        264,
        4195,
        567,
        264,
        1691,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20878621303673947,
      "compression_ratio": 1.7085714285714286,
      "no_speech_prob": 0.010584245435893536
    },
    {
      "id": 91,
      "seek": 78636,
      "start": 803.88,
      "end": 811.08,
      "text": " should target might be some entirely different the compliance manager or the release manager or",
      "tokens": [
        51240,
        820,
        3779,
        1062,
        312,
        512,
        7696,
        819,
        264,
        15882,
        6598,
        420,
        264,
        4374,
        6598,
        420,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20878621303673947,
      "compression_ratio": 1.7085714285714286,
      "no_speech_prob": 0.010584245435893536
    },
    {
      "id": 92,
      "seek": 81108,
      "start": 812.0400000000001,
      "end": 820.5200000000001,
      "text": " who's our concern. Yes, it's teamwork. Yeah. Yeah. So one thing that I saw in the video today,",
      "tokens": [
        50412,
        567,
        311,
        527,
        3136,
        13,
        1079,
        11,
        309,
        311,
        30015,
        13,
        865,
        13,
        865,
        13,
        407,
        472,
        551,
        300,
        286,
        1866,
        294,
        264,
        960,
        965,
        11,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29095529626916955,
      "compression_ratio": 1.572972972972973,
      "no_speech_prob": 0.0017821276560425758
    },
    {
      "id": 93,
      "seek": 81108,
      "start": 820.5200000000001,
      "end": 828.12,
      "text": " in one of the videos that I was watching is so there the person talked about that let's say you're",
      "tokens": [
        50836,
        294,
        472,
        295,
        264,
        2145,
        300,
        286,
        390,
        1976,
        307,
        370,
        456,
        264,
        954,
        2825,
        466,
        300,
        718,
        311,
        584,
        291,
        434,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29095529626916955,
      "compression_ratio": 1.572972972972973,
      "no_speech_prob": 0.0017821276560425758
    },
    {
      "id": 94,
      "seek": 81108,
      "start": 828.12,
      "end": 837.5600000000001,
      "text": " working for a B2B company and you have a buyer, but the buyer is not your user. The buyer is like",
      "tokens": [
        51216,
        1364,
        337,
        257,
        363,
        17,
        33,
        2237,
        293,
        291,
        362,
        257,
        24645,
        11,
        457,
        264,
        24645,
        307,
        406,
        428,
        4195,
        13,
        440,
        24645,
        307,
        411,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.29095529626916955,
      "compression_ratio": 1.572972972972973,
      "no_speech_prob": 0.0017821276560425758
    },
    {
      "id": 95,
      "seek": 83756,
      "start": 838.3599999999999,
      "end": 845.56,
      "text": " of course purchasing from you, but you should never like build the persona, build the jobs to be done",
      "tokens": [
        50404,
        295,
        1164,
        20906,
        490,
        291,
        11,
        457,
        291,
        820,
        1128,
        411,
        1322,
        264,
        12184,
        11,
        1322,
        264,
        4782,
        281,
        312,
        1096,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12720955439976284,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.0029887210112065077
    },
    {
      "id": 96,
      "seek": 83756,
      "start": 845.56,
      "end": 850.28,
      "text": " targeting the buyer because it has to be about the user or the user is trying to accomplish.",
      "tokens": [
        50764,
        17918,
        264,
        24645,
        570,
        309,
        575,
        281,
        312,
        466,
        264,
        4195,
        420,
        264,
        4195,
        307,
        1382,
        281,
        9021,
        13,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12720955439976284,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.0029887210112065077
    },
    {
      "id": 97,
      "seek": 83756,
      "start": 850.28,
      "end": 856.4399999999999,
      "text": " So even though we're not talking about the buyer here, but in terms of who the jobs to be done",
      "tokens": [
        51000,
        407,
        754,
        1673,
        321,
        434,
        406,
        1417,
        466,
        264,
        24645,
        510,
        11,
        457,
        294,
        2115,
        295,
        567,
        264,
        4782,
        281,
        312,
        1096,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12720955439976284,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.0029887210112065077
    },
    {
      "id": 98,
      "seek": 85644,
      "start": 856.5200000000001,
      "end": 864.6,
      "text": " should target like the end user of that, I think in this case it's different set of people.",
      "tokens": [
        50368,
        820,
        3779,
        411,
        264,
        917,
        4195,
        295,
        300,
        11,
        286,
        519,
        294,
        341,
        1389,
        309,
        311,
        819,
        992,
        295,
        561,
        13,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33710047777961283,
      "compression_ratio": 1.4550898203592815,
      "no_speech_prob": 0.014145431108772755
    },
    {
      "id": 99,
      "seek": 85644,
      "start": 866.7600000000001,
      "end": 873.0,
      "text": " Yeah, or at least they're in control and the developers are working within those.",
      "tokens": [
        50880,
        865,
        11,
        420,
        412,
        1935,
        436,
        434,
        294,
        1969,
        293,
        264,
        8849,
        366,
        1364,
        1951,
        729,
        13,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33710047777961283,
      "compression_ratio": 1.4550898203592815,
      "no_speech_prob": 0.014145431108772755
    },
    {
      "id": 100,
      "seek": 85644,
      "start": 875.0,
      "end": 885.0,
      "text": " Yes, how it bar rails. Yeah. Okay. And then stage six, six, six, yes.",
      "tokens": [
        51292,
        1079,
        11,
        577,
        309,
        2159,
        27649,
        13,
        865,
        13,
        1033,
        13,
        400,
        550,
        3233,
        2309,
        11,
        2309,
        11,
        2309,
        11,
        2086,
        13,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33710047777961283,
      "compression_ratio": 1.4550898203592815,
      "no_speech_prob": 0.014145431108772755
    },
    {
      "id": 101,
      "seek": 88500,
      "start": 885.16,
      "end": 889.48,
      "text": " So like I had mentioned that from stage six, different kind of",
      "tokens": [
        50372,
        407,
        411,
        286,
        632,
        2835,
        300,
        490,
        3233,
        2309,
        11,
        819,
        733,
        295,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22448579196272225,
      "compression_ratio": 1.4853801169590644,
      "no_speech_prob": 0.005251910537481308
    },
    {
      "id": 102,
      "seek": 88500,
      "start": 890.28,
      "end": 899.4,
      "text": " personas would have different expectations. Here, it's feared because now when I think of it that",
      "tokens": [
        50628,
        12019,
        576,
        362,
        819,
        9843,
        13,
        1692,
        11,
        309,
        311,
        30629,
        570,
        586,
        562,
        286,
        519,
        295,
        309,
        300,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22448579196272225,
      "compression_ratio": 1.4853801169590644,
      "no_speech_prob": 0.005251910537481308
    },
    {
      "id": 103,
      "seek": 88500,
      "start": 899.4,
      "end": 904.6,
      "text": " even though this involves like defining the core executors at the very beginning, I think the",
      "tokens": [
        51084,
        754,
        1673,
        341,
        11626,
        411,
        17827,
        264,
        4965,
        7568,
        830,
        412,
        264,
        588,
        2863,
        11,
        286,
        519,
        264,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22448579196272225,
      "compression_ratio": 1.4853801169590644,
      "no_speech_prob": 0.005251910537481308
    },
    {
      "id": 104,
      "seek": 90460,
      "start": 904.6,
      "end": 916.36,
      "text": " core executors for every stage is different. Yeah, because I'm thinking that yeah,",
      "tokens": [
        50364,
        4965,
        7568,
        830,
        337,
        633,
        3233,
        307,
        819,
        13,
        865,
        11,
        570,
        286,
        478,
        1953,
        300,
        1338,
        11,
        50952
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3110075388869194,
      "compression_ratio": 1.558011049723757,
      "no_speech_prob": 0.0018233248265460134
    },
    {
      "id": 105,
      "seek": 90460,
      "start": 916.36,
      "end": 924.44,
      "text": " the stage six, the devs are hands on again, right? Yes. Okay. Yeah, but should it matter like who's",
      "tokens": [
        50952,
        264,
        3233,
        2309,
        11,
        264,
        1905,
        82,
        366,
        2377,
        322,
        797,
        11,
        558,
        30,
        1079,
        13,
        1033,
        13,
        865,
        11,
        457,
        820,
        309,
        1871,
        411,
        567,
        311,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3110075388869194,
      "compression_ratio": 1.558011049723757,
      "no_speech_prob": 0.0018233248265460134
    },
    {
      "id": 106,
      "seek": 90460,
      "start": 924.44,
      "end": 933.88,
      "text": " the most hands on? Should it matter like who's concern is this particular stage attendant to? Well,",
      "tokens": [
        51356,
        264,
        881,
        2377,
        322,
        30,
        6454,
        309,
        1871,
        411,
        567,
        311,
        3136,
        307,
        341,
        1729,
        3233,
        39339,
        281,
        30,
        1042,
        11,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3110075388869194,
      "compression_ratio": 1.558011049723757,
      "no_speech_prob": 0.0018233248265460134
    },
    {
      "id": 107,
      "seek": 93460,
      "start": 934.6,
      "end": 941.32,
      "text": " I think that's why the jobs to be done, at least this is the page, this is the like handbook page with",
      "tokens": [
        50364,
        286,
        519,
        300,
        311,
        983,
        264,
        4782,
        281,
        312,
        1096,
        11,
        412,
        1935,
        341,
        307,
        264,
        3028,
        11,
        341,
        307,
        264,
        411,
        1011,
        2939,
        3028,
        365,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17504125833511353,
      "compression_ratio": 1.7268518518518519,
      "no_speech_prob": 0.00030469370540231466
    },
    {
      "id": 108,
      "seek": 93460,
      "start": 941.32,
      "end": 950.2,
      "text": " Jackie's video that like I can understand it. So because the job can be anybody that does it, but",
      "tokens": [
        50700,
        23402,
        311,
        960,
        300,
        411,
        286,
        393,
        1223,
        309,
        13,
        407,
        570,
        264,
        1691,
        393,
        312,
        4472,
        300,
        775,
        309,
        11,
        457,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17504125833511353,
      "compression_ratio": 1.7268518518518519,
      "no_speech_prob": 0.00030469370540231466
    },
    {
      "id": 109,
      "seek": 93460,
      "start": 950.2,
      "end": 955.32,
      "text": " eventually the person when it becomes a jobs to be done, the persona steps in.",
      "tokens": [
        51144,
        4728,
        264,
        954,
        562,
        309,
        3643,
        257,
        4782,
        281,
        312,
        1096,
        11,
        264,
        12184,
        4439,
        294,
        13,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17504125833511353,
      "compression_ratio": 1.7268518518518519,
      "no_speech_prob": 0.00030469370540231466
    },
    {
      "id": 110,
      "seek": 93460,
      "start": 957.16,
      "end": 963.32,
      "text": " Because it says in this handbook, a page says job, deploy and build into place offer and then",
      "tokens": [
        51492,
        1436,
        309,
        1619,
        294,
        341,
        1011,
        2939,
        11,
        257,
        3028,
        1619,
        1691,
        11,
        7274,
        293,
        1322,
        666,
        1081,
        2626,
        293,
        550,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17504125833511353,
      "compression_ratio": 1.7268518518518519,
      "no_speech_prob": 0.00030469370540231466
    },
    {
      "id": 111,
      "seek": 96332,
      "start": 963.32,
      "end": 969.32,
      "text": " job performer is an element of jobs to be done and that brings in the persona.",
      "tokens": [
        50364,
        1691,
        30248,
        307,
        364,
        4478,
        295,
        4782,
        281,
        312,
        1096,
        293,
        300,
        5607,
        294,
        264,
        12184,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1350029165094549,
      "compression_ratio": 1.6919431279620853,
      "no_speech_prob": 0.00029837244073860347
    },
    {
      "id": 112,
      "seek": 96332,
      "start": 971.8000000000001,
      "end": 978.6800000000001,
      "text": " Which is part of the circumstance. Yes, but I could get us in a lot of trouble because I'm not",
      "tokens": [
        50788,
        3013,
        307,
        644,
        295,
        264,
        27640,
        13,
        1079,
        11,
        457,
        286,
        727,
        483,
        505,
        294,
        257,
        688,
        295,
        5253,
        570,
        286,
        478,
        406,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1350029165094549,
      "compression_ratio": 1.6919431279620853,
      "no_speech_prob": 0.00029837244073860347
    },
    {
      "id": 113,
      "seek": 96332,
      "start": 978.6800000000001,
      "end": 985.88,
      "text": " sure that I'm tracking how we do it here, but that's how I think it that's that's what I mean,",
      "tokens": [
        51132,
        988,
        300,
        286,
        478,
        11603,
        577,
        321,
        360,
        309,
        510,
        11,
        457,
        300,
        311,
        577,
        286,
        519,
        309,
        300,
        311,
        300,
        311,
        437,
        286,
        914,
        11,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1350029165094549,
      "compression_ratio": 1.6919431279620853,
      "no_speech_prob": 0.00029837244073860347
    },
    {
      "id": 114,
      "seek": 96332,
      "start": 985.88,
      "end": 991.72,
      "text": " like we want to just be able to pull out not the jobs to be done, but even just the job.",
      "tokens": [
        51492,
        411,
        321,
        528,
        281,
        445,
        312,
        1075,
        281,
        2235,
        484,
        406,
        264,
        4782,
        281,
        312,
        1096,
        11,
        457,
        754,
        445,
        264,
        1691,
        13,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1350029165094549,
      "compression_ratio": 1.6919431279620853,
      "no_speech_prob": 0.00029837244073860347
    },
    {
      "id": 115,
      "seek": 99172,
      "start": 992.36,
      "end": 1001.72,
      "text": " But I think the job is more about like kind of how we said, making the releases more efficient in a way",
      "tokens": [
        50396,
        583,
        286,
        519,
        264,
        1691,
        307,
        544,
        466,
        411,
        733,
        295,
        577,
        321,
        848,
        11,
        1455,
        264,
        16952,
        544,
        7148,
        294,
        257,
        636,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3596371078491211,
      "compression_ratio": 1.3496503496503496,
      "no_speech_prob": 0.0009432972292415798
    },
    {
      "id": 116,
      "seek": 99172,
      "start": 1001.72,
      "end": 1010.52,
      "text": " that is secure. Yeah. For that meets the security requirements.",
      "tokens": [
        50864,
        300,
        307,
        7144,
        13,
        865,
        13,
        1171,
        300,
        13961,
        264,
        3825,
        7728,
        13,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3596371078491211,
      "compression_ratio": 1.3496503496503496,
      "no_speech_prob": 0.0009432972292415798
    },
    {
      "id": 117,
      "seek": 99172,
      "start": 1013.72,
      "end": 1015.24,
      "text": " We did within my company.",
      "tokens": [
        51464,
        492,
        630,
        1951,
        452,
        2237,
        13,
        51540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3596371078491211,
      "compression_ratio": 1.3496503496503496,
      "no_speech_prob": 0.0009432972292415798
    },
    {
      "id": 118,
      "seek": 101524,
      "start": 1015.72,
      "end": 1025.8,
      "text": " Yeah, I think thinking in the constraint, only thinking in the constraint of the",
      "tokens": [
        50388,
        865,
        11,
        286,
        519,
        1953,
        294,
        264,
        25534,
        11,
        787,
        1953,
        294,
        264,
        25534,
        295,
        264,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26935822216432487,
      "compression_ratio": 1.608187134502924,
      "no_speech_prob": 0.0075418055057525635
    },
    {
      "id": 119,
      "seek": 101524,
      "start": 1026.52,
      "end": 1031.16,
      "text": " executive person, as that we shortly start at the beginning, I think that's a wrong approach.",
      "tokens": [
        50928,
        10140,
        954,
        11,
        382,
        300,
        321,
        13392,
        722,
        412,
        264,
        2863,
        11,
        286,
        519,
        300,
        311,
        257,
        2085,
        3109,
        13,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26935822216432487,
      "compression_ratio": 1.608187134502924,
      "no_speech_prob": 0.0075418055057525635
    },
    {
      "id": 120,
      "seek": 101524,
      "start": 1033.24,
      "end": 1039.8,
      "text": " That kind of limits in some way, like how we are defining the job should be done and it might not be",
      "tokens": [
        51264,
        663,
        733,
        295,
        10406,
        294,
        512,
        636,
        11,
        411,
        577,
        321,
        366,
        17827,
        264,
        1691,
        820,
        312,
        1096,
        293,
        309,
        1062,
        406,
        312,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26935822216432487,
      "compression_ratio": 1.608187134502924,
      "no_speech_prob": 0.0075418055057525635
    },
    {
      "id": 121,
      "seek": 103980,
      "start": 1040.76,
      "end": 1048.28,
      "text": " because a developer would never be too concerned about the compliance standards or the security",
      "tokens": [
        50412,
        570,
        257,
        10754,
        576,
        1128,
        312,
        886,
        5922,
        466,
        264,
        15882,
        7787,
        420,
        264,
        3825,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11952994851505055,
      "compression_ratio": 1.6511627906976745,
      "no_speech_prob": 0.0012786276638507843
    },
    {
      "id": 122,
      "seek": 103980,
      "start": 1048.28,
      "end": 1053.0,
      "text": " standards. It would always be somebody else, but if I only think of like what the developer is",
      "tokens": [
        50788,
        7787,
        13,
        467,
        576,
        1009,
        312,
        2618,
        1646,
        11,
        457,
        498,
        286,
        787,
        519,
        295,
        411,
        437,
        264,
        10754,
        307,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11952994851505055,
      "compression_ratio": 1.6511627906976745,
      "no_speech_prob": 0.0012786276638507843
    },
    {
      "id": 123,
      "seek": 103980,
      "start": 1053.0,
      "end": 1059.24,
      "text": " trying to achieve here, I might get things wrong. What do you think?",
      "tokens": [
        51024,
        1382,
        281,
        4584,
        510,
        11,
        286,
        1062,
        483,
        721,
        2085,
        13,
        708,
        360,
        291,
        519,
        30,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11952994851505055,
      "compression_ratio": 1.6511627906976745,
      "no_speech_prob": 0.0012786276638507843
    },
    {
      "id": 124,
      "seek": 103980,
      "start": 1061.56,
      "end": 1068.36,
      "text": " Yeah, I mean, I think we want to just talk to them about these about what they're trying to do,",
      "tokens": [
        51452,
        865,
        11,
        286,
        914,
        11,
        286,
        519,
        321,
        528,
        281,
        445,
        751,
        281,
        552,
        466,
        613,
        466,
        437,
        436,
        434,
        1382,
        281,
        360,
        11,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11952994851505055,
      "compression_ratio": 1.6511627906976745,
      "no_speech_prob": 0.0012786276638507843
    },
    {
      "id": 125,
      "seek": 106836,
      "start": 1068.36,
      "end": 1074.52,
      "text": " because some of them I've talked to are in charge of security stuff, but they're not like the",
      "tokens": [
        50364,
        570,
        512,
        295,
        552,
        286,
        600,
        2825,
        281,
        366,
        294,
        4602,
        295,
        3825,
        1507,
        11,
        457,
        436,
        434,
        406,
        411,
        264,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19564258730089343,
      "compression_ratio": 1.459016393442623,
      "no_speech_prob": 7.859813922550529e-05
    },
    {
      "id": 126,
      "seek": 106836,
      "start": 1074.52,
      "end": 1082.84,
      "text": " author, kind of how we're doing it. We can also have a discussion around this.",
      "tokens": [
        50672,
        3793,
        11,
        733,
        295,
        577,
        321,
        434,
        884,
        309,
        13,
        492,
        393,
        611,
        362,
        257,
        5017,
        926,
        341,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19564258730089343,
      "compression_ratio": 1.459016393442623,
      "no_speech_prob": 7.859813922550529e-05
    },
    {
      "id": 127,
      "seek": 106836,
      "start": 1084.12,
      "end": 1092.04,
      "text": " Yeah. No, and I think that I mean, even now, one question I have is just like, where does Nadi",
      "tokens": [
        51152,
        865,
        13,
        883,
        11,
        293,
        286,
        519,
        300,
        286,
        914,
        11,
        754,
        586,
        11,
        472,
        1168,
        286,
        362,
        307,
        445,
        411,
        11,
        689,
        775,
        426,
        5688,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19564258730089343,
      "compression_ratio": 1.459016393442623,
      "no_speech_prob": 7.859813922550529e-05
    },
    {
      "id": 128,
      "seek": 109204,
      "start": 1092.12,
      "end": 1096.12,
      "text": " has work stop up and then your work pick up? I mean, I'm not even sure there.",
      "tokens": [
        50368,
        575,
        589,
        1590,
        493,
        293,
        550,
        428,
        589,
        1888,
        493,
        30,
        286,
        914,
        11,
        286,
        478,
        406,
        754,
        988,
        456,
        13,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440345287322998,
      "compression_ratio": 1.6403508771929824,
      "no_speech_prob": 0.03157971799373627
    },
    {
      "id": 129,
      "seek": 109204,
      "start": 1097.1599999999999,
      "end": 1104.12,
      "text": " So this modified part where I talked about a reverse handover, this is Nadi's, and then this is",
      "tokens": [
        50620,
        407,
        341,
        15873,
        644,
        689,
        286,
        2825,
        466,
        257,
        9943,
        1011,
        3570,
        11,
        341,
        307,
        426,
        5688,
        311,
        11,
        293,
        550,
        341,
        307,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440345287322998,
      "compression_ratio": 1.6403508771929824,
      "no_speech_prob": 0.03157971799373627
    },
    {
      "id": 130,
      "seek": 109204,
      "start": 1104.12,
      "end": 1111.08,
      "text": " Nadi's define and to some extent locate. Okay, I think that's what I think I'm always wanting to make",
      "tokens": [
        50968,
        426,
        5688,
        311,
        6964,
        293,
        281,
        512,
        8396,
        22370,
        13,
        1033,
        11,
        286,
        519,
        300,
        311,
        437,
        286,
        519,
        286,
        478,
        1009,
        7935,
        281,
        652,
        51316
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440345287322998,
      "compression_ratio": 1.6403508771929824,
      "no_speech_prob": 0.03157971799373627
    },
    {
      "id": 131,
      "seek": 109204,
      "start": 1111.08,
      "end": 1119.56,
      "text": " it like a literal break off, but that's good. Okay. Yeah. Yeah. And then I did this small exercise",
      "tokens": [
        51316,
        309,
        411,
        257,
        20411,
        1821,
        766,
        11,
        457,
        300,
        311,
        665,
        13,
        1033,
        13,
        865,
        13,
        865,
        13,
        400,
        550,
        286,
        630,
        341,
        1359,
        5380,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2440345287322998,
      "compression_ratio": 1.6403508771929824,
      "no_speech_prob": 0.03157971799373627
    },
    {
      "id": 132,
      "seek": 111956,
      "start": 1119.56,
      "end": 1125.08,
      "text": " of prioritization. At this point, I couldn't tell like what the colors denote, because I was smart",
      "tokens": [
        50364,
        295,
        14846,
        2144,
        13,
        1711,
        341,
        935,
        11,
        286,
        2809,
        380,
        980,
        411,
        437,
        264,
        4577,
        45708,
        11,
        570,
        286,
        390,
        4069,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17590848019248562,
      "compression_ratio": 1.5846774193548387,
      "no_speech_prob": 0.024566249921917915
    },
    {
      "id": 133,
      "seek": 111956,
      "start": 1125.08,
      "end": 1134.36,
      "text": " enough not to make an index for that. But yeah, we had a synchronous session, B and the PM, and we",
      "tokens": [
        50640,
        1547,
        406,
        281,
        652,
        364,
        8186,
        337,
        300,
        13,
        583,
        1338,
        11,
        321,
        632,
        257,
        44743,
        5481,
        11,
        363,
        293,
        264,
        12499,
        11,
        293,
        321,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17590848019248562,
      "compression_ratio": 1.5846774193548387,
      "no_speech_prob": 0.024566249921917915
    },
    {
      "id": 134,
      "seek": 111956,
      "start": 1134.36,
      "end": 1143.1599999999999,
      "text": " talked about like which are the most important and most important personas, but we satisfy it,",
      "tokens": [
        51104,
        2825,
        466,
        411,
        597,
        366,
        264,
        881,
        1021,
        293,
        881,
        1021,
        12019,
        11,
        457,
        321,
        19319,
        309,
        11,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17590848019248562,
      "compression_ratio": 1.5846774193548387,
      "no_speech_prob": 0.024566249921917915
    },
    {
      "id": 135,
      "seek": 111956,
      "start": 1143.1599999999999,
      "end": 1149.0,
      "text": " so we mark them as opportunities for ourselves. Like this is the area where we should be thinking of",
      "tokens": [
        51544,
        370,
        321,
        1491,
        552,
        382,
        4786,
        337,
        4175,
        13,
        1743,
        341,
        307,
        264,
        1859,
        689,
        321,
        820,
        312,
        1953,
        295,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17590848019248562,
      "compression_ratio": 1.5846774193548387,
      "no_speech_prob": 0.024566249921917915
    },
    {
      "id": 136,
      "seek": 114900,
      "start": 1149.0,
      "end": 1153.08,
      "text": " making improvements in our future of plans for categories.",
      "tokens": [
        50364,
        1455,
        13797,
        294,
        527,
        2027,
        295,
        5482,
        337,
        10479,
        13,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17717465332576207,
      "compression_ratio": 1.4768211920529801,
      "no_speech_prob": 0.00015537549916189164
    },
    {
      "id": 137,
      "seek": 114900,
      "start": 1156.36,
      "end": 1162.84,
      "text": " And then yeah, I mean, it feels like we're implicitly mapping the",
      "tokens": [
        50732,
        400,
        550,
        1338,
        11,
        286,
        914,
        11,
        309,
        3417,
        411,
        321,
        434,
        26947,
        356,
        18350,
        264,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17717465332576207,
      "compression_ratio": 1.4768211920529801,
      "no_speech_prob": 0.00015537549916189164
    },
    {
      "id": 138,
      "seek": 114900,
      "start": 1165.96,
      "end": 1172.84,
      "text": " personas to the stages. But what if we just make the job, making the release, making the releases,",
      "tokens": [
        51212,
        12019,
        281,
        264,
        10232,
        13,
        583,
        437,
        498,
        321,
        445,
        652,
        264,
        1691,
        11,
        1455,
        264,
        4374,
        11,
        1455,
        264,
        16952,
        11,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17717465332576207,
      "compression_ratio": 1.4768211920529801,
      "no_speech_prob": 0.00015537549916189164
    },
    {
      "id": 139,
      "seek": 117284,
      "start": 1172.84,
      "end": 1181.08,
      "text": " is it of my software, more efficient in a way that meets the security requirements",
      "tokens": [
        50364,
        307,
        309,
        295,
        452,
        4722,
        11,
        544,
        7148,
        294,
        257,
        636,
        300,
        13961,
        264,
        3825,
        7728,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23818089885096397,
      "compression_ratio": 2.068702290076336,
      "no_speech_prob": 0.0028280504047870636
    },
    {
      "id": 140,
      "seek": 117284,
      "start": 1183.3999999999999,
      "end": 1188.6799999999998,
      "text": " of the software, which didn't say mine, that making the releases of software more efficient in a",
      "tokens": [
        50892,
        295,
        264,
        4722,
        11,
        597,
        994,
        380,
        584,
        3892,
        11,
        300,
        1455,
        264,
        16952,
        295,
        4722,
        544,
        7148,
        294,
        257,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23818089885096397,
      "compression_ratio": 2.068702290076336,
      "no_speech_prob": 0.0028280504047870636
    },
    {
      "id": 141,
      "seek": 117284,
      "start": 1188.6799999999998,
      "end": 1196.04,
      "text": " way that meets the security requirements of our company, our company, in the way that meets",
      "tokens": [
        51156,
        636,
        300,
        13961,
        264,
        3825,
        7728,
        295,
        527,
        2237,
        11,
        527,
        2237,
        11,
        294,
        264,
        636,
        300,
        13961,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23818089885096397,
      "compression_ratio": 2.068702290076336,
      "no_speech_prob": 0.0028280504047870636
    },
    {
      "id": 142,
      "seek": 119604,
      "start": 1196.12,
      "end": 1202.2,
      "text": " company security requirements. Because that will cover this whole flow.",
      "tokens": [
        50368,
        2237,
        3825,
        7728,
        13,
        1436,
        300,
        486,
        2060,
        341,
        1379,
        3095,
        13,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16427700860159739,
      "compression_ratio": 1.6009174311926606,
      "no_speech_prob": 0.002373805968090892
    },
    {
      "id": 143,
      "seek": 119604,
      "start": 1204.36,
      "end": 1209.8,
      "text": " That's also what confuses me is whether or not the job needs to cover a whole flow or",
      "tokens": [
        50780,
        663,
        311,
        611,
        437,
        1497,
        8355,
        385,
        307,
        1968,
        420,
        406,
        264,
        1691,
        2203,
        281,
        2060,
        257,
        1379,
        3095,
        420,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16427700860159739,
      "compression_ratio": 1.6009174311926606,
      "no_speech_prob": 0.002373805968090892
    },
    {
      "id": 144,
      "seek": 119604,
      "start": 1210.92,
      "end": 1218.44,
      "text": " yeah, that's where the elevation and the granularity that mapping comes into picture. So we can",
      "tokens": [
        51108,
        1338,
        11,
        300,
        311,
        689,
        264,
        25827,
        293,
        264,
        39962,
        507,
        300,
        18350,
        1487,
        666,
        3036,
        13,
        407,
        321,
        393,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16427700860159739,
      "compression_ratio": 1.6009174311926606,
      "no_speech_prob": 0.002373805968090892
    },
    {
      "id": 145,
      "seek": 119604,
      "start": 1218.44,
      "end": 1224.92,
      "text": " like if you map it as a reverse triangle, then what you're saying, that can totally be the core",
      "tokens": [
        51484,
        411,
        498,
        291,
        4471,
        309,
        382,
        257,
        9943,
        13369,
        11,
        550,
        437,
        291,
        434,
        1566,
        11,
        300,
        393,
        3879,
        312,
        264,
        4965,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16427700860159739,
      "compression_ratio": 1.6009174311926606,
      "no_speech_prob": 0.002373805968090892
    },
    {
      "id": 146,
      "seek": 122492,
      "start": 1225.0,
      "end": 1231.0,
      "text": " jobs to be done, which is at the highest level. And then when we try to like break it further, it would",
      "tokens": [
        50368,
        4782,
        281,
        312,
        1096,
        11,
        597,
        307,
        412,
        264,
        6343,
        1496,
        13,
        400,
        550,
        562,
        321,
        853,
        281,
        411,
        1821,
        309,
        3052,
        11,
        309,
        576,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1967426852176064,
      "compression_ratio": 1.497142857142857,
      "no_speech_prob": 0.0006881649605929852
    },
    {
      "id": 147,
      "seek": 122492,
      "start": 1231.0,
      "end": 1233.8000000000002,
      "text": " be, it would cover the flow.",
      "tokens": [
        50668,
        312,
        11,
        309,
        576,
        2060,
        264,
        3095,
        13,
        50808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1967426852176064,
      "compression_ratio": 1.497142857142857,
      "no_speech_prob": 0.0006881649605929852
    },
    {
      "id": 148,
      "seek": 122492,
      "start": 1236.8400000000001,
      "end": 1237.16,
      "text": " Okay.",
      "tokens": [
        50960,
        1033,
        13,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1967426852176064,
      "compression_ratio": 1.497142857142857,
      "no_speech_prob": 0.0006881649605929852
    },
    {
      "id": 149,
      "seek": 122492,
      "start": 1242.1200000000001,
      "end": 1244.04,
      "text": " I love that reverse triangle. Yep.",
      "tokens": [
        51224,
        286,
        959,
        300,
        9943,
        13369,
        13,
        7010,
        13,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1967426852176064,
      "compression_ratio": 1.497142857142857,
      "no_speech_prob": 0.0006881649605929852
    },
    {
      "id": 150,
      "seek": 122492,
      "start": 1245.96,
      "end": 1253.24,
      "text": " Okay, and then okay, let's talk about a little bit about where the merge trains come in.",
      "tokens": [
        51416,
        1033,
        11,
        293,
        550,
        1392,
        11,
        718,
        311,
        751,
        466,
        257,
        707,
        857,
        466,
        689,
        264,
        22183,
        16329,
        808,
        294,
        13,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1967426852176064,
      "compression_ratio": 1.497142857142857,
      "no_speech_prob": 0.0006881649605929852
    },
    {
      "id": 151,
      "seek": 125324,
      "start": 1253.24,
      "end": 1258.6,
      "text": " So let me tell you. And then I think the merge trains come in at five stage five.",
      "tokens": [
        50364,
        407,
        718,
        385,
        980,
        291,
        13,
        400,
        550,
        286,
        519,
        264,
        22183,
        16329,
        808,
        294,
        412,
        1732,
        3233,
        1732,
        13,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20778429146968957,
      "compression_ratio": 1.4216867469879517,
      "no_speech_prob": 0.00015455097309313715
    },
    {
      "id": 152,
      "seek": 125324,
      "start": 1259.64,
      "end": 1267.24,
      "text": " Yes, they do. That's right. Okay. And then the, what was that other thing?",
      "tokens": [
        50684,
        1079,
        11,
        436,
        360,
        13,
        663,
        311,
        558,
        13,
        1033,
        13,
        400,
        550,
        264,
        11,
        437,
        390,
        300,
        661,
        551,
        30,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20778429146968957,
      "compression_ratio": 1.4216867469879517,
      "no_speech_prob": 0.00015455097309313715
    },
    {
      "id": 153,
      "seek": 125324,
      "start": 1272.36,
      "end": 1276.2,
      "text": " Yeah. So I think, so because we were talking about combining those two studies.",
      "tokens": [
        51320,
        865,
        13,
        407,
        286,
        519,
        11,
        370,
        570,
        321,
        645,
        1417,
        466,
        21928,
        729,
        732,
        5313,
        13,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20778429146968957,
      "compression_ratio": 1.4216867469879517,
      "no_speech_prob": 0.00015455097309313715
    },
    {
      "id": 154,
      "seek": 127620,
      "start": 1276.6000000000001,
      "end": 1277.0,
      "text": " Mm-hmm.",
      "tokens": [
        50384,
        8266,
        12,
        10250,
        13,
        50404
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2790929175711967,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.0030465321615338326
    },
    {
      "id": 155,
      "seek": 127620,
      "start": 1278.6000000000001,
      "end": 1282.6000000000001,
      "text": " So I think that's how we can kind of think about it is like mapping out.",
      "tokens": [
        50484,
        407,
        286,
        519,
        300,
        311,
        577,
        321,
        393,
        733,
        295,
        519,
        466,
        309,
        307,
        411,
        18350,
        484,
        13,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2790929175711967,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.0030465321615338326
    },
    {
      "id": 156,
      "seek": 127620,
      "start": 1284.04,
      "end": 1288.92,
      "text": " Can we think about it like mapping out the jobs to be done across this one job workflow?",
      "tokens": [
        50756,
        1664,
        321,
        519,
        466,
        309,
        411,
        18350,
        484,
        264,
        4782,
        281,
        312,
        1096,
        2108,
        341,
        472,
        1691,
        20993,
        30,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2790929175711967,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.0030465321615338326
    },
    {
      "id": 157,
      "seek": 127620,
      "start": 1292.3600000000001,
      "end": 1299.32,
      "text": " Merge trains execute. I'm going to enter the note for the one job workflow. The one that you mentioned",
      "tokens": [
        51172,
        6124,
        432,
        16329,
        14483,
        13,
        286,
        478,
        516,
        281,
        3242,
        264,
        3637,
        337,
        264,
        472,
        1691,
        20993,
        13,
        440,
        472,
        300,
        291,
        2835,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2790929175711967,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.0030465321615338326
    },
    {
      "id": 158,
      "seek": 129932,
      "start": 1299.32,
      "end": 1311.1599999999999,
      "text": " about the one that you had framed. Yeah. That can be, so in my case, I had something for the core job.",
      "tokens": [
        50364,
        466,
        264,
        472,
        300,
        291,
        632,
        30420,
        13,
        865,
        13,
        663,
        393,
        312,
        11,
        370,
        294,
        452,
        1389,
        11,
        286,
        632,
        746,
        337,
        264,
        4965,
        1691,
        13,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24500217685451756,
      "compression_ratio": 1.6198830409356726,
      "no_speech_prob": 0.0020945908036082983
    },
    {
      "id": 159,
      "seek": 129932,
      "start": 1311.1599999999999,
      "end": 1316.9199999999998,
      "text": " And like for the new mapping, what you mentioned could be our core job.",
      "tokens": [
        50956,
        400,
        411,
        337,
        264,
        777,
        18350,
        11,
        437,
        291,
        2835,
        727,
        312,
        527,
        4965,
        1691,
        13,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24500217685451756,
      "compression_ratio": 1.6198830409356726,
      "no_speech_prob": 0.0020945908036082983
    },
    {
      "id": 160,
      "seek": 129932,
      "start": 1318.52,
      "end": 1326.76,
      "text": " I think so. Yeah, the top of the triangle one. And then I think is what our main research goal can be.",
      "tokens": [
        51324,
        286,
        519,
        370,
        13,
        865,
        11,
        264,
        1192,
        295,
        264,
        13369,
        472,
        13,
        400,
        550,
        286,
        519,
        307,
        437,
        527,
        2135,
        2132,
        3387,
        393,
        312,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24500217685451756,
      "compression_ratio": 1.6198830409356726,
      "no_speech_prob": 0.0020945908036082983
    },
    {
      "id": 161,
      "seek": 132676,
      "start": 1327.08,
      "end": 1335.56,
      "text": " Or where I mean research question can be would be to figure out. Where did I write it? I wrote it.",
      "tokens": [
        50380,
        1610,
        689,
        286,
        914,
        2132,
        1168,
        393,
        312,
        576,
        312,
        281,
        2573,
        484,
        13,
        2305,
        630,
        286,
        2464,
        309,
        30,
        286,
        4114,
        309,
        13,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2568199157714844,
      "compression_ratio": 1.4960629921259843,
      "no_speech_prob": 0.0011663107434287667
    },
    {
      "id": 162,
      "seek": 132676,
      "start": 1342.76,
      "end": 1351.08,
      "text": " Yeah, how do we help developers to. How do we? Yeah, here it is. How do we help developers?",
      "tokens": [
        51164,
        865,
        11,
        577,
        360,
        321,
        854,
        8849,
        281,
        13,
        1012,
        360,
        321,
        30,
        865,
        11,
        510,
        309,
        307,
        13,
        1012,
        360,
        321,
        854,
        8849,
        30,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2568199157714844,
      "compression_ratio": 1.4960629921259843,
      "no_speech_prob": 0.0011663107434287667
    },
    {
      "id": 163,
      "seek": 135108,
      "start": 1351.1599999999999,
      "end": 1367.8799999999999,
      "text": " Oh no, how do we help users? Because we don't want to say users to make their releases more efficient.",
      "tokens": [
        50368,
        876,
        572,
        11,
        577,
        360,
        321,
        854,
        5022,
        30,
        1436,
        321,
        500,
        380,
        528,
        281,
        584,
        5022,
        281,
        652,
        641,
        16952,
        544,
        7148,
        13,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2680928473379098,
      "compression_ratio": 1.337837837837838,
      "no_speech_prob": 0.0008112456416711211
    },
    {
      "id": 164,
      "seek": 135108,
      "start": 1373.08,
      "end": 1379.48,
      "text": " So that could be of this combined research study. We can say that's our primary goal. Like that",
      "tokens": [
        51464,
        407,
        300,
        727,
        312,
        295,
        341,
        9354,
        2132,
        2979,
        13,
        492,
        393,
        584,
        300,
        311,
        527,
        6194,
        3387,
        13,
        1743,
        300,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2680928473379098,
      "compression_ratio": 1.337837837837838,
      "no_speech_prob": 0.0008112456416711211
    },
    {
      "id": 165,
      "seek": 137948,
      "start": 1379.48,
      "end": 1386.3600000000001,
      "text": " could be the name of the research study. And then kind of our approach could be.",
      "tokens": [
        50364,
        727,
        312,
        264,
        1315,
        295,
        264,
        2132,
        2979,
        13,
        400,
        550,
        733,
        295,
        527,
        3109,
        727,
        312,
        13,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1256444398746934,
      "compression_ratio": 1.70935960591133,
      "no_speech_prob": 0.0003062114992644638
    },
    {
      "id": 166,
      "seek": 137948,
      "start": 1390.84,
      "end": 1396.04,
      "text": " We could even have we could even have these stages here and then say like",
      "tokens": [
        50932,
        492,
        727,
        754,
        362,
        321,
        727,
        754,
        362,
        613,
        10232,
        510,
        293,
        550,
        584,
        411,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1256444398746934,
      "compression_ratio": 1.70935960591133,
      "no_speech_prob": 0.0003062114992644638
    },
    {
      "id": 167,
      "seek": 137948,
      "start": 1397.4,
      "end": 1401.88,
      "text": " walk us through your process with these stages. Like ideally they would show us in the tool,",
      "tokens": [
        51260,
        1792,
        505,
        807,
        428,
        1399,
        365,
        613,
        10232,
        13,
        1743,
        22915,
        436,
        576,
        855,
        505,
        294,
        264,
        2290,
        11,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1256444398746934,
      "compression_ratio": 1.70935960591133,
      "no_speech_prob": 0.0003062114992644638
    },
    {
      "id": 168,
      "seek": 137948,
      "start": 1401.88,
      "end": 1408.04,
      "text": " but they are sometimes not what they don't want to do that. So we could just put this in a deck and",
      "tokens": [
        51484,
        457,
        436,
        366,
        2171,
        406,
        437,
        436,
        500,
        380,
        528,
        281,
        360,
        300,
        13,
        407,
        321,
        727,
        445,
        829,
        341,
        294,
        257,
        9341,
        293,
        51792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1256444398746934,
      "compression_ratio": 1.70935960591133,
      "no_speech_prob": 0.0003062114992644638
    },
    {
      "id": 169,
      "seek": 140804,
      "start": 1408.04,
      "end": 1422.84,
      "text": " then have them talk through like first to say where are you involved in this flow, right? Yeah. And then say, okay, now unpack what are your goals here? What are you trying to do and what are your key tasks?",
      "tokens": [
        50364,
        550,
        362,
        552,
        751,
        807,
        411,
        700,
        281,
        584,
        689,
        366,
        291,
        3288,
        294,
        341,
        3095,
        11,
        558,
        30,
        865,
        13,
        400,
        550,
        584,
        11,
        1392,
        11,
        586,
        26699,
        437,
        366,
        428,
        5493,
        510,
        30,
        708,
        366,
        291,
        1382,
        281,
        360,
        293,
        437,
        366,
        428,
        2141,
        9608,
        30,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34302435250117863,
      "compression_ratio": 1.4342105263157894,
      "no_speech_prob": 0.0002569305070210248
    },
    {
      "id": 170,
      "seek": 140804,
      "start": 1425.56,
      "end": 1426.2,
      "text": " So that's.",
      "tokens": [
        51240,
        407,
        300,
        311,
        13,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34302435250117863,
      "compression_ratio": 1.4342105263157894,
      "no_speech_prob": 0.0002569305070210248
    },
    {
      "id": 171,
      "seek": 142620,
      "start": 1426.52,
      "end": 1430.1200000000001,
      "text": " I think that sounds good. Yeah.",
      "tokens": [
        50380,
        286,
        519,
        300,
        3263,
        665,
        13,
        865,
        13,
        50560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23026041014004597,
      "compression_ratio": 1.685823754789272,
      "no_speech_prob": 0.08216356486082077
    },
    {
      "id": 172,
      "seek": 142620,
      "start": 1430.1200000000001,
      "end": 1444.04,
      "text": " It would be critical though. Yeah, because my current plan was kind of to create the initial mapping by myself and then go to validation, but this is so much better because we won't have to like take a U-turn at any part of the process.",
      "tokens": [
        50560,
        467,
        576,
        312,
        4924,
        1673,
        13,
        865,
        11,
        570,
        452,
        2190,
        1393,
        390,
        733,
        295,
        281,
        1884,
        264,
        5883,
        18350,
        538,
        2059,
        293,
        550,
        352,
        281,
        24071,
        11,
        457,
        341,
        307,
        370,
        709,
        1101,
        570,
        321,
        1582,
        380,
        362,
        281,
        411,
        747,
        257,
        624,
        12,
        33886,
        412,
        604,
        644,
        295,
        264,
        1399,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23026041014004597,
      "compression_ratio": 1.685823754789272,
      "no_speech_prob": 0.08216356486082077
    },
    {
      "id": 173,
      "seek": 142620,
      "start": 1444.04,
      "end": 1455.8,
      "text": " Yeah, I think so. And then we just get them to kind of tell us. And it's like ideally we wouldn't do that, but this is such a technical space that I think it's defensible.",
      "tokens": [
        51256,
        865,
        11,
        286,
        519,
        370,
        13,
        400,
        550,
        321,
        445,
        483,
        552,
        281,
        733,
        295,
        980,
        505,
        13,
        400,
        309,
        311,
        411,
        22915,
        321,
        2759,
        380,
        360,
        300,
        11,
        457,
        341,
        307,
        1270,
        257,
        6191,
        1901,
        300,
        286,
        519,
        309,
        311,
        1060,
        30633,
        13,
        51844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23026041014004597,
      "compression_ratio": 1.685823754789272,
      "no_speech_prob": 0.08216356486082077
    },
    {
      "id": 174,
      "seek": 145580,
      "start": 1455.8,
      "end": 1466.44,
      "text": " Hold it. We're not asking me. Yeah, I think it's right. So, okay. So the method would be to interview to work through.",
      "tokens": [
        50364,
        6962,
        309,
        13,
        492,
        434,
        406,
        3365,
        385,
        13,
        865,
        11,
        286,
        519,
        309,
        311,
        558,
        13,
        407,
        11,
        1392,
        13,
        407,
        264,
        3170,
        576,
        312,
        281,
        4049,
        281,
        589,
        807,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3887147903442383,
      "compression_ratio": 1.3006993006993006,
      "no_speech_prob": 0.001135862316004932
    },
    {
      "id": 175,
      "seek": 145580,
      "start": 1471.56,
      "end": 1477.56,
      "text": " The different stages involved in pipelines.",
      "tokens": [
        51152,
        440,
        819,
        10232,
        3288,
        294,
        40168,
        13,
        51452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3887147903442383,
      "compression_ratio": 1.3006993006993006,
      "no_speech_prob": 0.001135862316004932
    },
    {
      "id": 176,
      "seek": 145580,
      "start": 1479.08,
      "end": 1481.56,
      "text": " To see where our users.",
      "tokens": [
        51528,
        1407,
        536,
        689,
        527,
        5022,
        13,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3887147903442383,
      "compression_ratio": 1.3006993006993006,
      "no_speech_prob": 0.001135862316004932
    },
    {
      "id": 177,
      "seek": 148580,
      "start": 1486.04,
      "end": 1491.72,
      "text": " Working and what their goals are.",
      "tokens": [
        50376,
        18337,
        293,
        437,
        641,
        5493,
        366,
        13,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3169074194771903,
      "compression_ratio": 1.1923076923076923,
      "no_speech_prob": 0.004080068785697222
    },
    {
      "id": 178,
      "seek": 148580,
      "start": 1496.36,
      "end": 1502.12,
      "text": " Do you think they'll recognize these parks or it doesn't matter. We can even just say, um,",
      "tokens": [
        50892,
        1144,
        291,
        519,
        436,
        603,
        5521,
        613,
        16213,
        420,
        309,
        1177,
        380,
        1871,
        13,
        492,
        393,
        754,
        445,
        584,
        11,
        1105,
        11,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3169074194771903,
      "compression_ratio": 1.1923076923076923,
      "no_speech_prob": 0.004080068785697222
    },
    {
      "id": 179,
      "seek": 150212,
      "start": 1502.9199999999998,
      "end": 1515.2399999999998,
      "text": " we can even just say this is how we're defining this isn't in define, locate, prepare, confirm. Is that coming from us in any way or that's not coming from us that's actually coming from the",
      "tokens": [
        50404,
        321,
        393,
        754,
        445,
        584,
        341,
        307,
        577,
        321,
        434,
        17827,
        341,
        1943,
        380,
        294,
        6964,
        11,
        22370,
        11,
        5940,
        11,
        9064,
        13,
        1119,
        300,
        1348,
        490,
        505,
        294,
        604,
        636,
        420,
        300,
        311,
        406,
        1348,
        490,
        505,
        300,
        311,
        767,
        1348,
        490,
        264,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3453870557018162,
      "compression_ratio": 1.728395061728395,
      "no_speech_prob": 0.018158497288823128
    },
    {
      "id": 180,
      "seek": 150212,
      "start": 1515.2399999999998,
      "end": 1529.56,
      "text": " uh, job, stability and templates. If you think like changing this to and even combining a few stages would help, which I think would help. For example, I don't see like very clear differentiation between prepare and confirm here.",
      "tokens": [
        51020,
        2232,
        11,
        1691,
        11,
        11826,
        293,
        21165,
        13,
        759,
        291,
        519,
        411,
        4473,
        341,
        281,
        293,
        754,
        21928,
        257,
        1326,
        10232,
        576,
        854,
        11,
        597,
        286,
        519,
        576,
        854,
        13,
        1171,
        1365,
        11,
        286,
        500,
        380,
        536,
        411,
        588,
        1850,
        38902,
        1296,
        5940,
        293,
        9064,
        510,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3453870557018162,
      "compression_ratio": 1.728395061728395,
      "no_speech_prob": 0.018158497288823128
    },
    {
      "id": 181,
      "seek": 152956,
      "start": 1529.8,
      "end": 1530.8,
      "text": " It's kind of.",
      "tokens": [
        50376,
        467,
        311,
        733,
        295,
        13,
        50426
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5384111037621131,
      "compression_ratio": 1.3706293706293706,
      "no_speech_prob": 0.00798027217388153
    },
    {
      "id": 182,
      "seek": 152956,
      "start": 1534.24,
      "end": 1545.56,
      "text": " Maybe that's an idea too is maybe what we do first is just say from your perspective, let's map out. What are the different stages.",
      "tokens": [
        50598,
        2704,
        300,
        311,
        364,
        1558,
        886,
        307,
        1310,
        437,
        321,
        360,
        700,
        307,
        445,
        584,
        490,
        428,
        4585,
        11,
        718,
        311,
        4471,
        484,
        13,
        708,
        366,
        264,
        819,
        10232,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5384111037621131,
      "compression_ratio": 1.3706293706293706,
      "no_speech_prob": 0.00798027217388153
    },
    {
      "id": 183,
      "seek": 152956,
      "start": 1547.56,
      "end": 1551.56,
      "text": " Like card sorting sort of without providing cards.",
      "tokens": [
        51264,
        1743,
        2920,
        32411,
        1333,
        295,
        1553,
        6530,
        5632,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5384111037621131,
      "compression_ratio": 1.3706293706293706,
      "no_speech_prob": 0.00798027217388153
    },
    {
      "id": 184,
      "seek": 155156,
      "start": 1552.28,
      "end": 1553.08,
      "text": " Well, yeah.",
      "tokens": [
        50400,
        1042,
        11,
        1338,
        13,
        50440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20356360902177525,
      "compression_ratio": 1.7073170731707317,
      "no_speech_prob": 0.0037238390650600195
    },
    {
      "id": 185,
      "seek": 155156,
      "start": 1554.2,
      "end": 1563.96,
      "text": " Like what I end up doing, I'll show you one of these sessions, but what I end up doing is like just like making shapes with them and like having them talk about it.",
      "tokens": [
        50496,
        1743,
        437,
        286,
        917,
        493,
        884,
        11,
        286,
        603,
        855,
        291,
        472,
        295,
        613,
        11081,
        11,
        457,
        437,
        286,
        917,
        493,
        884,
        307,
        411,
        445,
        411,
        1455,
        10854,
        365,
        552,
        293,
        411,
        1419,
        552,
        751,
        466,
        309,
        13,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20356360902177525,
      "compression_ratio": 1.7073170731707317,
      "no_speech_prob": 0.0037238390650600195
    },
    {
      "id": 186,
      "seek": 155156,
      "start": 1563.96,
      "end": 1575.1599999999999,
      "text": " Like, so what we're doing right now with the, um, the secrets lifecycle is just to be like, tell me about a secret. Where's the beginning. What's the middle. What's the end.",
      "tokens": [
        50984,
        1743,
        11,
        370,
        437,
        321,
        434,
        884,
        558,
        586,
        365,
        264,
        11,
        1105,
        11,
        264,
        14093,
        45722,
        307,
        445,
        281,
        312,
        411,
        11,
        980,
        385,
        466,
        257,
        4054,
        13,
        2305,
        311,
        264,
        2863,
        13,
        708,
        311,
        264,
        2808,
        13,
        708,
        311,
        264,
        917,
        13,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20356360902177525,
      "compression_ratio": 1.7073170731707317,
      "no_speech_prob": 0.0037238390650600195
    },
    {
      "id": 187,
      "seek": 157516,
      "start": 1575.88,
      "end": 1578.6000000000001,
      "text": " And then they kind of articulated there.",
      "tokens": [
        50400,
        400,
        550,
        436,
        733,
        295,
        43322,
        456,
        13,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2137957220678931,
      "compression_ratio": 1.711297071129707,
      "no_speech_prob": 0.0031687242444604635
    },
    {
      "id": 188,
      "seek": 157516,
      "start": 1579.24,
      "end": 1590.1200000000001,
      "text": " But in that one, we're like, who what where when. But I think in this one, we would just be like, so where does your process start. But I'm not the only thing I'm not sure about there is like how we frame it. Yeah.",
      "tokens": [
        50568,
        583,
        294,
        300,
        472,
        11,
        321,
        434,
        411,
        11,
        567,
        437,
        689,
        562,
        13,
        583,
        286,
        519,
        294,
        341,
        472,
        11,
        321,
        576,
        445,
        312,
        411,
        11,
        370,
        689,
        775,
        428,
        1399,
        722,
        13,
        583,
        286,
        478,
        406,
        264,
        787,
        551,
        286,
        478,
        406,
        988,
        466,
        456,
        307,
        411,
        577,
        321,
        3920,
        309,
        13,
        865,
        13,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2137957220678931,
      "compression_ratio": 1.711297071129707,
      "no_speech_prob": 0.0031687242444604635
    },
    {
      "id": 189,
      "seek": 157516,
      "start": 1591.64,
      "end": 1597.5600000000002,
      "text": " So keeping it open ended, but uh, kind of nudging them to define those stages themselves.",
      "tokens": [
        51188,
        407,
        5145,
        309,
        1269,
        4590,
        11,
        457,
        2232,
        11,
        733,
        295,
        40045,
        3249,
        552,
        281,
        6964,
        729,
        10232,
        2969,
        13,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2137957220678931,
      "compression_ratio": 1.711297071129707,
      "no_speech_prob": 0.0031687242444604635
    },
    {
      "id": 190,
      "seek": 157516,
      "start": 1598.3600000000001,
      "end": 1601.3200000000002,
      "text": " Yeah. And what's what do we say this? What is at the stages of.",
      "tokens": [
        51524,
        865,
        13,
        400,
        437,
        311,
        437,
        360,
        321,
        584,
        341,
        30,
        708,
        307,
        412,
        264,
        10232,
        295,
        13,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2137957220678931,
      "compression_ratio": 1.711297071129707,
      "no_speech_prob": 0.0031687242444604635
    },
    {
      "id": 191,
      "seek": 160516,
      "start": 1605.24,
      "end": 1608.92,
      "text": " What is that? What do we, how do we say it? Uh, how do you.",
      "tokens": [
        50368,
        708,
        307,
        300,
        30,
        708,
        360,
        321,
        11,
        577,
        360,
        321,
        584,
        309,
        30,
        4019,
        11,
        577,
        360,
        291,
        13,
        50552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37884369815688534,
      "compression_ratio": 1.6271186440677967,
      "no_speech_prob": 0.0012055154656991363
    },
    {
      "id": 192,
      "seek": 160516,
      "start": 1611.0,
      "end": 1614.76,
      "text": " Your perspective, what are the stages of a pipeline.",
      "tokens": [
        50656,
        2260,
        4585,
        11,
        437,
        366,
        264,
        10232,
        295,
        257,
        15517,
        13,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37884369815688534,
      "compression_ratio": 1.6271186440677967,
      "no_speech_prob": 0.0012055154656991363
    },
    {
      "id": 193,
      "seek": 160516,
      "start": 1616.8400000000001,
      "end": 1620.76,
      "text": " Of pipeline execution of pipeline. Um,",
      "tokens": [
        50948,
        2720,
        15517,
        15058,
        295,
        15517,
        13,
        3301,
        11,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37884369815688534,
      "compression_ratio": 1.6271186440677967,
      "no_speech_prob": 0.0012055154656991363
    },
    {
      "id": 194,
      "seek": 160516,
      "start": 1623.16,
      "end": 1624.3600000000001,
      "text": " the stages of.",
      "tokens": [
        51264,
        264,
        10232,
        295,
        13,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37884369815688534,
      "compression_ratio": 1.6271186440677967,
      "no_speech_prob": 0.0012055154656991363
    },
    {
      "id": 195,
      "seek": 160516,
      "start": 1626.1200000000001,
      "end": 1633.16,
      "text": " How you were. Oh, should we like keep it a little more generic and talk about what are the stages of verifying your code.",
      "tokens": [
        51412,
        1012,
        291,
        645,
        13,
        876,
        11,
        820,
        321,
        411,
        1066,
        309,
        257,
        707,
        544,
        19577,
        293,
        751,
        466,
        437,
        366,
        264,
        10232,
        295,
        1306,
        5489,
        428,
        3089,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37884369815688534,
      "compression_ratio": 1.6271186440677967,
      "no_speech_prob": 0.0012055154656991363
    },
    {
      "id": 196,
      "seek": 163316,
      "start": 1634.1200000000001,
      "end": 1634.52,
      "text": " Got it.",
      "tokens": [
        50412,
        5803,
        309,
        13,
        50432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27058935165405273,
      "compression_ratio": 1.4808743169398908,
      "no_speech_prob": 0.00033461389830335975
    },
    {
      "id": 197,
      "seek": 163316,
      "start": 1639.16,
      "end": 1653.72,
      "text": " Yeah. And you know what we can say to like we can say like not from your perspective or like what I mean, that's fine too, but we could just say tell us how your teams are breaking up the process of verifying your code into stages.",
      "tokens": [
        50664,
        865,
        13,
        400,
        291,
        458,
        437,
        321,
        393,
        584,
        281,
        411,
        321,
        393,
        584,
        411,
        406,
        490,
        428,
        4585,
        420,
        411,
        437,
        286,
        914,
        11,
        300,
        311,
        2489,
        886,
        11,
        457,
        321,
        727,
        445,
        584,
        980,
        505,
        577,
        428,
        5491,
        366,
        7697,
        493,
        264,
        1399,
        295,
        1306,
        5489,
        428,
        3089,
        666,
        10232,
        13,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27058935165405273,
      "compression_ratio": 1.4808743169398908,
      "no_speech_prob": 0.00033461389830335975
    },
    {
      "id": 198,
      "seek": 163316,
      "start": 1656.44,
      "end": 1657.72,
      "text": " I'm liking where this is going.",
      "tokens": [
        51528,
        286,
        478,
        16933,
        689,
        341,
        307,
        516,
        13,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27058935165405273,
      "compression_ratio": 1.4808743169398908,
      "no_speech_prob": 0.00033461389830335975
    },
    {
      "id": 199,
      "seek": 165772,
      "start": 1658.68,
      "end": 1659.72,
      "text": " Yeah.",
      "tokens": [
        50412,
        865,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943776681389607,
      "compression_ratio": 1.4939759036144578,
      "no_speech_prob": 0.0014154489617794752
    },
    {
      "id": 200,
      "seek": 165772,
      "start": 1659.72,
      "end": 1662.52,
      "text": " Yeah. This is the kind of information that uh,",
      "tokens": [
        50464,
        865,
        13,
        639,
        307,
        264,
        733,
        295,
        1589,
        300,
        2232,
        11,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943776681389607,
      "compression_ratio": 1.4939759036144578,
      "no_speech_prob": 0.0014154489617794752
    },
    {
      "id": 201,
      "seek": 165772,
      "start": 1664.3600000000001,
      "end": 1666.28,
      "text": " they never asked for.",
      "tokens": [
        50696,
        436,
        1128,
        2351,
        337,
        13,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943776681389607,
      "compression_ratio": 1.4939759036144578,
      "no_speech_prob": 0.0014154489617794752
    },
    {
      "id": 202,
      "seek": 165772,
      "start": 1669.24,
      "end": 1670.1200000000001,
      "text": " Mm-hmm.",
      "tokens": [
        50940,
        8266,
        12,
        10250,
        13,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943776681389607,
      "compression_ratio": 1.4939759036144578,
      "no_speech_prob": 0.0014154489617794752
    },
    {
      "id": 203,
      "seek": 165772,
      "start": 1670.1200000000001,
      "end": 1680.68,
      "text": " I think we want to step back. Tell us how your team, especially if you have the bandwidth. Tell us how your teams are breaking up the process of verifying your code.",
      "tokens": [
        50984,
        286,
        519,
        321,
        528,
        281,
        1823,
        646,
        13,
        5115,
        505,
        577,
        428,
        1469,
        11,
        2318,
        498,
        291,
        362,
        264,
        23647,
        13,
        5115,
        505,
        577,
        428,
        5491,
        366,
        7697,
        493,
        264,
        1399,
        295,
        1306,
        5489,
        428,
        3089,
        13,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3943776681389607,
      "compression_ratio": 1.4939759036144578,
      "no_speech_prob": 0.0014154489617794752
    },
    {
      "id": 204,
      "seek": 168068,
      "start": 1681.0,
      "end": 1681.8,
      "text": " Mm-hmm.",
      "tokens": [
        50380,
        8266,
        12,
        10250,
        13,
        50420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3682668021555697,
      "compression_ratio": 1.38860103626943,
      "no_speech_prob": 0.0006753202760592103
    },
    {
      "id": 205,
      "seek": 168068,
      "start": 1683.0,
      "end": 1688.76,
      "text": " And the good part is the same set of information can also be useful for Gina and Nadia.",
      "tokens": [
        50480,
        400,
        264,
        665,
        644,
        307,
        264,
        912,
        992,
        295,
        1589,
        393,
        611,
        312,
        4420,
        337,
        34711,
        293,
        23269,
        654,
        13,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3682668021555697,
      "compression_ratio": 1.38860103626943,
      "no_speech_prob": 0.0006753202760592103
    },
    {
      "id": 206,
      "seek": 168068,
      "start": 1689.72,
      "end": 1690.52,
      "text": " Yeah.",
      "tokens": [
        50816,
        865,
        13,
        50856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3682668021555697,
      "compression_ratio": 1.38860103626943,
      "no_speech_prob": 0.0006753202760592103
    },
    {
      "id": 207,
      "seek": 168068,
      "start": 1691.24,
      "end": 1695.72,
      "text": " Um, uh, yeah, because they're in this flow too, right?",
      "tokens": [
        50892,
        3301,
        11,
        2232,
        11,
        1338,
        11,
        570,
        436,
        434,
        294,
        341,
        3095,
        886,
        11,
        558,
        30,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3682668021555697,
      "compression_ratio": 1.38860103626943,
      "no_speech_prob": 0.0006753202760592103
    },
    {
      "id": 208,
      "seek": 168068,
      "start": 1695.72,
      "end": 1696.68,
      "text": " Yeah. Yeah.",
      "tokens": [
        51116,
        865,
        13,
        865,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3682668021555697,
      "compression_ratio": 1.38860103626943,
      "no_speech_prob": 0.0006753202760592103
    },
    {
      "id": 209,
      "seek": 168068,
      "start": 1696.68,
      "end": 1701.64,
      "text": " Okay. At some point we'll need to put, where is, can we do it now really quickly?",
      "tokens": [
        51164,
        1033,
        13,
        1711,
        512,
        935,
        321,
        603,
        643,
        281,
        829,
        11,
        689,
        307,
        11,
        393,
        321,
        360,
        309,
        586,
        534,
        2661,
        30,
        51412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3682668021555697,
      "compression_ratio": 1.38860103626943,
      "no_speech_prob": 0.0006753202760592103
    },
    {
      "id": 210,
      "seek": 168068,
      "start": 1701.64,
      "end": 1703.0800000000002,
      "text": " To help my brain?",
      "tokens": [
        51412,
        1407,
        854,
        452,
        3567,
        30,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3682668021555697,
      "compression_ratio": 1.38860103626943,
      "no_speech_prob": 0.0006753202760592103
    },
    {
      "id": 211,
      "seek": 170308,
      "start": 1703.6399999999999,
      "end": 1705.6399999999999,
      "text": " What stage is Gina doing?",
      "tokens": [
        50392,
        708,
        3233,
        307,
        34711,
        884,
        30,
        50492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41621477850552263,
      "compression_ratio": 1.4921465968586387,
      "no_speech_prob": 0.05338580161333084
    },
    {
      "id": 212,
      "seek": 170308,
      "start": 1706.4399999999998,
      "end": 1708.84,
      "text": " Uh, pipe and insights and runner.",
      "tokens": [
        50532,
        4019,
        11,
        11240,
        293,
        14310,
        293,
        24376,
        13,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41621477850552263,
      "compression_ratio": 1.4921465968586387,
      "no_speech_prob": 0.05338580161333084
    },
    {
      "id": 213,
      "seek": 170308,
      "start": 1710.04,
      "end": 1712.28,
      "text": " But in this, I like these stages.",
      "tokens": [
        50712,
        583,
        294,
        341,
        11,
        286,
        411,
        613,
        10232,
        13,
        50824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41621477850552263,
      "compression_ratio": 1.4921465968586387,
      "no_speech_prob": 0.05338580161333084
    },
    {
      "id": 214,
      "seek": 170308,
      "start": 1712.28,
      "end": 1713.72,
      "text": " Okay. All right.",
      "tokens": [
        50824,
        1033,
        13,
        1057,
        558,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41621477850552263,
      "compression_ratio": 1.4921465968586387,
      "no_speech_prob": 0.05338580161333084
    },
    {
      "id": 215,
      "seek": 170308,
      "start": 1714.76,
      "end": 1715.96,
      "text": " I thought stage groups.",
      "tokens": [
        50948,
        286,
        1194,
        3233,
        3935,
        13,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41621477850552263,
      "compression_ratio": 1.4921465968586387,
      "no_speech_prob": 0.05338580161333084
    },
    {
      "id": 216,
      "seek": 170308,
      "start": 1716.52,
      "end": 1718.28,
      "text": " That's what was going on in the mind.",
      "tokens": [
        51036,
        663,
        311,
        437,
        390,
        516,
        322,
        294,
        264,
        1575,
        13,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41621477850552263,
      "compression_ratio": 1.4921465968586387,
      "no_speech_prob": 0.05338580161333084
    },
    {
      "id": 217,
      "seek": 170308,
      "start": 1718.28,
      "end": 1722.9199999999998,
      "text": " So here we should call them, maybe we should call them steps so we don't confuse ourselves.",
      "tokens": [
        51124,
        407,
        510,
        321,
        820,
        818,
        552,
        11,
        1310,
        321,
        820,
        818,
        552,
        4439,
        370,
        321,
        500,
        380,
        28584,
        4175,
        13,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41621477850552263,
      "compression_ratio": 1.4921465968586387,
      "no_speech_prob": 0.05338580161333084
    },
    {
      "id": 218,
      "seek": 170308,
      "start": 1723.96,
      "end": 1726.9199999999998,
      "text": " Uh, I think execute.",
      "tokens": [
        51408,
        4019,
        11,
        286,
        519,
        14483,
        13,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.41621477850552263,
      "compression_ratio": 1.4921465968586387,
      "no_speech_prob": 0.05338580161333084
    },
    {
      "id": 219,
      "seek": 172692,
      "start": 1726.92,
      "end": 1733.16,
      "text": " Execute is where both the stage groups are genius working with would very well fit.",
      "tokens": [
        50364,
        17662,
        1169,
        307,
        689,
        1293,
        264,
        3233,
        3935,
        366,
        14017,
        1364,
        365,
        576,
        588,
        731,
        3318,
        13,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2825631618499756,
      "compression_ratio": 1.4848484848484849,
      "no_speech_prob": 0.07314353436231613
    },
    {
      "id": 220,
      "seek": 172692,
      "start": 1735.0,
      "end": 1740.1200000000001,
      "text": " And sorry, the pipeline insights can be more about monitor, I guess.",
      "tokens": [
        50768,
        400,
        2597,
        11,
        264,
        15517,
        14310,
        393,
        312,
        544,
        466,
        6002,
        11,
        286,
        2041,
        13,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2825631618499756,
      "compression_ratio": 1.4848484848484849,
      "no_speech_prob": 0.07314353436231613
    },
    {
      "id": 221,
      "seek": 172692,
      "start": 1741.64,
      "end": 1742.3600000000001,
      "text": " Stage six.",
      "tokens": [
        51100,
        25907,
        2309,
        13,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2825631618499756,
      "compression_ratio": 1.4848484848484849,
      "no_speech_prob": 0.07314353436231613
    },
    {
      "id": 222,
      "seek": 172692,
      "start": 1743.16,
      "end": 1743.48,
      "text": " Yes.",
      "tokens": [
        51176,
        1079,
        13,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2825631618499756,
      "compression_ratio": 1.4848484848484849,
      "no_speech_prob": 0.07314353436231613
    },
    {
      "id": 223,
      "seek": 172692,
      "start": 1744.1200000000001,
      "end": 1751.64,
      "text": " And runner is of course execute because when the, uh, jobs are being executed, that's when the role of runner kicks in.",
      "tokens": [
        51224,
        400,
        24376,
        307,
        295,
        1164,
        14483,
        570,
        562,
        264,
        11,
        2232,
        11,
        4782,
        366,
        885,
        17577,
        11,
        300,
        311,
        562,
        264,
        3090,
        295,
        24376,
        21293,
        294,
        13,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2825631618499756,
      "compression_ratio": 1.4848484848484849,
      "no_speech_prob": 0.07314353436231613
    },
    {
      "id": 224,
      "seek": 172692,
      "start": 1753.4,
      "end": 1753.8000000000002,
      "text": " Okay.",
      "tokens": [
        51688,
        1033,
        13,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2825631618499756,
      "compression_ratio": 1.4848484848484849,
      "no_speech_prob": 0.07314353436231613
    },
    {
      "id": 225,
      "seek": 175380,
      "start": 1754.68,
      "end": 1755.56,
      "text": " Okay.",
      "tokens": [
        50408,
        1033,
        13,
        50452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 226,
      "seek": 175380,
      "start": 1755.56,
      "end": 1757.0,
      "text": " So it's a look up here.",
      "tokens": [
        50452,
        407,
        309,
        311,
        257,
        574,
        493,
        510,
        13,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 227,
      "seek": 175380,
      "start": 1757.0,
      "end": 1762.36,
      "text": " So stage one, so stage five is Gina when she's doing runners.",
      "tokens": [
        50524,
        407,
        3233,
        472,
        11,
        370,
        3233,
        1732,
        307,
        34711,
        562,
        750,
        311,
        884,
        33892,
        13,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 228,
      "seek": 175380,
      "start": 1763.0,
      "end": 1763.3999999999999,
      "text": " Yes.",
      "tokens": [
        50824,
        1079,
        13,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 229,
      "seek": 175380,
      "start": 1764.44,
      "end": 1768.12,
      "text": " Right. How does one day we'll talk about how runners and merge trains",
      "tokens": [
        50896,
        1779,
        13,
        1012,
        775,
        472,
        786,
        321,
        603,
        751,
        466,
        577,
        33892,
        293,
        22183,
        16329,
        51080
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 230,
      "seek": 175380,
      "start": 1769.08,
      "end": 1769.56,
      "text": " interact?",
      "tokens": [
        51128,
        4648,
        30,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 231,
      "seek": 175380,
      "start": 1770.36,
      "end": 1771.24,
      "text": " It's all in that.",
      "tokens": [
        51192,
        467,
        311,
        439,
        294,
        300,
        13,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 232,
      "seek": 175380,
      "start": 1772.36,
      "end": 1773.96,
      "text": " It's hopefully in that blog post.",
      "tokens": [
        51292,
        467,
        311,
        4696,
        294,
        300,
        6968,
        2183,
        13,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 233,
      "seek": 175380,
      "start": 1774.36,
      "end": 1774.68,
      "text": " Uh, okay.",
      "tokens": [
        51392,
        4019,
        11,
        1392,
        13,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 234,
      "seek": 175380,
      "start": 1774.68,
      "end": 1774.84,
      "text": " Cool.",
      "tokens": [
        51408,
        8561,
        13,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 235,
      "seek": 175380,
      "start": 1774.84,
      "end": 1775.72,
      "text": " Uh, yeah.",
      "tokens": [
        51416,
        4019,
        11,
        1338,
        13,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 236,
      "seek": 175380,
      "start": 1777.08,
      "end": 1777.56,
      "text": " Okay.",
      "tokens": [
        51528,
        1033,
        13,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 237,
      "seek": 175380,
      "start": 1778.04,
      "end": 1782.84,
      "text": " Well, it seems like, um, maybe let's start recording when we recording still.",
      "tokens": [
        51576,
        1042,
        11,
        309,
        2544,
        411,
        11,
        1105,
        11,
        1310,
        718,
        311,
        722,
        6613,
        562,
        321,
        6613,
        920,
        13,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 238,
      "seek": 175380,
      "start": 1782.84,
      "end": 1783.32,
      "text": " Yes.",
      "tokens": [
        51816,
        1079,
        13,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43660008112589516,
      "compression_ratio": 1.5244444444444445,
      "no_speech_prob": 0.001583749777637422
    },
    {
      "id": 239,
      "seek": 178332,
      "start": 1783.3999999999999,
      "end": 1784.36,
      "text": " We are recording still.",
      "tokens": [
        50368,
        492,
        366,
        6613,
        920,
        13,
        50416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 240,
      "seek": 178332,
      "start": 1785.8799999999999,
      "end": 1786.4399999999998,
      "text": " No, let's talk.",
      "tokens": [
        50492,
        883,
        11,
        718,
        311,
        751,
        13,
        50520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 241,
      "seek": 178332,
      "start": 1787.96,
      "end": 1789.1599999999999,
      "text": " Let's talk calendars now.",
      "tokens": [
        50596,
        961,
        311,
        751,
        37022,
        685,
        586,
        13,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 242,
      "seek": 178332,
      "start": 1790.76,
      "end": 1791.8,
      "text": " Okay, we can stop.",
      "tokens": [
        50736,
        1033,
        11,
        321,
        393,
        1590,
        13,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 243,
      "seek": 178332,
      "start": 1793.0,
      "end": 1793.8,
      "text": " That's a brilliant.",
      "tokens": [
        50848,
        663,
        311,
        257,
        10248,
        13,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 244,
      "seek": 178332,
      "start": 1793.8,
      "end": 1794.28,
      "text": " Yeah, yeah.",
      "tokens": [
        50888,
        865,
        11,
        1338,
        13,
        50912
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 245,
      "seek": 178332,
      "start": 1795.1599999999999,
      "end": 1796.36,
      "text": " That was so good.",
      "tokens": [
        50956,
        663,
        390,
        370,
        665,
        13,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 246,
      "seek": 178332,
      "start": 1796.36,
      "end": 1797.96,
      "text": " Yeah, that was so fun too.",
      "tokens": [
        51016,
        865,
        11,
        300,
        390,
        370,
        1019,
        886,
        13,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 247,
      "seek": 178332,
      "start": 1798.9199999999998,
      "end": 1799.24,
      "text": " Okay.",
      "tokens": [
        51144,
        1033,
        13,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 248,
      "seek": 178332,
      "start": 1799.8799999999999,
      "end": 1800.76,
      "text": " So that's stuff now?",
      "tokens": [
        51192,
        407,
        300,
        311,
        1507,
        586,
        30,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 249,
      "seek": 178332,
      "start": 1801.8,
      "end": 1802.6,
      "text": " Yeah, yeah, yeah.",
      "tokens": [
        51288,
        865,
        11,
        1338,
        11,
        1338,
        13,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 250,
      "seek": 178332,
      "start": 1802.6,
      "end": 1803.08,
      "text": " Okay.",
      "tokens": [
        51328,
        1033,
        13,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 251,
      "seek": 178332,
      "start": 1803.3999999999999,
      "end": 1803.8,
      "text": " All right.",
      "tokens": [
        51368,
        1057,
        558,
        13,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    },
    {
      "id": 252,
      "seek": 178332,
      "start": 1803.8,
      "end": 1804.28,
      "text": " I'm stopping.",
      "tokens": [
        51388,
        286,
        478,
        12767,
        13,
        51412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39352288538095903,
      "compression_ratio": 1.490566037735849,
      "no_speech_prob": 0.0006072339019738138
    }
  ]
}