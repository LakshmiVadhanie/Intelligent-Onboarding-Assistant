{
  "title": "CI/CD UX Meeting (August 24, 2022)",
  "video_id": "MRr9_0_y6BU",
  "url": "https://www.youtube.com/watch?v=MRr9_0_y6BU",
  "transcript": " Okay, hello, it's August 24th, almost September, which is crazy. This is the CICDUX meeting and there's just one announcement that we have friends and family day on the 29th, which is Monday. And then, Hianah had also asked for us to just give progress on, I think this was supposed to be for Q3 OKRs, but it says Q2. Does anybody have anything that's blocked or at risk? All right. Any other announcements or general stuff? Okay. All right. I'll move into the items for pilot insights and runner then. The for runner, we're running a category maturity score card for the first time ever for runner fleet. It's been going really well. We're, I've done four sessions. I have one more scheduled for next week, I think. And we're shooting to be scored at complete. So right now we have that with for those four participants, we've gotten to that score. So we'll just see if we stay there. And then for pipeline insights, this was something I wanted to share with the group because. There's a lot of overlap with our groups. I'm just going to share my screen. OK. So we. In a test report for a pipeline, if there are child pipelines that are included, then the tests from that child pipeline will be aggregated into the single report at the parent pipeline level. And the problem is the jobs, aka the tests that are in those jobs that are listed here. We don't like tell you if they're from this pipeline or if they're from the child pipeline. And there can be many children. So what I wanted to do was indicate which jobs are from which pipeline basically. And I added this child badge here because it looks like we were doing that within the pipeline visualization. I'll zoom in a bit here. We use this like child badge. I thought it would be a good way to reuse that pattern. But what I did differently was added the pipeline ID because. I assume that there can be many children and I wanted there to be a difference. And then I was thinking that you could just click on that badge and it would bring you to that child's test report. So it would be like a similar page to this, but it would just be for that pipeline. Is there any feedback that you have anyone has on this? I have a lot of questions which I think you both you and Nadia could answer. So when I come to this tab on the vibrant overview page, I expect the experience to be very similar to what I would see on the jobs page or the jobs tab, right? The list. Now I have added a link here in the agenda that's for one of the pipeline steps running currently for GitLab. And when I navigate through the multi project and the child pipeline like upstream downstream. So what I see is the list and the jobs, it doesn't change until I go ahead and select the pipeline in the graph. Like for example, I'm in the parent pipeline. The job list is not to have the items which are in the child pipeline until I go and select the child pipeline. Okay. So we don't show the jobs for child pipelines, basically at the parent level. That's what I failed when I checked this in the morning. I'm not I wasn't aware of this actually. So I had no idea that we have some kind of connection there. So just to confirm when you expand the child pipeline in the pipeline graph, only then we show the jobs from the pipeline in the job steps. If you like just look at the badge and see when. And if you click on the on expanding the downstream, it doesn't change like the number of jobs inside the tab, it doesn't change at all. It doesn't expand. And it doesn't give a new list until you click on the pipeline like child pipeline numbers to express me that now I'm looking at the details for the child pipeline. Oh, like that. Oh, yeah, makes sense. Yeah, I mean, it sounds like an issue, something that we have to consider separately. I have never heard this come up. Yeah, it's it seems reasonable to update it if you expand the graph. I think what Gina is doing is the experience that's expected, but the overall experience for the job step it needs to be a bit that's well. Yeah. So I have a comment around the around the usage of the badge for this. So currently the badges on the child pipelines are not applicable. They're just meant to show you the type of the item that it is. And oftentimes the badges in the UI are not clickable. So they don't have a strong visual affordance that you can click on them and users are not necessarily used to that. So my concern would be that this link would not be discoverable. And also placing the ID inside the badge makes it kind of more difficult to read in a way because it's together with the child, the world child and makes more difficult to copy and paste it if you need to if you to search for the pipeline, for example. So these are just like my thoughts on using the badge here. I do like using badge for the child just to show that it's the child pipeline because it's exactly the same what we show in the pipeline graph. But maybe the idea could be a separate link or yeah, something that the user will immediately see as an obligation item because we do use linked ideas a lot in the UI to navigate between pipelines and jobs. Okay, yeah, I can play around with separating it out. I agree. I like the reuse of the badge just because it's already something that we use. And I was thinking of maybe doing a full other like column that includes the pipeline ID. I'll think about that more though. Also, this might be unrelated, but we were actually finding the opposite where we had a success badge on the deployment, the environment page and people thought it was clickable. Even though it wasn't because it was a badge. So I think I know why because of the badges on the pipeline page. They are pickable. Yeah, so I'm wondering if you could style the badge a little bit differently where it looks like it's clickable. I don't know what options for badges there, but I feel like if they there is like a badge version that looks like it's clickable. And when we made it not clickable, people were confused. Is there any guidance from pajamas about whether or not they should be interactive elements? I think they can be both. Okay, cool. But yeah, I'm trying to think of like a joke like issue labels. I guess those are technically labels, not badges. But those are clickable. And sometimes not clickable. One other question I had was just thinking about like the idea of having the sophisticated simplicity. Like thing that's going on right now. I was wondering if it made sense to maybe keep this like the child pipeline test collapsed by default because we do that in the pipeline too. Like you have to expand it to show the child pipeline. So I'm wondering if it will be worth exploring. I was going to show high like toggle to show and hide them. It was just a thought. You mean in the pipeline craft? I mean like in this all of this. Yeah, adding like a toggle here. It's like something that could be also a filter like a drop down because you would filter by a type of job. Assorting mechanism of sort. Or the bridge or trigger job can be expanded. Like the job that's calling the downstream or the child pipeline that can be a little. That can be treated differently visually and there can be an option to expand it. And go. It might just be something that I needed like. Validate a little bit too. Yeah, I feel like I don't feel confident enough to be like let's complicate this by adding filters. Just yet. And I think you know what you can do to is come up with just two or three key tasks and then look at the impact on the flow. But I'm thinking that we want to optimize for when they're debugging. Yeah, that's a good idea too. Stalk sharing. Thank you for the feedback. That was really great. So fun to have everybody in the call. Like live brainstorming. I know it's very useful. My last thing I'm. I'm not sure if I can do that. I'm not sure if I can do that. We can take this a sink if we wanted to. But I just feel like I'm taking forever creating issues with the feature. That feature detailed template. I feel like there's a lot of different sections I need to fill out label to add. And I was wondering if people had best practices around making it more efficient. Yeah, I just wanted to say that I can relate and I don't have any specific tips because my process manual, but. I see that physical mention templates and I can also second that is very important to use templates. Yeah, but it doesn't really solve. I mean, it applies some labels actually some basic labels. So yes, mostly you have to delete. But I. I've been talking in terms of efficiency because you highlighted that Gina. I would say. It makes efficient, but in a very different way, for example, it really makes people think about the problem statement when they're filling out this detailed template. So in private execution, when we started to get to the like very heavy backlog that was there for. It there were about 315,000 issues. We started to be very careful about like what exists there and what we need to close us to decades and what is not valid anymore. But we started to notice that people open issues with just two lines like this is what I want. This is how it should be done like with proposal. So we started to like discourage that and every issue when it used to come to me for charging, especially through that. So that's created over the weekend. I always used to make it a point I still do to like request people to like apply the template and fill up the questions. And that has really made everyone think about the proposals that they're trying to put across like what isn't that they're trying to solve who is it for is it. Just for that one person. Even it feels very heavy to do that at that particular time in pipeline execution that has like really helped us. I just had a comment that I don't currently use templates. I totally get what you're saying though, Vietika, I guess I don't know if it's required to use the template. Maybe for me the reason why I don't is sometimes we'll just have like a small bug or something that needs to be addressed and I never want to be a barrier to document that in an issue. And it can always be refined later. But maybe I'm a bit lucky that when my team is creating issues, they usually have a strong why and like a, you know, like maybe I'm just a bit fortunate in that regard. In terms of expediting, I set up a keyboard shortcut in system preferences that will apply the kind of like 10 most common labels that I use. So then I just literally just have two keystrokes and then I have like the labels and then I can just edit them from there that has helped a bit. That's really cool. I didn't even know that that was a thing. I like a like a one minute video of how to do it and I'll post it on our channel or on UX or something. Yeah, that'd be great. Yeah, that would be awesome, because I remember when I had my coworking session with Vietika, I was asking about like, how do you copy and paste labels or is there a more efficient way to add lab, the same labels to issues like creating UX themes, all of them head the same labels, but I had to manually add them. So if there's any way to speed up that process. I use a very manual method so I keep like the shortcuts to create those labels that I have to based on the issues. Handy on my notepad so I just copy based. Very cool. Okay. Thank you for all the conversation. Emily, do you want to go through your items? So my first item is release held office hours last week, which was actually a huge success. It was a surprising how many people we got to attend with the first one. And during this office hours, we really walked through like how community contributors can contribute like open the floor to ask them questions. And then we went through how to find issues that are available to take on and take syndrux on how to get help on MR's like how to take us in those so it was like a very helpful thing to do. And we're planning to hold another one in September around UX front end, which hopefully will increase the amount of like community contributions we get. So I know that's a big thing right now. That's the exact thing I pointed out to my product manager, I guess in the meeting that actually has had an office hour. I looked at the agenda that like really highlighted the opportunity for contribution so well. And like I'm not sure if we have to bandwidth to do this at this moment, but yeah, I'm really happy to like learn from like how that went. Yeah, I noticed some of the like main questions we had were just how to get feedback. So people who wanted to contribute or curious about like when they should like create the MR can they do it when they're still working on something if it's still a draft and how to take people to get feedback on things. Tips on how to find issues in like the languages they're comfortable working on and all of that. We also had some questions too that were a little topic of how to look for open jobs at get lab. So I think just feel where that some people might be coming in because they are also interested in working at get lab and having answers to that as well. Yeah, that's true. I just, I'm sorry. Oh, and I'm just saying like a closing statement like I hope more teams are able to do something. I put the question what are office hours in this context, but I'm I'm gathering that you you had kind of an open conversation with users of get lab is that what if was. So what we did was we created a I think is on meetup.com just like a release office hours added in an agenda and then the release team kind of. Advertised done LinkedIn, we kind of went to our older community contributors and told them that they could come to this so we like advertised it out a little bit to just the broader community who would be interested in seeing how release worked to come with questions. And yeah, it's like open to absolutely anyone who is interested. The only thing we did learn is that it's important to have this through like meetup or another site and not just have an open zoom link because apparently zoom bombing is like a big thing if you just randomly put a zoom link out there. So having kind of like stricter access into the meeting was important. That's also that such a good idea. I'll have a closer look into it. So it's good. Well, and then the only other thing is on release for planning and onboarded onboarding focused improvement to our empty state pages because we realized kind of across the board the empty state pages. And that's not very like they're all slightly different design wise. They could have more helpful like CTAs for people just landing on them. So this is like an idea we're doing, but just wanted to share it out because I think it's helpful like across all stage groups and get lab. And that's it unless there's any questions. I have a quick suggestion for the empty states. Just like a quick thought that they have I don't know if there's there's probably reasons why you did it this way, but. It would be interesting to see the buttons placed underneath the empty state UI copy and illustrations. I think this is how we usually deal with those empty states. But I guess there's going to be like a table here or like a list of items and then the buttons will be at the top. But I think usually what we do is we have the action buttons inside the empty state and then once there are items to show them the buttons are placed above the items list. Yeah, I think right now all three of the empty states and deployments are look different. So I think this is kind of like getting that CTA. The CTA is to be consistent across the three of them getting like a good CTA, finising some of like the copies. So I think there's some really simple things we can do to fix it up. But yeah, the main. Yeah, sure. The main thing is yeah, like you said, I think the CTA on the release page is up in the top right corner, which is kind of missing. So I think just getting the CTA is in the empty state would be an interesting one to do. If that's it, I can pass over to the two. Okay, yeah, so I wanted to update about the insights that have known through a very recent validation exercise that I am it was unmodulated on user testing. It kind of gave some good like even to how users are using their user namespace today and what kind of projects they host under there. How many projects they host so it turns out that users usually put just like small personal projects directly under their namespace and those are not the kind that are very engagement heavy like it's something that they only interact with by themselves. And that's the reason like they also don't have much concerns around what's the CI CD minutes consumption because they might not even be a pilot for this project. And there is no contribution to get concerns for sure for these projects and that applies that there's little or no need to control the mid consumption. And user namespace related settings, I mean, we did provide them with certain tasks in the test, but it was really difficult for them to go to those setting options, which are existing today, it was not even something that I had added on the top because something that had been there since long, for example, we are still able to see the usage code for the projects which are directly under your name space through the user settings usage code of page. But the way we land on the user setting is kind of here because today, if you click on your profile picture and you go to preferences that takes you to users settings preferences and for me that has been my gateway into the settings and that's how like I always land there, I don't know if there's any other way that someone else uses. And that gives everybody an idea that maybe it's just something that's used for customizing like how good luck looks for you and like not do anything deeper than that. So some resonated with this thought and the others expected the quota to be controlled through the existing usage quota tab because it was pretty clear for them that this is quota and I'm getting to like. Control micro rise it has to be through this, but the interesting part is we never do that like so far we have never done that it only kind of shows you like what a consumption is like, but that page has never historically been used for allowing users to kind of set any configurations as far as I remember it's mostly just to view and like consume information about the consumption. Now apart from that what else. Yeah, so this feature as we had already expected. Is as mentioned that it would be more useful for groups and sub groups now I'll give a little background about like why we had started with user namespace. So this feature is like currently we only allow users to control their minutes consumption minutes is the resource that's required to run the pipelines. We only allow them to control this through the admin view and all that is done today is the admins are able to add like a standard cap to the usage so they can define like all the groups can only use 2000 minutes like they cannot exceed. But at a more granular level like when it comes to projects because a group can have a lot many projects it can have some groups and some groups under that and under that many projects so it gets pretty complex now at project level maintainers who are working on this projects they would want some like some sort of control because not all the projects inside a group or a circle has the same amount of input. So they would want to make sure that this particular one that sees a lot of contribution from our users and it's very critical to our business should always be able to run its pipeline and it shouldn't happen that this other project that's line parallel to it, which is not as much of our priority to us it ends up consuming all the city minutes that's allotted to this group. So that situation we started working on this feature but right like while we were having the discussion on like how we would make this happen we realized that the moment we like touch upon groups and sub groups this is going to get so much complicated because then we have to take into account like how there will be the subdivisions of the minutes and how would we surface the code like this much out of this much is used right this group. This is what you're left with this is what you can do with it so we started with the easiest path available so that we can also validated we started with us and space because that's like flat that's just one level like the projects which are directly under your use and space and once that happens once we get good insights from those we decided that will create issues and we make improvements and then we'll move to groups of groups. I see that we're very close to diamond not you also not you do so. I'm having to take questions on slide as well and I'll pass it on to Nadia. Thanks, Vedika. Yeah, so this milestone I'm participating in beautifying UI there's an issue where I'm gathering all of the ideas that I want to work on brainstorming some solutions so I'm trying to keep I keep it like one thread for one improvement so if there's anything that you would like to work on but maybe your team doesn't have capacity or anything like that. Like that tool for drop your ideas into that issue and I can promise that we'll get picked up because also the engineer I'm working with he has limited capacity this milestone which is unfortunate because I dedicated half of my time to this and I think he dedicated like 20% of his time to this. But we're going to choose like the top impact maybe also easiest to do kinds of improvements and run with that so drop your comments there. Yeah, I see that you have a lot of suggestions but let's keep it pretty only for the sake of time and another thing I wanted to share is our results from the secrets management jobs to be done research. So it was meta analysis of existing research that we have around secrets and there's lots of great insights that came out of it that you can check out in this issue that a link I summarized everything in the issue description so you can just skip through that if you want. And wanted to point out that secrets is our top priority right now for pipeline authoring generally as far as new features are concerned our main focus is secrets management and the CIC catalog work that we're doing. And there's an MR for updated secrets jobs to be done and there's a lot of overlap there that we're finding with compliance and security so we'll be collaborating with those teams to make sure that we connect the secrets management workflow to management of your security policies and compliance policies and so on. Yeah, and now on to Katie. Cool, I first ones just an FYI in case people don't know we have a dedicated product analyst named Nicole who we can make UX data request to she can help with structuring the kind of the right questions to ask to remove bias and implementation in the code for tracking things and then also size and stash boards. She is across all of ops so she also works with many pms so she's got quite a lot of competing priorities so she did request that when we are creating issues to kind of indicate the urgency and the priority but I just didn't know that we had this relationship so in case anyone else didn't. And not much else to report for package i'm still covering ecosystem until like November but we're working on some process improvements and package about how we refine and how issues come into the milestone and I've also gotten the opportunity to speak to a number of enterprise customers because our PM is on parental leave. And you might have seen Eric and I discussing in slack yesterday now that I have those relationships with those enterprise customers and terms I would love to recruit them. But Erica wisely pointed out that you know we should be really strategic these are very valuable and hard to find research participants so I just wanted to have a group discussion in terms of like does anyone have any ideas about any light process that we could use to make sure that we're. And utilizing these to the most high value research amongst us or maybe amongst get left in general. I mean one thing that I can add is that i've mainly worked for tabs or worked with tabs to like get access to large enterprise customers. I think we maybe have some within like our first look panel but i'm not entirely sure I think it's relatively low. I think it's important whenever scheduling these research sessions with large enterprise customers is since there's not a whole lot of them. Trying to not overuse and you know over leverage that group. Because you know they are so hard to access and you know we're essentially talking to like the same handful of people over and over again so that can influence the design. Even if we do see them as like wow there you know they're representing a large company that has a lot of users we tend to just talk to the same individuals from those companies they're representing their set of users. Yeah that makes total sense I wonder if like if we have some kind of process that we can also track who spoke to which enterprise customer at which time so that we can kind of avoid what you are mentioning will in terms of biasing for three customers or something like this. And and that's why we have kind of set up this in part one of the reasons why we've set up the enterprise company profiles and personas. Is that we kind of just want to cobble together all of those interviews and touch points and then like abstract them away on what if we can. So that we can really do the like small business enterprise. So just advertising that we have that. So if we can get consent through that form that's linked in Slack to record and then put those in the dovetail that's linked there. I have it in queue four plans to begin to like put those together. And when we start on that like in a more full fledged manner which isn't cobbling I'll be like really asking for help on recruit for that but they won't be in Tokyo for. That's all good. I'm just wondering you know because I have these relationships now and I would love to just speak to these customers anyway but I'm wondering if. Should we even just have informal conversations amongst ourselves to make sure that those customers aren't needed or they haven't been kind of overused as well as mentioning or should there be a more formal process or does anyone have any thoughts on this. We could start in that love tell issue just a table where we mark who we've talked to and bring them in. I have an intention to bring in that one company that I won't name so we can share this out but that will and Hiana and I think Tina has also met with. So maybe there's just like an informal table but if it's in dovetail maybe it is like accessible and we can cross reference it with the videos we have. Okay, cool so I'm happy to create that table. Did you say you wanted that on the get lab issue that's about that enterprise or do you want to end off tell itself. I think that tail because then we can. Okay video. Okay cool yeah I can set that up. Cool thank you. Katie can you tag off once you do that too because it's in my to do is I'll do it. Okay yeah sure. Cool I can pass over to will. Yeah and I guess before I talk about my section just to add on to the group discussion I think this is something important that we could bring to the larger UX research team to talk about like longer term strategy. For how we deal with this. I think Eric is on board with. For on point with like how we're going to address it in the term at least. Sounds good. So the only update that I have is that I'm halfway done with my benchmarking city so I've gotten 10 out of 20 sessions complete. I've added the videos to do I'm continuing to get them tagged. And I have another 10 sessions over around the next week. It might bleed over until the end of next week but hoping to have it done pretty soon. And if there are not any questions I'll pass it over to Erica. Yes so I didn't make little points about this but my Q3 and Q4 plans are kind of set so in a way that's good for my life. But then also just so you know that I'm if possible like for example with Nadia's like job to be done stuff I can sometimes fold in or like build out a research question if there's pressing needs. So just remember that we're locked but we have some freedom within that structure. And then what I'm working on is just the secrets features survey. And that will help us to understand the trade offs between the developer needs. And the SRE slash maybe security compliance depending on who we can find. And we're going to field it for quite some time because to reach those two groups we know we need to go to coupon. And then we need to have a long email campaign. And so I'm sprinting towards that. And then also just say yay for the team that Nadia and and Gina maybe in reverse order. And then we're working on a really cool participatory design activity. Where we're going to kind of map out the secrets workflow so it's still emergent but it's exciting. And I think we might have a new paradigm. Yeah I wanted to ask about that so I know that there's some feedback there that I was going to provide. And I wanted to ask what's the latest time that you need to buy because you mentioned that you want to run the pilots next week. And I'm taking the family and friends day on Friday. So I'm a bit short on time this week. So maybe you can just message me. Let me know what's like the best way for us to collaborate on this or point me to an issue comment or threat. Where I can jump in and help out. Okay. I think you can come in after the pilots will use the pilot. See if it stands and how it looks more. Okay. Okay. Sounds good. Yeah. With the secret features we might need your your feedback. I think we're actually good on that with the survey stuff. And I think we'll come back. Okay. Okay. Thank you for that. Well, I will catch up with you on Slack about that as well too. So I'm going to ask you a question. Erica, do you want to do your, oh, they read only. Well, did you want to voice it? We have four minutes. Yeah. Yeah. So there was a paper posted yesterday in the security research channel. And they said it wasn't a good paper. It's not what it is. And this is what the data was made. And this is what we actually did that was, which I think means it's like not we can maybe follow it because it's not that technically complex and good. But I actually felt it found it really helpful because it takes a few competitors. And kind of talks about their different roles in access. is not that they've found a new idea about security breaches, but they basically go through and explain how in these different platforms, also including our competitors, secrets might be leaked. So yeah, so that's not like a pressing need, but I think it's a nice resource. And I also did this thing where when I first started and kind of saw that security was one of our product focuses, I was watching like DevSecOps conferences and taking notes. I saw some of you early on, I think you may remember. Anyway, I turned that into a plus white papers. And so I'm like taking notes in that issue as well. Thanks for sharing. I think this is exactly what I need to dive into. Yeah, if anybody ever wonders, like what do we mean by hard code secrets? It's like right there. So we can, I think this will be a good resource for us moving forward. Yeah. I have one other question for us before we wrap up. Would we, I'm just thinking about the order that we go in when we're going through this meeting. Would anyone be interested in swapping maybe next time so that people near the end have more time in the beginning? Seeing a lot of head knots. Yeah, I think it's a good idea. How about putting research first and then design? Inquire change. Yeah, and we can swap the order of design too. I'm doing it exactly the opposite of what it is today. So, I'm going to start. Okay. Cool. All right. I'll do that next time. Thanks. All right. Thanks, everyone. Have a good day. Thanks. Thanks.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 10.8,
      "text": " Okay, hello, it's August 24th, almost September, which is crazy.",
      "tokens": [
        50364,
        1033,
        11,
        7751,
        11,
        309,
        311,
        6897,
        4022,
        392,
        11,
        1920,
        7216,
        11,
        597,
        307,
        3219,
        13,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27969771298495205,
      "compression_ratio": 1.232258064516129,
      "no_speech_prob": 0.04046301171183586
    },
    {
      "id": 1,
      "seek": 0,
      "start": 10.8,
      "end": 18.96,
      "text": " This is the CICDUX meeting and there's just one announcement that we have friends and",
      "tokens": [
        50904,
        639,
        307,
        264,
        37777,
        16508,
        52,
        55,
        3440,
        293,
        456,
        311,
        445,
        472,
        12847,
        300,
        321,
        362,
        1855,
        293,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27969771298495205,
      "compression_ratio": 1.232258064516129,
      "no_speech_prob": 0.04046301171183586
    },
    {
      "id": 2,
      "seek": 0,
      "start": 18.96,
      "end": 24.0,
      "text": " family day on the 29th, which is Monday.",
      "tokens": [
        51312,
        1605,
        786,
        322,
        264,
        9413,
        392,
        11,
        597,
        307,
        8138,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27969771298495205,
      "compression_ratio": 1.232258064516129,
      "no_speech_prob": 0.04046301171183586
    },
    {
      "id": 3,
      "seek": 2400,
      "start": 24.0,
      "end": 32.24,
      "text": " And then, Hianah had also asked for us to just give progress on, I think this was supposed",
      "tokens": [
        50364,
        400,
        550,
        11,
        389,
        952,
        545,
        632,
        611,
        2351,
        337,
        505,
        281,
        445,
        976,
        4205,
        322,
        11,
        286,
        519,
        341,
        390,
        3442,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39173873526151065,
      "compression_ratio": 1.2582781456953642,
      "no_speech_prob": 0.002506980439648032
    },
    {
      "id": 4,
      "seek": 2400,
      "start": 32.24,
      "end": 37.76,
      "text": " to be for Q3 OKRs, but it says Q2.",
      "tokens": [
        50776,
        281,
        312,
        337,
        1249,
        18,
        2264,
        49,
        82,
        11,
        457,
        309,
        1619,
        1249,
        17,
        13,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39173873526151065,
      "compression_ratio": 1.2582781456953642,
      "no_speech_prob": 0.002506980439648032
    },
    {
      "id": 5,
      "seek": 2400,
      "start": 37.76,
      "end": 41.84,
      "text": " Does anybody have anything that's blocked or at risk?",
      "tokens": [
        51052,
        4402,
        4472,
        362,
        1340,
        300,
        311,
        15470,
        420,
        412,
        3148,
        30,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39173873526151065,
      "compression_ratio": 1.2582781456953642,
      "no_speech_prob": 0.002506980439648032
    },
    {
      "id": 6,
      "seek": 2400,
      "start": 41.84,
      "end": 49.84,
      "text": " All right.",
      "tokens": [
        51256,
        1057,
        558,
        13,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39173873526151065,
      "compression_ratio": 1.2582781456953642,
      "no_speech_prob": 0.002506980439648032
    },
    {
      "id": 7,
      "seek": 4984,
      "start": 49.84,
      "end": 60.080000000000005,
      "text": " Any other announcements or general stuff?",
      "tokens": [
        50364,
        2639,
        661,
        23785,
        420,
        2674,
        1507,
        30,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3468208970694706,
      "compression_ratio": 1.414012738853503,
      "no_speech_prob": 0.008918664418160915
    },
    {
      "id": 8,
      "seek": 4984,
      "start": 60.080000000000005,
      "end": 61.120000000000005,
      "text": " Okay.",
      "tokens": [
        50876,
        1033,
        13,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3468208970694706,
      "compression_ratio": 1.414012738853503,
      "no_speech_prob": 0.008918664418160915
    },
    {
      "id": 9,
      "seek": 4984,
      "start": 61.120000000000005,
      "end": 61.6,
      "text": " All right.",
      "tokens": [
        50928,
        1057,
        558,
        13,
        50952
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3468208970694706,
      "compression_ratio": 1.414012738853503,
      "no_speech_prob": 0.008918664418160915
    },
    {
      "id": 10,
      "seek": 4984,
      "start": 61.6,
      "end": 69.2,
      "text": " I'll move into the items for pilot insights and runner then.",
      "tokens": [
        50952,
        286,
        603,
        1286,
        666,
        264,
        4754,
        337,
        9691,
        14310,
        293,
        24376,
        550,
        13,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3468208970694706,
      "compression_ratio": 1.414012738853503,
      "no_speech_prob": 0.008918664418160915
    },
    {
      "id": 11,
      "seek": 4984,
      "start": 69.2,
      "end": 76.08000000000001,
      "text": " The for runner, we're running a category maturity score card for the first time ever for runner fleet.",
      "tokens": [
        51332,
        440,
        337,
        24376,
        11,
        321,
        434,
        2614,
        257,
        7719,
        28874,
        6175,
        2920,
        337,
        264,
        700,
        565,
        1562,
        337,
        24376,
        19396,
        13,
        51676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3468208970694706,
      "compression_ratio": 1.414012738853503,
      "no_speech_prob": 0.008918664418160915
    },
    {
      "id": 12,
      "seek": 7608,
      "start": 76.08,
      "end": 78.39999999999999,
      "text": " It's been going really well.",
      "tokens": [
        50364,
        467,
        311,
        668,
        516,
        534,
        731,
        13,
        50480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20172997462896652,
      "compression_ratio": 1.4919786096256684,
      "no_speech_prob": 0.00100608728826046
    },
    {
      "id": 13,
      "seek": 7608,
      "start": 78.39999999999999,
      "end": 80.64,
      "text": " We're, I've done four sessions.",
      "tokens": [
        50480,
        492,
        434,
        11,
        286,
        600,
        1096,
        1451,
        11081,
        13,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20172997462896652,
      "compression_ratio": 1.4919786096256684,
      "no_speech_prob": 0.00100608728826046
    },
    {
      "id": 14,
      "seek": 7608,
      "start": 80.64,
      "end": 85.28,
      "text": " I have one more scheduled for next week, I think.",
      "tokens": [
        50592,
        286,
        362,
        472,
        544,
        15678,
        337,
        958,
        1243,
        11,
        286,
        519,
        13,
        50824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20172997462896652,
      "compression_ratio": 1.4919786096256684,
      "no_speech_prob": 0.00100608728826046
    },
    {
      "id": 15,
      "seek": 7608,
      "start": 85.28,
      "end": 88.28,
      "text": " And we're shooting to be scored at complete.",
      "tokens": [
        50824,
        400,
        321,
        434,
        5942,
        281,
        312,
        18139,
        412,
        3566,
        13,
        50974
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20172997462896652,
      "compression_ratio": 1.4919786096256684,
      "no_speech_prob": 0.00100608728826046
    },
    {
      "id": 16,
      "seek": 7608,
      "start": 88.28,
      "end": 94.8,
      "text": " So right now we have that with for those four participants, we've gotten to that score.",
      "tokens": [
        50974,
        407,
        558,
        586,
        321,
        362,
        300,
        365,
        337,
        729,
        1451,
        10503,
        11,
        321,
        600,
        5768,
        281,
        300,
        6175,
        13,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20172997462896652,
      "compression_ratio": 1.4919786096256684,
      "no_speech_prob": 0.00100608728826046
    },
    {
      "id": 17,
      "seek": 7608,
      "start": 94.8,
      "end": 99.12,
      "text": " So we'll just see if we stay there.",
      "tokens": [
        51300,
        407,
        321,
        603,
        445,
        536,
        498,
        321,
        1754,
        456,
        13,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20172997462896652,
      "compression_ratio": 1.4919786096256684,
      "no_speech_prob": 0.00100608728826046
    },
    {
      "id": 18,
      "seek": 9912,
      "start": 99.12,
      "end": 109.60000000000001,
      "text": " And then for pipeline insights, this was something I wanted to share with the group because.",
      "tokens": [
        50364,
        400,
        550,
        337,
        15517,
        14310,
        11,
        341,
        390,
        746,
        286,
        1415,
        281,
        2073,
        365,
        264,
        1594,
        570,
        13,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20091860261681962,
      "compression_ratio": 1.4829545454545454,
      "no_speech_prob": 0.00037115367013029754
    },
    {
      "id": 19,
      "seek": 9912,
      "start": 109.60000000000001,
      "end": 112.48,
      "text": " There's a lot of overlap with our groups.",
      "tokens": [
        50888,
        821,
        311,
        257,
        688,
        295,
        19959,
        365,
        527,
        3935,
        13,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20091860261681962,
      "compression_ratio": 1.4829545454545454,
      "no_speech_prob": 0.00037115367013029754
    },
    {
      "id": 20,
      "seek": 9912,
      "start": 112.48,
      "end": 116.96000000000001,
      "text": " I'm just going to share my screen.",
      "tokens": [
        51032,
        286,
        478,
        445,
        516,
        281,
        2073,
        452,
        2568,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20091860261681962,
      "compression_ratio": 1.4829545454545454,
      "no_speech_prob": 0.00037115367013029754
    },
    {
      "id": 21,
      "seek": 9912,
      "start": 116.96000000000001,
      "end": 119.28,
      "text": " OK.",
      "tokens": [
        51256,
        2264,
        13,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20091860261681962,
      "compression_ratio": 1.4829545454545454,
      "no_speech_prob": 0.00037115367013029754
    },
    {
      "id": 22,
      "seek": 9912,
      "start": 119.28,
      "end": 121.92,
      "text": " So we.",
      "tokens": [
        51372,
        407,
        321,
        13,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20091860261681962,
      "compression_ratio": 1.4829545454545454,
      "no_speech_prob": 0.00037115367013029754
    },
    {
      "id": 23,
      "seek": 9912,
      "start": 121.92,
      "end": 127.92,
      "text": " In a test report for a pipeline, if there are child pipelines that are included,",
      "tokens": [
        51504,
        682,
        257,
        1500,
        2275,
        337,
        257,
        15517,
        11,
        498,
        456,
        366,
        1440,
        40168,
        300,
        366,
        5556,
        11,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20091860261681962,
      "compression_ratio": 1.4829545454545454,
      "no_speech_prob": 0.00037115367013029754
    },
    {
      "id": 24,
      "seek": 12792,
      "start": 127.92,
      "end": 136.96,
      "text": " then the tests from that child pipeline will be aggregated into the single report at the parent pipeline level.",
      "tokens": [
        50364,
        550,
        264,
        6921,
        490,
        300,
        1440,
        15517,
        486,
        312,
        16743,
        770,
        666,
        264,
        2167,
        2275,
        412,
        264,
        2596,
        15517,
        1496,
        13,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12983450104918662,
      "compression_ratio": 1.7650273224043715,
      "no_speech_prob": 0.0003314838104415685
    },
    {
      "id": 25,
      "seek": 12792,
      "start": 136.96,
      "end": 146.88,
      "text": " And the problem is the jobs, aka the tests that are in those jobs that are listed here.",
      "tokens": [
        50816,
        400,
        264,
        1154,
        307,
        264,
        4782,
        11,
        28042,
        264,
        6921,
        300,
        366,
        294,
        729,
        4782,
        300,
        366,
        10052,
        510,
        13,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12983450104918662,
      "compression_ratio": 1.7650273224043715,
      "no_speech_prob": 0.0003314838104415685
    },
    {
      "id": 26,
      "seek": 12792,
      "start": 146.88,
      "end": 152.56,
      "text": " We don't like tell you if they're from this pipeline or if they're from the child pipeline.",
      "tokens": [
        51312,
        492,
        500,
        380,
        411,
        980,
        291,
        498,
        436,
        434,
        490,
        341,
        15517,
        420,
        498,
        436,
        434,
        490,
        264,
        1440,
        15517,
        13,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12983450104918662,
      "compression_ratio": 1.7650273224043715,
      "no_speech_prob": 0.0003314838104415685
    },
    {
      "id": 27,
      "seek": 12792,
      "start": 152.56,
      "end": 154.8,
      "text": " And there can be many children.",
      "tokens": [
        51596,
        400,
        456,
        393,
        312,
        867,
        2227,
        13,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12983450104918662,
      "compression_ratio": 1.7650273224043715,
      "no_speech_prob": 0.0003314838104415685
    },
    {
      "id": 28,
      "seek": 15480,
      "start": 154.8,
      "end": 162.64000000000001,
      "text": " So what I wanted to do was indicate which jobs are from which pipeline basically.",
      "tokens": [
        50364,
        407,
        437,
        286,
        1415,
        281,
        360,
        390,
        13330,
        597,
        4782,
        366,
        490,
        597,
        15517,
        1936,
        13,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468402335518285,
      "compression_ratio": 1.5252525252525253,
      "no_speech_prob": 0.0010155340423807502
    },
    {
      "id": 29,
      "seek": 15480,
      "start": 162.64000000000001,
      "end": 173.76000000000002,
      "text": " And I added this child badge here because it looks like we were doing that within the pipeline visualization.",
      "tokens": [
        50756,
        400,
        286,
        3869,
        341,
        1440,
        25797,
        510,
        570,
        309,
        1542,
        411,
        321,
        645,
        884,
        300,
        1951,
        264,
        15517,
        25801,
        13,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468402335518285,
      "compression_ratio": 1.5252525252525253,
      "no_speech_prob": 0.0010155340423807502
    },
    {
      "id": 30,
      "seek": 15480,
      "start": 173.76000000000002,
      "end": 175.36,
      "text": " I'll zoom in a bit here.",
      "tokens": [
        51312,
        286,
        603,
        8863,
        294,
        257,
        857,
        510,
        13,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468402335518285,
      "compression_ratio": 1.5252525252525253,
      "no_speech_prob": 0.0010155340423807502
    },
    {
      "id": 31,
      "seek": 15480,
      "start": 175.36,
      "end": 177.68,
      "text": " We use this like child badge.",
      "tokens": [
        51392,
        492,
        764,
        341,
        411,
        1440,
        25797,
        13,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468402335518285,
      "compression_ratio": 1.5252525252525253,
      "no_speech_prob": 0.0010155340423807502
    },
    {
      "id": 32,
      "seek": 15480,
      "start": 177.68,
      "end": 182.60000000000002,
      "text": " I thought it would be a good way to reuse that pattern.",
      "tokens": [
        51508,
        286,
        1194,
        309,
        576,
        312,
        257,
        665,
        636,
        281,
        26225,
        300,
        5102,
        13,
        51754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468402335518285,
      "compression_ratio": 1.5252525252525253,
      "no_speech_prob": 0.0010155340423807502
    },
    {
      "id": 33,
      "seek": 18260,
      "start": 182.6,
      "end": 188.35999999999999,
      "text": " But what I did differently was added the pipeline ID because.",
      "tokens": [
        50364,
        583,
        437,
        286,
        630,
        7614,
        390,
        3869,
        264,
        15517,
        7348,
        570,
        13,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13928779290646923,
      "compression_ratio": 1.6893617021276597,
      "no_speech_prob": 0.00029905090923421085
    },
    {
      "id": 34,
      "seek": 18260,
      "start": 188.35999999999999,
      "end": 192.6,
      "text": " I assume that there can be many children and I wanted there to be a difference.",
      "tokens": [
        50652,
        286,
        6552,
        300,
        456,
        393,
        312,
        867,
        2227,
        293,
        286,
        1415,
        456,
        281,
        312,
        257,
        2649,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13928779290646923,
      "compression_ratio": 1.6893617021276597,
      "no_speech_prob": 0.00029905090923421085
    },
    {
      "id": 35,
      "seek": 18260,
      "start": 192.6,
      "end": 200.6,
      "text": " And then I was thinking that you could just click on that badge and it would bring you to that child's test report.",
      "tokens": [
        50864,
        400,
        550,
        286,
        390,
        1953,
        300,
        291,
        727,
        445,
        2052,
        322,
        300,
        25797,
        293,
        309,
        576,
        1565,
        291,
        281,
        300,
        1440,
        311,
        1500,
        2275,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13928779290646923,
      "compression_ratio": 1.6893617021276597,
      "no_speech_prob": 0.00029905090923421085
    },
    {
      "id": 36,
      "seek": 18260,
      "start": 200.6,
      "end": 206.2,
      "text": " So it would be like a similar page to this, but it would just be for that pipeline.",
      "tokens": [
        51264,
        407,
        309,
        576,
        312,
        411,
        257,
        2531,
        3028,
        281,
        341,
        11,
        457,
        309,
        576,
        445,
        312,
        337,
        300,
        15517,
        13,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13928779290646923,
      "compression_ratio": 1.6893617021276597,
      "no_speech_prob": 0.00029905090923421085
    },
    {
      "id": 37,
      "seek": 18260,
      "start": 206.2,
      "end": 211.76,
      "text": " Is there any feedback that you have anyone has on this?",
      "tokens": [
        51544,
        1119,
        456,
        604,
        5824,
        300,
        291,
        362,
        2878,
        575,
        322,
        341,
        30,
        51822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13928779290646923,
      "compression_ratio": 1.6893617021276597,
      "no_speech_prob": 0.00029905090923421085
    },
    {
      "id": 38,
      "seek": 21176,
      "start": 211.76,
      "end": 217.51999999999998,
      "text": " I have a lot of questions which I think you both you and Nadia could answer.",
      "tokens": [
        50364,
        286,
        362,
        257,
        688,
        295,
        1651,
        597,
        286,
        519,
        291,
        1293,
        291,
        293,
        23269,
        654,
        727,
        1867,
        13,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740026473999023,
      "compression_ratio": 1.5454545454545454,
      "no_speech_prob": 0.0039748623967170715
    },
    {
      "id": 39,
      "seek": 21176,
      "start": 217.51999999999998,
      "end": 228.76,
      "text": " So when I come to this tab on the vibrant overview page, I expect the experience to be very similar to what I would see on the jobs page or the jobs tab, right?",
      "tokens": [
        50652,
        407,
        562,
        286,
        808,
        281,
        341,
        4421,
        322,
        264,
        21571,
        12492,
        3028,
        11,
        286,
        2066,
        264,
        1752,
        281,
        312,
        588,
        2531,
        281,
        437,
        286,
        576,
        536,
        322,
        264,
        4782,
        3028,
        420,
        264,
        4782,
        4421,
        11,
        558,
        30,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740026473999023,
      "compression_ratio": 1.5454545454545454,
      "no_speech_prob": 0.0039748623967170715
    },
    {
      "id": 40,
      "seek": 21176,
      "start": 228.76,
      "end": 230.07999999999998,
      "text": " The list.",
      "tokens": [
        51214,
        440,
        1329,
        13,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740026473999023,
      "compression_ratio": 1.5454545454545454,
      "no_speech_prob": 0.0039748623967170715
    },
    {
      "id": 41,
      "seek": 21176,
      "start": 230.07999999999998,
      "end": 239.12,
      "text": " Now I have added a link here in the agenda that's for one of the pipeline steps running currently for GitLab.",
      "tokens": [
        51280,
        823,
        286,
        362,
        3869,
        257,
        2113,
        510,
        294,
        264,
        9829,
        300,
        311,
        337,
        472,
        295,
        264,
        15517,
        4439,
        2614,
        4362,
        337,
        16939,
        37880,
        13,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740026473999023,
      "compression_ratio": 1.5454545454545454,
      "no_speech_prob": 0.0039748623967170715
    },
    {
      "id": 42,
      "seek": 23912,
      "start": 239.12,
      "end": 245.68,
      "text": " And when I navigate through the multi project and the child pipeline like upstream downstream.",
      "tokens": [
        50364,
        400,
        562,
        286,
        12350,
        807,
        264,
        4825,
        1716,
        293,
        264,
        1440,
        15517,
        411,
        33915,
        30621,
        13,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20428663751353388,
      "compression_ratio": 1.7666666666666666,
      "no_speech_prob": 0.009484508074820042
    },
    {
      "id": 43,
      "seek": 23912,
      "start": 245.68,
      "end": 255.12,
      "text": " So what I see is the list and the jobs, it doesn't change until I go ahead and select the pipeline in the graph.",
      "tokens": [
        50692,
        407,
        437,
        286,
        536,
        307,
        264,
        1329,
        293,
        264,
        4782,
        11,
        309,
        1177,
        380,
        1319,
        1826,
        286,
        352,
        2286,
        293,
        3048,
        264,
        15517,
        294,
        264,
        4295,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20428663751353388,
      "compression_ratio": 1.7666666666666666,
      "no_speech_prob": 0.009484508074820042
    },
    {
      "id": 44,
      "seek": 23912,
      "start": 255.12,
      "end": 258.12,
      "text": " Like for example, I'm in the parent pipeline.",
      "tokens": [
        51164,
        1743,
        337,
        1365,
        11,
        286,
        478,
        294,
        264,
        2596,
        15517,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20428663751353388,
      "compression_ratio": 1.7666666666666666,
      "no_speech_prob": 0.009484508074820042
    },
    {
      "id": 45,
      "seek": 23912,
      "start": 258.12,
      "end": 265.12,
      "text": " The job list is not to have the items which are in the child pipeline until I go and select the child pipeline.",
      "tokens": [
        51314,
        440,
        1691,
        1329,
        307,
        406,
        281,
        362,
        264,
        4754,
        597,
        366,
        294,
        264,
        1440,
        15517,
        1826,
        286,
        352,
        293,
        3048,
        264,
        1440,
        15517,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20428663751353388,
      "compression_ratio": 1.7666666666666666,
      "no_speech_prob": 0.009484508074820042
    },
    {
      "id": 46,
      "seek": 23912,
      "start": 265.12,
      "end": 267.12,
      "text": " Okay.",
      "tokens": [
        51664,
        1033,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20428663751353388,
      "compression_ratio": 1.7666666666666666,
      "no_speech_prob": 0.009484508074820042
    },
    {
      "id": 47,
      "seek": 26712,
      "start": 267.12,
      "end": 274.12,
      "text": " So we don't show the jobs for child pipelines, basically at the parent level.",
      "tokens": [
        50364,
        407,
        321,
        500,
        380,
        855,
        264,
        4782,
        337,
        1440,
        40168,
        11,
        1936,
        412,
        264,
        2596,
        1496,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15933454953707182,
      "compression_ratio": 1.4216867469879517,
      "no_speech_prob": 0.001635005115531385
    },
    {
      "id": 48,
      "seek": 26712,
      "start": 274.12,
      "end": 280.12,
      "text": " That's what I failed when I checked this in the morning.",
      "tokens": [
        50714,
        663,
        311,
        437,
        286,
        7612,
        562,
        286,
        10033,
        341,
        294,
        264,
        2446,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15933454953707182,
      "compression_ratio": 1.4216867469879517,
      "no_speech_prob": 0.001635005115531385
    },
    {
      "id": 49,
      "seek": 26712,
      "start": 280.12,
      "end": 284.12,
      "text": " I'm not I wasn't aware of this actually.",
      "tokens": [
        51014,
        286,
        478,
        406,
        286,
        2067,
        380,
        3650,
        295,
        341,
        767,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15933454953707182,
      "compression_ratio": 1.4216867469879517,
      "no_speech_prob": 0.001635005115531385
    },
    {
      "id": 50,
      "seek": 26712,
      "start": 284.12,
      "end": 289.12,
      "text": " So I had no idea that we have some kind of connection there.",
      "tokens": [
        51214,
        407,
        286,
        632,
        572,
        1558,
        300,
        321,
        362,
        512,
        733,
        295,
        4984,
        456,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15933454953707182,
      "compression_ratio": 1.4216867469879517,
      "no_speech_prob": 0.001635005115531385
    },
    {
      "id": 51,
      "seek": 28912,
      "start": 289.12,
      "end": 301.12,
      "text": " So just to confirm when you expand the child pipeline in the pipeline graph, only then we show the jobs from the pipeline in the job steps.",
      "tokens": [
        50364,
        407,
        445,
        281,
        9064,
        562,
        291,
        5268,
        264,
        1440,
        15517,
        294,
        264,
        15517,
        4295,
        11,
        787,
        550,
        321,
        855,
        264,
        4782,
        490,
        264,
        15517,
        294,
        264,
        1691,
        4439,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22252048330104096,
      "compression_ratio": 1.4803149606299213,
      "no_speech_prob": 0.20131395757198334
    },
    {
      "id": 52,
      "seek": 28912,
      "start": 301.12,
      "end": 306.12,
      "text": " If you like just look at the badge and see when.",
      "tokens": [
        50964,
        759,
        291,
        411,
        445,
        574,
        412,
        264,
        25797,
        293,
        536,
        562,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22252048330104096,
      "compression_ratio": 1.4803149606299213,
      "no_speech_prob": 0.20131395757198334
    },
    {
      "id": 53,
      "seek": 30612,
      "start": 306.12,
      "end": 314.12,
      "text": " And if you click on the on expanding the downstream, it doesn't change like the number of jobs inside the tab, it doesn't change at all.",
      "tokens": [
        50364,
        400,
        498,
        291,
        2052,
        322,
        264,
        322,
        14702,
        264,
        30621,
        11,
        309,
        1177,
        380,
        1319,
        411,
        264,
        1230,
        295,
        4782,
        1854,
        264,
        4421,
        11,
        309,
        1177,
        380,
        1319,
        412,
        439,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2511650044867333,
      "compression_ratio": 1.8080808080808082,
      "no_speech_prob": 0.6074396371841431
    },
    {
      "id": 54,
      "seek": 30612,
      "start": 314.12,
      "end": 316.12,
      "text": " It doesn't expand.",
      "tokens": [
        50764,
        467,
        1177,
        380,
        5268,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2511650044867333,
      "compression_ratio": 1.8080808080808082,
      "no_speech_prob": 0.6074396371841431
    },
    {
      "id": 55,
      "seek": 30612,
      "start": 316.12,
      "end": 327.12,
      "text": " And it doesn't give a new list until you click on the pipeline like child pipeline numbers to express me that now I'm looking at the details for the child pipeline.",
      "tokens": [
        50864,
        400,
        309,
        1177,
        380,
        976,
        257,
        777,
        1329,
        1826,
        291,
        2052,
        322,
        264,
        15517,
        411,
        1440,
        15517,
        3547,
        281,
        5109,
        385,
        300,
        586,
        286,
        478,
        1237,
        412,
        264,
        4365,
        337,
        264,
        1440,
        15517,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2511650044867333,
      "compression_ratio": 1.8080808080808082,
      "no_speech_prob": 0.6074396371841431
    },
    {
      "id": 56,
      "seek": 30612,
      "start": 327.12,
      "end": 329.12,
      "text": " Oh, like that.",
      "tokens": [
        51414,
        876,
        11,
        411,
        300,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2511650044867333,
      "compression_ratio": 1.8080808080808082,
      "no_speech_prob": 0.6074396371841431
    },
    {
      "id": 57,
      "seek": 30612,
      "start": 329.12,
      "end": 332.12,
      "text": " Oh, yeah, makes sense.",
      "tokens": [
        51514,
        876,
        11,
        1338,
        11,
        1669,
        2020,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2511650044867333,
      "compression_ratio": 1.8080808080808082,
      "no_speech_prob": 0.6074396371841431
    },
    {
      "id": 58,
      "seek": 33212,
      "start": 332.12,
      "end": 344.12,
      "text": " Yeah, I mean, it sounds like an issue, something that we have to consider separately. I have never heard this come up.",
      "tokens": [
        50364,
        865,
        11,
        286,
        914,
        11,
        309,
        3263,
        411,
        364,
        2734,
        11,
        746,
        300,
        321,
        362,
        281,
        1949,
        14759,
        13,
        286,
        362,
        1128,
        2198,
        341,
        808,
        493,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18207908163265307,
      "compression_ratio": 1.375,
      "no_speech_prob": 0.005519448313862085
    },
    {
      "id": 59,
      "seek": 33212,
      "start": 344.12,
      "end": 353.12,
      "text": " Yeah, it's it seems reasonable to update it if you expand the graph.",
      "tokens": [
        50964,
        865,
        11,
        309,
        311,
        309,
        2544,
        10585,
        281,
        5623,
        309,
        498,
        291,
        5268,
        264,
        4295,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18207908163265307,
      "compression_ratio": 1.375,
      "no_speech_prob": 0.005519448313862085
    },
    {
      "id": 60,
      "seek": 35312,
      "start": 353.12,
      "end": 365.12,
      "text": " I think what Gina is doing is the experience that's expected, but the overall experience for the job step it needs to be a bit that's well.",
      "tokens": [
        50364,
        286,
        519,
        437,
        34711,
        307,
        884,
        307,
        264,
        1752,
        300,
        311,
        5176,
        11,
        457,
        264,
        4787,
        1752,
        337,
        264,
        1691,
        1823,
        309,
        2203,
        281,
        312,
        257,
        857,
        300,
        311,
        731,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2884223889081906,
      "compression_ratio": 1.3181818181818181,
      "no_speech_prob": 0.0205821730196476
    },
    {
      "id": 61,
      "seek": 35312,
      "start": 365.12,
      "end": 368.12,
      "text": " Yeah.",
      "tokens": [
        50964,
        865,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2884223889081906,
      "compression_ratio": 1.3181818181818181,
      "no_speech_prob": 0.0205821730196476
    },
    {
      "id": 62,
      "seek": 36812,
      "start": 368.12,
      "end": 378.12,
      "text": " So I have a comment around the around the usage of the badge for this.",
      "tokens": [
        50364,
        407,
        286,
        362,
        257,
        2871,
        926,
        264,
        926,
        264,
        14924,
        295,
        264,
        25797,
        337,
        341,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1298345947265625,
      "compression_ratio": 1.4779411764705883,
      "no_speech_prob": 0.036223266273736954
    },
    {
      "id": 63,
      "seek": 36812,
      "start": 378.12,
      "end": 388.12,
      "text": " So currently the badges on the child pipelines are not applicable. They're just meant to show you the type of the item that it is.",
      "tokens": [
        50864,
        407,
        4362,
        264,
        43894,
        322,
        264,
        1440,
        40168,
        366,
        406,
        21142,
        13,
        814,
        434,
        445,
        4140,
        281,
        855,
        291,
        264,
        2010,
        295,
        264,
        3174,
        300,
        309,
        307,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1298345947265625,
      "compression_ratio": 1.4779411764705883,
      "no_speech_prob": 0.036223266273736954
    },
    {
      "id": 64,
      "seek": 38812,
      "start": 388.12,
      "end": 399.12,
      "text": " And oftentimes the badges in the UI are not clickable. So they don't have a strong visual affordance that you can click on them and users are not necessarily used to that.",
      "tokens": [
        50364,
        400,
        18349,
        264,
        43894,
        294,
        264,
        15682,
        366,
        406,
        2052,
        712,
        13,
        407,
        436,
        500,
        380,
        362,
        257,
        2068,
        5056,
        6157,
        719,
        300,
        291,
        393,
        2052,
        322,
        552,
        293,
        5022,
        366,
        406,
        4725,
        1143,
        281,
        300,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10595701451887164,
      "compression_ratio": 1.5031847133757963,
      "no_speech_prob": 0.2792949974536896
    },
    {
      "id": 65,
      "seek": 38812,
      "start": 399.12,
      "end": 404.12,
      "text": " So my concern would be that this link would not be discoverable.",
      "tokens": [
        50914,
        407,
        452,
        3136,
        576,
        312,
        300,
        341,
        2113,
        576,
        406,
        312,
        4411,
        712,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10595701451887164,
      "compression_ratio": 1.5031847133757963,
      "no_speech_prob": 0.2792949974536896
    },
    {
      "id": 66,
      "seek": 40412,
      "start": 404.12,
      "end": 420.12,
      "text": " And also placing the ID inside the badge makes it kind of more difficult to read in a way because it's together with the child, the world child and makes more difficult to copy and paste it if you need to if you to search for the pipeline, for example.",
      "tokens": [
        50364,
        400,
        611,
        17221,
        264,
        7348,
        1854,
        264,
        25797,
        1669,
        309,
        733,
        295,
        544,
        2252,
        281,
        1401,
        294,
        257,
        636,
        570,
        309,
        311,
        1214,
        365,
        264,
        1440,
        11,
        264,
        1002,
        1440,
        293,
        1669,
        544,
        2252,
        281,
        5055,
        293,
        9163,
        309,
        498,
        291,
        643,
        281,
        498,
        291,
        281,
        3164,
        337,
        264,
        15517,
        11,
        337,
        1365,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13460212740404853,
      "compression_ratio": 1.5555555555555556,
      "no_speech_prob": 0.03407219424843788
    },
    {
      "id": 67,
      "seek": 42012,
      "start": 420.12,
      "end": 425.12,
      "text": " So these are just like my thoughts on using the badge here.",
      "tokens": [
        50364,
        407,
        613,
        366,
        445,
        411,
        452,
        4598,
        322,
        1228,
        264,
        25797,
        510,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11581242469049269,
      "compression_ratio": 1.715481171548117,
      "no_speech_prob": 0.015082151629030704
    },
    {
      "id": 68,
      "seek": 42012,
      "start": 425.12,
      "end": 433.12,
      "text": " I do like using badge for the child just to show that it's the child pipeline because it's exactly the same what we show in the pipeline graph.",
      "tokens": [
        50614,
        286,
        360,
        411,
        1228,
        25797,
        337,
        264,
        1440,
        445,
        281,
        855,
        300,
        309,
        311,
        264,
        1440,
        15517,
        570,
        309,
        311,
        2293,
        264,
        912,
        437,
        321,
        855,
        294,
        264,
        15517,
        4295,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11581242469049269,
      "compression_ratio": 1.715481171548117,
      "no_speech_prob": 0.015082151629030704
    },
    {
      "id": 69,
      "seek": 42012,
      "start": 433.12,
      "end": 449.12,
      "text": " But maybe the idea could be a separate link or yeah, something that the user will immediately see as an obligation item because we do use linked ideas a lot in the UI to navigate between pipelines and jobs.",
      "tokens": [
        51014,
        583,
        1310,
        264,
        1558,
        727,
        312,
        257,
        4994,
        2113,
        420,
        1338,
        11,
        746,
        300,
        264,
        4195,
        486,
        4258,
        536,
        382,
        364,
        20326,
        3174,
        570,
        321,
        360,
        764,
        9408,
        3487,
        257,
        688,
        294,
        264,
        15682,
        281,
        12350,
        1296,
        40168,
        293,
        4782,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11581242469049269,
      "compression_ratio": 1.715481171548117,
      "no_speech_prob": 0.015082151629030704
    },
    {
      "id": 70,
      "seek": 44912,
      "start": 449.12,
      "end": 462.12,
      "text": " Okay, yeah, I can play around with separating it out. I agree. I like the reuse of the badge just because it's already something that we use.",
      "tokens": [
        50364,
        1033,
        11,
        1338,
        11,
        286,
        393,
        862,
        926,
        365,
        29279,
        309,
        484,
        13,
        286,
        3986,
        13,
        286,
        411,
        264,
        26225,
        295,
        264,
        25797,
        445,
        570,
        309,
        311,
        1217,
        746,
        300,
        321,
        764,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030579282526383,
      "compression_ratio": 1.4171779141104295,
      "no_speech_prob": 0.001556553179398179
    },
    {
      "id": 71,
      "seek": 44912,
      "start": 462.12,
      "end": 472.12,
      "text": " And I was thinking of maybe doing a full other like column that includes the pipeline ID.",
      "tokens": [
        51014,
        400,
        286,
        390,
        1953,
        295,
        1310,
        884,
        257,
        1577,
        661,
        411,
        7738,
        300,
        5974,
        264,
        15517,
        7348,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030579282526383,
      "compression_ratio": 1.4171779141104295,
      "no_speech_prob": 0.001556553179398179
    },
    {
      "id": 72,
      "seek": 47212,
      "start": 473.12,
      "end": 477.12,
      "text": " I'll think about that more though.",
      "tokens": [
        50414,
        286,
        603,
        519,
        466,
        300,
        544,
        1673,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2189866863951391,
      "compression_ratio": 1.392156862745098,
      "no_speech_prob": 0.021915670484304428
    },
    {
      "id": 73,
      "seek": 47212,
      "start": 479.12,
      "end": 492.12,
      "text": " Also, this might be unrelated, but we were actually finding the opposite where we had a success badge on the deployment, the environment page and people thought it was clickable.",
      "tokens": [
        50714,
        2743,
        11,
        341,
        1062,
        312,
        38967,
        11,
        457,
        321,
        645,
        767,
        5006,
        264,
        6182,
        689,
        321,
        632,
        257,
        2245,
        25797,
        322,
        264,
        19317,
        11,
        264,
        2823,
        3028,
        293,
        561,
        1194,
        309,
        390,
        2052,
        712,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2189866863951391,
      "compression_ratio": 1.392156862745098,
      "no_speech_prob": 0.021915670484304428
    },
    {
      "id": 74,
      "seek": 49212,
      "start": 493.12,
      "end": 500.12,
      "text": " Even though it wasn't because it was a badge. So I think I know why because of the badges on the pipeline page.",
      "tokens": [
        50414,
        2754,
        1673,
        309,
        2067,
        380,
        570,
        309,
        390,
        257,
        25797,
        13,
        407,
        286,
        519,
        286,
        458,
        983,
        570,
        295,
        264,
        43894,
        322,
        264,
        15517,
        3028,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1743505597114563,
      "compression_ratio": 1.759433962264151,
      "no_speech_prob": 0.017328506335616112
    },
    {
      "id": 75,
      "seek": 49212,
      "start": 500.12,
      "end": 502.12,
      "text": " They are pickable.",
      "tokens": [
        50764,
        814,
        366,
        1888,
        712,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1743505597114563,
      "compression_ratio": 1.759433962264151,
      "no_speech_prob": 0.017328506335616112
    },
    {
      "id": 76,
      "seek": 49212,
      "start": 502.12,
      "end": 509.12,
      "text": " Yeah, so I'm wondering if you could style the badge a little bit differently where it looks like it's clickable.",
      "tokens": [
        50864,
        865,
        11,
        370,
        286,
        478,
        6359,
        498,
        291,
        727,
        3758,
        264,
        25797,
        257,
        707,
        857,
        7614,
        689,
        309,
        1542,
        411,
        309,
        311,
        2052,
        712,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1743505597114563,
      "compression_ratio": 1.759433962264151,
      "no_speech_prob": 0.017328506335616112
    },
    {
      "id": 77,
      "seek": 49212,
      "start": 509.12,
      "end": 517.12,
      "text": " I don't know what options for badges there, but I feel like if they there is like a badge version that looks like it's clickable.",
      "tokens": [
        51214,
        286,
        500,
        380,
        458,
        437,
        3956,
        337,
        43894,
        456,
        11,
        457,
        286,
        841,
        411,
        498,
        436,
        456,
        307,
        411,
        257,
        25797,
        3037,
        300,
        1542,
        411,
        309,
        311,
        2052,
        712,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1743505597114563,
      "compression_ratio": 1.759433962264151,
      "no_speech_prob": 0.017328506335616112
    },
    {
      "id": 78,
      "seek": 51712,
      "start": 517.12,
      "end": 521.12,
      "text": " And when we made it not clickable, people were confused.",
      "tokens": [
        50364,
        400,
        562,
        321,
        1027,
        309,
        406,
        2052,
        712,
        11,
        561,
        645,
        9019,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19856500625610352,
      "compression_ratio": 1.4682926829268292,
      "no_speech_prob": 0.009698312729597092
    },
    {
      "id": 79,
      "seek": 51712,
      "start": 521.12,
      "end": 528.12,
      "text": " Is there any guidance from pajamas about whether or not they should be interactive elements?",
      "tokens": [
        50564,
        1119,
        456,
        604,
        10056,
        490,
        43625,
        466,
        1968,
        420,
        406,
        436,
        820,
        312,
        15141,
        4959,
        30,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19856500625610352,
      "compression_ratio": 1.4682926829268292,
      "no_speech_prob": 0.009698312729597092
    },
    {
      "id": 80,
      "seek": 51712,
      "start": 528.12,
      "end": 530.12,
      "text": " I think they can be both.",
      "tokens": [
        50914,
        286,
        519,
        436,
        393,
        312,
        1293,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19856500625610352,
      "compression_ratio": 1.4682926829268292,
      "no_speech_prob": 0.009698312729597092
    },
    {
      "id": 81,
      "seek": 51712,
      "start": 530.12,
      "end": 532.12,
      "text": " Okay, cool.",
      "tokens": [
        51014,
        1033,
        11,
        1627,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19856500625610352,
      "compression_ratio": 1.4682926829268292,
      "no_speech_prob": 0.009698312729597092
    },
    {
      "id": 82,
      "seek": 51712,
      "start": 532.12,
      "end": 537.12,
      "text": " But yeah, I'm trying to think of like a joke like issue labels.",
      "tokens": [
        51114,
        583,
        1338,
        11,
        286,
        478,
        1382,
        281,
        519,
        295,
        411,
        257,
        7647,
        411,
        2734,
        16949,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19856500625610352,
      "compression_ratio": 1.4682926829268292,
      "no_speech_prob": 0.009698312729597092
    },
    {
      "id": 83,
      "seek": 51712,
      "start": 537.12,
      "end": 541.12,
      "text": " I guess those are technically labels, not badges.",
      "tokens": [
        51364,
        286,
        2041,
        729,
        366,
        12120,
        16949,
        11,
        406,
        43894,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19856500625610352,
      "compression_ratio": 1.4682926829268292,
      "no_speech_prob": 0.009698312729597092
    },
    {
      "id": 84,
      "seek": 54112,
      "start": 541.12,
      "end": 544.12,
      "text": " But those are clickable.",
      "tokens": [
        50364,
        583,
        729,
        366,
        2052,
        712,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10317632399107281,
      "compression_ratio": 1.3109243697478992,
      "no_speech_prob": 0.0002565686299931258
    },
    {
      "id": 85,
      "seek": 54112,
      "start": 544.12,
      "end": 553.12,
      "text": " And sometimes not clickable.",
      "tokens": [
        50514,
        400,
        2171,
        406,
        2052,
        712,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10317632399107281,
      "compression_ratio": 1.3109243697478992,
      "no_speech_prob": 0.0002565686299931258
    },
    {
      "id": 86,
      "seek": 54112,
      "start": 553.12,
      "end": 563.12,
      "text": " One other question I had was just thinking about like the idea of having the sophisticated simplicity.",
      "tokens": [
        50964,
        1485,
        661,
        1168,
        286,
        632,
        390,
        445,
        1953,
        466,
        411,
        264,
        1558,
        295,
        1419,
        264,
        16950,
        25632,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10317632399107281,
      "compression_ratio": 1.3109243697478992,
      "no_speech_prob": 0.0002565686299931258
    },
    {
      "id": 87,
      "seek": 56312,
      "start": 563.12,
      "end": 566.12,
      "text": " Like thing that's going on right now.",
      "tokens": [
        50364,
        1743,
        551,
        300,
        311,
        516,
        322,
        558,
        586,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17434941700526646,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.04462651163339615
    },
    {
      "id": 88,
      "seek": 56312,
      "start": 566.12,
      "end": 579.12,
      "text": " I was wondering if it made sense to maybe keep this like the child pipeline test collapsed by default because we do that in the pipeline too.",
      "tokens": [
        50514,
        286,
        390,
        6359,
        498,
        309,
        1027,
        2020,
        281,
        1310,
        1066,
        341,
        411,
        264,
        1440,
        15517,
        1500,
        24578,
        538,
        7576,
        570,
        321,
        360,
        300,
        294,
        264,
        15517,
        886,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17434941700526646,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.04462651163339615
    },
    {
      "id": 89,
      "seek": 56312,
      "start": 579.12,
      "end": 584.12,
      "text": " Like you have to expand it to show the child pipeline.",
      "tokens": [
        51164,
        1743,
        291,
        362,
        281,
        5268,
        309,
        281,
        855,
        264,
        1440,
        15517,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17434941700526646,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.04462651163339615
    },
    {
      "id": 90,
      "seek": 56312,
      "start": 584.12,
      "end": 588.12,
      "text": " So I'm wondering if it will be worth exploring.",
      "tokens": [
        51414,
        407,
        286,
        478,
        6359,
        498,
        309,
        486,
        312,
        3163,
        12736,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17434941700526646,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.04462651163339615
    },
    {
      "id": 91,
      "seek": 58812,
      "start": 588.12,
      "end": 592.12,
      "text": " I was going to show high like toggle to show and hide them.",
      "tokens": [
        50364,
        286,
        390,
        516,
        281,
        855,
        1090,
        411,
        31225,
        281,
        855,
        293,
        6479,
        552,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35870630400521414,
      "compression_ratio": 1.4285714285714286,
      "no_speech_prob": 0.028146209195256233
    },
    {
      "id": 92,
      "seek": 58812,
      "start": 592.12,
      "end": 601.12,
      "text": " It was just a thought.",
      "tokens": [
        50564,
        467,
        390,
        445,
        257,
        1194,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35870630400521414,
      "compression_ratio": 1.4285714285714286,
      "no_speech_prob": 0.028146209195256233
    },
    {
      "id": 93,
      "seek": 58812,
      "start": 601.12,
      "end": 604.12,
      "text": " You mean in the pipeline craft?",
      "tokens": [
        51014,
        509,
        914,
        294,
        264,
        15517,
        8448,
        30,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35870630400521414,
      "compression_ratio": 1.4285714285714286,
      "no_speech_prob": 0.028146209195256233
    },
    {
      "id": 94,
      "seek": 58812,
      "start": 604.12,
      "end": 607.12,
      "text": " I mean like in this all of this.",
      "tokens": [
        51164,
        286,
        914,
        411,
        294,
        341,
        439,
        295,
        341,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35870630400521414,
      "compression_ratio": 1.4285714285714286,
      "no_speech_prob": 0.028146209195256233
    },
    {
      "id": 95,
      "seek": 58812,
      "start": 607.12,
      "end": 612.12,
      "text": " Yeah, adding like a toggle here.",
      "tokens": [
        51314,
        865,
        11,
        5127,
        411,
        257,
        31225,
        510,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35870630400521414,
      "compression_ratio": 1.4285714285714286,
      "no_speech_prob": 0.028146209195256233
    },
    {
      "id": 96,
      "seek": 61212,
      "start": 612.12,
      "end": 621.12,
      "text": " It's like something that could be also a filter like a drop down because you would filter by a type of job.",
      "tokens": [
        50364,
        467,
        311,
        411,
        746,
        300,
        727,
        312,
        611,
        257,
        6608,
        411,
        257,
        3270,
        760,
        570,
        291,
        576,
        6608,
        538,
        257,
        2010,
        295,
        1691,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17169306229571907,
      "compression_ratio": 1.3582089552238805,
      "no_speech_prob": 0.030973507091403008
    },
    {
      "id": 97,
      "seek": 61212,
      "start": 621.12,
      "end": 625.12,
      "text": " Assorting mechanism of sort.",
      "tokens": [
        50814,
        6281,
        477,
        278,
        7513,
        295,
        1333,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17169306229571907,
      "compression_ratio": 1.3582089552238805,
      "no_speech_prob": 0.030973507091403008
    },
    {
      "id": 98,
      "seek": 61212,
      "start": 625.12,
      "end": 633.12,
      "text": " Or the bridge or trigger job can be expanded.",
      "tokens": [
        51014,
        1610,
        264,
        7283,
        420,
        7875,
        1691,
        393,
        312,
        14342,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17169306229571907,
      "compression_ratio": 1.3582089552238805,
      "no_speech_prob": 0.030973507091403008
    },
    {
      "id": 99,
      "seek": 63312,
      "start": 633.12,
      "end": 640.12,
      "text": " Like the job that's calling the downstream or the child pipeline that can be a little.",
      "tokens": [
        50364,
        1743,
        264,
        1691,
        300,
        311,
        5141,
        264,
        30621,
        420,
        264,
        1440,
        15517,
        300,
        393,
        312,
        257,
        707,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24278509794776118,
      "compression_ratio": 1.4970059880239521,
      "no_speech_prob": 0.009313119575381279
    },
    {
      "id": 100,
      "seek": 63312,
      "start": 640.12,
      "end": 646.12,
      "text": " That can be treated differently visually and there can be an option to expand it.",
      "tokens": [
        50714,
        663,
        393,
        312,
        8668,
        7614,
        19622,
        293,
        456,
        393,
        312,
        364,
        3614,
        281,
        5268,
        309,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24278509794776118,
      "compression_ratio": 1.4970059880239521,
      "no_speech_prob": 0.009313119575381279
    },
    {
      "id": 101,
      "seek": 63312,
      "start": 646.12,
      "end": 650.12,
      "text": " And go.",
      "tokens": [
        51014,
        400,
        352,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24278509794776118,
      "compression_ratio": 1.4970059880239521,
      "no_speech_prob": 0.009313119575381279
    },
    {
      "id": 102,
      "seek": 63312,
      "start": 650.12,
      "end": 653.12,
      "text": " It might just be something that I needed like.",
      "tokens": [
        51214,
        467,
        1062,
        445,
        312,
        746,
        300,
        286,
        2978,
        411,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24278509794776118,
      "compression_ratio": 1.4970059880239521,
      "no_speech_prob": 0.009313119575381279
    },
    {
      "id": 103,
      "seek": 63312,
      "start": 653.12,
      "end": 657.12,
      "text": " Validate a little bit too.",
      "tokens": [
        51364,
        7188,
        327,
        473,
        257,
        707,
        857,
        886,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24278509794776118,
      "compression_ratio": 1.4970059880239521,
      "no_speech_prob": 0.009313119575381279
    },
    {
      "id": 104,
      "seek": 65712,
      "start": 657.12,
      "end": 666.12,
      "text": " Yeah, I feel like I don't feel confident enough to be like let's complicate this by adding filters.",
      "tokens": [
        50364,
        865,
        11,
        286,
        841,
        411,
        286,
        500,
        380,
        841,
        6679,
        1547,
        281,
        312,
        411,
        718,
        311,
        1209,
        8700,
        341,
        538,
        5127,
        15995,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13369674447142046,
      "compression_ratio": 1.4975369458128078,
      "no_speech_prob": 0.0017100119730457664
    },
    {
      "id": 105,
      "seek": 65712,
      "start": 666.12,
      "end": 668.12,
      "text": " Just yet.",
      "tokens": [
        50814,
        1449,
        1939,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13369674447142046,
      "compression_ratio": 1.4975369458128078,
      "no_speech_prob": 0.0017100119730457664
    },
    {
      "id": 106,
      "seek": 65712,
      "start": 668.12,
      "end": 675.12,
      "text": " And I think you know what you can do to is come up with just two or three key tasks and then look at the impact on the flow.",
      "tokens": [
        50914,
        400,
        286,
        519,
        291,
        458,
        437,
        291,
        393,
        360,
        281,
        307,
        808,
        493,
        365,
        445,
        732,
        420,
        1045,
        2141,
        9608,
        293,
        550,
        574,
        412,
        264,
        2712,
        322,
        264,
        3095,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13369674447142046,
      "compression_ratio": 1.4975369458128078,
      "no_speech_prob": 0.0017100119730457664
    },
    {
      "id": 107,
      "seek": 65712,
      "start": 675.12,
      "end": 683.12,
      "text": " But I'm thinking that we want to optimize for when they're debugging.",
      "tokens": [
        51264,
        583,
        286,
        478,
        1953,
        300,
        321,
        528,
        281,
        19719,
        337,
        562,
        436,
        434,
        45592,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13369674447142046,
      "compression_ratio": 1.4975369458128078,
      "no_speech_prob": 0.0017100119730457664
    },
    {
      "id": 108,
      "seek": 68312,
      "start": 683.12,
      "end": 687.12,
      "text": " Yeah, that's a good idea too.",
      "tokens": [
        50364,
        865,
        11,
        300,
        311,
        257,
        665,
        1558,
        886,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28607257444467116,
      "compression_ratio": 1.3377483443708609,
      "no_speech_prob": 0.0019070999696850777
    },
    {
      "id": 109,
      "seek": 68312,
      "start": 687.12,
      "end": 689.12,
      "text": " Stalk sharing.",
      "tokens": [
        50564,
        745,
        667,
        5414,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28607257444467116,
      "compression_ratio": 1.3377483443708609,
      "no_speech_prob": 0.0019070999696850777
    },
    {
      "id": 110,
      "seek": 68312,
      "start": 689.12,
      "end": 693.12,
      "text": " Thank you for the feedback. That was really great.",
      "tokens": [
        50664,
        1044,
        291,
        337,
        264,
        5824,
        13,
        663,
        390,
        534,
        869,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28607257444467116,
      "compression_ratio": 1.3377483443708609,
      "no_speech_prob": 0.0019070999696850777
    },
    {
      "id": 111,
      "seek": 68312,
      "start": 693.12,
      "end": 696.12,
      "text": " So fun to have everybody in the call.",
      "tokens": [
        50864,
        407,
        1019,
        281,
        362,
        2201,
        294,
        264,
        818,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28607257444467116,
      "compression_ratio": 1.3377483443708609,
      "no_speech_prob": 0.0019070999696850777
    },
    {
      "id": 112,
      "seek": 68312,
      "start": 696.12,
      "end": 699.12,
      "text": " Like live brainstorming.",
      "tokens": [
        51014,
        1743,
        1621,
        35245,
        278,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28607257444467116,
      "compression_ratio": 1.3377483443708609,
      "no_speech_prob": 0.0019070999696850777
    },
    {
      "id": 113,
      "seek": 68312,
      "start": 699.12,
      "end": 703.12,
      "text": " I know it's very useful.",
      "tokens": [
        51164,
        286,
        458,
        309,
        311,
        588,
        4420,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28607257444467116,
      "compression_ratio": 1.3377483443708609,
      "no_speech_prob": 0.0019070999696850777
    },
    {
      "id": 114,
      "seek": 68312,
      "start": 703.12,
      "end": 705.12,
      "text": " My last thing I'm.",
      "tokens": [
        51364,
        1222,
        1036,
        551,
        286,
        478,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28607257444467116,
      "compression_ratio": 1.3377483443708609,
      "no_speech_prob": 0.0019070999696850777
    },
    {
      "id": 115,
      "seek": 70512,
      "start": 705.12,
      "end": 707.12,
      "text": " I'm not sure if I can do that.",
      "tokens": [
        50364,
        286,
        478,
        406,
        988,
        498,
        286,
        393,
        360,
        300,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3840221367260017,
      "compression_ratio": 1.701834862385321,
      "no_speech_prob": 0.0017191431252285838
    },
    {
      "id": 116,
      "seek": 70512,
      "start": 707.12,
      "end": 709.12,
      "text": " I'm not sure if I can do that.",
      "tokens": [
        50464,
        286,
        478,
        406,
        988,
        498,
        286,
        393,
        360,
        300,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3840221367260017,
      "compression_ratio": 1.701834862385321,
      "no_speech_prob": 0.0017191431252285838
    },
    {
      "id": 117,
      "seek": 70512,
      "start": 709.12,
      "end": 712.12,
      "text": " We can take this a sink if we wanted to.",
      "tokens": [
        50564,
        492,
        393,
        747,
        341,
        257,
        9500,
        498,
        321,
        1415,
        281,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3840221367260017,
      "compression_ratio": 1.701834862385321,
      "no_speech_prob": 0.0017191431252285838
    },
    {
      "id": 118,
      "seek": 70512,
      "start": 712.12,
      "end": 718.12,
      "text": " But I just feel like I'm taking forever creating issues with the feature.",
      "tokens": [
        50714,
        583,
        286,
        445,
        841,
        411,
        286,
        478,
        1940,
        5680,
        4084,
        2663,
        365,
        264,
        4111,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3840221367260017,
      "compression_ratio": 1.701834862385321,
      "no_speech_prob": 0.0017191431252285838
    },
    {
      "id": 119,
      "seek": 70512,
      "start": 718.12,
      "end": 721.12,
      "text": " That feature detailed template.",
      "tokens": [
        51014,
        663,
        4111,
        9942,
        12379,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3840221367260017,
      "compression_ratio": 1.701834862385321,
      "no_speech_prob": 0.0017191431252285838
    },
    {
      "id": 120,
      "seek": 70512,
      "start": 721.12,
      "end": 726.12,
      "text": " I feel like there's a lot of different sections I need to fill out label to add.",
      "tokens": [
        51164,
        286,
        841,
        411,
        456,
        311,
        257,
        688,
        295,
        819,
        10863,
        286,
        643,
        281,
        2836,
        484,
        7645,
        281,
        909,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3840221367260017,
      "compression_ratio": 1.701834862385321,
      "no_speech_prob": 0.0017191431252285838
    },
    {
      "id": 121,
      "seek": 70512,
      "start": 726.12,
      "end": 731.12,
      "text": " And I was wondering if people had best practices around making it more efficient.",
      "tokens": [
        51414,
        400,
        286,
        390,
        6359,
        498,
        561,
        632,
        1151,
        7525,
        926,
        1455,
        309,
        544,
        7148,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3840221367260017,
      "compression_ratio": 1.701834862385321,
      "no_speech_prob": 0.0017191431252285838
    },
    {
      "id": 122,
      "seek": 73112,
      "start": 731.12,
      "end": 738.12,
      "text": " Yeah, I just wanted to say that I can relate and I don't have any specific tips because my process manual, but.",
      "tokens": [
        50364,
        865,
        11,
        286,
        445,
        1415,
        281,
        584,
        300,
        286,
        393,
        10961,
        293,
        286,
        500,
        380,
        362,
        604,
        2685,
        6082,
        570,
        452,
        1399,
        9688,
        11,
        457,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21963785005652386,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 0.0648907795548439
    },
    {
      "id": 123,
      "seek": 73112,
      "start": 738.12,
      "end": 744.12,
      "text": " I see that physical mention templates and I can also second that is very important to use templates.",
      "tokens": [
        50714,
        286,
        536,
        300,
        4001,
        2152,
        21165,
        293,
        286,
        393,
        611,
        1150,
        300,
        307,
        588,
        1021,
        281,
        764,
        21165,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21963785005652386,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 0.0648907795548439
    },
    {
      "id": 124,
      "seek": 73112,
      "start": 744.12,
      "end": 746.12,
      "text": " Yeah, but it doesn't really solve.",
      "tokens": [
        51014,
        865,
        11,
        457,
        309,
        1177,
        380,
        534,
        5039,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21963785005652386,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 0.0648907795548439
    },
    {
      "id": 125,
      "seek": 73112,
      "start": 746.12,
      "end": 749.12,
      "text": " I mean, it applies some labels actually some basic labels.",
      "tokens": [
        51114,
        286,
        914,
        11,
        309,
        13165,
        512,
        16949,
        767,
        512,
        3875,
        16949,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21963785005652386,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 0.0648907795548439
    },
    {
      "id": 126,
      "seek": 73112,
      "start": 749.12,
      "end": 752.12,
      "text": " So yes, mostly you have to delete.",
      "tokens": [
        51264,
        407,
        2086,
        11,
        5240,
        291,
        362,
        281,
        12097,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21963785005652386,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 0.0648907795548439
    },
    {
      "id": 127,
      "seek": 73112,
      "start": 752.12,
      "end": 756.12,
      "text": " But I.",
      "tokens": [
        51414,
        583,
        286,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21963785005652386,
      "compression_ratio": 1.5963302752293578,
      "no_speech_prob": 0.0648907795548439
    },
    {
      "id": 128,
      "seek": 75612,
      "start": 756.12,
      "end": 761.12,
      "text": " I've been talking in terms of efficiency because you highlighted that Gina.",
      "tokens": [
        50364,
        286,
        600,
        668,
        1417,
        294,
        2115,
        295,
        10493,
        570,
        291,
        17173,
        300,
        34711,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20688951143654444,
      "compression_ratio": 1.564,
      "no_speech_prob": 0.07549622654914856
    },
    {
      "id": 129,
      "seek": 75612,
      "start": 761.12,
      "end": 763.12,
      "text": " I would say.",
      "tokens": [
        50614,
        286,
        576,
        584,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20688951143654444,
      "compression_ratio": 1.564,
      "no_speech_prob": 0.07549622654914856
    },
    {
      "id": 130,
      "seek": 75612,
      "start": 763.12,
      "end": 771.12,
      "text": " It makes efficient, but in a very different way, for example, it really makes people think about the problem statement when they're filling out this detailed template.",
      "tokens": [
        50714,
        467,
        1669,
        7148,
        11,
        457,
        294,
        257,
        588,
        819,
        636,
        11,
        337,
        1365,
        11,
        309,
        534,
        1669,
        561,
        519,
        466,
        264,
        1154,
        5629,
        562,
        436,
        434,
        10623,
        484,
        341,
        9942,
        12379,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20688951143654444,
      "compression_ratio": 1.564,
      "no_speech_prob": 0.07549622654914856
    },
    {
      "id": 131,
      "seek": 75612,
      "start": 771.12,
      "end": 778.12,
      "text": " So in private execution, when we started to get to the like very heavy backlog that was there for.",
      "tokens": [
        51114,
        407,
        294,
        4551,
        15058,
        11,
        562,
        321,
        1409,
        281,
        483,
        281,
        264,
        411,
        588,
        4676,
        47364,
        300,
        390,
        456,
        337,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20688951143654444,
      "compression_ratio": 1.564,
      "no_speech_prob": 0.07549622654914856
    },
    {
      "id": 132,
      "seek": 75612,
      "start": 778.12,
      "end": 782.12,
      "text": " It there were about 315,000 issues.",
      "tokens": [
        51464,
        467,
        456,
        645,
        466,
        805,
        5211,
        11,
        1360,
        2663,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20688951143654444,
      "compression_ratio": 1.564,
      "no_speech_prob": 0.07549622654914856
    },
    {
      "id": 133,
      "seek": 78212,
      "start": 782.12,
      "end": 790.12,
      "text": " We started to be very careful about like what exists there and what we need to close us to decades and what is not valid anymore.",
      "tokens": [
        50364,
        492,
        1409,
        281,
        312,
        588,
        5026,
        466,
        411,
        437,
        8198,
        456,
        293,
        437,
        321,
        643,
        281,
        1998,
        505,
        281,
        7878,
        293,
        437,
        307,
        406,
        7363,
        3602,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17154766410909672,
      "compression_ratio": 1.6982758620689655,
      "no_speech_prob": 0.14027495682239532
    },
    {
      "id": 134,
      "seek": 78212,
      "start": 790.12,
      "end": 797.12,
      "text": " But we started to notice that people open issues with just two lines like this is what I want.",
      "tokens": [
        50764,
        583,
        321,
        1409,
        281,
        3449,
        300,
        561,
        1269,
        2663,
        365,
        445,
        732,
        3876,
        411,
        341,
        307,
        437,
        286,
        528,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17154766410909672,
      "compression_ratio": 1.6982758620689655,
      "no_speech_prob": 0.14027495682239532
    },
    {
      "id": 135,
      "seek": 78212,
      "start": 797.12,
      "end": 800.12,
      "text": " This is how it should be done like with proposal.",
      "tokens": [
        51114,
        639,
        307,
        577,
        309,
        820,
        312,
        1096,
        411,
        365,
        11494,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17154766410909672,
      "compression_ratio": 1.6982758620689655,
      "no_speech_prob": 0.14027495682239532
    },
    {
      "id": 136,
      "seek": 78212,
      "start": 800.12,
      "end": 808.12,
      "text": " So we started to like discourage that and every issue when it used to come to me for charging, especially through that.",
      "tokens": [
        51264,
        407,
        321,
        1409,
        281,
        411,
        21497,
        609,
        300,
        293,
        633,
        2734,
        562,
        309,
        1143,
        281,
        808,
        281,
        385,
        337,
        11379,
        11,
        2318,
        807,
        300,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17154766410909672,
      "compression_ratio": 1.6982758620689655,
      "no_speech_prob": 0.14027495682239532
    },
    {
      "id": 137,
      "seek": 80812,
      "start": 808.12,
      "end": 811.12,
      "text": " So that's created over the weekend.",
      "tokens": [
        50364,
        407,
        300,
        311,
        2942,
        670,
        264,
        6711,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15962486040024532,
      "compression_ratio": 1.6847290640394088,
      "no_speech_prob": 0.005001924466341734
    },
    {
      "id": 138,
      "seek": 80812,
      "start": 811.12,
      "end": 819.12,
      "text": " I always used to make it a point I still do to like request people to like apply the template and fill up the questions.",
      "tokens": [
        50514,
        286,
        1009,
        1143,
        281,
        652,
        309,
        257,
        935,
        286,
        920,
        360,
        281,
        411,
        5308,
        561,
        281,
        411,
        3079,
        264,
        12379,
        293,
        2836,
        493,
        264,
        1651,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15962486040024532,
      "compression_ratio": 1.6847290640394088,
      "no_speech_prob": 0.005001924466341734
    },
    {
      "id": 139,
      "seek": 80812,
      "start": 819.12,
      "end": 826.12,
      "text": " And that has really made everyone think about the proposals that they're trying to put across like what isn't that they're trying to solve who is it for is it.",
      "tokens": [
        50914,
        400,
        300,
        575,
        534,
        1027,
        1518,
        519,
        466,
        264,
        20198,
        300,
        436,
        434,
        1382,
        281,
        829,
        2108,
        411,
        437,
        1943,
        380,
        300,
        436,
        434,
        1382,
        281,
        5039,
        567,
        307,
        309,
        337,
        307,
        309,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15962486040024532,
      "compression_ratio": 1.6847290640394088,
      "no_speech_prob": 0.005001924466341734
    },
    {
      "id": 140,
      "seek": 80812,
      "start": 826.12,
      "end": 828.12,
      "text": " Just for that one person.",
      "tokens": [
        51264,
        1449,
        337,
        300,
        472,
        954,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15962486040024532,
      "compression_ratio": 1.6847290640394088,
      "no_speech_prob": 0.005001924466341734
    },
    {
      "id": 141,
      "seek": 82812,
      "start": 828.12,
      "end": 840.12,
      "text": " Even it feels very heavy to do that at that particular time in pipeline execution that has like really helped us.",
      "tokens": [
        50364,
        2754,
        309,
        3417,
        588,
        4676,
        281,
        360,
        300,
        412,
        300,
        1729,
        565,
        294,
        15517,
        15058,
        300,
        575,
        411,
        534,
        4254,
        505,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16885364919468976,
      "compression_ratio": 1.4867724867724867,
      "no_speech_prob": 0.025705961510539055
    },
    {
      "id": 142,
      "seek": 82812,
      "start": 840.12,
      "end": 848.12,
      "text": " I just had a comment that I don't currently use templates. I totally get what you're saying though, Vietika, I guess I don't know if it's required to use the template.",
      "tokens": [
        50964,
        286,
        445,
        632,
        257,
        2871,
        300,
        286,
        500,
        380,
        4362,
        764,
        21165,
        13,
        286,
        3879,
        483,
        437,
        291,
        434,
        1566,
        1673,
        11,
        691,
        1684,
        5439,
        11,
        286,
        2041,
        286,
        500,
        380,
        458,
        498,
        309,
        311,
        4739,
        281,
        764,
        264,
        12379,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16885364919468976,
      "compression_ratio": 1.4867724867724867,
      "no_speech_prob": 0.025705961510539055
    },
    {
      "id": 143,
      "seek": 84812,
      "start": 848.12,
      "end": 859.12,
      "text": " Maybe for me the reason why I don't is sometimes we'll just have like a small bug or something that needs to be addressed and I never want to be a barrier to document that in an issue.",
      "tokens": [
        50364,
        2704,
        337,
        385,
        264,
        1778,
        983,
        286,
        500,
        380,
        307,
        2171,
        321,
        603,
        445,
        362,
        411,
        257,
        1359,
        7426,
        420,
        746,
        300,
        2203,
        281,
        312,
        13847,
        293,
        286,
        1128,
        528,
        281,
        312,
        257,
        13357,
        281,
        4166,
        300,
        294,
        364,
        2734,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10862250180588555,
      "compression_ratio": 1.6208333333333333,
      "no_speech_prob": 0.1155223473906517
    },
    {
      "id": 144,
      "seek": 84812,
      "start": 859.12,
      "end": 861.12,
      "text": " And it can always be refined later.",
      "tokens": [
        50914,
        400,
        309,
        393,
        1009,
        312,
        26201,
        1780,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10862250180588555,
      "compression_ratio": 1.6208333333333333,
      "no_speech_prob": 0.1155223473906517
    },
    {
      "id": 145,
      "seek": 84812,
      "start": 861.12,
      "end": 872.12,
      "text": " But maybe I'm a bit lucky that when my team is creating issues, they usually have a strong why and like a, you know, like maybe I'm just a bit fortunate in that regard.",
      "tokens": [
        51014,
        583,
        1310,
        286,
        478,
        257,
        857,
        6356,
        300,
        562,
        452,
        1469,
        307,
        4084,
        2663,
        11,
        436,
        2673,
        362,
        257,
        2068,
        983,
        293,
        411,
        257,
        11,
        291,
        458,
        11,
        411,
        1310,
        286,
        478,
        445,
        257,
        857,
        14096,
        294,
        300,
        3843,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10862250180588555,
      "compression_ratio": 1.6208333333333333,
      "no_speech_prob": 0.1155223473906517
    },
    {
      "id": 146,
      "seek": 87212,
      "start": 872.12,
      "end": 882.12,
      "text": " In terms of expediting, I set up a keyboard shortcut in system preferences that will apply the kind of like 10 most common labels that I use.",
      "tokens": [
        50364,
        682,
        2115,
        295,
        19348,
        1748,
        11,
        286,
        992,
        493,
        257,
        10186,
        24822,
        294,
        1185,
        21910,
        300,
        486,
        3079,
        264,
        733,
        295,
        411,
        1266,
        881,
        2689,
        16949,
        300,
        286,
        764,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11105707790074723,
      "compression_ratio": 1.6009174311926606,
      "no_speech_prob": 0.023341163992881775
    },
    {
      "id": 147,
      "seek": 87212,
      "start": 882.12,
      "end": 892.12,
      "text": " So then I just literally just have two keystrokes and then I have like the labels and then I can just edit them from there that has helped a bit.",
      "tokens": [
        50864,
        407,
        550,
        286,
        445,
        3736,
        445,
        362,
        732,
        2141,
        27616,
        5993,
        293,
        550,
        286,
        362,
        411,
        264,
        16949,
        293,
        550,
        286,
        393,
        445,
        8129,
        552,
        490,
        456,
        300,
        575,
        4254,
        257,
        857,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11105707790074723,
      "compression_ratio": 1.6009174311926606,
      "no_speech_prob": 0.023341163992881775
    },
    {
      "id": 148,
      "seek": 87212,
      "start": 892.12,
      "end": 894.12,
      "text": " That's really cool.",
      "tokens": [
        51364,
        663,
        311,
        534,
        1627,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11105707790074723,
      "compression_ratio": 1.6009174311926606,
      "no_speech_prob": 0.023341163992881775
    },
    {
      "id": 149,
      "seek": 87212,
      "start": 894.12,
      "end": 896.12,
      "text": " I didn't even know that that was a thing.",
      "tokens": [
        51464,
        286,
        994,
        380,
        754,
        458,
        300,
        300,
        390,
        257,
        551,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11105707790074723,
      "compression_ratio": 1.6009174311926606,
      "no_speech_prob": 0.023341163992881775
    },
    {
      "id": 150,
      "seek": 89612,
      "start": 896.12,
      "end": 902.12,
      "text": " I like a like a one minute video of how to do it and I'll post it on our channel or on UX or something.",
      "tokens": [
        50364,
        286,
        411,
        257,
        411,
        257,
        472,
        3456,
        960,
        295,
        577,
        281,
        360,
        309,
        293,
        286,
        603,
        2183,
        309,
        322,
        527,
        2269,
        420,
        322,
        40176,
        420,
        746,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19302217583907277,
      "compression_ratio": 1.685823754789272,
      "no_speech_prob": 0.05873602628707886
    },
    {
      "id": 151,
      "seek": 89612,
      "start": 902.12,
      "end": 904.12,
      "text": " Yeah, that'd be great.",
      "tokens": [
        50664,
        865,
        11,
        300,
        1116,
        312,
        869,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19302217583907277,
      "compression_ratio": 1.685823754789272,
      "no_speech_prob": 0.05873602628707886
    },
    {
      "id": 152,
      "seek": 89612,
      "start": 904.12,
      "end": 923.12,
      "text": " Yeah, that would be awesome, because I remember when I had my coworking session with Vietika, I was asking about like, how do you copy and paste labels or is there a more efficient way to add lab, the same labels to issues like creating UX themes, all of them head the same labels, but I had to manually add them.",
      "tokens": [
        50764,
        865,
        11,
        300,
        576,
        312,
        3476,
        11,
        570,
        286,
        1604,
        562,
        286,
        632,
        452,
        31998,
        278,
        5481,
        365,
        691,
        1684,
        5439,
        11,
        286,
        390,
        3365,
        466,
        411,
        11,
        577,
        360,
        291,
        5055,
        293,
        9163,
        16949,
        420,
        307,
        456,
        257,
        544,
        7148,
        636,
        281,
        909,
        2715,
        11,
        264,
        912,
        16949,
        281,
        2663,
        411,
        4084,
        40176,
        13544,
        11,
        439,
        295,
        552,
        1378,
        264,
        912,
        16949,
        11,
        457,
        286,
        632,
        281,
        16945,
        909,
        552,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19302217583907277,
      "compression_ratio": 1.685823754789272,
      "no_speech_prob": 0.05873602628707886
    },
    {
      "id": 153,
      "seek": 92312,
      "start": 923.12,
      "end": 926.12,
      "text": " So if there's any way to speed up that process.",
      "tokens": [
        50364,
        407,
        498,
        456,
        311,
        604,
        636,
        281,
        3073,
        493,
        300,
        1399,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16985691677440296,
      "compression_ratio": 1.4803921568627452,
      "no_speech_prob": 0.0014834123430773616
    },
    {
      "id": 154,
      "seek": 92312,
      "start": 926.12,
      "end": 934.12,
      "text": " I use a very manual method so I keep like the shortcuts to create those labels that I have to based on the issues.",
      "tokens": [
        50514,
        286,
        764,
        257,
        588,
        9688,
        3170,
        370,
        286,
        1066,
        411,
        264,
        34620,
        281,
        1884,
        729,
        16949,
        300,
        286,
        362,
        281,
        2361,
        322,
        264,
        2663,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16985691677440296,
      "compression_ratio": 1.4803921568627452,
      "no_speech_prob": 0.0014834123430773616
    },
    {
      "id": 155,
      "seek": 92312,
      "start": 934.12,
      "end": 941.12,
      "text": " Handy on my notepad so I just copy based.",
      "tokens": [
        50914,
        47006,
        322,
        452,
        406,
        595,
        345,
        370,
        286,
        445,
        5055,
        2361,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16985691677440296,
      "compression_ratio": 1.4803921568627452,
      "no_speech_prob": 0.0014834123430773616
    },
    {
      "id": 156,
      "seek": 92312,
      "start": 941.12,
      "end": 943.12,
      "text": " Very cool.",
      "tokens": [
        51264,
        4372,
        1627,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16985691677440296,
      "compression_ratio": 1.4803921568627452,
      "no_speech_prob": 0.0014834123430773616
    },
    {
      "id": 157,
      "seek": 92312,
      "start": 943.12,
      "end": 944.12,
      "text": " Okay.",
      "tokens": [
        51364,
        1033,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16985691677440296,
      "compression_ratio": 1.4803921568627452,
      "no_speech_prob": 0.0014834123430773616
    },
    {
      "id": 158,
      "seek": 92312,
      "start": 944.12,
      "end": 948.12,
      "text": " Thank you for all the conversation.",
      "tokens": [
        51414,
        1044,
        291,
        337,
        439,
        264,
        3761,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16985691677440296,
      "compression_ratio": 1.4803921568627452,
      "no_speech_prob": 0.0014834123430773616
    },
    {
      "id": 159,
      "seek": 92312,
      "start": 948.12,
      "end": 951.12,
      "text": " Emily, do you want to go through your items?",
      "tokens": [
        51614,
        15034,
        11,
        360,
        291,
        528,
        281,
        352,
        807,
        428,
        4754,
        30,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16985691677440296,
      "compression_ratio": 1.4803921568627452,
      "no_speech_prob": 0.0014834123430773616
    },
    {
      "id": 160,
      "seek": 95112,
      "start": 951.12,
      "end": 957.12,
      "text": " So my first item is release held office hours last week, which was actually a huge success.",
      "tokens": [
        50364,
        407,
        452,
        700,
        3174,
        307,
        4374,
        5167,
        3398,
        2496,
        1036,
        1243,
        11,
        597,
        390,
        767,
        257,
        2603,
        2245,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12390397576724782,
      "compression_ratio": 1.5606060606060606,
      "no_speech_prob": 0.0007503217202611268
    },
    {
      "id": 161,
      "seek": 95112,
      "start": 957.12,
      "end": 962.12,
      "text": " It was a surprising how many people we got to attend with the first one.",
      "tokens": [
        50664,
        467,
        390,
        257,
        8830,
        577,
        867,
        561,
        321,
        658,
        281,
        6888,
        365,
        264,
        700,
        472,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12390397576724782,
      "compression_ratio": 1.5606060606060606,
      "no_speech_prob": 0.0007503217202611268
    },
    {
      "id": 162,
      "seek": 95112,
      "start": 962.12,
      "end": 971.12,
      "text": " And during this office hours, we really walked through like how community contributors can contribute like open the floor to ask them questions.",
      "tokens": [
        50914,
        400,
        1830,
        341,
        3398,
        2496,
        11,
        321,
        534,
        7628,
        807,
        411,
        577,
        1768,
        45627,
        393,
        10586,
        411,
        1269,
        264,
        4123,
        281,
        1029,
        552,
        1651,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12390397576724782,
      "compression_ratio": 1.5606060606060606,
      "no_speech_prob": 0.0007503217202611268
    },
    {
      "id": 163,
      "seek": 97112,
      "start": 971.12,
      "end": 986.12,
      "text": " And then we went through how to find issues that are available to take on and take syndrux on how to get help on MR's like how to take us in those so it was like a very helpful thing to do.",
      "tokens": [
        50364,
        400,
        550,
        321,
        1437,
        807,
        577,
        281,
        915,
        2663,
        300,
        366,
        2435,
        281,
        747,
        322,
        293,
        747,
        15198,
        894,
        87,
        322,
        577,
        281,
        483,
        854,
        322,
        9808,
        311,
        411,
        577,
        281,
        747,
        505,
        294,
        729,
        370,
        309,
        390,
        411,
        257,
        588,
        4961,
        551,
        281,
        360,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3463808536529541,
      "compression_ratio": 1.559090909090909,
      "no_speech_prob": 0.354656457901001
    },
    {
      "id": 164,
      "seek": 97112,
      "start": 986.12,
      "end": 995.12,
      "text": " And we're planning to hold another one in September around UX front end, which hopefully will increase the amount of like community contributions we get.",
      "tokens": [
        51114,
        400,
        321,
        434,
        5038,
        281,
        1797,
        1071,
        472,
        294,
        7216,
        926,
        40176,
        1868,
        917,
        11,
        597,
        4696,
        486,
        3488,
        264,
        2372,
        295,
        411,
        1768,
        15725,
        321,
        483,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3463808536529541,
      "compression_ratio": 1.559090909090909,
      "no_speech_prob": 0.354656457901001
    },
    {
      "id": 165,
      "seek": 99512,
      "start": 995.12,
      "end": 1000.12,
      "text": " So I know that's a big thing right now.",
      "tokens": [
        50364,
        407,
        286,
        458,
        300,
        311,
        257,
        955,
        551,
        558,
        586,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2208781488162955,
      "compression_ratio": 1.6375,
      "no_speech_prob": 0.06414525955915451
    },
    {
      "id": 166,
      "seek": 99512,
      "start": 1000.12,
      "end": 1007.12,
      "text": " That's the exact thing I pointed out to my product manager, I guess in the meeting that actually has had an office hour.",
      "tokens": [
        50614,
        663,
        311,
        264,
        1900,
        551,
        286,
        10932,
        484,
        281,
        452,
        1674,
        6598,
        11,
        286,
        2041,
        294,
        264,
        3440,
        300,
        767,
        575,
        632,
        364,
        3398,
        1773,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2208781488162955,
      "compression_ratio": 1.6375,
      "no_speech_prob": 0.06414525955915451
    },
    {
      "id": 167,
      "seek": 99512,
      "start": 1007.12,
      "end": 1013.12,
      "text": " I looked at the agenda that like really highlighted the opportunity for contribution so well.",
      "tokens": [
        50964,
        286,
        2956,
        412,
        264,
        9829,
        300,
        411,
        534,
        17173,
        264,
        2650,
        337,
        13150,
        370,
        731,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2208781488162955,
      "compression_ratio": 1.6375,
      "no_speech_prob": 0.06414525955915451
    },
    {
      "id": 168,
      "seek": 99512,
      "start": 1013.12,
      "end": 1024.12,
      "text": " And like I'm not sure if we have to bandwidth to do this at this moment, but yeah, I'm really happy to like learn from like how that went.",
      "tokens": [
        51264,
        400,
        411,
        286,
        478,
        406,
        988,
        498,
        321,
        362,
        281,
        23647,
        281,
        360,
        341,
        412,
        341,
        1623,
        11,
        457,
        1338,
        11,
        286,
        478,
        534,
        2055,
        281,
        411,
        1466,
        490,
        411,
        577,
        300,
        1437,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2208781488162955,
      "compression_ratio": 1.6375,
      "no_speech_prob": 0.06414525955915451
    },
    {
      "id": 169,
      "seek": 102412,
      "start": 1024.12,
      "end": 1046.12,
      "text": " Yeah, I noticed some of the like main questions we had were just how to get feedback. So people who wanted to contribute or curious about like when they should like create the MR can they do it when they're still working on something if it's still a draft and how to take people to get feedback on things.",
      "tokens": [
        50364,
        865,
        11,
        286,
        5694,
        512,
        295,
        264,
        411,
        2135,
        1651,
        321,
        632,
        645,
        445,
        577,
        281,
        483,
        5824,
        13,
        407,
        561,
        567,
        1415,
        281,
        10586,
        420,
        6369,
        466,
        411,
        562,
        436,
        820,
        411,
        1884,
        264,
        9808,
        393,
        436,
        360,
        309,
        562,
        436,
        434,
        920,
        1364,
        322,
        746,
        498,
        309,
        311,
        920,
        257,
        11206,
        293,
        577,
        281,
        747,
        561,
        281,
        483,
        5824,
        322,
        721,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10145106736351461,
      "compression_ratio": 1.5803108808290156,
      "no_speech_prob": 0.0027927474584430456
    },
    {
      "id": 170,
      "seek": 104612,
      "start": 1046.12,
      "end": 1054.12,
      "text": " Tips on how to find issues in like the languages they're comfortable working on and all of that.",
      "tokens": [
        50364,
        36887,
        322,
        577,
        281,
        915,
        2663,
        294,
        411,
        264,
        8650,
        436,
        434,
        4619,
        1364,
        322,
        293,
        439,
        295,
        300,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15466519850718824,
      "compression_ratio": 1.6214953271028036,
      "no_speech_prob": 0.06302241235971451
    },
    {
      "id": 171,
      "seek": 104612,
      "start": 1054.12,
      "end": 1071.12,
      "text": " We also had some questions too that were a little topic of how to look for open jobs at get lab. So I think just feel where that some people might be coming in because they are also interested in working at get lab and having answers to that as well.",
      "tokens": [
        50764,
        492,
        611,
        632,
        512,
        1651,
        886,
        300,
        645,
        257,
        707,
        4829,
        295,
        577,
        281,
        574,
        337,
        1269,
        4782,
        412,
        483,
        2715,
        13,
        407,
        286,
        519,
        445,
        841,
        689,
        300,
        512,
        561,
        1062,
        312,
        1348,
        294,
        570,
        436,
        366,
        611,
        3102,
        294,
        1364,
        412,
        483,
        2715,
        293,
        1419,
        6338,
        281,
        300,
        382,
        731,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15466519850718824,
      "compression_ratio": 1.6214953271028036,
      "no_speech_prob": 0.06302241235971451
    },
    {
      "id": 172,
      "seek": 107112,
      "start": 1071.12,
      "end": 1073.12,
      "text": " Yeah, that's true.",
      "tokens": [
        50364,
        865,
        11,
        300,
        311,
        2074,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098440836711102,
      "compression_ratio": 1.5276381909547738,
      "no_speech_prob": 0.036422133445739746
    },
    {
      "id": 173,
      "seek": 107112,
      "start": 1073.12,
      "end": 1076.12,
      "text": " I just, I'm sorry.",
      "tokens": [
        50464,
        286,
        445,
        11,
        286,
        478,
        2597,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098440836711102,
      "compression_ratio": 1.5276381909547738,
      "no_speech_prob": 0.036422133445739746
    },
    {
      "id": 174,
      "seek": 107112,
      "start": 1076.12,
      "end": 1083.12,
      "text": " Oh, and I'm just saying like a closing statement like I hope more teams are able to do something.",
      "tokens": [
        50614,
        876,
        11,
        293,
        286,
        478,
        445,
        1566,
        411,
        257,
        10377,
        5629,
        411,
        286,
        1454,
        544,
        5491,
        366,
        1075,
        281,
        360,
        746,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098440836711102,
      "compression_ratio": 1.5276381909547738,
      "no_speech_prob": 0.036422133445739746
    },
    {
      "id": 175,
      "seek": 107112,
      "start": 1083.12,
      "end": 1094.12,
      "text": " I put the question what are office hours in this context, but I'm I'm gathering that you you had kind of an open conversation with users of get lab is that what if was.",
      "tokens": [
        50964,
        286,
        829,
        264,
        1168,
        437,
        366,
        3398,
        2496,
        294,
        341,
        4319,
        11,
        457,
        286,
        478,
        286,
        478,
        13519,
        300,
        291,
        291,
        632,
        733,
        295,
        364,
        1269,
        3761,
        365,
        5022,
        295,
        483,
        2715,
        307,
        300,
        437,
        498,
        390,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2098440836711102,
      "compression_ratio": 1.5276381909547738,
      "no_speech_prob": 0.036422133445739746
    },
    {
      "id": 176,
      "seek": 109412,
      "start": 1094.12,
      "end": 1105.12,
      "text": " So what we did was we created a I think is on meetup.com just like a release office hours added in an agenda and then the release team kind of.",
      "tokens": [
        50364,
        407,
        437,
        321,
        630,
        390,
        321,
        2942,
        257,
        286,
        519,
        307,
        322,
        1677,
        1010,
        13,
        1112,
        445,
        411,
        257,
        4374,
        3398,
        2496,
        3869,
        294,
        364,
        9829,
        293,
        550,
        264,
        4374,
        1469,
        733,
        295,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13533907351286514,
      "compression_ratio": 1.6926229508196722,
      "no_speech_prob": 0.013035525567829609
    },
    {
      "id": 177,
      "seek": 109412,
      "start": 1105.12,
      "end": 1120.12,
      "text": " Advertised done LinkedIn, we kind of went to our older community contributors and told them that they could come to this so we like advertised it out a little bit to just the broader community who would be interested in seeing how release worked to come with questions.",
      "tokens": [
        50914,
        1999,
        3281,
        2640,
        1096,
        20657,
        11,
        321,
        733,
        295,
        1437,
        281,
        527,
        4906,
        1768,
        45627,
        293,
        1907,
        552,
        300,
        436,
        727,
        808,
        281,
        341,
        370,
        321,
        411,
        42310,
        309,
        484,
        257,
        707,
        857,
        281,
        445,
        264,
        13227,
        1768,
        567,
        576,
        312,
        3102,
        294,
        2577,
        577,
        4374,
        2732,
        281,
        808,
        365,
        1651,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13533907351286514,
      "compression_ratio": 1.6926229508196722,
      "no_speech_prob": 0.013035525567829609
    },
    {
      "id": 178,
      "seek": 112012,
      "start": 1120.12,
      "end": 1137.12,
      "text": " And yeah, it's like open to absolutely anyone who is interested. The only thing we did learn is that it's important to have this through like meetup or another site and not just have an open zoom link because apparently zoom bombing is like a big thing if you just randomly put a zoom link out there.",
      "tokens": [
        50364,
        400,
        1338,
        11,
        309,
        311,
        411,
        1269,
        281,
        3122,
        2878,
        567,
        307,
        3102,
        13,
        440,
        787,
        551,
        321,
        630,
        1466,
        307,
        300,
        309,
        311,
        1021,
        281,
        362,
        341,
        807,
        411,
        1677,
        1010,
        420,
        1071,
        3621,
        293,
        406,
        445,
        362,
        364,
        1269,
        8863,
        2113,
        570,
        7970,
        8863,
        31292,
        307,
        411,
        257,
        955,
        551,
        498,
        291,
        445,
        16979,
        829,
        257,
        8863,
        2113,
        484,
        456,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12691252186613264,
      "compression_ratio": 1.7215686274509805,
      "no_speech_prob": 0.005668674595654011
    },
    {
      "id": 179,
      "seek": 112012,
      "start": 1137.12,
      "end": 1143.12,
      "text": " So having kind of like stricter access into the meeting was important.",
      "tokens": [
        51214,
        407,
        1419,
        733,
        295,
        411,
        1056,
        299,
        391,
        2105,
        666,
        264,
        3440,
        390,
        1021,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12691252186613264,
      "compression_ratio": 1.7215686274509805,
      "no_speech_prob": 0.005668674595654011
    },
    {
      "id": 180,
      "seek": 112012,
      "start": 1143.12,
      "end": 1145.12,
      "text": " That's also that such a good idea.",
      "tokens": [
        51514,
        663,
        311,
        611,
        300,
        1270,
        257,
        665,
        1558,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12691252186613264,
      "compression_ratio": 1.7215686274509805,
      "no_speech_prob": 0.005668674595654011
    },
    {
      "id": 181,
      "seek": 112012,
      "start": 1145.12,
      "end": 1147.12,
      "text": " I'll have a closer look into it.",
      "tokens": [
        51614,
        286,
        603,
        362,
        257,
        4966,
        574,
        666,
        309,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12691252186613264,
      "compression_ratio": 1.7215686274509805,
      "no_speech_prob": 0.005668674595654011
    },
    {
      "id": 182,
      "seek": 114712,
      "start": 1147.12,
      "end": 1153.12,
      "text": " So it's good.",
      "tokens": [
        50364,
        407,
        309,
        311,
        665,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25707030782894214,
      "compression_ratio": 1.5070422535211268,
      "no_speech_prob": 0.002708922140300274
    },
    {
      "id": 183,
      "seek": 114712,
      "start": 1153.12,
      "end": 1167.12,
      "text": " Well, and then the only other thing is on release for planning and onboarded onboarding focused improvement to our empty state pages because we realized kind of across the board the empty state pages.",
      "tokens": [
        50664,
        1042,
        11,
        293,
        550,
        264,
        787,
        661,
        551,
        307,
        322,
        4374,
        337,
        5038,
        293,
        24033,
        292,
        24033,
        278,
        5178,
        10444,
        281,
        527,
        6707,
        1785,
        7183,
        570,
        321,
        5334,
        733,
        295,
        2108,
        264,
        3150,
        264,
        6707,
        1785,
        7183,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25707030782894214,
      "compression_ratio": 1.5070422535211268,
      "no_speech_prob": 0.002708922140300274
    },
    {
      "id": 184,
      "seek": 116712,
      "start": 1167.12,
      "end": 1176.12,
      "text": " And that's not very like they're all slightly different design wise. They could have more helpful like CTAs for people just landing on them.",
      "tokens": [
        50364,
        400,
        300,
        311,
        406,
        588,
        411,
        436,
        434,
        439,
        4748,
        819,
        1715,
        10829,
        13,
        814,
        727,
        362,
        544,
        4961,
        411,
        383,
        8241,
        82,
        337,
        561,
        445,
        11202,
        322,
        552,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23845624923706055,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.09092571586370468
    },
    {
      "id": 185,
      "seek": 116712,
      "start": 1176.12,
      "end": 1189.12,
      "text": " So this is like an idea we're doing, but just wanted to share it out because I think it's helpful like across all stage groups and get lab.",
      "tokens": [
        50814,
        407,
        341,
        307,
        411,
        364,
        1558,
        321,
        434,
        884,
        11,
        457,
        445,
        1415,
        281,
        2073,
        309,
        484,
        570,
        286,
        519,
        309,
        311,
        4961,
        411,
        2108,
        439,
        3233,
        3935,
        293,
        483,
        2715,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23845624923706055,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.09092571586370468
    },
    {
      "id": 186,
      "seek": 116712,
      "start": 1189.12,
      "end": 1195.12,
      "text": " And that's it unless there's any questions.",
      "tokens": [
        51464,
        400,
        300,
        311,
        309,
        5969,
        456,
        311,
        604,
        1651,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23845624923706055,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.09092571586370468
    },
    {
      "id": 187,
      "seek": 119512,
      "start": 1195.12,
      "end": 1205.12,
      "text": " I have a quick suggestion for the empty states. Just like a quick thought that they have I don't know if there's there's probably reasons why you did it this way, but.",
      "tokens": [
        50364,
        286,
        362,
        257,
        1702,
        16541,
        337,
        264,
        6707,
        4368,
        13,
        1449,
        411,
        257,
        1702,
        1194,
        300,
        436,
        362,
        286,
        500,
        380,
        458,
        498,
        456,
        311,
        456,
        311,
        1391,
        4112,
        983,
        291,
        630,
        309,
        341,
        636,
        11,
        457,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16437755584716796,
      "compression_ratio": 1.6195121951219513,
      "no_speech_prob": 0.0037412114907056093
    },
    {
      "id": 188,
      "seek": 119512,
      "start": 1205.12,
      "end": 1220.12,
      "text": " It would be interesting to see the buttons placed underneath the empty state UI copy and illustrations. I think this is how we usually deal with those empty states.",
      "tokens": [
        50864,
        467,
        576,
        312,
        1880,
        281,
        536,
        264,
        9905,
        7074,
        7223,
        264,
        6707,
        1785,
        15682,
        5055,
        293,
        34540,
        13,
        286,
        519,
        341,
        307,
        577,
        321,
        2673,
        2028,
        365,
        729,
        6707,
        4368,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16437755584716796,
      "compression_ratio": 1.6195121951219513,
      "no_speech_prob": 0.0037412114907056093
    },
    {
      "id": 189,
      "seek": 122012,
      "start": 1220.12,
      "end": 1227.12,
      "text": " But I guess there's going to be like a table here or like a list of items and then the buttons will be at the top.",
      "tokens": [
        50364,
        583,
        286,
        2041,
        456,
        311,
        516,
        281,
        312,
        411,
        257,
        3199,
        510,
        420,
        411,
        257,
        1329,
        295,
        4754,
        293,
        550,
        264,
        9905,
        486,
        312,
        412,
        264,
        1192,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08463426949321359,
      "compression_ratio": 1.6923076923076923,
      "no_speech_prob": 0.014436507597565651
    },
    {
      "id": 190,
      "seek": 122012,
      "start": 1227.12,
      "end": 1240.12,
      "text": " But I think usually what we do is we have the action buttons inside the empty state and then once there are items to show them the buttons are placed above the items list.",
      "tokens": [
        50714,
        583,
        286,
        519,
        2673,
        437,
        321,
        360,
        307,
        321,
        362,
        264,
        3069,
        9905,
        1854,
        264,
        6707,
        1785,
        293,
        550,
        1564,
        456,
        366,
        4754,
        281,
        855,
        552,
        264,
        9905,
        366,
        7074,
        3673,
        264,
        4754,
        1329,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08463426949321359,
      "compression_ratio": 1.6923076923076923,
      "no_speech_prob": 0.014436507597565651
    },
    {
      "id": 191,
      "seek": 124012,
      "start": 1240.12,
      "end": 1249.12,
      "text": " Yeah, I think right now all three of the empty states and deployments are look different. So I think this is kind of like getting that CTA.",
      "tokens": [
        50364,
        865,
        11,
        286,
        519,
        558,
        586,
        439,
        1045,
        295,
        264,
        6707,
        4368,
        293,
        7274,
        1117,
        366,
        574,
        819,
        13,
        407,
        286,
        519,
        341,
        307,
        733,
        295,
        411,
        1242,
        300,
        383,
        8241,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2013976357199929,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.056671276688575745
    },
    {
      "id": 192,
      "seek": 124012,
      "start": 1249.12,
      "end": 1260.12,
      "text": " The CTA is to be consistent across the three of them getting like a good CTA, finising some of like the copies. So I think there's some really simple things we can do to fix it up. But yeah, the main.",
      "tokens": [
        50814,
        440,
        383,
        8241,
        307,
        281,
        312,
        8398,
        2108,
        264,
        1045,
        295,
        552,
        1242,
        411,
        257,
        665,
        383,
        8241,
        11,
        962,
        3436,
        512,
        295,
        411,
        264,
        14341,
        13,
        407,
        286,
        519,
        456,
        311,
        512,
        534,
        2199,
        721,
        321,
        393,
        360,
        281,
        3191,
        309,
        493,
        13,
        583,
        1338,
        11,
        264,
        2135,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2013976357199929,
      "compression_ratio": 1.619047619047619,
      "no_speech_prob": 0.056671276688575745
    },
    {
      "id": 193,
      "seek": 126012,
      "start": 1260.12,
      "end": 1262.12,
      "text": " Yeah, sure.",
      "tokens": [
        50364,
        865,
        11,
        988,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16100749373435974,
      "compression_ratio": 1.4591194968553458,
      "no_speech_prob": 0.012817278504371643
    },
    {
      "id": 194,
      "seek": 126012,
      "start": 1262.12,
      "end": 1284.12,
      "text": " The main thing is yeah, like you said, I think the CTA on the release page is up in the top right corner, which is kind of missing. So I think just getting the CTA is in the empty state would be an interesting one to do.",
      "tokens": [
        50464,
        440,
        2135,
        551,
        307,
        1338,
        11,
        411,
        291,
        848,
        11,
        286,
        519,
        264,
        383,
        8241,
        322,
        264,
        4374,
        3028,
        307,
        493,
        294,
        264,
        1192,
        558,
        4538,
        11,
        597,
        307,
        733,
        295,
        5361,
        13,
        407,
        286,
        519,
        445,
        1242,
        264,
        383,
        8241,
        307,
        294,
        264,
        6707,
        1785,
        576,
        312,
        364,
        1880,
        472,
        281,
        360,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16100749373435974,
      "compression_ratio": 1.4591194968553458,
      "no_speech_prob": 0.012817278504371643
    },
    {
      "id": 195,
      "seek": 128412,
      "start": 1284.12,
      "end": 1290.12,
      "text": " If that's it, I can pass over to the two.",
      "tokens": [
        50364,
        759,
        300,
        311,
        309,
        11,
        286,
        393,
        1320,
        670,
        281,
        264,
        732,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27397984724778396,
      "compression_ratio": 1.375,
      "no_speech_prob": 0.06599491834640503
    },
    {
      "id": 196,
      "seek": 128412,
      "start": 1290.12,
      "end": 1302.12,
      "text": " Okay, yeah, so I wanted to update about the insights that have known through a very recent validation exercise that I am it was unmodulated on user testing.",
      "tokens": [
        50664,
        1033,
        11,
        1338,
        11,
        370,
        286,
        1415,
        281,
        5623,
        466,
        264,
        14310,
        300,
        362,
        2570,
        807,
        257,
        588,
        5162,
        24071,
        5380,
        300,
        286,
        669,
        309,
        390,
        517,
        8014,
        6987,
        322,
        4195,
        4997,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27397984724778396,
      "compression_ratio": 1.375,
      "no_speech_prob": 0.06599491834640503
    },
    {
      "id": 197,
      "seek": 130212,
      "start": 1302.12,
      "end": 1313.12,
      "text": " It kind of gave some good like even to how users are using their user namespace today and what kind of projects they host under there.",
      "tokens": [
        50364,
        467,
        733,
        295,
        2729,
        512,
        665,
        411,
        754,
        281,
        577,
        5022,
        366,
        1228,
        641,
        4195,
        5288,
        17940,
        965,
        293,
        437,
        733,
        295,
        4455,
        436,
        3975,
        833,
        456,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15590920448303222,
      "compression_ratio": 1.7798165137614679,
      "no_speech_prob": 0.20397335290908813
    },
    {
      "id": 198,
      "seek": 130212,
      "start": 1313.12,
      "end": 1331.12,
      "text": " How many projects they host so it turns out that users usually put just like small personal projects directly under their namespace and those are not the kind that are very engagement heavy like it's something that they only interact with by themselves.",
      "tokens": [
        50914,
        1012,
        867,
        4455,
        436,
        3975,
        370,
        309,
        4523,
        484,
        300,
        5022,
        2673,
        829,
        445,
        411,
        1359,
        2973,
        4455,
        3838,
        833,
        641,
        5288,
        17940,
        293,
        729,
        366,
        406,
        264,
        733,
        300,
        366,
        588,
        8742,
        4676,
        411,
        309,
        311,
        746,
        300,
        436,
        787,
        4648,
        365,
        538,
        2969,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15590920448303222,
      "compression_ratio": 1.7798165137614679,
      "no_speech_prob": 0.20397335290908813
    },
    {
      "id": 199,
      "seek": 133112,
      "start": 1331.12,
      "end": 1344.12,
      "text": " And that's the reason like they also don't have much concerns around what's the CI CD minutes consumption because they might not even be a pilot for this project.",
      "tokens": [
        50364,
        400,
        300,
        311,
        264,
        1778,
        411,
        436,
        611,
        500,
        380,
        362,
        709,
        7389,
        926,
        437,
        311,
        264,
        37777,
        6743,
        2077,
        12126,
        570,
        436,
        1062,
        406,
        754,
        312,
        257,
        9691,
        337,
        341,
        1716,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2268948134254007,
      "compression_ratio": 1.6578947368421053,
      "no_speech_prob": 0.008159009739756584
    },
    {
      "id": 200,
      "seek": 133112,
      "start": 1344.12,
      "end": 1353.12,
      "text": " And there is no contribution to get concerns for sure for these projects and that applies that there's little or no need to control the mid consumption.",
      "tokens": [
        51014,
        400,
        456,
        307,
        572,
        13150,
        281,
        483,
        7389,
        337,
        988,
        337,
        613,
        4455,
        293,
        300,
        13165,
        300,
        456,
        311,
        707,
        420,
        572,
        643,
        281,
        1969,
        264,
        2062,
        12126,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2268948134254007,
      "compression_ratio": 1.6578947368421053,
      "no_speech_prob": 0.008159009739756584
    },
    {
      "id": 201,
      "seek": 135312,
      "start": 1353.12,
      "end": 1382.12,
      "text": " And user namespace related settings, I mean, we did provide them with certain tasks in the test, but it was really difficult for them to go to those setting options, which are existing today, it was not even something that I had added on the top because something that had been there since long, for example, we are still able to see the usage code for the projects which are directly under your name space through the user settings usage code of page.",
      "tokens": [
        50364,
        400,
        4195,
        5288,
        17940,
        4077,
        6257,
        11,
        286,
        914,
        11,
        321,
        630,
        2893,
        552,
        365,
        1629,
        9608,
        294,
        264,
        1500,
        11,
        457,
        309,
        390,
        534,
        2252,
        337,
        552,
        281,
        352,
        281,
        729,
        3287,
        3956,
        11,
        597,
        366,
        6741,
        965,
        11,
        309,
        390,
        406,
        754,
        746,
        300,
        286,
        632,
        3869,
        322,
        264,
        1192,
        570,
        746,
        300,
        632,
        668,
        456,
        1670,
        938,
        11,
        337,
        1365,
        11,
        321,
        366,
        920,
        1075,
        281,
        536,
        264,
        14924,
        3089,
        337,
        264,
        4455,
        597,
        366,
        3838,
        833,
        428,
        1315,
        1901,
        807,
        264,
        4195,
        6257,
        14924,
        3089,
        295,
        3028,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23134267330169678,
      "compression_ratio": 1.7451737451737452,
      "no_speech_prob": 0.2497943937778473
    },
    {
      "id": 202,
      "seek": 138212,
      "start": 1382.12,
      "end": 1405.12,
      "text": " But the way we land on the user setting is kind of here because today, if you click on your profile picture and you go to preferences that takes you to users settings preferences and for me that has been my gateway into the settings and that's how like I always land there, I don't know if there's any other way that someone else uses.",
      "tokens": [
        50364,
        583,
        264,
        636,
        321,
        2117,
        322,
        264,
        4195,
        3287,
        307,
        733,
        295,
        510,
        570,
        965,
        11,
        498,
        291,
        2052,
        322,
        428,
        7964,
        3036,
        293,
        291,
        352,
        281,
        21910,
        300,
        2516,
        291,
        281,
        5022,
        6257,
        21910,
        293,
        337,
        385,
        300,
        575,
        668,
        452,
        28532,
        666,
        264,
        6257,
        293,
        300,
        311,
        577,
        411,
        286,
        1009,
        2117,
        456,
        11,
        286,
        500,
        380,
        458,
        498,
        456,
        311,
        604,
        661,
        636,
        300,
        1580,
        1646,
        4960,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14351417541503905,
      "compression_ratio": 1.675,
      "no_speech_prob": 0.0893719419836998
    },
    {
      "id": 203,
      "seek": 140512,
      "start": 1405.12,
      "end": 1418.12,
      "text": " And that gives everybody an idea that maybe it's just something that's used for customizing like how good luck looks for you and like not do anything deeper than that.",
      "tokens": [
        50364,
        400,
        300,
        2709,
        2201,
        364,
        1558,
        300,
        1310,
        309,
        311,
        445,
        746,
        300,
        311,
        1143,
        337,
        2375,
        3319,
        411,
        577,
        665,
        3668,
        1542,
        337,
        291,
        293,
        411,
        406,
        360,
        1340,
        7731,
        813,
        300,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19008753571329237,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.5208353996276855
    },
    {
      "id": 204,
      "seek": 140512,
      "start": 1418.12,
      "end": 1434.12,
      "text": " So some resonated with this thought and the others expected the quota to be controlled through the existing usage quota tab because it was pretty clear for them that this is quota and I'm getting to like.",
      "tokens": [
        51014,
        407,
        512,
        47957,
        365,
        341,
        1194,
        293,
        264,
        2357,
        5176,
        264,
        45171,
        281,
        312,
        10164,
        807,
        264,
        6741,
        14924,
        45171,
        4421,
        570,
        309,
        390,
        1238,
        1850,
        337,
        552,
        300,
        341,
        307,
        45171,
        293,
        286,
        478,
        1242,
        281,
        411,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19008753571329237,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.5208353996276855
    },
    {
      "id": 205,
      "seek": 143412,
      "start": 1434.12,
      "end": 1462.12,
      "text": " Control micro rise it has to be through this, but the interesting part is we never do that like so far we have never done that it only kind of shows you like what a consumption is like, but that page has never historically been used for allowing users to kind of set any configurations as far as I remember it's mostly just to view and like consume information about the consumption.",
      "tokens": [
        50364,
        12912,
        4532,
        6272,
        309,
        575,
        281,
        312,
        807,
        341,
        11,
        457,
        264,
        1880,
        644,
        307,
        321,
        1128,
        360,
        300,
        411,
        370,
        1400,
        321,
        362,
        1128,
        1096,
        300,
        309,
        787,
        733,
        295,
        3110,
        291,
        411,
        437,
        257,
        12126,
        307,
        411,
        11,
        457,
        300,
        3028,
        575,
        1128,
        16180,
        668,
        1143,
        337,
        8293,
        5022,
        281,
        733,
        295,
        992,
        604,
        31493,
        382,
        1400,
        382,
        286,
        1604,
        309,
        311,
        5240,
        445,
        281,
        1910,
        293,
        411,
        14732,
        1589,
        466,
        264,
        12126,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13124247789382934,
      "compression_ratio": 1.7098214285714286,
      "no_speech_prob": 0.013154938817024231
    },
    {
      "id": 206,
      "seek": 146212,
      "start": 1462.12,
      "end": 1467.12,
      "text": " Now apart from that what else.",
      "tokens": [
        50364,
        823,
        4936,
        490,
        300,
        437,
        1646,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2048076267900138,
      "compression_ratio": 1.4303030303030304,
      "no_speech_prob": 0.009234676137566566
    },
    {
      "id": 207,
      "seek": 146212,
      "start": 1467.12,
      "end": 1474.12,
      "text": " Yeah, so this feature as we had already expected.",
      "tokens": [
        50614,
        865,
        11,
        370,
        341,
        4111,
        382,
        321,
        632,
        1217,
        5176,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2048076267900138,
      "compression_ratio": 1.4303030303030304,
      "no_speech_prob": 0.009234676137566566
    },
    {
      "id": 208,
      "seek": 146212,
      "start": 1474.12,
      "end": 1485.12,
      "text": " Is as mentioned that it would be more useful for groups and sub groups now I'll give a little background about like why we had started with user namespace.",
      "tokens": [
        50964,
        1119,
        382,
        2835,
        300,
        309,
        576,
        312,
        544,
        4420,
        337,
        3935,
        293,
        1422,
        3935,
        586,
        286,
        603,
        976,
        257,
        707,
        3678,
        466,
        411,
        983,
        321,
        632,
        1409,
        365,
        4195,
        5288,
        17940,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2048076267900138,
      "compression_ratio": 1.4303030303030304,
      "no_speech_prob": 0.009234676137566566
    },
    {
      "id": 209,
      "seek": 148512,
      "start": 1485.12,
      "end": 1497.12,
      "text": " So this feature is like currently we only allow users to control their minutes consumption minutes is the resource that's required to run the pipelines.",
      "tokens": [
        50364,
        407,
        341,
        4111,
        307,
        411,
        4362,
        321,
        787,
        2089,
        5022,
        281,
        1969,
        641,
        2077,
        12126,
        2077,
        307,
        264,
        7684,
        300,
        311,
        4739,
        281,
        1190,
        264,
        40168,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10720416149461126,
      "compression_ratio": 1.7808219178082192,
      "no_speech_prob": 0.03202589973807335
    },
    {
      "id": 210,
      "seek": 148512,
      "start": 1497.12,
      "end": 1514.12,
      "text": " We only allow them to control this through the admin view and all that is done today is the admins are able to add like a standard cap to the usage so they can define like all the groups can only use 2000 minutes like they cannot exceed.",
      "tokens": [
        50964,
        492,
        787,
        2089,
        552,
        281,
        1969,
        341,
        807,
        264,
        24236,
        1910,
        293,
        439,
        300,
        307,
        1096,
        965,
        307,
        264,
        5910,
        1292,
        366,
        1075,
        281,
        909,
        411,
        257,
        3832,
        1410,
        281,
        264,
        14924,
        370,
        436,
        393,
        6964,
        411,
        439,
        264,
        3935,
        393,
        787,
        764,
        8132,
        2077,
        411,
        436,
        2644,
        14048,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10720416149461126,
      "compression_ratio": 1.7808219178082192,
      "no_speech_prob": 0.03202589973807335
    },
    {
      "id": 211,
      "seek": 151412,
      "start": 1514.12,
      "end": 1542.12,
      "text": " But at a more granular level like when it comes to projects because a group can have a lot many projects it can have some groups and some groups under that and under that many projects so it gets pretty complex now at project level maintainers who are working on this projects they would want some like some sort of control because not all the projects inside a group or a circle has the same amount of input.",
      "tokens": [
        50364,
        583,
        412,
        257,
        544,
        39962,
        1496,
        411,
        562,
        309,
        1487,
        281,
        4455,
        570,
        257,
        1594,
        393,
        362,
        257,
        688,
        867,
        4455,
        309,
        393,
        362,
        512,
        3935,
        293,
        512,
        3935,
        833,
        300,
        293,
        833,
        300,
        867,
        4455,
        370,
        309,
        2170,
        1238,
        3997,
        586,
        412,
        1716,
        1496,
        6909,
        433,
        567,
        366,
        1364,
        322,
        341,
        4455,
        436,
        576,
        528,
        512,
        411,
        512,
        1333,
        295,
        1969,
        570,
        406,
        439,
        264,
        4455,
        1854,
        257,
        1594,
        420,
        257,
        6329,
        575,
        264,
        912,
        2372,
        295,
        4846,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15482265608651297,
      "compression_ratio": 1.8675799086757991,
      "no_speech_prob": 0.014188272878527641
    },
    {
      "id": 212,
      "seek": 154212,
      "start": 1542.12,
      "end": 1570.12,
      "text": " So they would want to make sure that this particular one that sees a lot of contribution from our users and it's very critical to our business should always be able to run its pipeline and it shouldn't happen that this other project that's line parallel to it, which is not as much of our priority to us it ends up consuming all the city minutes that's allotted to this group.",
      "tokens": [
        50364,
        407,
        436,
        576,
        528,
        281,
        652,
        988,
        300,
        341,
        1729,
        472,
        300,
        8194,
        257,
        688,
        295,
        13150,
        490,
        527,
        5022,
        293,
        309,
        311,
        588,
        4924,
        281,
        527,
        1606,
        820,
        1009,
        312,
        1075,
        281,
        1190,
        1080,
        15517,
        293,
        309,
        4659,
        380,
        1051,
        300,
        341,
        661,
        1716,
        300,
        311,
        1622,
        8952,
        281,
        309,
        11,
        597,
        307,
        406,
        382,
        709,
        295,
        527,
        9365,
        281,
        505,
        309,
        5314,
        493,
        19867,
        439,
        264,
        2307,
        2077,
        300,
        311,
        439,
        11252,
        281,
        341,
        1594,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15527039039425733,
      "compression_ratio": 1.6563876651982379,
      "no_speech_prob": 0.19136004149913788
    },
    {
      "id": 213,
      "seek": 157012,
      "start": 1570.12,
      "end": 1599.12,
      "text": " So that situation we started working on this feature but right like while we were having the discussion on like how we would make this happen we realized that the moment we like touch upon groups and sub groups this is going to get so much complicated because then we have to take into account like how there will be the subdivisions of the minutes and how would we surface the code like this much out of this much is used right this group.",
      "tokens": [
        50364,
        407,
        300,
        2590,
        321,
        1409,
        1364,
        322,
        341,
        4111,
        457,
        558,
        411,
        1339,
        321,
        645,
        1419,
        264,
        5017,
        322,
        411,
        577,
        321,
        576,
        652,
        341,
        1051,
        321,
        5334,
        300,
        264,
        1623,
        321,
        411,
        2557,
        3564,
        3935,
        293,
        1422,
        3935,
        341,
        307,
        516,
        281,
        483,
        370,
        709,
        6179,
        570,
        550,
        321,
        362,
        281,
        747,
        666,
        2696,
        411,
        577,
        456,
        486,
        312,
        264,
        45331,
        4252,
        295,
        264,
        2077,
        293,
        577,
        576,
        321,
        3753,
        264,
        3089,
        411,
        341,
        709,
        484,
        295,
        341,
        709,
        307,
        1143,
        558,
        341,
        1594,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2330397711859809,
      "compression_ratio": 1.8181818181818181,
      "no_speech_prob": 0.4706171154975891
    },
    {
      "id": 214,
      "seek": 159912,
      "start": 1599.12,
      "end": 1628.12,
      "text": " This is what you're left with this is what you can do with it so we started with the easiest path available so that we can also validated we started with us and space because that's like flat that's just one level like the projects which are directly under your use and space and once that happens once we get good insights from those we decided that will create issues and we make improvements and then we'll move to groups of groups.",
      "tokens": [
        50364,
        639,
        307,
        437,
        291,
        434,
        1411,
        365,
        341,
        307,
        437,
        291,
        393,
        360,
        365,
        309,
        370,
        321,
        1409,
        365,
        264,
        12889,
        3100,
        2435,
        370,
        300,
        321,
        393,
        611,
        40693,
        321,
        1409,
        365,
        505,
        293,
        1901,
        570,
        300,
        311,
        411,
        4962,
        300,
        311,
        445,
        472,
        1496,
        411,
        264,
        4455,
        597,
        366,
        3838,
        833,
        428,
        764,
        293,
        1901,
        293,
        1564,
        300,
        2314,
        1564,
        321,
        483,
        665,
        14310,
        490,
        729,
        321,
        3047,
        300,
        486,
        1884,
        2663,
        293,
        321,
        652,
        13797,
        293,
        550,
        321,
        603,
        1286,
        281,
        3935,
        295,
        3935,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18241461030729525,
      "compression_ratio": 1.8049792531120332,
      "no_speech_prob": 0.003923478070646524
    },
    {
      "id": 215,
      "seek": 162812,
      "start": 1628.12,
      "end": 1632.12,
      "text": " I see that we're very close to diamond not you also not you do so.",
      "tokens": [
        50364,
        286,
        536,
        300,
        321,
        434,
        588,
        1998,
        281,
        16059,
        406,
        291,
        611,
        406,
        291,
        360,
        370,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5335929489135742,
      "compression_ratio": 1.2741935483870968,
      "no_speech_prob": 0.006962220184504986
    },
    {
      "id": 216,
      "seek": 162812,
      "start": 1633.12,
      "end": 1641.12,
      "text": " I'm having to take questions on slide as well and I'll pass it on to Nadia.",
      "tokens": [
        50614,
        286,
        478,
        1419,
        281,
        747,
        1651,
        322,
        4137,
        382,
        731,
        293,
        286,
        603,
        1320,
        309,
        322,
        281,
        23269,
        654,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5335929489135742,
      "compression_ratio": 1.2741935483870968,
      "no_speech_prob": 0.006962220184504986
    },
    {
      "id": 217,
      "seek": 162812,
      "start": 1642.12,
      "end": 1644.12,
      "text": " Thanks, Vedika.",
      "tokens": [
        51064,
        2561,
        11,
        26084,
        5439,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5335929489135742,
      "compression_ratio": 1.2741935483870968,
      "no_speech_prob": 0.006962220184504986
    },
    {
      "id": 218,
      "seek": 164412,
      "start": 1644.12,
      "end": 1671.12,
      "text": " Yeah, so this milestone I'm participating in beautifying UI there's an issue where I'm gathering all of the ideas that I want to work on brainstorming some solutions so I'm trying to keep I keep it like one thread for one improvement so if there's anything that you would like to work on but maybe your team doesn't have capacity or anything like that.",
      "tokens": [
        50364,
        865,
        11,
        370,
        341,
        28048,
        286,
        478,
        13950,
        294,
        1869,
        5489,
        15682,
        456,
        311,
        364,
        2734,
        689,
        286,
        478,
        13519,
        439,
        295,
        264,
        3487,
        300,
        286,
        528,
        281,
        589,
        322,
        35245,
        278,
        512,
        6547,
        370,
        286,
        478,
        1382,
        281,
        1066,
        286,
        1066,
        309,
        411,
        472,
        7207,
        337,
        472,
        10444,
        370,
        498,
        456,
        311,
        1340,
        300,
        291,
        576,
        411,
        281,
        589,
        322,
        457,
        1310,
        428,
        1469,
        1177,
        380,
        362,
        6042,
        420,
        1340,
        411,
        300,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13041340999114207,
      "compression_ratio": 1.6372093023255814,
      "no_speech_prob": 0.45155584812164307
    },
    {
      "id": 219,
      "seek": 167112,
      "start": 1671.12,
      "end": 1689.12,
      "text": " Like that tool for drop your ideas into that issue and I can promise that we'll get picked up because also the engineer I'm working with he has limited capacity this milestone which is unfortunate because I dedicated half of my time to this and I think he dedicated like 20% of his time to this.",
      "tokens": [
        50364,
        1743,
        300,
        2290,
        337,
        3270,
        428,
        3487,
        666,
        300,
        2734,
        293,
        286,
        393,
        6228,
        300,
        321,
        603,
        483,
        6183,
        493,
        570,
        611,
        264,
        11403,
        286,
        478,
        1364,
        365,
        415,
        575,
        5567,
        6042,
        341,
        28048,
        597,
        307,
        17843,
        570,
        286,
        8374,
        1922,
        295,
        452,
        565,
        281,
        341,
        293,
        286,
        519,
        415,
        8374,
        411,
        945,
        4,
        295,
        702,
        565,
        281,
        341,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14591650664806366,
      "compression_ratio": 1.560846560846561,
      "no_speech_prob": 0.12231182307004929
    },
    {
      "id": 220,
      "seek": 168912,
      "start": 1690.12,
      "end": 1701.12,
      "text": " But we're going to choose like the top impact maybe also easiest to do kinds of improvements and run with that so drop your comments there.",
      "tokens": [
        50414,
        583,
        321,
        434,
        516,
        281,
        2826,
        411,
        264,
        1192,
        2712,
        1310,
        611,
        12889,
        281,
        360,
        3685,
        295,
        13797,
        293,
        1190,
        365,
        300,
        370,
        3270,
        428,
        3053,
        456,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0984132754338252,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 0.10173216462135315
    },
    {
      "id": 221,
      "seek": 168912,
      "start": 1703.12,
      "end": 1716.12,
      "text": " Yeah, I see that you have a lot of suggestions but let's keep it pretty only for the sake of time and another thing I wanted to share is our results from the secrets management jobs to be done research.",
      "tokens": [
        51064,
        865,
        11,
        286,
        536,
        300,
        291,
        362,
        257,
        688,
        295,
        13396,
        457,
        718,
        311,
        1066,
        309,
        1238,
        787,
        337,
        264,
        9717,
        295,
        565,
        293,
        1071,
        551,
        286,
        1415,
        281,
        2073,
        307,
        527,
        3542,
        490,
        264,
        14093,
        4592,
        4782,
        281,
        312,
        1096,
        2132,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0984132754338252,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 0.10173216462135315
    },
    {
      "id": 222,
      "seek": 171612,
      "start": 1716.12,
      "end": 1731.12,
      "text": " So it was meta analysis of existing research that we have around secrets and there's lots of great insights that came out of it that you can check out in this issue that a link I summarized everything in the issue description so you can just skip through that if you want.",
      "tokens": [
        50364,
        407,
        309,
        390,
        19616,
        5215,
        295,
        6741,
        2132,
        300,
        321,
        362,
        926,
        14093,
        293,
        456,
        311,
        3195,
        295,
        869,
        14310,
        300,
        1361,
        484,
        295,
        309,
        300,
        291,
        393,
        1520,
        484,
        294,
        341,
        2734,
        300,
        257,
        2113,
        286,
        14611,
        1602,
        1203,
        294,
        264,
        2734,
        3855,
        370,
        291,
        393,
        445,
        10023,
        807,
        300,
        498,
        291,
        528,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13315402855307368,
      "compression_ratio": 1.5542857142857143,
      "no_speech_prob": 0.2588285505771637
    },
    {
      "id": 223,
      "seek": 173112,
      "start": 1732.12,
      "end": 1747.12,
      "text": " And wanted to point out that secrets is our top priority right now for pipeline authoring generally as far as new features are concerned our main focus is secrets management and the CIC catalog work that we're doing.",
      "tokens": [
        50414,
        400,
        1415,
        281,
        935,
        484,
        300,
        14093,
        307,
        527,
        1192,
        9365,
        558,
        586,
        337,
        15517,
        3793,
        278,
        5101,
        382,
        1400,
        382,
        777,
        4122,
        366,
        5922,
        527,
        2135,
        1879,
        307,
        14093,
        4592,
        293,
        264,
        383,
        2532,
        19746,
        589,
        300,
        321,
        434,
        884,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20646190643310547,
      "compression_ratio": 1.411764705882353,
      "no_speech_prob": 0.6498851776123047
    },
    {
      "id": 224,
      "seek": 174712,
      "start": 1748.12,
      "end": 1770.12,
      "text": " And there's an MR for updated secrets jobs to be done and there's a lot of overlap there that we're finding with compliance and security so we'll be collaborating with those teams to make sure that we connect the secrets management workflow to management of your security policies and compliance policies and so on.",
      "tokens": [
        50414,
        400,
        456,
        311,
        364,
        9808,
        337,
        10588,
        14093,
        4782,
        281,
        312,
        1096,
        293,
        456,
        311,
        257,
        688,
        295,
        19959,
        456,
        300,
        321,
        434,
        5006,
        365,
        15882,
        293,
        3825,
        370,
        321,
        603,
        312,
        30188,
        365,
        729,
        5491,
        281,
        652,
        988,
        300,
        321,
        1745,
        264,
        14093,
        4592,
        20993,
        281,
        4592,
        295,
        428,
        3825,
        7657,
        293,
        15882,
        7657,
        293,
        370,
        322,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10336384054732649,
      "compression_ratio": 1.7185929648241205,
      "no_speech_prob": 0.04929577186703682
    },
    {
      "id": 225,
      "seek": 174712,
      "start": 1772.12,
      "end": 1774.12,
      "text": " Yeah, and now on to Katie.",
      "tokens": [
        51614,
        865,
        11,
        293,
        586,
        322,
        281,
        19602,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10336384054732649,
      "compression_ratio": 1.7185929648241205,
      "no_speech_prob": 0.04929577186703682
    },
    {
      "id": 226,
      "seek": 177412,
      "start": 1775.12,
      "end": 1795.12,
      "text": " Cool, I first ones just an FYI in case people don't know we have a dedicated product analyst named Nicole who we can make UX data request to she can help with structuring the kind of the right questions to ask to remove bias and implementation in the code for tracking things and then also size and stash boards.",
      "tokens": [
        50414,
        8561,
        11,
        286,
        700,
        2306,
        445,
        364,
        42730,
        40,
        294,
        1389,
        561,
        500,
        380,
        458,
        321,
        362,
        257,
        8374,
        1674,
        19085,
        4926,
        18532,
        567,
        321,
        393,
        652,
        40176,
        1412,
        5308,
        281,
        750,
        393,
        854,
        365,
        6594,
        1345,
        264,
        733,
        295,
        264,
        558,
        1651,
        281,
        1029,
        281,
        4159,
        12577,
        293,
        11420,
        294,
        264,
        3089,
        337,
        11603,
        721,
        293,
        550,
        611,
        2744,
        293,
        342,
        1299,
        13293,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16579926532247793,
      "compression_ratio": 1.4857142857142858,
      "no_speech_prob": 0.01143951341509819
    },
    {
      "id": 227,
      "seek": 179512,
      "start": 1796.12,
      "end": 1816.12,
      "text": " She is across all of ops so she also works with many pms so she's got quite a lot of competing priorities so she did request that when we are creating issues to kind of indicate the urgency and the priority but I just didn't know that we had this relationship so in case anyone else didn't.",
      "tokens": [
        50414,
        1240,
        307,
        2108,
        439,
        295,
        44663,
        370,
        750,
        611,
        1985,
        365,
        867,
        280,
        2592,
        370,
        750,
        311,
        658,
        1596,
        257,
        688,
        295,
        15439,
        15503,
        370,
        750,
        630,
        5308,
        300,
        562,
        321,
        366,
        4084,
        2663,
        281,
        733,
        295,
        13330,
        264,
        29734,
        293,
        264,
        9365,
        457,
        286,
        445,
        994,
        380,
        458,
        300,
        321,
        632,
        341,
        2480,
        370,
        294,
        1389,
        2878,
        1646,
        994,
        380,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11874169291871967,
      "compression_ratio": 1.5675675675675675,
      "no_speech_prob": 0.0953725054860115
    },
    {
      "id": 228,
      "seek": 181612,
      "start": 1816.12,
      "end": 1840.12,
      "text": " And not much else to report for package i'm still covering ecosystem until like November but we're working on some process improvements and package about how we refine and how issues come into the milestone and I've also gotten the opportunity to speak to a number of enterprise customers because our PM is on parental leave.",
      "tokens": [
        50364,
        400,
        406,
        709,
        1646,
        281,
        2275,
        337,
        7372,
        741,
        478,
        920,
        10322,
        11311,
        1826,
        411,
        7674,
        457,
        321,
        434,
        1364,
        322,
        512,
        1399,
        13797,
        293,
        7372,
        466,
        577,
        321,
        33906,
        293,
        577,
        2663,
        808,
        666,
        264,
        28048,
        293,
        286,
        600,
        611,
        5768,
        264,
        2650,
        281,
        1710,
        281,
        257,
        1230,
        295,
        14132,
        4581,
        570,
        527,
        12499,
        307,
        322,
        41113,
        1856,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16291096806526184,
      "compression_ratio": 1.5258215962441315,
      "no_speech_prob": 0.2130393534898758
    },
    {
      "id": 229,
      "seek": 184012,
      "start": 1840.12,
      "end": 1849.12,
      "text": " And you might have seen Eric and I discussing in slack yesterday now that I have those relationships with those enterprise customers and terms I would love to recruit them.",
      "tokens": [
        50364,
        400,
        291,
        1062,
        362,
        1612,
        9336,
        293,
        286,
        10850,
        294,
        29767,
        5186,
        586,
        300,
        286,
        362,
        729,
        6159,
        365,
        729,
        14132,
        4581,
        293,
        2115,
        286,
        576,
        959,
        281,
        15119,
        552,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1470089881650863,
      "compression_ratio": 1.6836363636363636,
      "no_speech_prob": 0.014648756943643093
    },
    {
      "id": 230,
      "seek": 184012,
      "start": 1849.12,
      "end": 1867.12,
      "text": " But Erica wisely pointed out that you know we should be really strategic these are very valuable and hard to find research participants so I just wanted to have a group discussion in terms of like does anyone have any ideas about any light process that we could use to make sure that we're.",
      "tokens": [
        50814,
        583,
        37429,
        37632,
        10932,
        484,
        300,
        291,
        458,
        321,
        820,
        312,
        534,
        10924,
        613,
        366,
        588,
        8263,
        293,
        1152,
        281,
        915,
        2132,
        10503,
        370,
        286,
        445,
        1415,
        281,
        362,
        257,
        1594,
        5017,
        294,
        2115,
        295,
        411,
        775,
        2878,
        362,
        604,
        3487,
        466,
        604,
        1442,
        1399,
        300,
        321,
        727,
        764,
        281,
        652,
        988,
        300,
        321,
        434,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1470089881650863,
      "compression_ratio": 1.6836363636363636,
      "no_speech_prob": 0.014648756943643093
    },
    {
      "id": 231,
      "seek": 186712,
      "start": 1867.12,
      "end": 1882.12,
      "text": " And utilizing these to the most high value research amongst us or maybe amongst get left in general.",
      "tokens": [
        50364,
        400,
        26775,
        613,
        281,
        264,
        881,
        1090,
        2158,
        2132,
        12918,
        505,
        420,
        1310,
        12918,
        483,
        1411,
        294,
        2674,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2307214529617973,
      "compression_ratio": 1.1764705882352942,
      "no_speech_prob": 0.00459066778421402
    },
    {
      "id": 232,
      "seek": 188212,
      "start": 1882.12,
      "end": 1892.12,
      "text": " I mean one thing that I can add is that i've mainly worked for tabs or worked with tabs to like get access to large enterprise customers.",
      "tokens": [
        50364,
        286,
        914,
        472,
        551,
        300,
        286,
        393,
        909,
        307,
        300,
        741,
        600,
        8704,
        2732,
        337,
        20743,
        420,
        2732,
        365,
        20743,
        281,
        411,
        483,
        2105,
        281,
        2416,
        14132,
        4581,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1327376365661621,
      "compression_ratio": 1.5555555555555556,
      "no_speech_prob": 0.01133923139423132
    },
    {
      "id": 233,
      "seek": 188212,
      "start": 1892.12,
      "end": 1902.12,
      "text": " I think we maybe have some within like our first look panel but i'm not entirely sure I think it's relatively low.",
      "tokens": [
        50864,
        286,
        519,
        321,
        1310,
        362,
        512,
        1951,
        411,
        527,
        700,
        574,
        4831,
        457,
        741,
        478,
        406,
        7696,
        988,
        286,
        519,
        309,
        311,
        7226,
        2295,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1327376365661621,
      "compression_ratio": 1.5555555555555556,
      "no_speech_prob": 0.01133923139423132
    },
    {
      "id": 234,
      "seek": 190212,
      "start": 1902.12,
      "end": 1913.12,
      "text": " I think it's important whenever scheduling these research sessions with large enterprise customers is since there's not a whole lot of them.",
      "tokens": [
        50364,
        286,
        519,
        309,
        311,
        1021,
        5699,
        29055,
        613,
        2132,
        11081,
        365,
        2416,
        14132,
        4581,
        307,
        1670,
        456,
        311,
        406,
        257,
        1379,
        688,
        295,
        552,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13956094871867786,
      "compression_ratio": 1.4055944055944056,
      "no_speech_prob": 0.00838033389300108
    },
    {
      "id": 235,
      "seek": 190212,
      "start": 1913.12,
      "end": 1920.12,
      "text": " Trying to not overuse and you know over leverage that group.",
      "tokens": [
        50914,
        20180,
        281,
        406,
        670,
        438,
        293,
        291,
        458,
        670,
        13982,
        300,
        1594,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13956094871867786,
      "compression_ratio": 1.4055944055944056,
      "no_speech_prob": 0.00838033389300108
    },
    {
      "id": 236,
      "seek": 192012,
      "start": 1920.12,
      "end": 1934.12,
      "text": " Because you know they are so hard to access and you know we're essentially talking to like the same handful of people over and over again so that can influence the design.",
      "tokens": [
        50364,
        1436,
        291,
        458,
        436,
        366,
        370,
        1152,
        281,
        2105,
        293,
        291,
        458,
        321,
        434,
        4476,
        1417,
        281,
        411,
        264,
        912,
        16458,
        295,
        561,
        670,
        293,
        670,
        797,
        370,
        300,
        393,
        6503,
        264,
        1715,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09508046082087926,
      "compression_ratio": 1.792626728110599,
      "no_speech_prob": 0.01424577459692955
    },
    {
      "id": 237,
      "seek": 192012,
      "start": 1934.12,
      "end": 1949.12,
      "text": " Even if we do see them as like wow there you know they're representing a large company that has a lot of users we tend to just talk to the same individuals from those companies they're representing their set of users.",
      "tokens": [
        51064,
        2754,
        498,
        321,
        360,
        536,
        552,
        382,
        411,
        6076,
        456,
        291,
        458,
        436,
        434,
        13460,
        257,
        2416,
        2237,
        300,
        575,
        257,
        688,
        295,
        5022,
        321,
        3928,
        281,
        445,
        751,
        281,
        264,
        912,
        5346,
        490,
        729,
        3431,
        436,
        434,
        13460,
        641,
        992,
        295,
        5022,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09508046082087926,
      "compression_ratio": 1.792626728110599,
      "no_speech_prob": 0.01424577459692955
    },
    {
      "id": 238,
      "seek": 194912,
      "start": 1949.12,
      "end": 1970.12,
      "text": " Yeah that makes total sense I wonder if like if we have some kind of process that we can also track who spoke to which enterprise customer at which time so that we can kind of avoid what you are mentioning will in terms of biasing for three customers or something like this.",
      "tokens": [
        50364,
        865,
        300,
        1669,
        3217,
        2020,
        286,
        2441,
        498,
        411,
        498,
        321,
        362,
        512,
        733,
        295,
        1399,
        300,
        321,
        393,
        611,
        2837,
        567,
        7179,
        281,
        597,
        14132,
        5474,
        412,
        597,
        565,
        370,
        300,
        321,
        393,
        733,
        295,
        5042,
        437,
        291,
        366,
        18315,
        486,
        294,
        2115,
        295,
        3228,
        3349,
        337,
        1045,
        4581,
        420,
        746,
        411,
        341,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13642757221803828,
      "compression_ratio": 1.6023391812865497,
      "no_speech_prob": 0.007271600421518087
    },
    {
      "id": 239,
      "seek": 197012,
      "start": 1970.12,
      "end": 1979.12,
      "text": " And and that's why we have kind of set up this in part one of the reasons why we've set up the enterprise company profiles and personas.",
      "tokens": [
        50364,
        400,
        293,
        300,
        311,
        983,
        321,
        362,
        733,
        295,
        992,
        493,
        341,
        294,
        644,
        472,
        295,
        264,
        4112,
        983,
        321,
        600,
        992,
        493,
        264,
        14132,
        2237,
        23693,
        293,
        12019,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09909824132919312,
      "compression_ratio": 1.6650246305418719,
      "no_speech_prob": 0.0008456844370812178
    },
    {
      "id": 240,
      "seek": 197012,
      "start": 1979.12,
      "end": 1988.12,
      "text": " Is that we kind of just want to cobble together all of those interviews and touch points and then like abstract them away on what if we can.",
      "tokens": [
        50814,
        1119,
        300,
        321,
        733,
        295,
        445,
        528,
        281,
        598,
        10387,
        1214,
        439,
        295,
        729,
        12318,
        293,
        2557,
        2793,
        293,
        550,
        411,
        12649,
        552,
        1314,
        322,
        437,
        498,
        321,
        393,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09909824132919312,
      "compression_ratio": 1.6650246305418719,
      "no_speech_prob": 0.0008456844370812178
    },
    {
      "id": 241,
      "seek": 197012,
      "start": 1988.12,
      "end": 1993.12,
      "text": " So that we can really do the like small business enterprise.",
      "tokens": [
        51264,
        407,
        300,
        321,
        393,
        534,
        360,
        264,
        411,
        1359,
        1606,
        14132,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09909824132919312,
      "compression_ratio": 1.6650246305418719,
      "no_speech_prob": 0.0008456844370812178
    },
    {
      "id": 242,
      "seek": 199312,
      "start": 1993.12,
      "end": 1999.12,
      "text": " So just advertising that we have that.",
      "tokens": [
        50364,
        407,
        445,
        13097,
        300,
        321,
        362,
        300,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22668922924604573,
      "compression_ratio": 1.5592105263157894,
      "no_speech_prob": 0.008905714377760887
    },
    {
      "id": 243,
      "seek": 199312,
      "start": 1999.12,
      "end": 2009.12,
      "text": " So if we can get consent through that form that's linked in Slack to record and then put those in the dovetail that's linked there.",
      "tokens": [
        50664,
        407,
        498,
        321,
        393,
        483,
        14546,
        807,
        300,
        1254,
        300,
        311,
        9408,
        294,
        37211,
        281,
        2136,
        293,
        550,
        829,
        729,
        294,
        264,
        360,
        9771,
        864,
        300,
        311,
        9408,
        456,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22668922924604573,
      "compression_ratio": 1.5592105263157894,
      "no_speech_prob": 0.008905714377760887
    },
    {
      "id": 244,
      "seek": 199312,
      "start": 2009.12,
      "end": 2016.12,
      "text": " I have it in queue four plans to begin to like put those together.",
      "tokens": [
        51164,
        286,
        362,
        309,
        294,
        18639,
        1451,
        5482,
        281,
        1841,
        281,
        411,
        829,
        729,
        1214,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22668922924604573,
      "compression_ratio": 1.5592105263157894,
      "no_speech_prob": 0.008905714377760887
    },
    {
      "id": 245,
      "seek": 201612,
      "start": 2016.12,
      "end": 2029.12,
      "text": " And when we start on that like in a more full fledged manner which isn't cobbling I'll be like really asking for help on recruit for that but they won't be in Tokyo for.",
      "tokens": [
        50364,
        400,
        562,
        321,
        722,
        322,
        300,
        411,
        294,
        257,
        544,
        1577,
        24114,
        3004,
        9060,
        597,
        1943,
        380,
        598,
        6692,
        1688,
        286,
        603,
        312,
        411,
        534,
        3365,
        337,
        854,
        322,
        15119,
        337,
        300,
        457,
        436,
        1582,
        380,
        312,
        294,
        15147,
        337,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16631851426090102,
      "compression_ratio": 1.5809523809523809,
      "no_speech_prob": 0.07373496890068054
    },
    {
      "id": 246,
      "seek": 201612,
      "start": 2029.12,
      "end": 2030.12,
      "text": " That's all good.",
      "tokens": [
        51014,
        663,
        311,
        439,
        665,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16631851426090102,
      "compression_ratio": 1.5809523809523809,
      "no_speech_prob": 0.07373496890068054
    },
    {
      "id": 247,
      "seek": 201612,
      "start": 2030.12,
      "end": 2040.12,
      "text": " I'm just wondering you know because I have these relationships now and I would love to just speak to these customers anyway but I'm wondering if.",
      "tokens": [
        51064,
        286,
        478,
        445,
        6359,
        291,
        458,
        570,
        286,
        362,
        613,
        6159,
        586,
        293,
        286,
        576,
        959,
        281,
        445,
        1710,
        281,
        613,
        4581,
        4033,
        457,
        286,
        478,
        6359,
        498,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16631851426090102,
      "compression_ratio": 1.5809523809523809,
      "no_speech_prob": 0.07373496890068054
    },
    {
      "id": 248,
      "seek": 204012,
      "start": 2040.12,
      "end": 2060.12,
      "text": " Should we even just have informal conversations amongst ourselves to make sure that those customers aren't needed or they haven't been kind of overused as well as mentioning or should there be a more formal process or does anyone have any thoughts on this.",
      "tokens": [
        50364,
        6454,
        321,
        754,
        445,
        362,
        24342,
        7315,
        12918,
        4175,
        281,
        652,
        988,
        300,
        729,
        4581,
        3212,
        380,
        2978,
        420,
        436,
        2378,
        380,
        668,
        733,
        295,
        670,
        4717,
        382,
        731,
        382,
        18315,
        420,
        820,
        456,
        312,
        257,
        544,
        9860,
        1399,
        420,
        775,
        2878,
        362,
        604,
        4598,
        322,
        341,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07788613209357628,
      "compression_ratio": 1.514792899408284,
      "no_speech_prob": 0.01563376747071743
    },
    {
      "id": 249,
      "seek": 206012,
      "start": 2060.12,
      "end": 2067.12,
      "text": " We could start in that love tell issue just a table where we mark who we've talked to and bring them in.",
      "tokens": [
        50364,
        492,
        727,
        722,
        294,
        300,
        959,
        980,
        2734,
        445,
        257,
        3199,
        689,
        321,
        1491,
        567,
        321,
        600,
        2825,
        281,
        293,
        1565,
        552,
        294,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17812812689578894,
      "compression_ratio": 1.514792899408284,
      "no_speech_prob": 0.03769257292151451
    },
    {
      "id": 250,
      "seek": 206012,
      "start": 2067.12,
      "end": 2080.12,
      "text": " I have an intention to bring in that one company that I won't name so we can share this out but that will and Hiana and I think Tina has also met with.",
      "tokens": [
        50714,
        286,
        362,
        364,
        7789,
        281,
        1565,
        294,
        300,
        472,
        2237,
        300,
        286,
        1582,
        380,
        1315,
        370,
        321,
        393,
        2073,
        341,
        484,
        457,
        300,
        486,
        293,
        389,
        8497,
        293,
        286,
        519,
        28504,
        575,
        611,
        1131,
        365,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17812812689578894,
      "compression_ratio": 1.514792899408284,
      "no_speech_prob": 0.03769257292151451
    },
    {
      "id": 251,
      "seek": 208012,
      "start": 2080.12,
      "end": 2090.12,
      "text": " So maybe there's just like an informal table but if it's in dovetail maybe it is like accessible and we can cross reference it with the videos we have.",
      "tokens": [
        50364,
        407,
        1310,
        456,
        311,
        445,
        411,
        364,
        24342,
        3199,
        457,
        498,
        309,
        311,
        294,
        360,
        9771,
        864,
        1310,
        309,
        307,
        411,
        9515,
        293,
        321,
        393,
        3278,
        6408,
        309,
        365,
        264,
        2145,
        321,
        362,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21390110737568624,
      "compression_ratio": 1.6733870967741935,
      "no_speech_prob": 0.14390996098518372
    },
    {
      "id": 252,
      "seek": 208012,
      "start": 2090.12,
      "end": 2100.12,
      "text": " Okay, cool so I'm happy to create that table. Did you say you wanted that on the get lab issue that's about that enterprise or do you want to end off tell itself.",
      "tokens": [
        50864,
        1033,
        11,
        1627,
        370,
        286,
        478,
        2055,
        281,
        1884,
        300,
        3199,
        13,
        2589,
        291,
        584,
        291,
        1415,
        300,
        322,
        264,
        483,
        2715,
        2734,
        300,
        311,
        466,
        300,
        14132,
        420,
        360,
        291,
        528,
        281,
        917,
        766,
        980,
        2564,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21390110737568624,
      "compression_ratio": 1.6733870967741935,
      "no_speech_prob": 0.14390996098518372
    },
    {
      "id": 253,
      "seek": 208012,
      "start": 2100.12,
      "end": 2102.12,
      "text": " I think that tail because then we can.",
      "tokens": [
        51364,
        286,
        519,
        300,
        6838,
        570,
        550,
        321,
        393,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21390110737568624,
      "compression_ratio": 1.6733870967741935,
      "no_speech_prob": 0.14390996098518372
    },
    {
      "id": 254,
      "seek": 208012,
      "start": 2102.12,
      "end": 2103.12,
      "text": " Okay video.",
      "tokens": [
        51464,
        1033,
        960,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21390110737568624,
      "compression_ratio": 1.6733870967741935,
      "no_speech_prob": 0.14390996098518372
    },
    {
      "id": 255,
      "seek": 208012,
      "start": 2103.12,
      "end": 2106.12,
      "text": " Okay cool yeah I can set that up.",
      "tokens": [
        51514,
        1033,
        1627,
        1338,
        286,
        393,
        992,
        300,
        493,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21390110737568624,
      "compression_ratio": 1.6733870967741935,
      "no_speech_prob": 0.14390996098518372
    },
    {
      "id": 256,
      "seek": 208012,
      "start": 2106.12,
      "end": 2108.12,
      "text": " Cool thank you.",
      "tokens": [
        51664,
        8561,
        1309,
        291,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21390110737568624,
      "compression_ratio": 1.6733870967741935,
      "no_speech_prob": 0.14390996098518372
    },
    {
      "id": 257,
      "seek": 210812,
      "start": 2108.12,
      "end": 2115.12,
      "text": " Katie can you tag off once you do that too because it's in my to do is I'll do it.",
      "tokens": [
        50364,
        19602,
        393,
        291,
        6162,
        766,
        1564,
        291,
        360,
        300,
        886,
        570,
        309,
        311,
        294,
        452,
        281,
        360,
        307,
        286,
        603,
        360,
        309,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14879787927386404,
      "compression_ratio": 1.5381165919282511,
      "no_speech_prob": 0.0030811531469225883
    },
    {
      "id": 258,
      "seek": 210812,
      "start": 2115.12,
      "end": 2119.12,
      "text": " Okay yeah sure.",
      "tokens": [
        50714,
        1033,
        1338,
        988,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14879787927386404,
      "compression_ratio": 1.5381165919282511,
      "no_speech_prob": 0.0030811531469225883
    },
    {
      "id": 259,
      "seek": 210812,
      "start": 2119.12,
      "end": 2123.12,
      "text": " Cool I can pass over to will.",
      "tokens": [
        50914,
        8561,
        286,
        393,
        1320,
        670,
        281,
        486,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14879787927386404,
      "compression_ratio": 1.5381165919282511,
      "no_speech_prob": 0.0030811531469225883
    },
    {
      "id": 260,
      "seek": 210812,
      "start": 2123.12,
      "end": 2137.12,
      "text": " Yeah and I guess before I talk about my section just to add on to the group discussion I think this is something important that we could bring to the larger UX research team to talk about like longer term strategy.",
      "tokens": [
        51114,
        865,
        293,
        286,
        2041,
        949,
        286,
        751,
        466,
        452,
        3541,
        445,
        281,
        909,
        322,
        281,
        264,
        1594,
        5017,
        286,
        519,
        341,
        307,
        746,
        1021,
        300,
        321,
        727,
        1565,
        281,
        264,
        4833,
        40176,
        2132,
        1469,
        281,
        751,
        466,
        411,
        2854,
        1433,
        5206,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14879787927386404,
      "compression_ratio": 1.5381165919282511,
      "no_speech_prob": 0.0030811531469225883
    },
    {
      "id": 261,
      "seek": 213712,
      "start": 2137.12,
      "end": 2140.12,
      "text": " For how we deal with this.",
      "tokens": [
        50364,
        1171,
        577,
        321,
        2028,
        365,
        341,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2004832849874125,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.020565269514918327
    },
    {
      "id": 262,
      "seek": 213712,
      "start": 2140.12,
      "end": 2144.12,
      "text": " I think Eric is on board with.",
      "tokens": [
        50514,
        286,
        519,
        9336,
        307,
        322,
        3150,
        365,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2004832849874125,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.020565269514918327
    },
    {
      "id": 263,
      "seek": 213712,
      "start": 2144.12,
      "end": 2150.12,
      "text": " For on point with like how we're going to address it in the term at least.",
      "tokens": [
        50714,
        1171,
        322,
        935,
        365,
        411,
        577,
        321,
        434,
        516,
        281,
        2985,
        309,
        294,
        264,
        1433,
        412,
        1935,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2004832849874125,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.020565269514918327
    },
    {
      "id": 264,
      "seek": 213712,
      "start": 2150.12,
      "end": 2153.12,
      "text": " Sounds good.",
      "tokens": [
        51014,
        14576,
        665,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2004832849874125,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.020565269514918327
    },
    {
      "id": 265,
      "seek": 213712,
      "start": 2153.12,
      "end": 2162.12,
      "text": " So the only update that I have is that I'm halfway done with my benchmarking city so I've gotten 10 out of 20 sessions complete.",
      "tokens": [
        51164,
        407,
        264,
        787,
        5623,
        300,
        286,
        362,
        307,
        300,
        286,
        478,
        15461,
        1096,
        365,
        452,
        18927,
        278,
        2307,
        370,
        286,
        600,
        5768,
        1266,
        484,
        295,
        945,
        11081,
        3566,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2004832849874125,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.020565269514918327
    },
    {
      "id": 266,
      "seek": 216212,
      "start": 2162.12,
      "end": 2170.12,
      "text": " I've added the videos to do I'm continuing to get them tagged.",
      "tokens": [
        50364,
        286,
        600,
        3869,
        264,
        2145,
        281,
        360,
        286,
        478,
        9289,
        281,
        483,
        552,
        40239,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17833095872905894,
      "compression_ratio": 1.5083798882681565,
      "no_speech_prob": 0.1248418465256691
    },
    {
      "id": 267,
      "seek": 216212,
      "start": 2170.12,
      "end": 2175.12,
      "text": " And I have another 10 sessions over around the next week.",
      "tokens": [
        50764,
        400,
        286,
        362,
        1071,
        1266,
        11081,
        670,
        926,
        264,
        958,
        1243,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17833095872905894,
      "compression_ratio": 1.5083798882681565,
      "no_speech_prob": 0.1248418465256691
    },
    {
      "id": 268,
      "seek": 216212,
      "start": 2175.12,
      "end": 2183.12,
      "text": " It might bleed over until the end of next week but hoping to have it done pretty soon.",
      "tokens": [
        51014,
        467,
        1062,
        28385,
        670,
        1826,
        264,
        917,
        295,
        958,
        1243,
        457,
        7159,
        281,
        362,
        309,
        1096,
        1238,
        2321,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17833095872905894,
      "compression_ratio": 1.5083798882681565,
      "no_speech_prob": 0.1248418465256691
    },
    {
      "id": 269,
      "seek": 216212,
      "start": 2183.12,
      "end": 2191.12,
      "text": " And if there are not any questions I'll pass it over to Erica.",
      "tokens": [
        51414,
        400,
        498,
        456,
        366,
        406,
        604,
        1651,
        286,
        603,
        1320,
        309,
        670,
        281,
        37429,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17833095872905894,
      "compression_ratio": 1.5083798882681565,
      "no_speech_prob": 0.1248418465256691
    },
    {
      "id": 270,
      "seek": 219112,
      "start": 2191.12,
      "end": 2204.12,
      "text": " Yes so I didn't make little points about this but my Q3 and Q4 plans are kind of set so in a way that's good for my life.",
      "tokens": [
        50364,
        1079,
        370,
        286,
        994,
        380,
        652,
        707,
        2793,
        466,
        341,
        457,
        452,
        1249,
        18,
        293,
        1249,
        19,
        5482,
        366,
        733,
        295,
        992,
        370,
        294,
        257,
        636,
        300,
        311,
        665,
        337,
        452,
        993,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15011637385298565,
      "compression_ratio": 1.4790697674418605,
      "no_speech_prob": 0.0007699478883296251
    },
    {
      "id": 271,
      "seek": 219112,
      "start": 2204.12,
      "end": 2220.12,
      "text": " But then also just so you know that I'm if possible like for example with Nadia's like job to be done stuff I can sometimes fold in or like build out a research question if there's pressing needs.",
      "tokens": [
        51014,
        583,
        550,
        611,
        445,
        370,
        291,
        458,
        300,
        286,
        478,
        498,
        1944,
        411,
        337,
        1365,
        365,
        23269,
        654,
        311,
        411,
        1691,
        281,
        312,
        1096,
        1507,
        286,
        393,
        2171,
        4860,
        294,
        420,
        411,
        1322,
        484,
        257,
        2132,
        1168,
        498,
        456,
        311,
        12417,
        2203,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15011637385298565,
      "compression_ratio": 1.4790697674418605,
      "no_speech_prob": 0.0007699478883296251
    },
    {
      "id": 272,
      "seek": 222012,
      "start": 2220.12,
      "end": 2226.12,
      "text": " So just remember that we're locked but we have some freedom within that structure.",
      "tokens": [
        50364,
        407,
        445,
        1604,
        300,
        321,
        434,
        9376,
        457,
        321,
        362,
        512,
        5645,
        1951,
        300,
        3877,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11114368438720704,
      "compression_ratio": 1.532994923857868,
      "no_speech_prob": 0.001036778325214982
    },
    {
      "id": 273,
      "seek": 222012,
      "start": 2226.12,
      "end": 2232.12,
      "text": " And then what I'm working on is just the secrets features survey.",
      "tokens": [
        50664,
        400,
        550,
        437,
        286,
        478,
        1364,
        322,
        307,
        445,
        264,
        14093,
        4122,
        8984,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11114368438720704,
      "compression_ratio": 1.532994923857868,
      "no_speech_prob": 0.001036778325214982
    },
    {
      "id": 274,
      "seek": 222012,
      "start": 2232.12,
      "end": 2240.12,
      "text": " And that will help us to understand the trade offs between the developer needs.",
      "tokens": [
        50964,
        400,
        300,
        486,
        854,
        505,
        281,
        1223,
        264,
        4923,
        39457,
        1296,
        264,
        10754,
        2203,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11114368438720704,
      "compression_ratio": 1.532994923857868,
      "no_speech_prob": 0.001036778325214982
    },
    {
      "id": 275,
      "seek": 222012,
      "start": 2240.12,
      "end": 2246.12,
      "text": " And the SRE slash maybe security compliance depending on who we can find.",
      "tokens": [
        51364,
        400,
        264,
        318,
        3850,
        17330,
        1310,
        3825,
        15882,
        5413,
        322,
        567,
        321,
        393,
        915,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11114368438720704,
      "compression_ratio": 1.532994923857868,
      "no_speech_prob": 0.001036778325214982
    },
    {
      "id": 276,
      "seek": 224612,
      "start": 2246.12,
      "end": 2252.12,
      "text": " And we're going to field it for quite some time because to reach those two groups we know we need to go to coupon.",
      "tokens": [
        50364,
        400,
        321,
        434,
        516,
        281,
        2519,
        309,
        337,
        1596,
        512,
        565,
        570,
        281,
        2524,
        729,
        732,
        3935,
        321,
        458,
        321,
        643,
        281,
        352,
        281,
        33390,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13361382484436035,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 0.002879975363612175
    },
    {
      "id": 277,
      "seek": 224612,
      "start": 2252.12,
      "end": 2256.12,
      "text": " And then we need to have a long email campaign.",
      "tokens": [
        50664,
        400,
        550,
        321,
        643,
        281,
        362,
        257,
        938,
        3796,
        5129,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13361382484436035,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 0.002879975363612175
    },
    {
      "id": 278,
      "seek": 224612,
      "start": 2256.12,
      "end": 2259.12,
      "text": " And so I'm sprinting towards that.",
      "tokens": [
        50864,
        400,
        370,
        286,
        478,
        25075,
        278,
        3030,
        300,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13361382484436035,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 0.002879975363612175
    },
    {
      "id": 279,
      "seek": 224612,
      "start": 2259.12,
      "end": 2270.12,
      "text": " And then also just say yay for the team that Nadia and and Gina maybe in reverse order.",
      "tokens": [
        51014,
        400,
        550,
        611,
        445,
        584,
        23986,
        337,
        264,
        1469,
        300,
        23269,
        654,
        293,
        293,
        34711,
        1310,
        294,
        9943,
        1668,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13361382484436035,
      "compression_ratio": 1.5405405405405406,
      "no_speech_prob": 0.002879975363612175
    },
    {
      "id": 280,
      "seek": 227012,
      "start": 2270.12,
      "end": 2275.12,
      "text": " And then we're working on a really cool participatory design activity.",
      "tokens": [
        50364,
        400,
        550,
        321,
        434,
        1364,
        322,
        257,
        534,
        1627,
        3421,
        4745,
        1715,
        5191,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18276036977767945,
      "compression_ratio": 1.5490196078431373,
      "no_speech_prob": 0.027684660628437996
    },
    {
      "id": 281,
      "seek": 227012,
      "start": 2275.12,
      "end": 2281.12,
      "text": " Where we're going to kind of map out the secrets workflow so it's still emergent but it's exciting.",
      "tokens": [
        50614,
        2305,
        321,
        434,
        516,
        281,
        733,
        295,
        4471,
        484,
        264,
        14093,
        20993,
        370,
        309,
        311,
        920,
        4345,
        6930,
        457,
        309,
        311,
        4670,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18276036977767945,
      "compression_ratio": 1.5490196078431373,
      "no_speech_prob": 0.027684660628437996
    },
    {
      "id": 282,
      "seek": 227012,
      "start": 2281.12,
      "end": 2286.12,
      "text": " And I think we might have a new paradigm.",
      "tokens": [
        50914,
        400,
        286,
        519,
        321,
        1062,
        362,
        257,
        777,
        24709,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18276036977767945,
      "compression_ratio": 1.5490196078431373,
      "no_speech_prob": 0.027684660628437996
    },
    {
      "id": 283,
      "seek": 227012,
      "start": 2286.12,
      "end": 2297.12,
      "text": " Yeah I wanted to ask about that so I know that there's some feedback there that I was going to provide.",
      "tokens": [
        51164,
        865,
        286,
        1415,
        281,
        1029,
        466,
        300,
        370,
        286,
        458,
        300,
        456,
        311,
        512,
        5824,
        456,
        300,
        286,
        390,
        516,
        281,
        2893,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18276036977767945,
      "compression_ratio": 1.5490196078431373,
      "no_speech_prob": 0.027684660628437996
    },
    {
      "id": 284,
      "seek": 229712,
      "start": 2297.12,
      "end": 2303.12,
      "text": " And I wanted to ask what's the latest time that you need to buy because you mentioned that you want to run the pilots next week.",
      "tokens": [
        50364,
        400,
        286,
        1415,
        281,
        1029,
        437,
        311,
        264,
        6792,
        565,
        300,
        291,
        643,
        281,
        2256,
        570,
        291,
        2835,
        300,
        291,
        528,
        281,
        1190,
        264,
        21506,
        958,
        1243,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09827294750748394,
      "compression_ratio": 1.640495867768595,
      "no_speech_prob": 0.15436379611492157
    },
    {
      "id": 285,
      "seek": 229712,
      "start": 2303.12,
      "end": 2307.12,
      "text": " And I'm taking the family and friends day on Friday.",
      "tokens": [
        50664,
        400,
        286,
        478,
        1940,
        264,
        1605,
        293,
        1855,
        786,
        322,
        6984,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09827294750748394,
      "compression_ratio": 1.640495867768595,
      "no_speech_prob": 0.15436379611492157
    },
    {
      "id": 286,
      "seek": 229712,
      "start": 2307.12,
      "end": 2309.12,
      "text": " So I'm a bit short on time this week.",
      "tokens": [
        50864,
        407,
        286,
        478,
        257,
        857,
        2099,
        322,
        565,
        341,
        1243,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09827294750748394,
      "compression_ratio": 1.640495867768595,
      "no_speech_prob": 0.15436379611492157
    },
    {
      "id": 287,
      "seek": 229712,
      "start": 2309.12,
      "end": 2312.12,
      "text": " So maybe you can just message me.",
      "tokens": [
        50964,
        407,
        1310,
        291,
        393,
        445,
        3636,
        385,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09827294750748394,
      "compression_ratio": 1.640495867768595,
      "no_speech_prob": 0.15436379611492157
    },
    {
      "id": 288,
      "seek": 229712,
      "start": 2312.12,
      "end": 2320.12,
      "text": " Let me know what's like the best way for us to collaborate on this or point me to an issue comment or threat.",
      "tokens": [
        51114,
        961,
        385,
        458,
        437,
        311,
        411,
        264,
        1151,
        636,
        337,
        505,
        281,
        18338,
        322,
        341,
        420,
        935,
        385,
        281,
        364,
        2734,
        2871,
        420,
        4734,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09827294750748394,
      "compression_ratio": 1.640495867768595,
      "no_speech_prob": 0.15436379611492157
    },
    {
      "id": 289,
      "seek": 229712,
      "start": 2320.12,
      "end": 2323.12,
      "text": " Where I can jump in and help out.",
      "tokens": [
        51514,
        2305,
        286,
        393,
        3012,
        294,
        293,
        854,
        484,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09827294750748394,
      "compression_ratio": 1.640495867768595,
      "no_speech_prob": 0.15436379611492157
    },
    {
      "id": 290,
      "seek": 232312,
      "start": 2323.12,
      "end": 2327.12,
      "text": " Okay. I think you can come in after the pilots will use the pilot.",
      "tokens": [
        50364,
        1033,
        13,
        286,
        519,
        291,
        393,
        808,
        294,
        934,
        264,
        21506,
        486,
        764,
        264,
        9691,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2158389392199817,
      "compression_ratio": 1.6740088105726871,
      "no_speech_prob": 0.00314681907184422
    },
    {
      "id": 291,
      "seek": 232312,
      "start": 2327.12,
      "end": 2330.12,
      "text": " See if it stands and how it looks more.",
      "tokens": [
        50564,
        3008,
        498,
        309,
        7382,
        293,
        577,
        309,
        1542,
        544,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2158389392199817,
      "compression_ratio": 1.6740088105726871,
      "no_speech_prob": 0.00314681907184422
    },
    {
      "id": 292,
      "seek": 232312,
      "start": 2330.12,
      "end": 2333.12,
      "text": " Okay. Okay. Sounds good.",
      "tokens": [
        50714,
        1033,
        13,
        1033,
        13,
        14576,
        665,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2158389392199817,
      "compression_ratio": 1.6740088105726871,
      "no_speech_prob": 0.00314681907184422
    },
    {
      "id": 293,
      "seek": 232312,
      "start": 2333.12,
      "end": 2334.12,
      "text": " Yeah.",
      "tokens": [
        50864,
        865,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2158389392199817,
      "compression_ratio": 1.6740088105726871,
      "no_speech_prob": 0.00314681907184422
    },
    {
      "id": 294,
      "seek": 232312,
      "start": 2334.12,
      "end": 2337.12,
      "text": " With the secret features we might need your your feedback.",
      "tokens": [
        50914,
        2022,
        264,
        4054,
        4122,
        321,
        1062,
        643,
        428,
        428,
        5824,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2158389392199817,
      "compression_ratio": 1.6740088105726871,
      "no_speech_prob": 0.00314681907184422
    },
    {
      "id": 295,
      "seek": 232312,
      "start": 2337.12,
      "end": 2339.12,
      "text": " I think we're actually good on that with the survey stuff.",
      "tokens": [
        51064,
        286,
        519,
        321,
        434,
        767,
        665,
        322,
        300,
        365,
        264,
        8984,
        1507,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2158389392199817,
      "compression_ratio": 1.6740088105726871,
      "no_speech_prob": 0.00314681907184422
    },
    {
      "id": 296,
      "seek": 232312,
      "start": 2339.12,
      "end": 2341.12,
      "text": " And I think we'll come back.",
      "tokens": [
        51164,
        400,
        286,
        519,
        321,
        603,
        808,
        646,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2158389392199817,
      "compression_ratio": 1.6740088105726871,
      "no_speech_prob": 0.00314681907184422
    },
    {
      "id": 297,
      "seek": 232312,
      "start": 2341.12,
      "end": 2343.12,
      "text": " Okay. Okay. Thank you for that.",
      "tokens": [
        51264,
        1033,
        13,
        1033,
        13,
        1044,
        291,
        337,
        300,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2158389392199817,
      "compression_ratio": 1.6740088105726871,
      "no_speech_prob": 0.00314681907184422
    },
    {
      "id": 298,
      "seek": 232312,
      "start": 2343.12,
      "end": 2346.12,
      "text": " Well, I will catch up with you on Slack about that as well too.",
      "tokens": [
        51364,
        1042,
        11,
        286,
        486,
        3745,
        493,
        365,
        291,
        322,
        37211,
        466,
        300,
        382,
        731,
        886,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2158389392199817,
      "compression_ratio": 1.6740088105726871,
      "no_speech_prob": 0.00314681907184422
    },
    {
      "id": 299,
      "seek": 235312,
      "start": 2353.12,
      "end": 2356.12,
      "text": " So I'm going to ask you a question.",
      "tokens": [
        50364,
        407,
        286,
        478,
        516,
        281,
        1029,
        291,
        257,
        1168,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39029033009598896,
      "compression_ratio": 1.4555555555555555,
      "no_speech_prob": 0.007185657043009996
    },
    {
      "id": 300,
      "seek": 235312,
      "start": 2356.12,
      "end": 2361.12,
      "text": " Erica, do you want to do your, oh, they read only.",
      "tokens": [
        50514,
        37429,
        11,
        360,
        291,
        528,
        281,
        360,
        428,
        11,
        1954,
        11,
        436,
        1401,
        787,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39029033009598896,
      "compression_ratio": 1.4555555555555555,
      "no_speech_prob": 0.007185657043009996
    },
    {
      "id": 301,
      "seek": 235312,
      "start": 2361.12,
      "end": 2365.12,
      "text": " Well, did you want to voice it? We have four minutes.",
      "tokens": [
        50764,
        1042,
        11,
        630,
        291,
        528,
        281,
        3177,
        309,
        30,
        492,
        362,
        1451,
        2077,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39029033009598896,
      "compression_ratio": 1.4555555555555555,
      "no_speech_prob": 0.007185657043009996
    },
    {
      "id": 302,
      "seek": 235312,
      "start": 2365.12,
      "end": 2366.12,
      "text": " Yeah.",
      "tokens": [
        50964,
        865,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39029033009598896,
      "compression_ratio": 1.4555555555555555,
      "no_speech_prob": 0.007185657043009996
    },
    {
      "id": 303,
      "seek": 235312,
      "start": 2366.12,
      "end": 2367.12,
      "text": " Yeah.",
      "tokens": [
        51014,
        865,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39029033009598896,
      "compression_ratio": 1.4555555555555555,
      "no_speech_prob": 0.007185657043009996
    },
    {
      "id": 304,
      "seek": 235312,
      "start": 2367.12,
      "end": 2375.12,
      "text": " So there was a paper posted yesterday in the security research channel.",
      "tokens": [
        51064,
        407,
        456,
        390,
        257,
        3035,
        9437,
        5186,
        294,
        264,
        3825,
        2132,
        2269,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39029033009598896,
      "compression_ratio": 1.4555555555555555,
      "no_speech_prob": 0.007185657043009996
    },
    {
      "id": 305,
      "seek": 235312,
      "start": 2375.12,
      "end": 2379.12,
      "text": " And they said it wasn't a good paper.",
      "tokens": [
        51464,
        400,
        436,
        848,
        309,
        2067,
        380,
        257,
        665,
        3035,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.39029033009598896,
      "compression_ratio": 1.4555555555555555,
      "no_speech_prob": 0.007185657043009996
    },
    {
      "id": 306,
      "seek": 237912,
      "start": 2379.12,
      "end": 2381.12,
      "text": " It's not what it is.",
      "tokens": [
        50364,
        467,
        311,
        406,
        437,
        309,
        307,
        13,
        50464
      ],
      "temperature": 0.6,
      "avg_logprob": -0.9951119630233102,
      "compression_ratio": 1.6650717703349283,
      "no_speech_prob": 0.03435498848557472
    },
    {
      "id": 307,
      "seek": 237912,
      "start": 2381.12,
      "end": 2385.12,
      "text": " And this is what the data was made.",
      "tokens": [
        50464,
        400,
        341,
        307,
        437,
        264,
        1412,
        390,
        1027,
        13,
        50664
      ],
      "temperature": 0.6,
      "avg_logprob": -0.9951119630233102,
      "compression_ratio": 1.6650717703349283,
      "no_speech_prob": 0.03435498848557472
    },
    {
      "id": 308,
      "seek": 237912,
      "start": 2385.12,
      "end": 2387.12,
      "text": " And this is what we actually did that was,",
      "tokens": [
        50664,
        400,
        341,
        307,
        437,
        321,
        767,
        630,
        300,
        390,
        11,
        50764
      ],
      "temperature": 0.6,
      "avg_logprob": -0.9951119630233102,
      "compression_ratio": 1.6650717703349283,
      "no_speech_prob": 0.03435498848557472
    },
    {
      "id": 309,
      "seek": 237912,
      "start": 2387.12,
      "end": 2391.12,
      "text": " which I think means it's like not we can maybe follow it because it's not",
      "tokens": [
        50764,
        597,
        286,
        519,
        1355,
        309,
        311,
        411,
        406,
        321,
        393,
        1310,
        1524,
        309,
        570,
        309,
        311,
        406,
        50964
      ],
      "temperature": 0.6,
      "avg_logprob": -0.9951119630233102,
      "compression_ratio": 1.6650717703349283,
      "no_speech_prob": 0.03435498848557472
    },
    {
      "id": 310,
      "seek": 237912,
      "start": 2391.12,
      "end": 2394.12,
      "text": " that technically complex and good.",
      "tokens": [
        50964,
        300,
        12120,
        3997,
        293,
        665,
        13,
        51114
      ],
      "temperature": 0.6,
      "avg_logprob": -0.9951119630233102,
      "compression_ratio": 1.6650717703349283,
      "no_speech_prob": 0.03435498848557472
    },
    {
      "id": 311,
      "seek": 237912,
      "start": 2394.12,
      "end": 2399.12,
      "text": " But I actually felt it found it really helpful because it takes a few competitors.",
      "tokens": [
        51114,
        583,
        286,
        767,
        2762,
        309,
        1352,
        309,
        534,
        4961,
        570,
        309,
        2516,
        257,
        1326,
        18333,
        13,
        51364
      ],
      "temperature": 0.6,
      "avg_logprob": -0.9951119630233102,
      "compression_ratio": 1.6650717703349283,
      "no_speech_prob": 0.03435498848557472
    },
    {
      "id": 312,
      "seek": 237912,
      "start": 2399.12,
      "end": 2403.12,
      "text": " And kind of talks about their different roles in access.",
      "tokens": [
        51364,
        400,
        733,
        295,
        6686,
        466,
        641,
        819,
        9604,
        294,
        2105,
        13,
        51564
      ],
      "temperature": 0.6,
      "avg_logprob": -0.9951119630233102,
      "compression_ratio": 1.6650717703349283,
      "no_speech_prob": 0.03435498848557472
    },
    {
      "id": 313,
      "seek": 240312,
      "start": 2403.12,
      "end": 2407.04,
      "text": " is not that they've found a new idea about security breaches,",
      "tokens": [
        50364,
        307,
        406,
        300,
        436,
        600,
        1352,
        257,
        777,
        1558,
        466,
        3825,
        1403,
        13272,
        11,
        50560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21321186065673828,
      "compression_ratio": 1.5901639344262295,
      "no_speech_prob": 0.0043906234204769135
    },
    {
      "id": 314,
      "seek": 240312,
      "start": 2407.04,
      "end": 2409.88,
      "text": " but they basically go through and explain",
      "tokens": [
        50560,
        457,
        436,
        1936,
        352,
        807,
        293,
        2903,
        50702
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21321186065673828,
      "compression_ratio": 1.5901639344262295,
      "no_speech_prob": 0.0043906234204769135
    },
    {
      "id": 315,
      "seek": 240312,
      "start": 2409.88,
      "end": 2412.7999999999997,
      "text": " how in these different platforms, also including",
      "tokens": [
        50702,
        577,
        294,
        613,
        819,
        9473,
        11,
        611,
        3009,
        50848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21321186065673828,
      "compression_ratio": 1.5901639344262295,
      "no_speech_prob": 0.0043906234204769135
    },
    {
      "id": 316,
      "seek": 240312,
      "start": 2412.7999999999997,
      "end": 2417.96,
      "text": " our competitors, secrets might be leaked.",
      "tokens": [
        50848,
        527,
        18333,
        11,
        14093,
        1062,
        312,
        31779,
        13,
        51106
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21321186065673828,
      "compression_ratio": 1.5901639344262295,
      "no_speech_prob": 0.0043906234204769135
    },
    {
      "id": 317,
      "seek": 240312,
      "start": 2417.96,
      "end": 2420.3199999999997,
      "text": " So yeah, so that's not like a pressing need,",
      "tokens": [
        51106,
        407,
        1338,
        11,
        370,
        300,
        311,
        406,
        411,
        257,
        12417,
        643,
        11,
        51224
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21321186065673828,
      "compression_ratio": 1.5901639344262295,
      "no_speech_prob": 0.0043906234204769135
    },
    {
      "id": 318,
      "seek": 240312,
      "start": 2420.3199999999997,
      "end": 2423.7599999999998,
      "text": " but I think it's a nice resource.",
      "tokens": [
        51224,
        457,
        286,
        519,
        309,
        311,
        257,
        1481,
        7684,
        13,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21321186065673828,
      "compression_ratio": 1.5901639344262295,
      "no_speech_prob": 0.0043906234204769135
    },
    {
      "id": 319,
      "seek": 240312,
      "start": 2423.7599999999998,
      "end": 2426.7999999999997,
      "text": " And I also did this thing where when I first started",
      "tokens": [
        51396,
        400,
        286,
        611,
        630,
        341,
        551,
        689,
        562,
        286,
        700,
        1409,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21321186065673828,
      "compression_ratio": 1.5901639344262295,
      "no_speech_prob": 0.0043906234204769135
    },
    {
      "id": 320,
      "seek": 240312,
      "start": 2426.7999999999997,
      "end": 2431.08,
      "text": " and kind of saw that security was one of our product focuses,",
      "tokens": [
        51548,
        293,
        733,
        295,
        1866,
        300,
        3825,
        390,
        472,
        295,
        527,
        1674,
        16109,
        11,
        51762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21321186065673828,
      "compression_ratio": 1.5901639344262295,
      "no_speech_prob": 0.0043906234204769135
    },
    {
      "id": 321,
      "seek": 243108,
      "start": 2431.16,
      "end": 2434.3199999999997,
      "text": " I was watching like DevSecOps conferences",
      "tokens": [
        50368,
        286,
        390,
        1976,
        411,
        9096,
        29511,
        36179,
        22032,
        50526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30634496500203895,
      "compression_ratio": 1.5023923444976077,
      "no_speech_prob": 0.00033073066151700914
    },
    {
      "id": 322,
      "seek": 243108,
      "start": 2434.3199999999997,
      "end": 2435.48,
      "text": " and taking notes.",
      "tokens": [
        50526,
        293,
        1940,
        5570,
        13,
        50584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30634496500203895,
      "compression_ratio": 1.5023923444976077,
      "no_speech_prob": 0.00033073066151700914
    },
    {
      "id": 323,
      "seek": 243108,
      "start": 2435.48,
      "end": 2438.36,
      "text": " I saw some of you early on, I think you may remember.",
      "tokens": [
        50584,
        286,
        1866,
        512,
        295,
        291,
        2440,
        322,
        11,
        286,
        519,
        291,
        815,
        1604,
        13,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30634496500203895,
      "compression_ratio": 1.5023923444976077,
      "no_speech_prob": 0.00033073066151700914
    },
    {
      "id": 324,
      "seek": 243108,
      "start": 2438.36,
      "end": 2442.3199999999997,
      "text": " Anyway, I turned that into a plus white papers.",
      "tokens": [
        50728,
        5684,
        11,
        286,
        3574,
        300,
        666,
        257,
        1804,
        2418,
        10577,
        13,
        50926
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30634496500203895,
      "compression_ratio": 1.5023923444976077,
      "no_speech_prob": 0.00033073066151700914
    },
    {
      "id": 325,
      "seek": 243108,
      "start": 2442.3199999999997,
      "end": 2445.56,
      "text": " And so I'm like taking notes in that issue as well.",
      "tokens": [
        50926,
        400,
        370,
        286,
        478,
        411,
        1940,
        5570,
        294,
        300,
        2734,
        382,
        731,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30634496500203895,
      "compression_ratio": 1.5023923444976077,
      "no_speech_prob": 0.00033073066151700914
    },
    {
      "id": 326,
      "seek": 243108,
      "start": 2450.48,
      "end": 2451.48,
      "text": " Thanks for sharing.",
      "tokens": [
        51334,
        2561,
        337,
        5414,
        13,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30634496500203895,
      "compression_ratio": 1.5023923444976077,
      "no_speech_prob": 0.00033073066151700914
    },
    {
      "id": 327,
      "seek": 243108,
      "start": 2452.72,
      "end": 2455.64,
      "text": " I think this is exactly what I need to dive into.",
      "tokens": [
        51446,
        286,
        519,
        341,
        307,
        2293,
        437,
        286,
        643,
        281,
        9192,
        666,
        13,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30634496500203895,
      "compression_ratio": 1.5023923444976077,
      "no_speech_prob": 0.00033073066151700914
    },
    {
      "id": 328,
      "seek": 243108,
      "start": 2457.88,
      "end": 2459.7999999999997,
      "text": " Yeah, if anybody ever wonders,",
      "tokens": [
        51704,
        865,
        11,
        498,
        4472,
        1562,
        27348,
        11,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30634496500203895,
      "compression_ratio": 1.5023923444976077,
      "no_speech_prob": 0.00033073066151700914
    },
    {
      "id": 329,
      "seek": 245980,
      "start": 2459.8,
      "end": 2462.52,
      "text": " like what do we mean by hard code secrets?",
      "tokens": [
        50364,
        411,
        437,
        360,
        321,
        914,
        538,
        1152,
        3089,
        14093,
        30,
        50500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19410493638780382,
      "compression_ratio": 1.5515695067264574,
      "no_speech_prob": 0.0003572186396922916
    },
    {
      "id": 330,
      "seek": 245980,
      "start": 2462.52,
      "end": 2464.6000000000004,
      "text": " It's like right there.",
      "tokens": [
        50500,
        467,
        311,
        411,
        558,
        456,
        13,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19410493638780382,
      "compression_ratio": 1.5515695067264574,
      "no_speech_prob": 0.0003572186396922916
    },
    {
      "id": 331,
      "seek": 245980,
      "start": 2464.6000000000004,
      "end": 2468.0800000000004,
      "text": " So we can, I think this will be a good resource for us",
      "tokens": [
        50604,
        407,
        321,
        393,
        11,
        286,
        519,
        341,
        486,
        312,
        257,
        665,
        7684,
        337,
        505,
        50778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19410493638780382,
      "compression_ratio": 1.5515695067264574,
      "no_speech_prob": 0.0003572186396922916
    },
    {
      "id": 332,
      "seek": 245980,
      "start": 2468.0800000000004,
      "end": 2469.32,
      "text": " moving forward.",
      "tokens": [
        50778,
        2684,
        2128,
        13,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19410493638780382,
      "compression_ratio": 1.5515695067264574,
      "no_speech_prob": 0.0003572186396922916
    },
    {
      "id": 333,
      "seek": 245980,
      "start": 2469.32,
      "end": 2470.1600000000003,
      "text": " Yeah.",
      "tokens": [
        50840,
        865,
        13,
        50882
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19410493638780382,
      "compression_ratio": 1.5515695067264574,
      "no_speech_prob": 0.0003572186396922916
    },
    {
      "id": 334,
      "seek": 245980,
      "start": 2473.2000000000003,
      "end": 2477.8,
      "text": " I have one other question for us before we wrap up.",
      "tokens": [
        51034,
        286,
        362,
        472,
        661,
        1168,
        337,
        505,
        949,
        321,
        7019,
        493,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19410493638780382,
      "compression_ratio": 1.5515695067264574,
      "no_speech_prob": 0.0003572186396922916
    },
    {
      "id": 335,
      "seek": 245980,
      "start": 2477.8,
      "end": 2481.04,
      "text": " Would we, I'm just thinking about the order",
      "tokens": [
        51264,
        6068,
        321,
        11,
        286,
        478,
        445,
        1953,
        466,
        264,
        1668,
        51426
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19410493638780382,
      "compression_ratio": 1.5515695067264574,
      "no_speech_prob": 0.0003572186396922916
    },
    {
      "id": 336,
      "seek": 245980,
      "start": 2481.04,
      "end": 2484.96,
      "text": " that we go in when we're going through this meeting.",
      "tokens": [
        51426,
        300,
        321,
        352,
        294,
        562,
        321,
        434,
        516,
        807,
        341,
        3440,
        13,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19410493638780382,
      "compression_ratio": 1.5515695067264574,
      "no_speech_prob": 0.0003572186396922916
    },
    {
      "id": 337,
      "seek": 245980,
      "start": 2485.96,
      "end": 2489.32,
      "text": " Would anyone be interested in swapping maybe next time",
      "tokens": [
        51672,
        6068,
        2878,
        312,
        3102,
        294,
        1693,
        10534,
        1310,
        958,
        565,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19410493638780382,
      "compression_ratio": 1.5515695067264574,
      "no_speech_prob": 0.0003572186396922916
    },
    {
      "id": 338,
      "seek": 248932,
      "start": 2489.32,
      "end": 2493.76,
      "text": " so that people near the end have more time in the beginning?",
      "tokens": [
        50364,
        370,
        300,
        561,
        2651,
        264,
        917,
        362,
        544,
        565,
        294,
        264,
        2863,
        30,
        50586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 339,
      "seek": 248932,
      "start": 2496.04,
      "end": 2497.52,
      "text": " Seeing a lot of head knots.",
      "tokens": [
        50700,
        19703,
        257,
        688,
        295,
        1378,
        27426,
        13,
        50774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 340,
      "seek": 248932,
      "start": 2497.52,
      "end": 2499.36,
      "text": " Yeah, I think it's a good idea.",
      "tokens": [
        50774,
        865,
        11,
        286,
        519,
        309,
        311,
        257,
        665,
        1558,
        13,
        50866
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 341,
      "seek": 248932,
      "start": 2499.36,
      "end": 2502.1200000000003,
      "text": " How about putting research first and then design?",
      "tokens": [
        50866,
        1012,
        466,
        3372,
        2132,
        700,
        293,
        550,
        1715,
        30,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 342,
      "seek": 248932,
      "start": 2502.1200000000003,
      "end": 2503.1200000000003,
      "text": " Inquire change.",
      "tokens": [
        51004,
        682,
        358,
        621,
        1319,
        13,
        51054
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 343,
      "seek": 248932,
      "start": 2504.44,
      "end": 2507.2000000000003,
      "text": " Yeah, and we can swap the order of design too.",
      "tokens": [
        51120,
        865,
        11,
        293,
        321,
        393,
        18135,
        264,
        1668,
        295,
        1715,
        886,
        13,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 344,
      "seek": 248932,
      "start": 2510.8,
      "end": 2513.84,
      "text": " I'm doing it exactly the opposite of what it is today.",
      "tokens": [
        51438,
        286,
        478,
        884,
        309,
        2293,
        264,
        6182,
        295,
        437,
        309,
        307,
        965,
        13,
        51590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 345,
      "seek": 248932,
      "start": 2513.84,
      "end": 2515.92,
      "text": " So, I'm going to start.",
      "tokens": [
        51590,
        407,
        11,
        286,
        478,
        516,
        281,
        722,
        13,
        51694
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 346,
      "seek": 248932,
      "start": 2515.92,
      "end": 2517.52,
      "text": " Okay.",
      "tokens": [
        51694,
        1033,
        13,
        51774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 347,
      "seek": 248932,
      "start": 2517.52,
      "end": 2518.2400000000002,
      "text": " Cool.",
      "tokens": [
        51774,
        8561,
        13,
        51810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3410270839061552,
      "compression_ratio": 1.4930875576036866,
      "no_speech_prob": 0.0006742888945154846
    },
    {
      "id": 348,
      "seek": 251824,
      "start": 2518.24,
      "end": 2518.9199999999996,
      "text": " All right.",
      "tokens": [
        50364,
        1057,
        558,
        13,
        50398
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47518513997395834,
      "compression_ratio": 1.2380952380952381,
      "no_speech_prob": 0.003128010081127286
    },
    {
      "id": 349,
      "seek": 251824,
      "start": 2518.9199999999996,
      "end": 2520.7599999999998,
      "text": " I'll do that next time.",
      "tokens": [
        50398,
        286,
        603,
        360,
        300,
        958,
        565,
        13,
        50490
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47518513997395834,
      "compression_ratio": 1.2380952380952381,
      "no_speech_prob": 0.003128010081127286
    },
    {
      "id": 350,
      "seek": 251824,
      "start": 2520.7599999999998,
      "end": 2521.7599999999998,
      "text": " Thanks.",
      "tokens": [
        50490,
        2561,
        13,
        50540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47518513997395834,
      "compression_ratio": 1.2380952380952381,
      "no_speech_prob": 0.003128010081127286
    },
    {
      "id": 351,
      "seek": 251824,
      "start": 2522.9599999999996,
      "end": 2524.2,
      "text": " All right.",
      "tokens": [
        50600,
        1057,
        558,
        13,
        50662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47518513997395834,
      "compression_ratio": 1.2380952380952381,
      "no_speech_prob": 0.003128010081127286
    },
    {
      "id": 352,
      "seek": 251824,
      "start": 2524.2,
      "end": 2525.3599999999997,
      "text": " Thanks, everyone.",
      "tokens": [
        50662,
        2561,
        11,
        1518,
        13,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47518513997395834,
      "compression_ratio": 1.2380952380952381,
      "no_speech_prob": 0.003128010081127286
    },
    {
      "id": 353,
      "seek": 251824,
      "start": 2526.3199999999997,
      "end": 2527.9599999999996,
      "text": " Have a good day.",
      "tokens": [
        50768,
        3560,
        257,
        665,
        786,
        13,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47518513997395834,
      "compression_ratio": 1.2380952380952381,
      "no_speech_prob": 0.003128010081127286
    },
    {
      "id": 354,
      "seek": 251824,
      "start": 2527.9599999999996,
      "end": 2529.2799999999997,
      "text": " Thanks.",
      "tokens": [
        50850,
        2561,
        13,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47518513997395834,
      "compression_ratio": 1.2380952380952381,
      "no_speech_prob": 0.003128010081127286
    },
    {
      "id": 355,
      "seek": 251824,
      "start": 2529.2799999999997,
      "end": 2530.12,
      "text": " Thanks.",
      "tokens": [
        50916,
        2561,
        13,
        50958
      ],
      "temperature": 0.0,
      "avg_logprob": -0.47518513997395834,
      "compression_ratio": 1.2380952380952381,
      "no_speech_prob": 0.003128010081127286
    }
  ]
}