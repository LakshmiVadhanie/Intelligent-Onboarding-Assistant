{
  "title": "CI/CD UX Team Meeting - 2023-12-20",
  "video_id": "b5yBe59H2Vg",
  "url": "https://www.youtube.com/watch?v=b5yBe59H2Vg",
  "transcript": " Okay. We're good. It works. Right. Okay. Last team meeting of the year. I just want to start off by saying, it's been, it's been a crazy year. I think it's been a crazy couple of years for everyone, but yeah, I'm really happy that we've made it. It's really happy to be working with you all in 2023 looking forward to much more next year. I just wanted to like pass because there are anything that you have in mind that you like to share balls, what you're looking forward to work related, no work related in the next year. For me, for example, I'm really looking forward to the GitLab. What are we calling that now? Are we calling it Summit? We're calling Contribute Summit, right? Yeah. I really hope it happens next year. I'm taking all my spring plans around it because it would be super cool to meet you all in person, but also, yeah, just to meet again with some of our other colleagues in this traveling. So I think that's a highlight for my GitLab, GitLab bushes, but also to hire the designer and switch more to meet in a few months and board them. So these are like my plans and also something I'm looking forward to. And it can be quite annoying to have your manager ask you like, what do you want to share, but does anyone have something that they want to share in this last team call of the year? Yeah. Well, the first thing I was going to say was Summit as well. So now I'm going to try and think of something else, but again, that's one that I really haven't met many people from my immediate team. I have met a few people from our team, but it would be nice just for the first time ever to meet like a big jump to the people I work with in person, which will be really nice. I'm looking forward to figuring out what fleet visibility will look like next year. So like the first time I feel like I'm dealt with a brand new, not really a brand new feature, but it's a new category for us. So it's the first time I've dealt with that. And I think it will be very fun to collaborate with a lot of groups because it's really crossgroup. Yeah, so I'm looking forward to collaborating and figuring out what that's going to look like. And summit. We'll get on the summit trade. Eric, could you want to say something? I was just like, I didn't want to. No. Okay. I just be grateful for Erica. Right. This year and more Erica next year. Awesome. I think, oh yeah, I just before we jump into the agenda, just want to say, I was not going to take some time off next week, but I will because it's just two days. And in case any of you, I know that Emily asked for my coverage for a few days, but if anyone else that's going to be watching this recording. If you need a me as your backup, simply assign yourself in GitLab as busy. And don't forget in general to do that. And also link to your coverage issue because, yeah, if I'm not able to cover for it, we can point people in the request to the coverage issue. And you can leave comments there if needed. Yeah. Okay. Then we'll do so from top, so from top. Yes. Then over to Gina. I have a reminder that I'll be out of office for probably the longest amount of time I've ever taken here. So two weeks. And I linked my coverage issue there. Thank you for people who are covering for me. And then I have a few other items just for some ongoing work that's happening in early, well, in January, when I come back, I'll work on a competitive analysis for, or competitive evaluation for fleet visibility and. I will not state the competitors there that I will be looking at, but you can read them. And then go into that issue if you want to see more Darren has already added actually a lot of screenshots. And then I'm also working on auditing existing research and summarizing that into a video about kind of like the broader pipeline performance or how to optimize my pipeline. Erica has done a lot of research in that area that I'm also going to be just like summarizing in one place. And then there, to my not to my surprise, there is a lot of existing stuff. So we don't have to talk to more customers, which is also nice because the problems are already validated. So I'm going to speed things up a bit. And then lastly, I worked on, I worked with Graham and Alana who are two new product designers because they wanted to shadow someone while reviewing an MR. So it was a really fun experience for me. We were trying to get pipelines to be in the right states and I was like googling on the spot and we were all just like working together. They had GDK up on their instances as well. And we were working together on it and it was very valuable. So we, I opened an MR to add this officially to the onboarding template for product designers. You're welcome to jump in there. But yeah. I'm going to comment on this one. I can buy it. I left a comment in that Merge class, but you know, just in being VTika and Bonnie for feedback because VTika, wow, this is helping onboard Bonnie and they are doing something similar. So I think they had this week the first Merge class shadow call. They also were like in a call for like one hour. So they might have some some feedback. And I think this is a great addition because to your point right now that designers are assigned to rent. Randomly assigned to Merge class reviewing something out of sort of your state who can even can be if it's carrier. So I think in general, there's no opportunity for us to also define when should that happen. And who should help them with. You have to mean the process. So thanks for that. Mar. Yeah. And also I met with B this morning and she was saying that she'll create another MR because I she had some larger ideas of how to. Kind of like time box. A lot of the stuff that we have in the template. So there's going to be more changes. After that, but we were able to connect at least on the small change that I wanted to bring in. And I think that's the same page there. And she'll build on it. And that is it on for me. Emily. The first one is just an FIA. I that we're starting a new unmoderated study in 16 eight for a tree view on the Kubernetes dashboard. And a lot of competitors have a tree view of this and it's a concept that we didn't initially explore when the Kubernetes dashboard was first validated. So it's something we kind of want to sneak in there as we're working on it. And a big thanks for well will's been kind of helping me at the screener for this as well as the scenario. So thank him for his help with this study. And the second thing I wanted to say is Andrew one of the front end engineers on the team invited me to a Kubernetes meetup in Toronto last week, which was a lot of fun. It was very, very technical. So a little bit above my knowledge. But it was nice to just go kind of network with some of the people working in this area, making connections. We're also talking about maybe presenting our Kubernetes dashboard at one of these in the future. So I'm going to meet up with Vidika to see if this is something I could do speaking about and partner with Andrew so he can kind of answer all the engineering questions that come up, but it was a lot of fun. And I haven't done like an in person meetup for a while. And if no one has questions move to Vidika who's not attending. So do you want me to voice it for her? So it's I'm talking. So her first point is there's a discussion going on in PE on the time we show for duration created at started at. And it'll be helpful for some young and Gina to for and she's linked the epic for improvements. And then Gina I noticed yours is read only, but since we probably have time. Yeah, I can voice it. I brought this up. It's actually a really interesting issue. I would recommend going into it because it basic like the user saying that weren't misleading when we calculate duration for pipeline. I brought it up with the fleet team just because we have a lot of overlapping features that have to do with duration and runners and wait time and everything like that. And I left a comment for Vidika because we have some specific customer recordings of how they use duration metrics and why they're using them to optimize their pipelines. And the just a summary of what the fleet team talked about. And I would like to not be able to agree with the user that it is misleading because we're not including pending time and the duration, which is interesting and kind of weird. But anyways, I just she had asked me to jump in and just include some user stories I guess kind of like how customers are using this today. So that's what I did. Yeah, I like to inverse my comment too. I had my one on one new video today and I told her that there are some insights in one of the environments dashboard research issue. I think I did that maybe last year, this summer, that has some explanation about what the release manager is about engineers when looking context of deployments, right? They are in the pipeline pages, but looking at the point of production, what do they understand of that metadata? Why are they looking for when it comes to the duration of a pipeline or when it started running, et cetera? It might be interesting for her to look into that, but also connect with you and you might have a number updated, a more recent insight in that, but just as a reminder, I think later to what Gina said, there is some connections about the information that we need to make for many different personas. A lot of people just go to those pages, especially the pipeline view, and look for something very specific. There's a number or one tag. Keep that in mind, making this recommendations, but also look at these sites because we have them, and if you're going to find it, ask me, am I know where it is, but it's there. It's in the research project. It's the environment dashboard redesign. That's not the group level environments dash. That's the original environments. Okay. Yeah. Yeah. I think Daniel and Daniel Fosco started, and I finished that. It was before you joined Emily, but there, I remember, documented that in the off-tail, because we specifically asked about the order of the metadata and also what they want to do to why some of this effort is relevant. But anyways, missions like one or two insights about that. It's the environments dashboard redesign. Also, just another small note about this. I know that the issue was about the pipeline duration, and another thing that I was thinking about is that a lot of these metrics are, I think, more useful at the job level rather than the pipeline level, because each, even if the same pipeline runs, and so a pipeline is designated for a project. If that pipeline runs multiple times, the same, it might have a different set of jobs that run every time, because jobs can be skipped in it, whatever. So yeah, I think it's hard to think about this at the pipeline level, just because there's so many changes that could happen with each run. Hey, I can move on to our next point if we're done. Cool. And the next one is, we get to get started by identifying our UI in 16-8. There's many MRAs that emerged already, and now have validation in the form of that work. And Alvoise, Bonnie's comment here, if you want to take a look at the list of items, Maria, and her are working on. I think that's just a question for Vittica when she watches this. I think it's the opposite. I think it's Vittica's comment. Vittica's comment too, Bonnie. Okay. A buddy. Yeah. Got any questions? Yeah, because Maria is an intront and engineer in Tinas. No, no, that's right. Maria said that, sorry. Too many teams. You're right. No, so we're confused because it could be that 16-8, we're defining something Vittica's newbie, maybe with Maria. Anyways, they can figure it. I can take a look at the agenda. That's it for Vittica. Yeah. So, Bonnie and Syngen, I'm not here. And then my only update for Switchboard is that it's too hard and it's too interviewing. I don't have an interview scheduled for, well, this year and more. So hopefully by January, we'll pick up with more interviews than fingers crossed, hire someone to begin the year. And over to Eric. Yes. So, I posted the link to the draft of the report for the runner and CI Builder's Build, Builds Feature Prioritization Survey. So we did a Kano survey with 11 features to see how they got prioritized. The signal we would be looking for is if there was like one must have that we would want to champion. Actually, they were all either attractive or indifferent. So like, kind of cool, but like nothing like that we have a clear signal to deliver on. Looking across the ones that were in the attractive bucket versus the indifferent bucket, we have a signal that users want AI assisted things. Like, for example, like custom dashboards are actually not compelling because it's war work for them. But if it can be like AI assisted, then it's like attractive, but still not a must have. And so, Darren and Gina and I are going to go over that report in depth tomorrow. But I thought I would like give the high level overview that we don't have any must have. So I think it means that we're on the right track with like figuring out those little optimizations suggestions, which is a read we got from that qualitative study. And we wanted to do this just to make sure that there wasn't something that was like so cool across this bigger sample of users that we missed, but we didn't. So it kind of doesn't change the strategy in a way. I've also noticing that the sample was mainly small medium businesses. Yeah, two. Two. And I want, yeah, which is fine. Like, I kind of had the assumption that they had different interests than the enterprise customers that we're talking to that are self-managed. I, we did have, yeah, it's totally right. Very keen. The thing is, I think this idea that it would create more work still holds. Yes. I agree. But I guess my point is I feel like they have different needs because enterprise customers, first of all, are typically self-managed bringing a ton of runners. So when I look at the features profile as attractive, I would imagine runner usage and compute minutes are higher up on that than for small business, smaller medium business. Yeah. Yeah. And I assigned a fidelity of signal score to to kind of help us make sense of it. I think what we can do is really look at the, the, the five features that have strong, we have strong, have it like a strong signal that they're indifferent to. That's kind of the most. Okay. Oh, it's like, okay, don't invest heavily in these. Okay. Yeah. Oh, that's also so interesting though, because the notifications, I don't know, it's, yeah, because, yeah, because it's just, it could end up really distracting them, the notifications parts. Right. And it could take them out of their flow. Yeah. I guess that makes sense. But there, but then I guess does that mean that we just think about different ways of solving when your cube performance stinks or when your runners are airing out a lot, like we have to figure out of different ways to give them that information. I don't know. Or at least make the notifications like customizable as opposed to like across the board. So it's like, you know, they don't want to get like all of their runners aren't important to them. It might be like only this subset. So like allowing them to opt in. Yeah. Gin model versus like opting out. Okay. It's like just, we should just be really wary of creating more pings and they're already busy. Yeah. I totally understand that. This is really cool though, Erica. I'm going to look, this is my first time actually seeing it. So I'm going to look deeper into it. And I think our meetings tomorrow. Yeah. Yeah. And let me know what we what to do. But I think it's a really good critique of the of the sample that's like really on point. I just think that the problems that we're seeing with those features should also have a problem. Like notifications for enterprise level participants would skate that would scale that finding kind of right. Definitely. Yes. I was looking more at slide seven of the ones that are attractive because I figured the ones that are said they're set at week there. I would have thought that they would be higher up for enterprise users. But the findings that in slide eight definitely relate to all I totally agree. Yeah. Yeah. So we can decide. I think the thing is we didn't get a clear. I mean, I thought we might get a clear like champion here. So that's like important that we don't want to like sprint towards any one of these particular visions. And I think that like this AI assisted is the way that we want to be thinking about it. Like yeah, behind the scenes, they just wanted behind the scenes. Yeah. Okay, I have some more questions, but I don't want to take up a ton of time. Okay. I'm tomorrow. Cool everyone, don't you care? Yeah. And let me know if you want to seek today too. Okay. Yeah. And then or just slack about it. And then the other study I'm working on is this conversational AI study, which is like a team of researchers and I'm working with ops folks. And we were asking we did like an intro interview and then they're doing a diary study where every two to three days they let us know the tasks that they performed with conversational AI and how it went and they're giving a screenshots of those. And so we're getting a sense of how we might use conversational AI in the app space. Although we think it's not related to performance. Automations like we got a signal that they that's inefficient use of their time. It's more like it looks more like they like it like as an idea generator or like getting the right language to use for documentation searches, stuff like that. Anyway, but I'm threading the like really technical example tasks in that thread I linked. And we'll we'll be doing the follow up interviews with them in the second and third week of January. And so we'll be asking people to like give me follow up questions to ask about those tasks. Trying to put that on your radar. And then the next thing is I was initially thinking that we would run that shared resources workshop at the summit, but I think we should do it after the summit because it seems like I'll be like the only nerd being like, hey, let's work. But let me know if you want to go rock climbing because there's a rock climbing issue that someone created. Okay. Work or rock climbing. That's all I've got. We can have the workshop while rock climbing. That's a real challenge. Okay, we're too happy with that. But I think it's a good idea because yeah, you know, maybe some of us will also take some time off after summit or before right and some traveling. I think it's good. Well, once it gets confirmed, we can play in the round the summit for that. And if not, we'll just, you know, pick a date in Q. Is it going to be Q2? Things going to be Q2, right? Yeah, kind of Q2. Yeah, I think it's a safer. Anyway, no? Okay. I think that's that, right? We'll, it's already off. Anything else? We didn't discuss. We'd like to share before wrap up for the year. Goodness. And thank you, Emily, for recording this. And yeah, enjoy the rest of your day. I'll see you later. I'll see you later. See you next year. Enjoy your time off. Bye. Bye.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 1.0,
      "text": " Okay.",
      "tokens": [
        50364,
        1033,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 1,
      "seek": 0,
      "start": 1.0,
      "end": 3.48,
      "text": " We're good.",
      "tokens": [
        50414,
        492,
        434,
        665,
        13,
        50538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 2,
      "seek": 0,
      "start": 3.48,
      "end": 4.48,
      "text": " It works.",
      "tokens": [
        50538,
        467,
        1985,
        13,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 3,
      "seek": 0,
      "start": 4.48,
      "end": 5.48,
      "text": " Right.",
      "tokens": [
        50588,
        1779,
        13,
        50638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 4,
      "seek": 0,
      "start": 5.48,
      "end": 6.48,
      "text": " Okay.",
      "tokens": [
        50638,
        1033,
        13,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 5,
      "seek": 0,
      "start": 6.48,
      "end": 9.52,
      "text": " Last team meeting of the year.",
      "tokens": [
        50688,
        5264,
        1469,
        3440,
        295,
        264,
        1064,
        13,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 6,
      "seek": 0,
      "start": 9.52,
      "end": 15.92,
      "text": " I just want to start off by saying, it's been, it's been a crazy year.",
      "tokens": [
        50840,
        286,
        445,
        528,
        281,
        722,
        766,
        538,
        1566,
        11,
        309,
        311,
        668,
        11,
        309,
        311,
        668,
        257,
        3219,
        1064,
        13,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 7,
      "seek": 0,
      "start": 15.92,
      "end": 21.400000000000002,
      "text": " I think it's been a crazy couple of years for everyone, but yeah, I'm really happy that",
      "tokens": [
        51160,
        286,
        519,
        309,
        311,
        668,
        257,
        3219,
        1916,
        295,
        924,
        337,
        1518,
        11,
        457,
        1338,
        11,
        286,
        478,
        534,
        2055,
        300,
        51434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 8,
      "seek": 0,
      "start": 21.400000000000002,
      "end": 22.400000000000002,
      "text": " we've made it.",
      "tokens": [
        51434,
        321,
        600,
        1027,
        309,
        13,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 9,
      "seek": 0,
      "start": 22.400000000000002,
      "end": 27.8,
      "text": " It's really happy to be working with you all in 2023 looking forward to much more next",
      "tokens": [
        51484,
        467,
        311,
        534,
        2055,
        281,
        312,
        1364,
        365,
        291,
        439,
        294,
        44377,
        1237,
        2128,
        281,
        709,
        544,
        958,
        51754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 10,
      "seek": 0,
      "start": 27.8,
      "end": 28.8,
      "text": " year.",
      "tokens": [
        51754,
        1064,
        13,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30015893415971234,
      "compression_ratio": 1.572093023255814,
      "no_speech_prob": 0.012189342640340328
    },
    {
      "id": 11,
      "seek": 2880,
      "start": 28.8,
      "end": 35.88,
      "text": " I just wanted to like pass because there are anything that you have in mind that you",
      "tokens": [
        50364,
        286,
        445,
        1415,
        281,
        411,
        1320,
        570,
        456,
        366,
        1340,
        300,
        291,
        362,
        294,
        1575,
        300,
        291,
        50718
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3197761465001989,
      "compression_ratio": 1.7035398230088497,
      "no_speech_prob": 0.01704418659210205
    },
    {
      "id": 12,
      "seek": 2880,
      "start": 35.88,
      "end": 40.52,
      "text": " like to share balls, what you're looking forward to work related, no work related in the",
      "tokens": [
        50718,
        411,
        281,
        2073,
        9803,
        11,
        437,
        291,
        434,
        1237,
        2128,
        281,
        589,
        4077,
        11,
        572,
        589,
        4077,
        294,
        264,
        50950
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3197761465001989,
      "compression_ratio": 1.7035398230088497,
      "no_speech_prob": 0.01704418659210205
    },
    {
      "id": 13,
      "seek": 2880,
      "start": 40.52,
      "end": 42.72,
      "text": " next year.",
      "tokens": [
        50950,
        958,
        1064,
        13,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3197761465001989,
      "compression_ratio": 1.7035398230088497,
      "no_speech_prob": 0.01704418659210205
    },
    {
      "id": 14,
      "seek": 2880,
      "start": 42.72,
      "end": 48.120000000000005,
      "text": " For me, for example, I'm really looking forward to the GitLab.",
      "tokens": [
        51060,
        1171,
        385,
        11,
        337,
        1365,
        11,
        286,
        478,
        534,
        1237,
        2128,
        281,
        264,
        16939,
        37880,
        13,
        51330
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3197761465001989,
      "compression_ratio": 1.7035398230088497,
      "no_speech_prob": 0.01704418659210205
    },
    {
      "id": 15,
      "seek": 2880,
      "start": 48.120000000000005,
      "end": 49.120000000000005,
      "text": " What are we calling that now?",
      "tokens": [
        51330,
        708,
        366,
        321,
        5141,
        300,
        586,
        30,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3197761465001989,
      "compression_ratio": 1.7035398230088497,
      "no_speech_prob": 0.01704418659210205
    },
    {
      "id": 16,
      "seek": 2880,
      "start": 49.120000000000005,
      "end": 50.120000000000005,
      "text": " Are we calling it Summit?",
      "tokens": [
        51380,
        2014,
        321,
        5141,
        309,
        28726,
        30,
        51430
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3197761465001989,
      "compression_ratio": 1.7035398230088497,
      "no_speech_prob": 0.01704418659210205
    },
    {
      "id": 17,
      "seek": 2880,
      "start": 50.120000000000005,
      "end": 52.72,
      "text": " We're calling Contribute Summit, right?",
      "tokens": [
        51430,
        492,
        434,
        5141,
        4839,
        2024,
        1169,
        28726,
        11,
        558,
        30,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3197761465001989,
      "compression_ratio": 1.7035398230088497,
      "no_speech_prob": 0.01704418659210205
    },
    {
      "id": 18,
      "seek": 2880,
      "start": 52.72,
      "end": 53.72,
      "text": " Yeah.",
      "tokens": [
        51560,
        865,
        13,
        51610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3197761465001989,
      "compression_ratio": 1.7035398230088497,
      "no_speech_prob": 0.01704418659210205
    },
    {
      "id": 19,
      "seek": 2880,
      "start": 53.72,
      "end": 56.64,
      "text": " I really hope it happens next year.",
      "tokens": [
        51610,
        286,
        534,
        1454,
        309,
        2314,
        958,
        1064,
        13,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3197761465001989,
      "compression_ratio": 1.7035398230088497,
      "no_speech_prob": 0.01704418659210205
    },
    {
      "id": 20,
      "seek": 5664,
      "start": 56.64,
      "end": 62.52,
      "text": " I'm taking all my spring plans around it because it would be super cool to meet you all",
      "tokens": [
        50364,
        286,
        478,
        1940,
        439,
        452,
        5587,
        5482,
        926,
        309,
        570,
        309,
        576,
        312,
        1687,
        1627,
        281,
        1677,
        291,
        439,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3867808688770641,
      "compression_ratio": 1.5586854460093897,
      "no_speech_prob": 0.0730019062757492
    },
    {
      "id": 21,
      "seek": 5664,
      "start": 62.52,
      "end": 68.72,
      "text": " in person, but also, yeah, just to meet again with some of our other colleagues in this",
      "tokens": [
        50658,
        294,
        954,
        11,
        457,
        611,
        11,
        1338,
        11,
        445,
        281,
        1677,
        797,
        365,
        512,
        295,
        527,
        661,
        7734,
        294,
        341,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3867808688770641,
      "compression_ratio": 1.5586854460093897,
      "no_speech_prob": 0.0730019062757492
    },
    {
      "id": 22,
      "seek": 5664,
      "start": 68.72,
      "end": 69.72,
      "text": " traveling.",
      "tokens": [
        50968,
        9712,
        13,
        51018
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3867808688770641,
      "compression_ratio": 1.5586854460093897,
      "no_speech_prob": 0.0730019062757492
    },
    {
      "id": 23,
      "seek": 5664,
      "start": 69.72,
      "end": 77.6,
      "text": " So I think that's a highlight for my GitLab, GitLab bushes, but also to hire the designer",
      "tokens": [
        51018,
        407,
        286,
        519,
        300,
        311,
        257,
        5078,
        337,
        452,
        16939,
        37880,
        11,
        16939,
        37880,
        34303,
        11,
        457,
        611,
        281,
        11158,
        264,
        11795,
        51412
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3867808688770641,
      "compression_ratio": 1.5586854460093897,
      "no_speech_prob": 0.0730019062757492
    },
    {
      "id": 24,
      "seek": 5664,
      "start": 77.6,
      "end": 83.32,
      "text": " and switch more to meet in a few months and board them.",
      "tokens": [
        51412,
        293,
        3679,
        544,
        281,
        1677,
        294,
        257,
        1326,
        2493,
        293,
        3150,
        552,
        13,
        51698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3867808688770641,
      "compression_ratio": 1.5586854460093897,
      "no_speech_prob": 0.0730019062757492
    },
    {
      "id": 25,
      "seek": 8332,
      "start": 83.32,
      "end": 88.32,
      "text": " So these are like my plans and also something I'm looking forward to.",
      "tokens": [
        50364,
        407,
        613,
        366,
        411,
        452,
        5482,
        293,
        611,
        746,
        286,
        478,
        1237,
        2128,
        281,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23305304845174155,
      "compression_ratio": 1.7100840336134453,
      "no_speech_prob": 0.08147235214710236
    },
    {
      "id": 26,
      "seek": 8332,
      "start": 88.32,
      "end": 92.91999999999999,
      "text": " And it can be quite annoying to have your manager ask you like, what do you want to share,",
      "tokens": [
        50614,
        400,
        309,
        393,
        312,
        1596,
        11304,
        281,
        362,
        428,
        6598,
        1029,
        291,
        411,
        11,
        437,
        360,
        291,
        528,
        281,
        2073,
        11,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23305304845174155,
      "compression_ratio": 1.7100840336134453,
      "no_speech_prob": 0.08147235214710236
    },
    {
      "id": 27,
      "seek": 8332,
      "start": 92.91999999999999,
      "end": 100.0,
      "text": " but does anyone have something that they want to share in this last team call of the year?",
      "tokens": [
        50844,
        457,
        775,
        2878,
        362,
        746,
        300,
        436,
        528,
        281,
        2073,
        294,
        341,
        1036,
        1469,
        818,
        295,
        264,
        1064,
        30,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23305304845174155,
      "compression_ratio": 1.7100840336134453,
      "no_speech_prob": 0.08147235214710236
    },
    {
      "id": 28,
      "seek": 8332,
      "start": 100.0,
      "end": 101.0,
      "text": " Yeah.",
      "tokens": [
        51198,
        865,
        13,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23305304845174155,
      "compression_ratio": 1.7100840336134453,
      "no_speech_prob": 0.08147235214710236
    },
    {
      "id": 29,
      "seek": 8332,
      "start": 101.0,
      "end": 106.0,
      "text": " Well, the first thing I was going to say was Summit as well.",
      "tokens": [
        51248,
        1042,
        11,
        264,
        700,
        551,
        286,
        390,
        516,
        281,
        584,
        390,
        28726,
        382,
        731,
        13,
        51498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23305304845174155,
      "compression_ratio": 1.7100840336134453,
      "no_speech_prob": 0.08147235214710236
    },
    {
      "id": 30,
      "seek": 8332,
      "start": 106.0,
      "end": 111.0,
      "text": " So now I'm going to try and think of something else, but again, that's one that I really",
      "tokens": [
        51498,
        407,
        586,
        286,
        478,
        516,
        281,
        853,
        293,
        519,
        295,
        746,
        1646,
        11,
        457,
        797,
        11,
        300,
        311,
        472,
        300,
        286,
        534,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23305304845174155,
      "compression_ratio": 1.7100840336134453,
      "no_speech_prob": 0.08147235214710236
    },
    {
      "id": 31,
      "seek": 11100,
      "start": 111.0,
      "end": 113.96,
      "text": " haven't met many people from my immediate team.",
      "tokens": [
        50364,
        2378,
        380,
        1131,
        867,
        561,
        490,
        452,
        11629,
        1469,
        13,
        50512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21208413441975912,
      "compression_ratio": 1.5794871794871794,
      "no_speech_prob": 0.0041563683189451694
    },
    {
      "id": 32,
      "seek": 11100,
      "start": 113.96,
      "end": 118.68,
      "text": " I have met a few people from our team, but it would be nice just for the first time ever",
      "tokens": [
        50512,
        286,
        362,
        1131,
        257,
        1326,
        561,
        490,
        527,
        1469,
        11,
        457,
        309,
        576,
        312,
        1481,
        445,
        337,
        264,
        700,
        565,
        1562,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21208413441975912,
      "compression_ratio": 1.5794871794871794,
      "no_speech_prob": 0.0041563683189451694
    },
    {
      "id": 33,
      "seek": 11100,
      "start": 118.68,
      "end": 125.48,
      "text": " to meet like a big jump to the people I work with in person, which will be really nice.",
      "tokens": [
        50748,
        281,
        1677,
        411,
        257,
        955,
        3012,
        281,
        264,
        561,
        286,
        589,
        365,
        294,
        954,
        11,
        597,
        486,
        312,
        534,
        1481,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21208413441975912,
      "compression_ratio": 1.5794871794871794,
      "no_speech_prob": 0.0041563683189451694
    },
    {
      "id": 34,
      "seek": 11100,
      "start": 125.48,
      "end": 137.96,
      "text": " I'm looking forward to figuring out what fleet visibility will look like next year.",
      "tokens": [
        51088,
        286,
        478,
        1237,
        2128,
        281,
        15213,
        484,
        437,
        19396,
        19883,
        486,
        574,
        411,
        958,
        1064,
        13,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21208413441975912,
      "compression_ratio": 1.5794871794871794,
      "no_speech_prob": 0.0041563683189451694
    },
    {
      "id": 35,
      "seek": 13796,
      "start": 138.84,
      "end": 144.84,
      "text": " So like the first time I feel like I'm dealt with a brand new, not really a brand new feature,",
      "tokens": [
        50408,
        407,
        411,
        264,
        700,
        565,
        286,
        841,
        411,
        286,
        478,
        15991,
        365,
        257,
        3360,
        777,
        11,
        406,
        534,
        257,
        3360,
        777,
        4111,
        11,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14260084775029397,
      "compression_ratio": 1.7183098591549295,
      "no_speech_prob": 0.0034481568727642298
    },
    {
      "id": 36,
      "seek": 13796,
      "start": 144.84,
      "end": 148.16,
      "text": " but it's a new category for us.",
      "tokens": [
        50708,
        457,
        309,
        311,
        257,
        777,
        7719,
        337,
        505,
        13,
        50874
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14260084775029397,
      "compression_ratio": 1.7183098591549295,
      "no_speech_prob": 0.0034481568727642298
    },
    {
      "id": 37,
      "seek": 13796,
      "start": 148.16,
      "end": 150.24,
      "text": " So it's the first time I've dealt with that.",
      "tokens": [
        50874,
        407,
        309,
        311,
        264,
        700,
        565,
        286,
        600,
        15991,
        365,
        300,
        13,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14260084775029397,
      "compression_ratio": 1.7183098591549295,
      "no_speech_prob": 0.0034481568727642298
    },
    {
      "id": 38,
      "seek": 13796,
      "start": 150.24,
      "end": 159.88,
      "text": " And I think it will be very fun to collaborate with a lot of groups because it's really crossgroup.",
      "tokens": [
        50978,
        400,
        286,
        519,
        309,
        486,
        312,
        588,
        1019,
        281,
        18338,
        365,
        257,
        688,
        295,
        3935,
        570,
        309,
        311,
        534,
        3278,
        17377,
        13,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14260084775029397,
      "compression_ratio": 1.7183098591549295,
      "no_speech_prob": 0.0034481568727642298
    },
    {
      "id": 39,
      "seek": 13796,
      "start": 159.88,
      "end": 166.08,
      "text": " Yeah, so I'm looking forward to collaborating and figuring out what that's going to look like.",
      "tokens": [
        51460,
        865,
        11,
        370,
        286,
        478,
        1237,
        2128,
        281,
        30188,
        293,
        15213,
        484,
        437,
        300,
        311,
        516,
        281,
        574,
        411,
        13,
        51770
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14260084775029397,
      "compression_ratio": 1.7183098591549295,
      "no_speech_prob": 0.0034481568727642298
    },
    {
      "id": 40,
      "seek": 16608,
      "start": 166.08,
      "end": 167.08,
      "text": " And summit.",
      "tokens": [
        50364,
        400,
        21564,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44991944760692365,
      "compression_ratio": 1.1454545454545455,
      "no_speech_prob": 0.020672697573900223
    },
    {
      "id": 41,
      "seek": 16608,
      "start": 167.08,
      "end": 169.08,
      "text": " We'll get on the summit trade.",
      "tokens": [
        50414,
        492,
        603,
        483,
        322,
        264,
        21564,
        4923,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44991944760692365,
      "compression_ratio": 1.1454545454545455,
      "no_speech_prob": 0.020672697573900223
    },
    {
      "id": 42,
      "seek": 16608,
      "start": 184.08,
      "end": 185.08,
      "text": " Eric, could you want to say something?",
      "tokens": [
        51264,
        9336,
        11,
        727,
        291,
        528,
        281,
        584,
        746,
        30,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44991944760692365,
      "compression_ratio": 1.1454545454545455,
      "no_speech_prob": 0.020672697573900223
    },
    {
      "id": 43,
      "seek": 16608,
      "start": 185.08,
      "end": 188.08,
      "text": " I was just like, I didn't want to.",
      "tokens": [
        51314,
        286,
        390,
        445,
        411,
        11,
        286,
        994,
        380,
        528,
        281,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44991944760692365,
      "compression_ratio": 1.1454545454545455,
      "no_speech_prob": 0.020672697573900223
    },
    {
      "id": 44,
      "seek": 16608,
      "start": 189.08,
      "end": 190.08,
      "text": " No.",
      "tokens": [
        51514,
        883,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44991944760692365,
      "compression_ratio": 1.1454545454545455,
      "no_speech_prob": 0.020672697573900223
    },
    {
      "id": 45,
      "seek": 16608,
      "start": 191.08,
      "end": 192.08,
      "text": " Okay.",
      "tokens": [
        51614,
        1033,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44991944760692365,
      "compression_ratio": 1.1454545454545455,
      "no_speech_prob": 0.020672697573900223
    },
    {
      "id": 46,
      "seek": 19208,
      "start": 193.08,
      "end": 195.08,
      "text": " I just be grateful for Erica.",
      "tokens": [
        50414,
        286,
        445,
        312,
        7941,
        337,
        37429,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2720171523420778,
      "compression_ratio": 1.4523809523809523,
      "no_speech_prob": 0.05828265845775604
    },
    {
      "id": 47,
      "seek": 19208,
      "start": 195.08,
      "end": 196.08,
      "text": " Right.",
      "tokens": [
        50514,
        1779,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2720171523420778,
      "compression_ratio": 1.4523809523809523,
      "no_speech_prob": 0.05828265845775604
    },
    {
      "id": 48,
      "seek": 19208,
      "start": 196.08,
      "end": 199.08,
      "text": " This year and more Erica next year.",
      "tokens": [
        50564,
        639,
        1064,
        293,
        544,
        37429,
        958,
        1064,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2720171523420778,
      "compression_ratio": 1.4523809523809523,
      "no_speech_prob": 0.05828265845775604
    },
    {
      "id": 49,
      "seek": 19208,
      "start": 199.08,
      "end": 201.08,
      "text": " Awesome.",
      "tokens": [
        50714,
        10391,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2720171523420778,
      "compression_ratio": 1.4523809523809523,
      "no_speech_prob": 0.05828265845775604
    },
    {
      "id": 50,
      "seek": 19208,
      "start": 201.08,
      "end": 212.08,
      "text": " I think, oh yeah, I just before we jump into the agenda, just want to say, I was not going to take some time off next week, but I will because it's just two days.",
      "tokens": [
        50814,
        286,
        519,
        11,
        1954,
        1338,
        11,
        286,
        445,
        949,
        321,
        3012,
        666,
        264,
        9829,
        11,
        445,
        528,
        281,
        584,
        11,
        286,
        390,
        406,
        516,
        281,
        747,
        512,
        565,
        766,
        958,
        1243,
        11,
        457,
        286,
        486,
        570,
        309,
        311,
        445,
        732,
        1708,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2720171523420778,
      "compression_ratio": 1.4523809523809523,
      "no_speech_prob": 0.05828265845775604
    },
    {
      "id": 51,
      "seek": 21208,
      "start": 212.08,
      "end": 222.08,
      "text": " And in case any of you, I know that Emily asked for my coverage for a few days, but if anyone else that's going to be watching this recording.",
      "tokens": [
        50364,
        400,
        294,
        1389,
        604,
        295,
        291,
        11,
        286,
        458,
        300,
        15034,
        2351,
        337,
        452,
        9645,
        337,
        257,
        1326,
        1708,
        11,
        457,
        498,
        2878,
        1646,
        300,
        311,
        516,
        281,
        312,
        1976,
        341,
        6613,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21400860639718863,
      "compression_ratio": 1.6129032258064515,
      "no_speech_prob": 0.15606391429901123
    },
    {
      "id": 52,
      "seek": 21208,
      "start": 222.08,
      "end": 228.08,
      "text": " If you need a me as your backup, simply assign yourself in GitLab as busy.",
      "tokens": [
        50864,
        759,
        291,
        643,
        257,
        385,
        382,
        428,
        14807,
        11,
        2935,
        6269,
        1803,
        294,
        16939,
        37880,
        382,
        5856,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21400860639718863,
      "compression_ratio": 1.6129032258064515,
      "no_speech_prob": 0.15606391429901123
    },
    {
      "id": 53,
      "seek": 21208,
      "start": 228.08,
      "end": 230.08,
      "text": " And don't forget in general to do that.",
      "tokens": [
        51164,
        400,
        500,
        380,
        2870,
        294,
        2674,
        281,
        360,
        300,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21400860639718863,
      "compression_ratio": 1.6129032258064515,
      "no_speech_prob": 0.15606391429901123
    },
    {
      "id": 54,
      "seek": 21208,
      "start": 230.08,
      "end": 241.08,
      "text": " And also link to your coverage issue because, yeah, if I'm not able to cover for it, we can point people in the request to the coverage issue.",
      "tokens": [
        51264,
        400,
        611,
        2113,
        281,
        428,
        9645,
        2734,
        570,
        11,
        1338,
        11,
        498,
        286,
        478,
        406,
        1075,
        281,
        2060,
        337,
        309,
        11,
        321,
        393,
        935,
        561,
        294,
        264,
        5308,
        281,
        264,
        9645,
        2734,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21400860639718863,
      "compression_ratio": 1.6129032258064515,
      "no_speech_prob": 0.15606391429901123
    },
    {
      "id": 55,
      "seek": 24108,
      "start": 241.08,
      "end": 244.08,
      "text": " And you can leave comments there if needed.",
      "tokens": [
        50364,
        400,
        291,
        393,
        1856,
        3053,
        456,
        498,
        2978,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 56,
      "seek": 24108,
      "start": 244.08,
      "end": 246.08,
      "text": " Yeah.",
      "tokens": [
        50514,
        865,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 57,
      "seek": 24108,
      "start": 246.08,
      "end": 247.08,
      "text": " Okay.",
      "tokens": [
        50614,
        1033,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 58,
      "seek": 24108,
      "start": 247.08,
      "end": 249.08,
      "text": " Then we'll do so from top, so from top.",
      "tokens": [
        50664,
        1396,
        321,
        603,
        360,
        370,
        490,
        1192,
        11,
        370,
        490,
        1192,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 59,
      "seek": 24108,
      "start": 249.08,
      "end": 250.08,
      "text": " Yes.",
      "tokens": [
        50764,
        1079,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 60,
      "seek": 24108,
      "start": 250.08,
      "end": 252.08,
      "text": " Then over to Gina.",
      "tokens": [
        50814,
        1396,
        670,
        281,
        34711,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 61,
      "seek": 24108,
      "start": 252.08,
      "end": 260.08000000000004,
      "text": " I have a reminder that I'll be out of office for probably the longest amount of time I've ever taken here.",
      "tokens": [
        50914,
        286,
        362,
        257,
        13548,
        300,
        286,
        603,
        312,
        484,
        295,
        3398,
        337,
        1391,
        264,
        15438,
        2372,
        295,
        565,
        286,
        600,
        1562,
        2726,
        510,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 62,
      "seek": 24108,
      "start": 260.08000000000004,
      "end": 262.08000000000004,
      "text": " So two weeks.",
      "tokens": [
        51314,
        407,
        732,
        3259,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 63,
      "seek": 24108,
      "start": 262.08000000000004,
      "end": 265.08000000000004,
      "text": " And I linked my coverage issue there.",
      "tokens": [
        51414,
        400,
        286,
        9408,
        452,
        9645,
        2734,
        456,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 64,
      "seek": 24108,
      "start": 265.08000000000004,
      "end": 269.08000000000004,
      "text": " Thank you for people who are covering for me.",
      "tokens": [
        51564,
        1044,
        291,
        337,
        561,
        567,
        366,
        10322,
        337,
        385,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22703521728515624,
      "compression_ratio": 1.5211267605633803,
      "no_speech_prob": 0.0021008318290114403
    },
    {
      "id": 65,
      "seek": 26908,
      "start": 269.08,
      "end": 284.08,
      "text": " And then I have a few other items just for some ongoing work that's happening in early, well, in January, when I come back, I'll work on a competitive analysis for, or competitive evaluation for fleet visibility and.",
      "tokens": [
        50364,
        400,
        550,
        286,
        362,
        257,
        1326,
        661,
        4754,
        445,
        337,
        512,
        10452,
        589,
        300,
        311,
        2737,
        294,
        2440,
        11,
        731,
        11,
        294,
        7061,
        11,
        562,
        286,
        808,
        646,
        11,
        286,
        603,
        589,
        322,
        257,
        10043,
        5215,
        337,
        11,
        420,
        10043,
        13344,
        337,
        19396,
        19883,
        293,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13191527790493435,
      "compression_ratio": 1.564102564102564,
      "no_speech_prob": 0.0026471123564988375
    },
    {
      "id": 66,
      "seek": 26908,
      "start": 284.08,
      "end": 291.08,
      "text": " I will not state the competitors there that I will be looking at, but you can read them.",
      "tokens": [
        51114,
        286,
        486,
        406,
        1785,
        264,
        18333,
        456,
        300,
        286,
        486,
        312,
        1237,
        412,
        11,
        457,
        291,
        393,
        1401,
        552,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13191527790493435,
      "compression_ratio": 1.564102564102564,
      "no_speech_prob": 0.0026471123564988375
    },
    {
      "id": 67,
      "seek": 29108,
      "start": 291.08,
      "end": 299.08,
      "text": " And then go into that issue if you want to see more Darren has already added actually a lot of screenshots.",
      "tokens": [
        50364,
        400,
        550,
        352,
        666,
        300,
        2734,
        498,
        291,
        528,
        281,
        536,
        544,
        36691,
        575,
        1217,
        3869,
        767,
        257,
        688,
        295,
        40661,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12423449657002433,
      "compression_ratio": 1.5026737967914439,
      "no_speech_prob": 0.03483985736966133
    },
    {
      "id": 68,
      "seek": 29108,
      "start": 299.08,
      "end": 312.08,
      "text": " And then I'm also working on auditing existing research and summarizing that into a video about kind of like the broader pipeline performance or how to optimize my pipeline.",
      "tokens": [
        50764,
        400,
        550,
        286,
        478,
        611,
        1364,
        322,
        2379,
        1748,
        6741,
        2132,
        293,
        14611,
        3319,
        300,
        666,
        257,
        960,
        466,
        733,
        295,
        411,
        264,
        13227,
        15517,
        3389,
        420,
        577,
        281,
        19719,
        452,
        15517,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12423449657002433,
      "compression_ratio": 1.5026737967914439,
      "no_speech_prob": 0.03483985736966133
    },
    {
      "id": 69,
      "seek": 31208,
      "start": 312.08,
      "end": 318.08,
      "text": " Erica has done a lot of research in that area that I'm also going to be just like summarizing in one place.",
      "tokens": [
        50364,
        37429,
        575,
        1096,
        257,
        688,
        295,
        2132,
        294,
        300,
        1859,
        300,
        286,
        478,
        611,
        516,
        281,
        312,
        445,
        411,
        14611,
        3319,
        294,
        472,
        1081,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1377606520781646,
      "compression_ratio": 1.5025906735751295,
      "no_speech_prob": 0.007848620414733887
    },
    {
      "id": 70,
      "seek": 31208,
      "start": 318.08,
      "end": 324.08,
      "text": " And then there, to my not to my surprise, there is a lot of existing stuff.",
      "tokens": [
        50664,
        400,
        550,
        456,
        11,
        281,
        452,
        406,
        281,
        452,
        6365,
        11,
        456,
        307,
        257,
        688,
        295,
        6741,
        1507,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1377606520781646,
      "compression_ratio": 1.5025906735751295,
      "no_speech_prob": 0.007848620414733887
    },
    {
      "id": 71,
      "seek": 31208,
      "start": 324.08,
      "end": 330.08,
      "text": " So we don't have to talk to more customers, which is also nice because the problems are already validated.",
      "tokens": [
        50964,
        407,
        321,
        500,
        380,
        362,
        281,
        751,
        281,
        544,
        4581,
        11,
        597,
        307,
        611,
        1481,
        570,
        264,
        2740,
        366,
        1217,
        40693,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1377606520781646,
      "compression_ratio": 1.5025906735751295,
      "no_speech_prob": 0.007848620414733887
    },
    {
      "id": 72,
      "seek": 33008,
      "start": 330.08,
      "end": 345.08,
      "text": " So I'm going to speed things up a bit. And then lastly, I worked on, I worked with Graham and Alana who are two new product designers because they wanted to shadow someone while reviewing an MR.",
      "tokens": [
        50364,
        407,
        286,
        478,
        516,
        281,
        3073,
        721,
        493,
        257,
        857,
        13,
        400,
        550,
        16386,
        11,
        286,
        2732,
        322,
        11,
        286,
        2732,
        365,
        22691,
        293,
        967,
        2095,
        567,
        366,
        732,
        777,
        1674,
        16196,
        570,
        436,
        1415,
        281,
        8576,
        1580,
        1339,
        19576,
        364,
        9808,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27106967214810646,
      "compression_ratio": 1.3801169590643274,
      "no_speech_prob": 0.4454834461212158
    },
    {
      "id": 73,
      "seek": 33008,
      "start": 345.08,
      "end": 348.08,
      "text": " So it was a really fun experience for me.",
      "tokens": [
        51114,
        407,
        309,
        390,
        257,
        534,
        1019,
        1752,
        337,
        385,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27106967214810646,
      "compression_ratio": 1.3801169590643274,
      "no_speech_prob": 0.4454834461212158
    },
    {
      "id": 74,
      "seek": 34808,
      "start": 348.08,
      "end": 362.08,
      "text": " We were trying to get pipelines to be in the right states and I was like googling on the spot and we were all just like working together. They had GDK up on their instances as well. And we were working together on it and it was very valuable.",
      "tokens": [
        50364,
        492,
        645,
        1382,
        281,
        483,
        40168,
        281,
        312,
        294,
        264,
        558,
        4368,
        293,
        286,
        390,
        411,
        50061,
        1688,
        322,
        264,
        4008,
        293,
        321,
        645,
        439,
        445,
        411,
        1364,
        1214,
        13,
        814,
        632,
        460,
        35,
        42,
        493,
        322,
        641,
        14519,
        382,
        731,
        13,
        400,
        321,
        645,
        1364,
        1214,
        322,
        309,
        293,
        309,
        390,
        588,
        8263,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13196011807056182,
      "compression_ratio": 1.5767634854771784,
      "no_speech_prob": 0.13038192689418793
    },
    {
      "id": 75,
      "seek": 34808,
      "start": 362.08,
      "end": 371.08,
      "text": " So we, I opened an MR to add this officially to the onboarding template for product designers.",
      "tokens": [
        51064,
        407,
        321,
        11,
        286,
        5625,
        364,
        9808,
        281,
        909,
        341,
        12053,
        281,
        264,
        24033,
        278,
        12379,
        337,
        1674,
        16196,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13196011807056182,
      "compression_ratio": 1.5767634854771784,
      "no_speech_prob": 0.13038192689418793
    },
    {
      "id": 76,
      "seek": 34808,
      "start": 371.08,
      "end": 376.08,
      "text": " You're welcome to jump in there. But yeah.",
      "tokens": [
        51514,
        509,
        434,
        2928,
        281,
        3012,
        294,
        456,
        13,
        583,
        1338,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13196011807056182,
      "compression_ratio": 1.5767634854771784,
      "no_speech_prob": 0.13038192689418793
    },
    {
      "id": 77,
      "seek": 37608,
      "start": 376.08,
      "end": 388.08,
      "text": " I'm going to comment on this one. I can buy it. I left a comment in that Merge class, but you know, just in being VTika and Bonnie for feedback because VTika, wow, this is helping onboard Bonnie and they are doing something similar.",
      "tokens": [
        50364,
        286,
        478,
        516,
        281,
        2871,
        322,
        341,
        472,
        13,
        286,
        393,
        2256,
        309,
        13,
        286,
        1411,
        257,
        2871,
        294,
        300,
        6124,
        432,
        1508,
        11,
        457,
        291,
        458,
        11,
        445,
        294,
        885,
        691,
        51,
        5439,
        293,
        32170,
        337,
        5824,
        570,
        691,
        51,
        5439,
        11,
        6076,
        11,
        341,
        307,
        4315,
        24033,
        32170,
        293,
        436,
        366,
        884,
        746,
        2531,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4584246654899753,
      "compression_ratio": 1.673913043478261,
      "no_speech_prob": 0.16788411140441895
    },
    {
      "id": 78,
      "seek": 37608,
      "start": 388.08,
      "end": 399.08,
      "text": " So I think they had this week the first Merge class shadow call. They also were like in a call for like one hour. So they might have some some feedback.",
      "tokens": [
        50964,
        407,
        286,
        519,
        436,
        632,
        341,
        1243,
        264,
        700,
        6124,
        432,
        1508,
        8576,
        818,
        13,
        814,
        611,
        645,
        411,
        294,
        257,
        818,
        337,
        411,
        472,
        1773,
        13,
        407,
        436,
        1062,
        362,
        512,
        512,
        5824,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4584246654899753,
      "compression_ratio": 1.673913043478261,
      "no_speech_prob": 0.16788411140441895
    },
    {
      "id": 79,
      "seek": 39908,
      "start": 399.08,
      "end": 406.08,
      "text": " And I think this is a great addition because to your point right now that designers are assigned to rent.",
      "tokens": [
        50364,
        400,
        286,
        519,
        341,
        307,
        257,
        869,
        4500,
        570,
        281,
        428,
        935,
        558,
        586,
        300,
        16196,
        366,
        13279,
        281,
        6214,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2656779433741714,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.10998517274856567
    },
    {
      "id": 80,
      "seek": 39908,
      "start": 406.08,
      "end": 412.08,
      "text": " Randomly assigned to Merge class reviewing something out of sort of your state who can even can be if it's carrier.",
      "tokens": [
        50714,
        37603,
        356,
        13279,
        281,
        6124,
        432,
        1508,
        19576,
        746,
        484,
        295,
        1333,
        295,
        428,
        1785,
        567,
        393,
        754,
        393,
        312,
        498,
        309,
        311,
        17574,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2656779433741714,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.10998517274856567
    },
    {
      "id": 81,
      "seek": 39908,
      "start": 412.08,
      "end": 418.08,
      "text": " So I think in general, there's no opportunity for us to also define when should that happen.",
      "tokens": [
        51014,
        407,
        286,
        519,
        294,
        2674,
        11,
        456,
        311,
        572,
        2650,
        337,
        505,
        281,
        611,
        6964,
        562,
        820,
        300,
        1051,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2656779433741714,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.10998517274856567
    },
    {
      "id": 82,
      "seek": 39908,
      "start": 418.08,
      "end": 422.08,
      "text": " And who should help them with.",
      "tokens": [
        51314,
        400,
        567,
        820,
        854,
        552,
        365,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2656779433741714,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.10998517274856567
    },
    {
      "id": 83,
      "seek": 39908,
      "start": 422.08,
      "end": 426.08,
      "text": " You have to mean the process. So thanks for that. Mar.",
      "tokens": [
        51514,
        509,
        362,
        281,
        914,
        264,
        1399,
        13,
        407,
        3231,
        337,
        300,
        13,
        2039,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2656779433741714,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.10998517274856567
    },
    {
      "id": 84,
      "seek": 42608,
      "start": 426.08,
      "end": 436.08,
      "text": " Yeah. And also I met with B this morning and she was saying that she'll create another MR because I she had some larger ideas of how to.",
      "tokens": [
        50364,
        865,
        13,
        400,
        611,
        286,
        1131,
        365,
        363,
        341,
        2446,
        293,
        750,
        390,
        1566,
        300,
        750,
        603,
        1884,
        1071,
        9808,
        570,
        286,
        750,
        632,
        512,
        4833,
        3487,
        295,
        577,
        281,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13546345450661398,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.00491460133343935
    },
    {
      "id": 85,
      "seek": 42608,
      "start": 436.08,
      "end": 443.08,
      "text": " Kind of like time box. A lot of the stuff that we have in the template. So there's going to be more changes.",
      "tokens": [
        50864,
        9242,
        295,
        411,
        565,
        2424,
        13,
        316,
        688,
        295,
        264,
        1507,
        300,
        321,
        362,
        294,
        264,
        12379,
        13,
        407,
        456,
        311,
        516,
        281,
        312,
        544,
        2962,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13546345450661398,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.00491460133343935
    },
    {
      "id": 86,
      "seek": 42608,
      "start": 443.08,
      "end": 450.08,
      "text": " After that, but we were able to connect at least on the small change that I wanted to bring in.",
      "tokens": [
        51214,
        2381,
        300,
        11,
        457,
        321,
        645,
        1075,
        281,
        1745,
        412,
        1935,
        322,
        264,
        1359,
        1319,
        300,
        286,
        1415,
        281,
        1565,
        294,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13546345450661398,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.00491460133343935
    },
    {
      "id": 87,
      "seek": 45008,
      "start": 450.08,
      "end": 456.08,
      "text": " And I think that's the same page there. And she'll build on it.",
      "tokens": [
        50364,
        400,
        286,
        519,
        300,
        311,
        264,
        912,
        3028,
        456,
        13,
        400,
        750,
        603,
        1322,
        322,
        309,
        13,
        50664
      ],
      "temperature": 0.2,
      "avg_logprob": -0.3925495147705078,
      "compression_ratio": 1.387878787878788,
      "no_speech_prob": 0.07655438780784607
    },
    {
      "id": 88,
      "seek": 45008,
      "start": 456.08,
      "end": 460.08,
      "text": " And that is it on for me. Emily.",
      "tokens": [
        50664,
        400,
        300,
        307,
        309,
        322,
        337,
        385,
        13,
        15034,
        13,
        50864
      ],
      "temperature": 0.2,
      "avg_logprob": -0.3925495147705078,
      "compression_ratio": 1.387878787878788,
      "no_speech_prob": 0.07655438780784607
    },
    {
      "id": 89,
      "seek": 45008,
      "start": 460.08,
      "end": 470.08,
      "text": " The first one is just an FIA. I that we're starting a new unmoderated study in 16 eight for a tree view on the Kubernetes dashboard.",
      "tokens": [
        50864,
        440,
        700,
        472,
        307,
        445,
        364,
        479,
        6914,
        13,
        286,
        300,
        321,
        434,
        2891,
        257,
        777,
        517,
        8014,
        260,
        770,
        2979,
        294,
        3165,
        3180,
        337,
        257,
        4230,
        1910,
        322,
        264,
        23145,
        18342,
        13,
        51364
      ],
      "temperature": 0.2,
      "avg_logprob": -0.3925495147705078,
      "compression_ratio": 1.387878787878788,
      "no_speech_prob": 0.07655438780784607
    },
    {
      "id": 90,
      "seek": 47008,
      "start": 470.08,
      "end": 479.08,
      "text": " And a lot of competitors have a tree view of this and it's a concept that we didn't initially explore when the Kubernetes dashboard was first validated.",
      "tokens": [
        50364,
        400,
        257,
        688,
        295,
        18333,
        362,
        257,
        4230,
        1910,
        295,
        341,
        293,
        309,
        311,
        257,
        3410,
        300,
        321,
        994,
        380,
        9105,
        6839,
        562,
        264,
        23145,
        18342,
        390,
        700,
        40693,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15325525973705537,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.08962637186050415
    },
    {
      "id": 91,
      "seek": 47008,
      "start": 479.08,
      "end": 484.08,
      "text": " So it's something we kind of want to sneak in there as we're working on it.",
      "tokens": [
        50814,
        407,
        309,
        311,
        746,
        321,
        733,
        295,
        528,
        281,
        13164,
        294,
        456,
        382,
        321,
        434,
        1364,
        322,
        309,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15325525973705537,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.08962637186050415
    },
    {
      "id": 92,
      "seek": 47008,
      "start": 484.08,
      "end": 490.08,
      "text": " And a big thanks for well will's been kind of helping me at the screener for this as well as the scenario.",
      "tokens": [
        51064,
        400,
        257,
        955,
        3231,
        337,
        731,
        486,
        311,
        668,
        733,
        295,
        4315,
        385,
        412,
        264,
        2568,
        260,
        337,
        341,
        382,
        731,
        382,
        264,
        9005,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15325525973705537,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.08962637186050415
    },
    {
      "id": 93,
      "seek": 47008,
      "start": 490.08,
      "end": 495.08,
      "text": " So thank him for his help with this study.",
      "tokens": [
        51364,
        407,
        1309,
        796,
        337,
        702,
        854,
        365,
        341,
        2979,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15325525973705537,
      "compression_ratio": 1.6363636363636365,
      "no_speech_prob": 0.08962637186050415
    },
    {
      "id": 94,
      "seek": 49508,
      "start": 495.08,
      "end": 508.08,
      "text": " And the second thing I wanted to say is Andrew one of the front end engineers on the team invited me to a Kubernetes meetup in Toronto last week, which was a lot of fun.",
      "tokens": [
        50364,
        400,
        264,
        1150,
        551,
        286,
        1415,
        281,
        584,
        307,
        10110,
        472,
        295,
        264,
        1868,
        917,
        11955,
        322,
        264,
        1469,
        9185,
        385,
        281,
        257,
        23145,
        1677,
        1010,
        294,
        14140,
        1036,
        1243,
        11,
        597,
        390,
        257,
        688,
        295,
        1019,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13511750811622256,
      "compression_ratio": 1.545045045045045,
      "no_speech_prob": 0.12735913693904877
    },
    {
      "id": 95,
      "seek": 49508,
      "start": 508.08,
      "end": 512.0799999999999,
      "text": " It was very, very technical. So a little bit above my knowledge.",
      "tokens": [
        51014,
        467,
        390,
        588,
        11,
        588,
        6191,
        13,
        407,
        257,
        707,
        857,
        3673,
        452,
        3601,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13511750811622256,
      "compression_ratio": 1.545045045045045,
      "no_speech_prob": 0.12735913693904877
    },
    {
      "id": 96,
      "seek": 49508,
      "start": 512.0799999999999,
      "end": 519.0799999999999,
      "text": " But it was nice to just go kind of network with some of the people working in this area, making connections.",
      "tokens": [
        51214,
        583,
        309,
        390,
        1481,
        281,
        445,
        352,
        733,
        295,
        3209,
        365,
        512,
        295,
        264,
        561,
        1364,
        294,
        341,
        1859,
        11,
        1455,
        9271,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13511750811622256,
      "compression_ratio": 1.545045045045045,
      "no_speech_prob": 0.12735913693904877
    },
    {
      "id": 97,
      "seek": 51908,
      "start": 519.08,
      "end": 525.08,
      "text": " We're also talking about maybe presenting our Kubernetes dashboard at one of these in the future.",
      "tokens": [
        50364,
        492,
        434,
        611,
        1417,
        466,
        1310,
        15578,
        527,
        23145,
        18342,
        412,
        472,
        295,
        613,
        294,
        264,
        2027,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13336784189397638,
      "compression_ratio": 1.5404255319148936,
      "no_speech_prob": 0.010009286925196648
    },
    {
      "id": 98,
      "seek": 51908,
      "start": 525.08,
      "end": 539.08,
      "text": " So I'm going to meet up with Vidika to see if this is something I could do speaking about and partner with Andrew so he can kind of answer all the engineering questions that come up, but it was a lot of fun.",
      "tokens": [
        50664,
        407,
        286,
        478,
        516,
        281,
        1677,
        493,
        365,
        31185,
        5439,
        281,
        536,
        498,
        341,
        307,
        746,
        286,
        727,
        360,
        4124,
        466,
        293,
        4975,
        365,
        10110,
        370,
        415,
        393,
        733,
        295,
        1867,
        439,
        264,
        7043,
        1651,
        300,
        808,
        493,
        11,
        457,
        309,
        390,
        257,
        688,
        295,
        1019,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13336784189397638,
      "compression_ratio": 1.5404255319148936,
      "no_speech_prob": 0.010009286925196648
    },
    {
      "id": 99,
      "seek": 51908,
      "start": 539.08,
      "end": 543.08,
      "text": " And I haven't done like an in person meetup for a while.",
      "tokens": [
        51364,
        400,
        286,
        2378,
        380,
        1096,
        411,
        364,
        294,
        954,
        1677,
        1010,
        337,
        257,
        1339,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13336784189397638,
      "compression_ratio": 1.5404255319148936,
      "no_speech_prob": 0.010009286925196648
    },
    {
      "id": 100,
      "seek": 54308,
      "start": 543.08,
      "end": 555.08,
      "text": " And if no one has questions move to Vidika who's not attending.",
      "tokens": [
        50364,
        400,
        498,
        572,
        472,
        575,
        1651,
        1286,
        281,
        31185,
        5439,
        567,
        311,
        406,
        15862,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22479459716052544,
      "compression_ratio": 1.1941747572815533,
      "no_speech_prob": 0.014572357758879662
    },
    {
      "id": 101,
      "seek": 54308,
      "start": 555.08,
      "end": 559.08,
      "text": " So do you want me to voice it for her?",
      "tokens": [
        50964,
        407,
        360,
        291,
        528,
        385,
        281,
        3177,
        309,
        337,
        720,
        30,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22479459716052544,
      "compression_ratio": 1.1941747572815533,
      "no_speech_prob": 0.014572357758879662
    },
    {
      "id": 102,
      "seek": 54308,
      "start": 559.08,
      "end": 561.08,
      "text": " So it's I'm talking.",
      "tokens": [
        51164,
        407,
        309,
        311,
        286,
        478,
        1417,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22479459716052544,
      "compression_ratio": 1.1941747572815533,
      "no_speech_prob": 0.014572357758879662
    },
    {
      "id": 103,
      "seek": 56108,
      "start": 561.08,
      "end": 570.08,
      "text": " So her first point is there's a discussion going on in PE on the time we show for duration created at started at.",
      "tokens": [
        50364,
        407,
        720,
        700,
        935,
        307,
        456,
        311,
        257,
        5017,
        516,
        322,
        294,
        24346,
        322,
        264,
        565,
        321,
        855,
        337,
        16365,
        2942,
        412,
        1409,
        412,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1775328755378723,
      "compression_ratio": 1.502439024390244,
      "no_speech_prob": 0.04818448796868324
    },
    {
      "id": 104,
      "seek": 56108,
      "start": 570.08,
      "end": 578.08,
      "text": " And it'll be helpful for some young and Gina to for and she's linked the epic for improvements.",
      "tokens": [
        50814,
        400,
        309,
        603,
        312,
        4961,
        337,
        512,
        2037,
        293,
        34711,
        281,
        337,
        293,
        750,
        311,
        9408,
        264,
        13581,
        337,
        13797,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1775328755378723,
      "compression_ratio": 1.502439024390244,
      "no_speech_prob": 0.04818448796868324
    },
    {
      "id": 105,
      "seek": 56108,
      "start": 578.08,
      "end": 584.08,
      "text": " And then Gina I noticed yours is read only, but since we probably have time.",
      "tokens": [
        51214,
        400,
        550,
        34711,
        286,
        5694,
        6342,
        307,
        1401,
        787,
        11,
        457,
        1670,
        321,
        1391,
        362,
        565,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1775328755378723,
      "compression_ratio": 1.502439024390244,
      "no_speech_prob": 0.04818448796868324
    },
    {
      "id": 106,
      "seek": 56108,
      "start": 584.08,
      "end": 587.08,
      "text": " Yeah, I can voice it.",
      "tokens": [
        51514,
        865,
        11,
        286,
        393,
        3177,
        309,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1775328755378723,
      "compression_ratio": 1.502439024390244,
      "no_speech_prob": 0.04818448796868324
    },
    {
      "id": 107,
      "seek": 58708,
      "start": 587.08,
      "end": 601.08,
      "text": " I brought this up. It's actually a really interesting issue. I would recommend going into it because it basic like the user saying that weren't misleading when we calculate duration for pipeline.",
      "tokens": [
        50364,
        286,
        3038,
        341,
        493,
        13,
        467,
        311,
        767,
        257,
        534,
        1880,
        2734,
        13,
        286,
        576,
        2748,
        516,
        666,
        309,
        570,
        309,
        3875,
        411,
        264,
        4195,
        1566,
        300,
        4999,
        380,
        36429,
        562,
        321,
        8873,
        16365,
        337,
        15517,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15002175381309107,
      "compression_ratio": 1.6545454545454545,
      "no_speech_prob": 0.012140586972236633
    },
    {
      "id": 108,
      "seek": 58708,
      "start": 601.08,
      "end": 610.08,
      "text": " I brought it up with the fleet team just because we have a lot of overlapping features that have to do with duration and runners and wait time and everything like that.",
      "tokens": [
        51064,
        286,
        3038,
        309,
        493,
        365,
        264,
        19396,
        1469,
        445,
        570,
        321,
        362,
        257,
        688,
        295,
        33535,
        4122,
        300,
        362,
        281,
        360,
        365,
        16365,
        293,
        33892,
        293,
        1699,
        565,
        293,
        1203,
        411,
        300,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15002175381309107,
      "compression_ratio": 1.6545454545454545,
      "no_speech_prob": 0.012140586972236633
    },
    {
      "id": 109,
      "seek": 61008,
      "start": 610.08,
      "end": 624.08,
      "text": " And I left a comment for Vidika because we have some specific customer recordings of how they use duration metrics and why they're using them to optimize their pipelines.",
      "tokens": [
        50364,
        400,
        286,
        1411,
        257,
        2871,
        337,
        31185,
        5439,
        570,
        321,
        362,
        512,
        2685,
        5474,
        25162,
        295,
        577,
        436,
        764,
        16365,
        16367,
        293,
        983,
        436,
        434,
        1228,
        552,
        281,
        19719,
        641,
        40168,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11589702905393114,
      "compression_ratio": 1.393939393939394,
      "no_speech_prob": 0.008808598853647709
    },
    {
      "id": 110,
      "seek": 61008,
      "start": 624.08,
      "end": 628.08,
      "text": " And the just a summary of what the fleet team talked about.",
      "tokens": [
        51064,
        400,
        264,
        445,
        257,
        12691,
        295,
        437,
        264,
        19396,
        1469,
        2825,
        466,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11589702905393114,
      "compression_ratio": 1.393939393939394,
      "no_speech_prob": 0.008808598853647709
    },
    {
      "id": 111,
      "seek": 62808,
      "start": 628.08,
      "end": 640.08,
      "text": " And I would like to not be able to agree with the user that it is misleading because we're not including pending time and the duration, which is interesting and kind of weird.",
      "tokens": [
        50364,
        400,
        286,
        576,
        411,
        281,
        406,
        312,
        1075,
        281,
        3986,
        365,
        264,
        4195,
        300,
        309,
        307,
        36429,
        570,
        321,
        434,
        406,
        3009,
        32110,
        565,
        293,
        264,
        16365,
        11,
        597,
        307,
        1880,
        293,
        733,
        295,
        3657,
        13,
        50964
      ],
      "temperature": 0.6,
      "avg_logprob": -0.342237569108794,
      "compression_ratio": 1.5674418604651164,
      "no_speech_prob": 0.15042486786842346
    },
    {
      "id": 112,
      "seek": 62808,
      "start": 640.08,
      "end": 654.08,
      "text": " But anyways, I just she had asked me to jump in and just include some user stories I guess kind of like how customers are using this today. So that's what I did.",
      "tokens": [
        50964,
        583,
        13448,
        11,
        286,
        445,
        750,
        632,
        2351,
        385,
        281,
        3012,
        294,
        293,
        445,
        4090,
        512,
        4195,
        3676,
        286,
        2041,
        733,
        295,
        411,
        577,
        4581,
        366,
        1228,
        341,
        965,
        13,
        407,
        300,
        311,
        437,
        286,
        630,
        13,
        51664
      ],
      "temperature": 0.6,
      "avg_logprob": -0.342237569108794,
      "compression_ratio": 1.5674418604651164,
      "no_speech_prob": 0.15042486786842346
    },
    {
      "id": 113,
      "seek": 65408,
      "start": 654.08,
      "end": 657.44,
      "text": " Yeah, I like to inverse my comment too.",
      "tokens": [
        50364,
        865,
        11,
        286,
        411,
        281,
        17340,
        452,
        2871,
        886,
        13,
        50532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44551142250619286,
      "compression_ratio": 1.586046511627907,
      "no_speech_prob": 0.12408861517906189
    },
    {
      "id": 114,
      "seek": 65408,
      "start": 657.44,
      "end": 665.88,
      "text": " I had my one on one new video today and I told her that there are some insights in one",
      "tokens": [
        50532,
        286,
        632,
        452,
        472,
        322,
        472,
        777,
        960,
        965,
        293,
        286,
        1907,
        720,
        300,
        456,
        366,
        512,
        14310,
        294,
        472,
        50954
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44551142250619286,
      "compression_ratio": 1.586046511627907,
      "no_speech_prob": 0.12408861517906189
    },
    {
      "id": 115,
      "seek": 65408,
      "start": 665.88,
      "end": 668.88,
      "text": " of the environments dashboard research issue.",
      "tokens": [
        50954,
        295,
        264,
        12388,
        18342,
        2132,
        2734,
        13,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44551142250619286,
      "compression_ratio": 1.586046511627907,
      "no_speech_prob": 0.12408861517906189
    },
    {
      "id": 116,
      "seek": 65408,
      "start": 668.88,
      "end": 677.12,
      "text": " I think I did that maybe last year, this summer, that has some explanation about what the",
      "tokens": [
        51104,
        286,
        519,
        286,
        630,
        300,
        1310,
        1036,
        1064,
        11,
        341,
        4266,
        11,
        300,
        575,
        512,
        10835,
        466,
        437,
        264,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44551142250619286,
      "compression_ratio": 1.586046511627907,
      "no_speech_prob": 0.12408861517906189
    },
    {
      "id": 117,
      "seek": 65408,
      "start": 677.12,
      "end": 681.76,
      "text": " release manager is about engineers when looking context of deployments, right?",
      "tokens": [
        51516,
        4374,
        6598,
        307,
        466,
        11955,
        562,
        1237,
        4319,
        295,
        7274,
        1117,
        11,
        558,
        30,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44551142250619286,
      "compression_ratio": 1.586046511627907,
      "no_speech_prob": 0.12408861517906189
    },
    {
      "id": 118,
      "seek": 68176,
      "start": 682.4,
      "end": 689.68,
      "text": " They are in the pipeline pages, but looking at the point of production, what do they understand",
      "tokens": [
        50396,
        814,
        366,
        294,
        264,
        15517,
        7183,
        11,
        457,
        1237,
        412,
        264,
        935,
        295,
        4265,
        11,
        437,
        360,
        436,
        1223,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31322761634727575,
      "compression_ratio": 1.6684491978609626,
      "no_speech_prob": 0.028832176700234413
    },
    {
      "id": 119,
      "seek": 68176,
      "start": 689.68,
      "end": 691.68,
      "text": " of that metadata?",
      "tokens": [
        50760,
        295,
        300,
        26603,
        30,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31322761634727575,
      "compression_ratio": 1.6684491978609626,
      "no_speech_prob": 0.028832176700234413
    },
    {
      "id": 120,
      "seek": 68176,
      "start": 691.68,
      "end": 703.12,
      "text": " Why are they looking for when it comes to the duration of a pipeline or when it started running,",
      "tokens": [
        50860,
        1545,
        366,
        436,
        1237,
        337,
        562,
        309,
        1487,
        281,
        264,
        16365,
        295,
        257,
        15517,
        420,
        562,
        309,
        1409,
        2614,
        11,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31322761634727575,
      "compression_ratio": 1.6684491978609626,
      "no_speech_prob": 0.028832176700234413
    },
    {
      "id": 121,
      "seek": 68176,
      "start": 703.12,
      "end": 705.12,
      "text": " et cetera?",
      "tokens": [
        51432,
        1030,
        11458,
        30,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31322761634727575,
      "compression_ratio": 1.6684491978609626,
      "no_speech_prob": 0.028832176700234413
    },
    {
      "id": 122,
      "seek": 68176,
      "start": 705.12,
      "end": 708.96,
      "text": " It might be interesting for her to look into that, but also connect with you and you might",
      "tokens": [
        51532,
        467,
        1062,
        312,
        1880,
        337,
        720,
        281,
        574,
        666,
        300,
        11,
        457,
        611,
        1745,
        365,
        291,
        293,
        291,
        1062,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31322761634727575,
      "compression_ratio": 1.6684491978609626,
      "no_speech_prob": 0.028832176700234413
    },
    {
      "id": 123,
      "seek": 70896,
      "start": 708.96,
      "end": 715.2,
      "text": " have a number updated, a more recent insight in that, but just as a reminder, I think later",
      "tokens": [
        50364,
        362,
        257,
        1230,
        10588,
        11,
        257,
        544,
        5162,
        11269,
        294,
        300,
        11,
        457,
        445,
        382,
        257,
        13548,
        11,
        286,
        519,
        1780,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32451715140507137,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.023272313177585602
    },
    {
      "id": 124,
      "seek": 70896,
      "start": 715.2,
      "end": 721.84,
      "text": " to what Gina said, there is some connections about the information that we need to make",
      "tokens": [
        50676,
        281,
        437,
        34711,
        848,
        11,
        456,
        307,
        512,
        9271,
        466,
        264,
        1589,
        300,
        321,
        643,
        281,
        652,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32451715140507137,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.023272313177585602
    },
    {
      "id": 125,
      "seek": 70896,
      "start": 722.64,
      "end": 724.5600000000001,
      "text": " for many different personas.",
      "tokens": [
        51048,
        337,
        867,
        819,
        12019,
        13,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32451715140507137,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.023272313177585602
    },
    {
      "id": 126,
      "seek": 70896,
      "start": 724.5600000000001,
      "end": 730.24,
      "text": " A lot of people just go to those pages, especially the pipeline view, and look for something",
      "tokens": [
        51144,
        316,
        688,
        295,
        561,
        445,
        352,
        281,
        729,
        7183,
        11,
        2318,
        264,
        15517,
        1910,
        11,
        293,
        574,
        337,
        746,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32451715140507137,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.023272313177585602
    },
    {
      "id": 127,
      "seek": 70896,
      "start": 730.24,
      "end": 731.24,
      "text": " very specific.",
      "tokens": [
        51428,
        588,
        2685,
        13,
        51478
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32451715140507137,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.023272313177585602
    },
    {
      "id": 128,
      "seek": 70896,
      "start": 731.24,
      "end": 733.12,
      "text": " There's a number or one tag.",
      "tokens": [
        51478,
        821,
        311,
        257,
        1230,
        420,
        472,
        6162,
        13,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32451715140507137,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.023272313177585602
    },
    {
      "id": 129,
      "seek": 73312,
      "start": 733.6,
      "end": 740.0,
      "text": " Keep that in mind, making this recommendations, but also look at these sites because we have them,",
      "tokens": [
        50388,
        5527,
        300,
        294,
        1575,
        11,
        1455,
        341,
        10434,
        11,
        457,
        611,
        574,
        412,
        613,
        7533,
        570,
        321,
        362,
        552,
        11,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3871502936640872,
      "compression_ratio": 1.53125,
      "no_speech_prob": 0.06905655562877655
    },
    {
      "id": 130,
      "seek": 73312,
      "start": 740.5600000000001,
      "end": 747.6,
      "text": " and if you're going to find it, ask me, am I know where it is, but it's there.",
      "tokens": [
        50736,
        293,
        498,
        291,
        434,
        516,
        281,
        915,
        309,
        11,
        1029,
        385,
        11,
        669,
        286,
        458,
        689,
        309,
        307,
        11,
        457,
        309,
        311,
        456,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3871502936640872,
      "compression_ratio": 1.53125,
      "no_speech_prob": 0.06905655562877655
    },
    {
      "id": 131,
      "seek": 73312,
      "start": 747.6,
      "end": 749.6,
      "text": " It's in the research project.",
      "tokens": [
        51088,
        467,
        311,
        294,
        264,
        2132,
        1716,
        13,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3871502936640872,
      "compression_ratio": 1.53125,
      "no_speech_prob": 0.06905655562877655
    },
    {
      "id": 132,
      "seek": 73312,
      "start": 749.6,
      "end": 752.4,
      "text": " It's the environment dashboard redesign.",
      "tokens": [
        51188,
        467,
        311,
        264,
        2823,
        18342,
        39853,
        13,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3871502936640872,
      "compression_ratio": 1.53125,
      "no_speech_prob": 0.06905655562877655
    },
    {
      "id": 133,
      "seek": 73312,
      "start": 759.2,
      "end": 762.5600000000001,
      "text": " That's not the group level environments dash.",
      "tokens": [
        51668,
        663,
        311,
        406,
        264,
        1594,
        1496,
        12388,
        8240,
        13,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3871502936640872,
      "compression_ratio": 1.53125,
      "no_speech_prob": 0.06905655562877655
    },
    {
      "id": 134,
      "seek": 76256,
      "start": 762.64,
      "end": 764.4799999999999,
      "text": " That's the original environments.",
      "tokens": [
        50368,
        663,
        311,
        264,
        3380,
        12388,
        13,
        50460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4390071350851177,
      "compression_ratio": 1.4723618090452262,
      "no_speech_prob": 0.0019567625131458044
    },
    {
      "id": 135,
      "seek": 76256,
      "start": 764.4799999999999,
      "end": 764.9599999999999,
      "text": " Okay.",
      "tokens": [
        50460,
        1033,
        13,
        50484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4390071350851177,
      "compression_ratio": 1.4723618090452262,
      "no_speech_prob": 0.0019567625131458044
    },
    {
      "id": 136,
      "seek": 76256,
      "start": 764.9599999999999,
      "end": 765.5999999999999,
      "text": " Yeah.",
      "tokens": [
        50484,
        865,
        13,
        50516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4390071350851177,
      "compression_ratio": 1.4723618090452262,
      "no_speech_prob": 0.0019567625131458044
    },
    {
      "id": 137,
      "seek": 76256,
      "start": 765.5999999999999,
      "end": 765.76,
      "text": " Yeah.",
      "tokens": [
        50516,
        865,
        13,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4390071350851177,
      "compression_ratio": 1.4723618090452262,
      "no_speech_prob": 0.0019567625131458044
    },
    {
      "id": 138,
      "seek": 76256,
      "start": 766.64,
      "end": 770.4,
      "text": " I think Daniel and Daniel Fosco started, and I finished that.",
      "tokens": [
        50568,
        286,
        519,
        8033,
        293,
        8033,
        479,
        329,
        1291,
        1409,
        11,
        293,
        286,
        4335,
        300,
        13,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4390071350851177,
      "compression_ratio": 1.4723618090452262,
      "no_speech_prob": 0.0019567625131458044
    },
    {
      "id": 139,
      "seek": 76256,
      "start": 770.4,
      "end": 775.68,
      "text": " It was before you joined Emily, but there, I remember, documented that in the off-tail,",
      "tokens": [
        50756,
        467,
        390,
        949,
        291,
        6869,
        15034,
        11,
        457,
        456,
        11,
        286,
        1604,
        11,
        23007,
        300,
        294,
        264,
        766,
        12,
        14430,
        11,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4390071350851177,
      "compression_ratio": 1.4723618090452262,
      "no_speech_prob": 0.0019567625131458044
    },
    {
      "id": 140,
      "seek": 76256,
      "start": 776.3199999999999,
      "end": 784.3199999999999,
      "text": " because we specifically asked about the order of the metadata and also what they want to do",
      "tokens": [
        51052,
        570,
        321,
        4682,
        2351,
        466,
        264,
        1668,
        295,
        264,
        26603,
        293,
        611,
        437,
        436,
        528,
        281,
        360,
        51452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4390071350851177,
      "compression_ratio": 1.4723618090452262,
      "no_speech_prob": 0.0019567625131458044
    },
    {
      "id": 141,
      "seek": 78432,
      "start": 784.96,
      "end": 789.2,
      "text": " to why some of this effort is relevant.",
      "tokens": [
        50396,
        281,
        983,
        512,
        295,
        341,
        4630,
        307,
        7340,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2585896194958296,
      "compression_ratio": 1.4695121951219512,
      "no_speech_prob": 0.0029233384411782026
    },
    {
      "id": 142,
      "seek": 78432,
      "start": 790.88,
      "end": 794.32,
      "text": " But anyways, missions like one or two insights about that.",
      "tokens": [
        50692,
        583,
        13448,
        11,
        13744,
        411,
        472,
        420,
        732,
        14310,
        466,
        300,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2585896194958296,
      "compression_ratio": 1.4695121951219512,
      "no_speech_prob": 0.0029233384411782026
    },
    {
      "id": 143,
      "seek": 78432,
      "start": 794.32,
      "end": 796.96,
      "text": " It's the environments dashboard redesign.",
      "tokens": [
        50864,
        467,
        311,
        264,
        12388,
        18342,
        39853,
        13,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2585896194958296,
      "compression_ratio": 1.4695121951219512,
      "no_speech_prob": 0.0029233384411782026
    },
    {
      "id": 144,
      "seek": 78432,
      "start": 802.1600000000001,
      "end": 805.44,
      "text": " Also, just another small note about this.",
      "tokens": [
        51256,
        2743,
        11,
        445,
        1071,
        1359,
        3637,
        466,
        341,
        13,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2585896194958296,
      "compression_ratio": 1.4695121951219512,
      "no_speech_prob": 0.0029233384411782026
    },
    {
      "id": 145,
      "seek": 78432,
      "start": 805.44,
      "end": 809.9200000000001,
      "text": " I know that the issue was about the pipeline duration, and",
      "tokens": [
        51420,
        286,
        458,
        300,
        264,
        2734,
        390,
        466,
        264,
        15517,
        16365,
        11,
        293,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2585896194958296,
      "compression_ratio": 1.4695121951219512,
      "no_speech_prob": 0.0029233384411782026
    },
    {
      "id": 146,
      "seek": 80992,
      "start": 810.56,
      "end": 815.8399999999999,
      "text": " another thing that I was thinking about is that a lot of these metrics are,",
      "tokens": [
        50396,
        1071,
        551,
        300,
        286,
        390,
        1953,
        466,
        307,
        300,
        257,
        688,
        295,
        613,
        16367,
        366,
        11,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138413985570272,
      "compression_ratio": 1.7647058823529411,
      "no_speech_prob": 0.0008088265312835574
    },
    {
      "id": 147,
      "seek": 80992,
      "start": 816.88,
      "end": 821.8399999999999,
      "text": " I think, more useful at the job level rather than the pipeline level, because each,",
      "tokens": [
        50712,
        286,
        519,
        11,
        544,
        4420,
        412,
        264,
        1691,
        1496,
        2831,
        813,
        264,
        15517,
        1496,
        11,
        570,
        1184,
        11,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138413985570272,
      "compression_ratio": 1.7647058823529411,
      "no_speech_prob": 0.0008088265312835574
    },
    {
      "id": 148,
      "seek": 80992,
      "start": 822.56,
      "end": 829.76,
      "text": " even if the same pipeline runs, and so a pipeline is designated for a project.",
      "tokens": [
        50996,
        754,
        498,
        264,
        912,
        15517,
        6676,
        11,
        293,
        370,
        257,
        15517,
        307,
        21688,
        337,
        257,
        1716,
        13,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138413985570272,
      "compression_ratio": 1.7647058823529411,
      "no_speech_prob": 0.0008088265312835574
    },
    {
      "id": 149,
      "seek": 80992,
      "start": 829.76,
      "end": 834.4,
      "text": " If that pipeline runs multiple times, the same, it might have a different set of jobs that run",
      "tokens": [
        51356,
        759,
        300,
        15517,
        6676,
        3866,
        1413,
        11,
        264,
        912,
        11,
        309,
        1062,
        362,
        257,
        819,
        992,
        295,
        4782,
        300,
        1190,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138413985570272,
      "compression_ratio": 1.7647058823529411,
      "no_speech_prob": 0.0008088265312835574
    },
    {
      "id": 150,
      "seek": 80992,
      "start": 834.4,
      "end": 836.7199999999999,
      "text": " every time, because jobs can be skipped in it, whatever.",
      "tokens": [
        51588,
        633,
        565,
        11,
        570,
        4782,
        393,
        312,
        30193,
        294,
        309,
        11,
        2035,
        13,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2138413985570272,
      "compression_ratio": 1.7647058823529411,
      "no_speech_prob": 0.0008088265312835574
    },
    {
      "id": 151,
      "seek": 83672,
      "start": 837.6,
      "end": 843.28,
      "text": " So yeah, I think it's hard to think about this at the pipeline level, just because there's",
      "tokens": [
        50408,
        407,
        1338,
        11,
        286,
        519,
        309,
        311,
        1152,
        281,
        519,
        466,
        341,
        412,
        264,
        15517,
        1496,
        11,
        445,
        570,
        456,
        311,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34390532970428467,
      "compression_ratio": 1.4041450777202074,
      "no_speech_prob": 0.00179432169534266
    },
    {
      "id": 152,
      "seek": 83672,
      "start": 843.28,
      "end": 845.52,
      "text": " so many changes that could happen with each run.",
      "tokens": [
        50692,
        370,
        867,
        2962,
        300,
        727,
        1051,
        365,
        1184,
        1190,
        13,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34390532970428467,
      "compression_ratio": 1.4041450777202074,
      "no_speech_prob": 0.00179432169534266
    },
    {
      "id": 153,
      "seek": 83672,
      "start": 854.5600000000001,
      "end": 858.88,
      "text": " Hey, I can move on to our next point if we're done.",
      "tokens": [
        51256,
        1911,
        11,
        286,
        393,
        1286,
        322,
        281,
        527,
        958,
        935,
        498,
        321,
        434,
        1096,
        13,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34390532970428467,
      "compression_ratio": 1.4041450777202074,
      "no_speech_prob": 0.00179432169534266
    },
    {
      "id": 154,
      "seek": 83672,
      "start": 859.6800000000001,
      "end": 860.0,
      "text": " Cool.",
      "tokens": [
        51512,
        8561,
        13,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34390532970428467,
      "compression_ratio": 1.4041450777202074,
      "no_speech_prob": 0.00179432169534266
    },
    {
      "id": 155,
      "seek": 83672,
      "start": 860.0,
      "end": 864.72,
      "text": " And the next one is, we get to get started by identifying our UI in 16-8.",
      "tokens": [
        51528,
        400,
        264,
        958,
        472,
        307,
        11,
        321,
        483,
        281,
        483,
        1409,
        538,
        16696,
        527,
        15682,
        294,
        3165,
        12,
        23,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34390532970428467,
      "compression_ratio": 1.4041450777202074,
      "no_speech_prob": 0.00179432169534266
    },
    {
      "id": 156,
      "seek": 86472,
      "start": 864.8000000000001,
      "end": 870.96,
      "text": " There's many MRAs that emerged already, and now have validation in the form of that work.",
      "tokens": [
        50368,
        821,
        311,
        867,
        9808,
        10884,
        300,
        20178,
        1217,
        11,
        293,
        586,
        362,
        24071,
        294,
        264,
        1254,
        295,
        300,
        589,
        13,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 157,
      "seek": 86472,
      "start": 871.9200000000001,
      "end": 876.64,
      "text": " And Alvoise, Bonnie's comment here, if you want to take a look at the list of items,",
      "tokens": [
        50724,
        400,
        967,
        3080,
        908,
        11,
        32170,
        311,
        2871,
        510,
        11,
        498,
        291,
        528,
        281,
        747,
        257,
        574,
        412,
        264,
        1329,
        295,
        4754,
        11,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 158,
      "seek": 86472,
      "start": 878.08,
      "end": 880.64,
      "text": " Maria, and her are working on.",
      "tokens": [
        51032,
        2039,
        654,
        11,
        293,
        720,
        366,
        1364,
        322,
        13,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 159,
      "seek": 86472,
      "start": 881.52,
      "end": 885.36,
      "text": " I think that's just a question for Vittica when she watches this.",
      "tokens": [
        51204,
        286,
        519,
        300,
        311,
        445,
        257,
        1168,
        337,
        691,
        593,
        2262,
        562,
        750,
        17062,
        341,
        13,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 160,
      "seek": 86472,
      "start": 887.52,
      "end": 888.48,
      "text": " I think it's the opposite.",
      "tokens": [
        51504,
        286,
        519,
        309,
        311,
        264,
        6182,
        13,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 161,
      "seek": 86472,
      "start": 888.48,
      "end": 890.1600000000001,
      "text": " I think it's Vittica's comment.",
      "tokens": [
        51552,
        286,
        519,
        309,
        311,
        691,
        593,
        2262,
        311,
        2871,
        13,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 162,
      "seek": 86472,
      "start": 890.1600000000001,
      "end": 891.84,
      "text": " Vittica's comment too, Bonnie.",
      "tokens": [
        51636,
        691,
        593,
        2262,
        311,
        2871,
        886,
        11,
        32170,
        13,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 163,
      "seek": 86472,
      "start": 891.84,
      "end": 892.32,
      "text": " Okay.",
      "tokens": [
        51720,
        1033,
        13,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 164,
      "seek": 86472,
      "start": 892.32,
      "end": 893.0400000000001,
      "text": " A buddy.",
      "tokens": [
        51744,
        316,
        10340,
        13,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 165,
      "seek": 86472,
      "start": 893.0400000000001,
      "end": 893.84,
      "text": " Yeah.",
      "tokens": [
        51780,
        865,
        13,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30702395555449696,
      "compression_ratio": 1.6394849785407726,
      "no_speech_prob": 0.017585238441824913
    },
    {
      "id": 166,
      "seek": 89384,
      "start": 893.84,
      "end": 894.48,
      "text": " Got any questions?",
      "tokens": [
        50364,
        5803,
        604,
        1651,
        30,
        50396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 167,
      "seek": 89384,
      "start": 895.52,
      "end": 899.12,
      "text": " Yeah, because Maria is an intront and engineer in Tinas.",
      "tokens": [
        50448,
        865,
        11,
        570,
        2039,
        654,
        307,
        364,
        560,
        10001,
        293,
        11403,
        294,
        314,
        17094,
        13,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 168,
      "seek": 89384,
      "start": 900.8000000000001,
      "end": 902.32,
      "text": " No, no, that's right.",
      "tokens": [
        50712,
        883,
        11,
        572,
        11,
        300,
        311,
        558,
        13,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 169,
      "seek": 89384,
      "start": 902.32,
      "end": 904.0,
      "text": " Maria said that, sorry.",
      "tokens": [
        50788,
        2039,
        654,
        848,
        300,
        11,
        2597,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 170,
      "seek": 89384,
      "start": 904.64,
      "end": 906.32,
      "text": " Too many teams.",
      "tokens": [
        50904,
        11395,
        867,
        5491,
        13,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 171,
      "seek": 89384,
      "start": 906.32,
      "end": 906.72,
      "text": " You're right.",
      "tokens": [
        50988,
        509,
        434,
        558,
        13,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 172,
      "seek": 89384,
      "start": 910.64,
      "end": 915.2,
      "text": " No, so we're confused because it could be that 16-8,",
      "tokens": [
        51204,
        883,
        11,
        370,
        321,
        434,
        9019,
        570,
        309,
        727,
        312,
        300,
        3165,
        12,
        23,
        11,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 173,
      "seek": 89384,
      "start": 915.2,
      "end": 918.48,
      "text": " we're defining something Vittica's newbie, maybe with Maria.",
      "tokens": [
        51432,
        321,
        434,
        17827,
        746,
        691,
        593,
        2262,
        311,
        777,
        7392,
        11,
        1310,
        365,
        2039,
        654,
        13,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 174,
      "seek": 89384,
      "start": 918.48,
      "end": 920.24,
      "text": " Anyways, they can figure it.",
      "tokens": [
        51596,
        15585,
        11,
        436,
        393,
        2573,
        309,
        13,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 175,
      "seek": 89384,
      "start": 921.2,
      "end": 922.72,
      "text": " I can take a look at the agenda.",
      "tokens": [
        51732,
        286,
        393,
        747,
        257,
        574,
        412,
        264,
        9829,
        13,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.44908402182839136,
      "compression_ratio": 1.4863636363636363,
      "no_speech_prob": 0.013865349814295769
    },
    {
      "id": 176,
      "seek": 92384,
      "start": 924.5600000000001,
      "end": 926.88,
      "text": " That's it for Vittica.",
      "tokens": [
        50400,
        663,
        311,
        309,
        337,
        691,
        593,
        2262,
        13,
        50516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3636645550997752,
      "compression_ratio": 1.5414847161572052,
      "no_speech_prob": 0.0006866181502118707
    },
    {
      "id": 177,
      "seek": 92384,
      "start": 928.08,
      "end": 928.5600000000001,
      "text": " Yeah.",
      "tokens": [
        50576,
        865,
        13,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3636645550997752,
      "compression_ratio": 1.5414847161572052,
      "no_speech_prob": 0.0006866181502118707
    },
    {
      "id": 178,
      "seek": 92384,
      "start": 928.5600000000001,
      "end": 931.12,
      "text": " So, Bonnie and Syngen, I'm not here.",
      "tokens": [
        50600,
        407,
        11,
        32170,
        293,
        3902,
        872,
        268,
        11,
        286,
        478,
        406,
        510,
        13,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3636645550997752,
      "compression_ratio": 1.5414847161572052,
      "no_speech_prob": 0.0006866181502118707
    },
    {
      "id": 179,
      "seek": 92384,
      "start": 931.12,
      "end": 934.0,
      "text": " And then my only update for Switchboard is that it's too hard and it's too",
      "tokens": [
        50728,
        400,
        550,
        452,
        787,
        5623,
        337,
        13893,
        3787,
        307,
        300,
        309,
        311,
        886,
        1152,
        293,
        309,
        311,
        886,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3636645550997752,
      "compression_ratio": 1.5414847161572052,
      "no_speech_prob": 0.0006866181502118707
    },
    {
      "id": 180,
      "seek": 92384,
      "start": 934.0,
      "end": 934.5600000000001,
      "text": " interviewing.",
      "tokens": [
        50872,
        26524,
        13,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3636645550997752,
      "compression_ratio": 1.5414847161572052,
      "no_speech_prob": 0.0006866181502118707
    },
    {
      "id": 181,
      "seek": 92384,
      "start": 934.5600000000001,
      "end": 938.64,
      "text": " I don't have an interview scheduled for, well, this year and more.",
      "tokens": [
        50900,
        286,
        500,
        380,
        362,
        364,
        4049,
        15678,
        337,
        11,
        731,
        11,
        341,
        1064,
        293,
        544,
        13,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3636645550997752,
      "compression_ratio": 1.5414847161572052,
      "no_speech_prob": 0.0006866181502118707
    },
    {
      "id": 182,
      "seek": 92384,
      "start": 939.36,
      "end": 943.9200000000001,
      "text": " So hopefully by January, we'll pick up with more interviews",
      "tokens": [
        51140,
        407,
        4696,
        538,
        7061,
        11,
        321,
        603,
        1888,
        493,
        365,
        544,
        12318,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3636645550997752,
      "compression_ratio": 1.5414847161572052,
      "no_speech_prob": 0.0006866181502118707
    },
    {
      "id": 183,
      "seek": 92384,
      "start": 943.9200000000001,
      "end": 948.08,
      "text": " than fingers crossed, hire someone to begin the year.",
      "tokens": [
        51368,
        813,
        7350,
        14622,
        11,
        11158,
        1580,
        281,
        1841,
        264,
        1064,
        13,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3636645550997752,
      "compression_ratio": 1.5414847161572052,
      "no_speech_prob": 0.0006866181502118707
    },
    {
      "id": 184,
      "seek": 92384,
      "start": 950.32,
      "end": 951.76,
      "text": " And over to Eric.",
      "tokens": [
        51688,
        400,
        670,
        281,
        9336,
        13,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3636645550997752,
      "compression_ratio": 1.5414847161572052,
      "no_speech_prob": 0.0006866181502118707
    },
    {
      "id": 185,
      "seek": 95384,
      "start": 954.1600000000001,
      "end": 955.0400000000001,
      "text": " Yes.",
      "tokens": [
        50380,
        1079,
        13,
        50424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30807211460211337,
      "compression_ratio": 1.4497354497354498,
      "no_speech_prob": 0.0007483374793082476
    },
    {
      "id": 186,
      "seek": 95384,
      "start": 955.0400000000001,
      "end": 963.36,
      "text": " So, I posted the link to the draft of the report for the runner and CI",
      "tokens": [
        50424,
        407,
        11,
        286,
        9437,
        264,
        2113,
        281,
        264,
        11206,
        295,
        264,
        2275,
        337,
        264,
        24376,
        293,
        37777,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30807211460211337,
      "compression_ratio": 1.4497354497354498,
      "no_speech_prob": 0.0007483374793082476
    },
    {
      "id": 187,
      "seek": 95384,
      "start": 963.36,
      "end": 968.08,
      "text": " Builder's Build, Builds Feature Prioritization Survey.",
      "tokens": [
        50840,
        11875,
        260,
        311,
        11875,
        11,
        11875,
        82,
        3697,
        1503,
        24032,
        270,
        2144,
        33365,
        13,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30807211460211337,
      "compression_ratio": 1.4497354497354498,
      "no_speech_prob": 0.0007483374793082476
    },
    {
      "id": 188,
      "seek": 95384,
      "start": 968.08,
      "end": 976.24,
      "text": " So we did a Kano survey with 11 features to see how they got prioritized.",
      "tokens": [
        51076,
        407,
        321,
        630,
        257,
        591,
        3730,
        8984,
        365,
        2975,
        4122,
        281,
        536,
        577,
        436,
        658,
        14846,
        1602,
        13,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30807211460211337,
      "compression_ratio": 1.4497354497354498,
      "no_speech_prob": 0.0007483374793082476
    },
    {
      "id": 189,
      "seek": 95384,
      "start": 977.2800000000001,
      "end": 981.6,
      "text": " The signal we would be looking for is if there was like one must have",
      "tokens": [
        51536,
        440,
        6358,
        321,
        576,
        312,
        1237,
        337,
        307,
        498,
        456,
        390,
        411,
        472,
        1633,
        362,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30807211460211337,
      "compression_ratio": 1.4497354497354498,
      "no_speech_prob": 0.0007483374793082476
    },
    {
      "id": 190,
      "seek": 98160,
      "start": 981.6,
      "end": 983.36,
      "text": " that we would want to champion.",
      "tokens": [
        50364,
        300,
        321,
        576,
        528,
        281,
        10971,
        13,
        50452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1734294755118234,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.0007594384369440377
    },
    {
      "id": 191,
      "seek": 98160,
      "start": 984.16,
      "end": 988.72,
      "text": " Actually, they were all either attractive or indifferent.",
      "tokens": [
        50492,
        5135,
        11,
        436,
        645,
        439,
        2139,
        12609,
        420,
        48502,
        13,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1734294755118234,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.0007594384369440377
    },
    {
      "id": 192,
      "seek": 98160,
      "start": 988.72,
      "end": 995.44,
      "text": " So like, kind of cool, but like nothing like that we have a clear signal to deliver on.",
      "tokens": [
        50720,
        407,
        411,
        11,
        733,
        295,
        1627,
        11,
        457,
        411,
        1825,
        411,
        300,
        321,
        362,
        257,
        1850,
        6358,
        281,
        4239,
        322,
        13,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1734294755118234,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.0007594384369440377
    },
    {
      "id": 193,
      "seek": 98160,
      "start": 998.32,
      "end": 1004.4,
      "text": " Looking across the ones that were in the attractive bucket versus the indifferent bucket,",
      "tokens": [
        51200,
        11053,
        2108,
        264,
        2306,
        300,
        645,
        294,
        264,
        12609,
        13058,
        5717,
        264,
        48502,
        13058,
        11,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1734294755118234,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.0007594384369440377
    },
    {
      "id": 194,
      "seek": 98160,
      "start": 1004.4,
      "end": 1005.6800000000001,
      "text": " we have a signal that",
      "tokens": [
        51504,
        321,
        362,
        257,
        6358,
        300,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1734294755118234,
      "compression_ratio": 1.680232558139535,
      "no_speech_prob": 0.0007594384369440377
    },
    {
      "id": 195,
      "seek": 100568,
      "start": 1005.76,
      "end": 1010.64,
      "text": " users want AI assisted things.",
      "tokens": [
        50368,
        5022,
        528,
        7318,
        30291,
        721,
        13,
        50612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27375681400299073,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.003301962511613965
    },
    {
      "id": 196,
      "seek": 100568,
      "start": 1010.64,
      "end": 1015.68,
      "text": " Like, for example, like custom dashboards are actually not compelling because it's",
      "tokens": [
        50612,
        1743,
        11,
        337,
        1365,
        11,
        411,
        2375,
        8240,
        17228,
        366,
        767,
        406,
        20050,
        570,
        309,
        311,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27375681400299073,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.003301962511613965
    },
    {
      "id": 197,
      "seek": 100568,
      "start": 1015.68,
      "end": 1016.7199999999999,
      "text": " war work for them.",
      "tokens": [
        50864,
        1516,
        589,
        337,
        552,
        13,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27375681400299073,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.003301962511613965
    },
    {
      "id": 198,
      "seek": 100568,
      "start": 1020.16,
      "end": 1025.28,
      "text": " But if it can be like AI assisted, then it's like attractive, but still not a must have.",
      "tokens": [
        51088,
        583,
        498,
        309,
        393,
        312,
        411,
        7318,
        30291,
        11,
        550,
        309,
        311,
        411,
        12609,
        11,
        457,
        920,
        406,
        257,
        1633,
        362,
        13,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27375681400299073,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.003301962511613965
    },
    {
      "id": 199,
      "seek": 100568,
      "start": 1027.04,
      "end": 1032.32,
      "text": " And so, Darren and Gina and I are going to go over that report in depth tomorrow.",
      "tokens": [
        51432,
        400,
        370,
        11,
        36691,
        293,
        34711,
        293,
        286,
        366,
        516,
        281,
        352,
        670,
        300,
        2275,
        294,
        7161,
        4153,
        13,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27375681400299073,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.003301962511613965
    },
    {
      "id": 200,
      "seek": 103232,
      "start": 1032.3999999999999,
      "end": 1038.6399999999999,
      "text": " But I thought I would like give the high level overview that we don't have any must have.",
      "tokens": [
        50368,
        583,
        286,
        1194,
        286,
        576,
        411,
        976,
        264,
        1090,
        1496,
        12492,
        300,
        321,
        500,
        380,
        362,
        604,
        1633,
        362,
        13,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10200352668762207,
      "compression_ratio": 1.6388888888888888,
      "no_speech_prob": 0.0009108459926210344
    },
    {
      "id": 201,
      "seek": 103232,
      "start": 1038.6399999999999,
      "end": 1044.0,
      "text": " So I think it means that we're on the right track with like figuring out those little",
      "tokens": [
        50680,
        407,
        286,
        519,
        309,
        1355,
        300,
        321,
        434,
        322,
        264,
        558,
        2837,
        365,
        411,
        15213,
        484,
        729,
        707,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10200352668762207,
      "compression_ratio": 1.6388888888888888,
      "no_speech_prob": 0.0009108459926210344
    },
    {
      "id": 202,
      "seek": 103232,
      "start": 1044.0,
      "end": 1048.3999999999999,
      "text": " optimizations suggestions, which is a read we got from that qualitative study.",
      "tokens": [
        50948,
        5028,
        14455,
        13396,
        11,
        597,
        307,
        257,
        1401,
        321,
        658,
        490,
        300,
        31312,
        2979,
        13,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10200352668762207,
      "compression_ratio": 1.6388888888888888,
      "no_speech_prob": 0.0009108459926210344
    },
    {
      "id": 203,
      "seek": 103232,
      "start": 1048.96,
      "end": 1055.28,
      "text": " And we wanted to do this just to make sure that there wasn't something that was like so cool",
      "tokens": [
        51196,
        400,
        321,
        1415,
        281,
        360,
        341,
        445,
        281,
        652,
        988,
        300,
        456,
        2067,
        380,
        746,
        300,
        390,
        411,
        370,
        1627,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10200352668762207,
      "compression_ratio": 1.6388888888888888,
      "no_speech_prob": 0.0009108459926210344
    },
    {
      "id": 204,
      "seek": 103232,
      "start": 1055.28,
      "end": 1060.48,
      "text": " across this bigger sample of users that we missed, but we didn't.",
      "tokens": [
        51512,
        2108,
        341,
        3801,
        6889,
        295,
        5022,
        300,
        321,
        6721,
        11,
        457,
        321,
        994,
        380,
        13,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10200352668762207,
      "compression_ratio": 1.6388888888888888,
      "no_speech_prob": 0.0009108459926210344
    },
    {
      "id": 205,
      "seek": 106048,
      "start": 1060.48,
      "end": 1064.24,
      "text": " So it kind of doesn't change the strategy in a way.",
      "tokens": [
        50364,
        407,
        309,
        733,
        295,
        1177,
        380,
        1319,
        264,
        5206,
        294,
        257,
        636,
        13,
        50552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21941119226916084,
      "compression_ratio": 1.5144230769230769,
      "no_speech_prob": 0.00014768286200705916
    },
    {
      "id": 206,
      "seek": 106048,
      "start": 1067.28,
      "end": 1073.1200000000001,
      "text": " I've also noticing that the sample was mainly small medium businesses.",
      "tokens": [
        50704,
        286,
        600,
        611,
        21814,
        300,
        264,
        6889,
        390,
        8704,
        1359,
        6399,
        6011,
        13,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21941119226916084,
      "compression_ratio": 1.5144230769230769,
      "no_speech_prob": 0.00014768286200705916
    },
    {
      "id": 207,
      "seek": 106048,
      "start": 1073.52,
      "end": 1074.72,
      "text": " Yeah, two.",
      "tokens": [
        51016,
        865,
        11,
        732,
        13,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21941119226916084,
      "compression_ratio": 1.5144230769230769,
      "no_speech_prob": 0.00014768286200705916
    },
    {
      "id": 208,
      "seek": 106048,
      "start": 1074.72,
      "end": 1075.2,
      "text": " Two.",
      "tokens": [
        51076,
        4453,
        13,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21941119226916084,
      "compression_ratio": 1.5144230769230769,
      "no_speech_prob": 0.00014768286200705916
    },
    {
      "id": 209,
      "seek": 106048,
      "start": 1075.52,
      "end": 1077.92,
      "text": " And I want, yeah, which is fine.",
      "tokens": [
        51116,
        400,
        286,
        528,
        11,
        1338,
        11,
        597,
        307,
        2489,
        13,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21941119226916084,
      "compression_ratio": 1.5144230769230769,
      "no_speech_prob": 0.00014768286200705916
    },
    {
      "id": 210,
      "seek": 106048,
      "start": 1077.92,
      "end": 1083.44,
      "text": " Like, I kind of had the assumption that they had different interests than the enterprise",
      "tokens": [
        51236,
        1743,
        11,
        286,
        733,
        295,
        632,
        264,
        15302,
        300,
        436,
        632,
        819,
        8847,
        813,
        264,
        14132,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21941119226916084,
      "compression_ratio": 1.5144230769230769,
      "no_speech_prob": 0.00014768286200705916
    },
    {
      "id": 211,
      "seek": 106048,
      "start": 1083.44,
      "end": 1086.16,
      "text": " customers that we're talking to that are self-managed.",
      "tokens": [
        51512,
        4581,
        300,
        321,
        434,
        1417,
        281,
        300,
        366,
        2698,
        12,
        1601,
        2980,
        13,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21941119226916084,
      "compression_ratio": 1.5144230769230769,
      "no_speech_prob": 0.00014768286200705916
    },
    {
      "id": 212,
      "seek": 108616,
      "start": 1086.72,
      "end": 1091.2,
      "text": " I, we did have, yeah, it's totally right.",
      "tokens": [
        50392,
        286,
        11,
        321,
        630,
        362,
        11,
        1338,
        11,
        309,
        311,
        3879,
        558,
        13,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2517035034881241,
      "compression_ratio": 1.458937198067633,
      "no_speech_prob": 0.001500817365013063
    },
    {
      "id": 213,
      "seek": 108616,
      "start": 1091.2,
      "end": 1091.92,
      "text": " Very keen.",
      "tokens": [
        50616,
        4372,
        20297,
        13,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2517035034881241,
      "compression_ratio": 1.458937198067633,
      "no_speech_prob": 0.001500817365013063
    },
    {
      "id": 214,
      "seek": 108616,
      "start": 1093.76,
      "end": 1098.64,
      "text": " The thing is, I think this idea that it would create more work still holds.",
      "tokens": [
        50744,
        440,
        551,
        307,
        11,
        286,
        519,
        341,
        1558,
        300,
        309,
        576,
        1884,
        544,
        589,
        920,
        9190,
        13,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2517035034881241,
      "compression_ratio": 1.458937198067633,
      "no_speech_prob": 0.001500817365013063
    },
    {
      "id": 215,
      "seek": 108616,
      "start": 1099.76,
      "end": 1100.0,
      "text": " Yes.",
      "tokens": [
        51044,
        1079,
        13,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2517035034881241,
      "compression_ratio": 1.458937198067633,
      "no_speech_prob": 0.001500817365013063
    },
    {
      "id": 216,
      "seek": 108616,
      "start": 1102.96,
      "end": 1103.68,
      "text": " I agree.",
      "tokens": [
        51204,
        286,
        3986,
        13,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2517035034881241,
      "compression_ratio": 1.458937198067633,
      "no_speech_prob": 0.001500817365013063
    },
    {
      "id": 217,
      "seek": 108616,
      "start": 1104.3200000000002,
      "end": 1109.44,
      "text": " But I guess my point is I feel like they have different needs because enterprise customers,",
      "tokens": [
        51272,
        583,
        286,
        2041,
        452,
        935,
        307,
        286,
        841,
        411,
        436,
        362,
        819,
        2203,
        570,
        14132,
        4581,
        11,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2517035034881241,
      "compression_ratio": 1.458937198067633,
      "no_speech_prob": 0.001500817365013063
    },
    {
      "id": 218,
      "seek": 108616,
      "start": 1109.44,
      "end": 1113.0400000000002,
      "text": " first of all, are typically self-managed bringing a ton of runners.",
      "tokens": [
        51528,
        700,
        295,
        439,
        11,
        366,
        5850,
        2698,
        12,
        1601,
        2980,
        5062,
        257,
        2952,
        295,
        33892,
        13,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2517035034881241,
      "compression_ratio": 1.458937198067633,
      "no_speech_prob": 0.001500817365013063
    },
    {
      "id": 219,
      "seek": 111304,
      "start": 1113.12,
      "end": 1119.52,
      "text": " So when I look at the features profile as attractive, I would imagine runner usage and compute",
      "tokens": [
        50368,
        407,
        562,
        286,
        574,
        412,
        264,
        4122,
        7964,
        382,
        12609,
        11,
        286,
        576,
        3811,
        24376,
        14924,
        293,
        14722,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18966463032890768,
      "compression_ratio": 1.488888888888889,
      "no_speech_prob": 0.00017178728012368083
    },
    {
      "id": 220,
      "seek": 111304,
      "start": 1119.52,
      "end": 1126.72,
      "text": " minutes are higher up on that than for small business, smaller medium business.",
      "tokens": [
        50688,
        2077,
        366,
        2946,
        493,
        322,
        300,
        813,
        337,
        1359,
        1606,
        11,
        4356,
        6399,
        1606,
        13,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18966463032890768,
      "compression_ratio": 1.488888888888889,
      "no_speech_prob": 0.00017178728012368083
    },
    {
      "id": 221,
      "seek": 111304,
      "start": 1130.08,
      "end": 1130.32,
      "text": " Yeah.",
      "tokens": [
        51216,
        865,
        13,
        51228
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18966463032890768,
      "compression_ratio": 1.488888888888889,
      "no_speech_prob": 0.00017178728012368083
    },
    {
      "id": 222,
      "seek": 111304,
      "start": 1131.12,
      "end": 1131.6,
      "text": " Yeah.",
      "tokens": [
        51268,
        865,
        13,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18966463032890768,
      "compression_ratio": 1.488888888888889,
      "no_speech_prob": 0.00017178728012368083
    },
    {
      "id": 223,
      "seek": 111304,
      "start": 1131.6,
      "end": 1139.76,
      "text": " And I assigned a fidelity of signal score to to kind of help us make sense of it.",
      "tokens": [
        51292,
        400,
        286,
        13279,
        257,
        46404,
        295,
        6358,
        6175,
        281,
        281,
        733,
        295,
        854,
        505,
        652,
        2020,
        295,
        309,
        13,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18966463032890768,
      "compression_ratio": 1.488888888888889,
      "no_speech_prob": 0.00017178728012368083
    },
    {
      "id": 224,
      "seek": 113976,
      "start": 1139.76,
      "end": 1145.68,
      "text": " I think what we can do is really look at the, the, the five features that have strong,",
      "tokens": [
        50364,
        286,
        519,
        437,
        321,
        393,
        360,
        307,
        534,
        574,
        412,
        264,
        11,
        264,
        11,
        264,
        1732,
        4122,
        300,
        362,
        2068,
        11,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19716690136836126,
      "compression_ratio": 1.6553398058252426,
      "no_speech_prob": 0.0007744713220745325
    },
    {
      "id": 225,
      "seek": 113976,
      "start": 1146.72,
      "end": 1150.16,
      "text": " we have strong, have it like a strong signal that they're indifferent to.",
      "tokens": [
        50712,
        321,
        362,
        2068,
        11,
        362,
        309,
        411,
        257,
        2068,
        6358,
        300,
        436,
        434,
        48502,
        281,
        13,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19716690136836126,
      "compression_ratio": 1.6553398058252426,
      "no_speech_prob": 0.0007744713220745325
    },
    {
      "id": 226,
      "seek": 113976,
      "start": 1150.16,
      "end": 1151.36,
      "text": " That's kind of the most.",
      "tokens": [
        50884,
        663,
        311,
        733,
        295,
        264,
        881,
        13,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19716690136836126,
      "compression_ratio": 1.6553398058252426,
      "no_speech_prob": 0.0007744713220745325
    },
    {
      "id": 227,
      "seek": 113976,
      "start": 1152.64,
      "end": 1152.96,
      "text": " Okay.",
      "tokens": [
        51008,
        1033,
        13,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19716690136836126,
      "compression_ratio": 1.6553398058252426,
      "no_speech_prob": 0.0007744713220745325
    },
    {
      "id": 228,
      "seek": 113976,
      "start": 1153.6,
      "end": 1156.48,
      "text": " Oh, it's like, okay, don't invest heavily in these.",
      "tokens": [
        51056,
        876,
        11,
        309,
        311,
        411,
        11,
        1392,
        11,
        500,
        380,
        1963,
        10950,
        294,
        613,
        13,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19716690136836126,
      "compression_ratio": 1.6553398058252426,
      "no_speech_prob": 0.0007744713220745325
    },
    {
      "id": 229,
      "seek": 113976,
      "start": 1157.36,
      "end": 1157.92,
      "text": " Okay.",
      "tokens": [
        51244,
        1033,
        13,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19716690136836126,
      "compression_ratio": 1.6553398058252426,
      "no_speech_prob": 0.0007744713220745325
    },
    {
      "id": 230,
      "seek": 113976,
      "start": 1157.92,
      "end": 1158.32,
      "text": " Yeah.",
      "tokens": [
        51272,
        865,
        13,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19716690136836126,
      "compression_ratio": 1.6553398058252426,
      "no_speech_prob": 0.0007744713220745325
    },
    {
      "id": 231,
      "seek": 113976,
      "start": 1158.96,
      "end": 1165.04,
      "text": " Oh, that's also so interesting though, because the notifications, I don't know, it's,",
      "tokens": [
        51324,
        876,
        11,
        300,
        311,
        611,
        370,
        1880,
        1673,
        11,
        570,
        264,
        13426,
        11,
        286,
        500,
        380,
        458,
        11,
        309,
        311,
        11,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19716690136836126,
      "compression_ratio": 1.6553398058252426,
      "no_speech_prob": 0.0007744713220745325
    },
    {
      "id": 232,
      "seek": 116504,
      "start": 1165.6,
      "end": 1171.44,
      "text": " yeah, because, yeah, because it's just, it could end up really distracting them,",
      "tokens": [
        50392,
        1338,
        11,
        570,
        11,
        1338,
        11,
        570,
        309,
        311,
        445,
        11,
        309,
        727,
        917,
        493,
        534,
        36689,
        552,
        11,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20612821823511368,
      "compression_ratio": 1.5384615384615385,
      "no_speech_prob": 0.0004968256107531488
    },
    {
      "id": 233,
      "seek": 116504,
      "start": 1171.44,
      "end": 1173.04,
      "text": " the notifications parts.",
      "tokens": [
        50684,
        264,
        13426,
        3166,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20612821823511368,
      "compression_ratio": 1.5384615384615385,
      "no_speech_prob": 0.0004968256107531488
    },
    {
      "id": 234,
      "seek": 116504,
      "start": 1174.8799999999999,
      "end": 1175.2,
      "text": " Right.",
      "tokens": [
        50856,
        1779,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20612821823511368,
      "compression_ratio": 1.5384615384615385,
      "no_speech_prob": 0.0004968256107531488
    },
    {
      "id": 235,
      "seek": 116504,
      "start": 1177.2,
      "end": 1179.04,
      "text": " And it could take them out of their flow.",
      "tokens": [
        50972,
        400,
        309,
        727,
        747,
        552,
        484,
        295,
        641,
        3095,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20612821823511368,
      "compression_ratio": 1.5384615384615385,
      "no_speech_prob": 0.0004968256107531488
    },
    {
      "id": 236,
      "seek": 116504,
      "start": 1183.52,
      "end": 1183.84,
      "text": " Yeah.",
      "tokens": [
        51288,
        865,
        13,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20612821823511368,
      "compression_ratio": 1.5384615384615385,
      "no_speech_prob": 0.0004968256107531488
    },
    {
      "id": 237,
      "seek": 116504,
      "start": 1186.08,
      "end": 1187.2,
      "text": " I guess that makes sense.",
      "tokens": [
        51416,
        286,
        2041,
        300,
        1669,
        2020,
        13,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20612821823511368,
      "compression_ratio": 1.5384615384615385,
      "no_speech_prob": 0.0004968256107531488
    },
    {
      "id": 238,
      "seek": 116504,
      "start": 1188.24,
      "end": 1194.32,
      "text": " But there, but then I guess does that mean that we just think about different ways of solving",
      "tokens": [
        51524,
        583,
        456,
        11,
        457,
        550,
        286,
        2041,
        775,
        300,
        914,
        300,
        321,
        445,
        519,
        466,
        819,
        2098,
        295,
        12606,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20612821823511368,
      "compression_ratio": 1.5384615384615385,
      "no_speech_prob": 0.0004968256107531488
    },
    {
      "id": 239,
      "seek": 119432,
      "start": 1194.8,
      "end": 1201.6799999999998,
      "text": " when your cube performance stinks or when your runners are airing out a lot, like we have to figure",
      "tokens": [
        50388,
        562,
        428,
        13728,
        3389,
        50114,
        420,
        562,
        428,
        33892,
        366,
        1988,
        278,
        484,
        257,
        688,
        11,
        411,
        321,
        362,
        281,
        2573,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17678519501083198,
      "compression_ratio": 1.6435185185185186,
      "no_speech_prob": 0.0002727691608015448
    },
    {
      "id": 240,
      "seek": 119432,
      "start": 1201.6799999999998,
      "end": 1205.36,
      "text": " out of different ways to give them that information. I don't know.",
      "tokens": [
        50732,
        484,
        295,
        819,
        2098,
        281,
        976,
        552,
        300,
        1589,
        13,
        286,
        500,
        380,
        458,
        13,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17678519501083198,
      "compression_ratio": 1.6435185185185186,
      "no_speech_prob": 0.0002727691608015448
    },
    {
      "id": 241,
      "seek": 119432,
      "start": 1207.28,
      "end": 1213.76,
      "text": " Or at least make the notifications like customizable as opposed to like across the board.",
      "tokens": [
        51012,
        1610,
        412,
        1935,
        652,
        264,
        13426,
        411,
        47922,
        382,
        8851,
        281,
        411,
        2108,
        264,
        3150,
        13,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17678519501083198,
      "compression_ratio": 1.6435185185185186,
      "no_speech_prob": 0.0002727691608015448
    },
    {
      "id": 242,
      "seek": 119432,
      "start": 1213.76,
      "end": 1218.1599999999999,
      "text": " So it's like, you know, they don't want to get like all of their runners aren't important to them.",
      "tokens": [
        51336,
        407,
        309,
        311,
        411,
        11,
        291,
        458,
        11,
        436,
        500,
        380,
        528,
        281,
        483,
        411,
        439,
        295,
        641,
        33892,
        3212,
        380,
        1021,
        281,
        552,
        13,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17678519501083198,
      "compression_ratio": 1.6435185185185186,
      "no_speech_prob": 0.0002727691608015448
    },
    {
      "id": 243,
      "seek": 121816,
      "start": 1218.24,
      "end": 1224.16,
      "text": " It might be like only this subset. So like allowing them to opt in.",
      "tokens": [
        50368,
        467,
        1062,
        312,
        411,
        787,
        341,
        25993,
        13,
        407,
        411,
        8293,
        552,
        281,
        2427,
        294,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22051420211791992,
      "compression_ratio": 1.5529953917050692,
      "no_speech_prob": 0.0011665972415357828
    },
    {
      "id": 244,
      "seek": 121816,
      "start": 1225.28,
      "end": 1225.6000000000001,
      "text": " Yeah.",
      "tokens": [
        50720,
        865,
        13,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22051420211791992,
      "compression_ratio": 1.5529953917050692,
      "no_speech_prob": 0.0011665972415357828
    },
    {
      "id": 245,
      "seek": 121816,
      "start": 1226.24,
      "end": 1228.16,
      "text": " Gin model versus like opting out.",
      "tokens": [
        50768,
        36846,
        2316,
        5717,
        411,
        2427,
        278,
        484,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22051420211791992,
      "compression_ratio": 1.5529953917050692,
      "no_speech_prob": 0.0011665972415357828
    },
    {
      "id": 246,
      "seek": 121816,
      "start": 1229.1200000000001,
      "end": 1229.44,
      "text": " Okay.",
      "tokens": [
        50912,
        1033,
        13,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22051420211791992,
      "compression_ratio": 1.5529953917050692,
      "no_speech_prob": 0.0011665972415357828
    },
    {
      "id": 247,
      "seek": 121816,
      "start": 1230.5600000000002,
      "end": 1238.3200000000002,
      "text": " It's like just, we should just be really wary of creating more pings and they're already busy.",
      "tokens": [
        50984,
        467,
        311,
        411,
        445,
        11,
        321,
        820,
        445,
        312,
        534,
        46585,
        295,
        4084,
        544,
        280,
        1109,
        293,
        436,
        434,
        1217,
        5856,
        13,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22051420211791992,
      "compression_ratio": 1.5529953917050692,
      "no_speech_prob": 0.0011665972415357828
    },
    {
      "id": 248,
      "seek": 121816,
      "start": 1239.92,
      "end": 1240.48,
      "text": " Yeah.",
      "tokens": [
        51452,
        865,
        13,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22051420211791992,
      "compression_ratio": 1.5529953917050692,
      "no_speech_prob": 0.0011665972415357828
    },
    {
      "id": 249,
      "seek": 121816,
      "start": 1240.8000000000002,
      "end": 1242.3200000000002,
      "text": " I totally understand that.",
      "tokens": [
        51496,
        286,
        3879,
        1223,
        300,
        13,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22051420211791992,
      "compression_ratio": 1.5529953917050692,
      "no_speech_prob": 0.0011665972415357828
    },
    {
      "id": 250,
      "seek": 121816,
      "start": 1242.72,
      "end": 1244.72,
      "text": " This is really cool though, Erica.",
      "tokens": [
        51592,
        639,
        307,
        534,
        1627,
        1673,
        11,
        37429,
        13,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22051420211791992,
      "compression_ratio": 1.5529953917050692,
      "no_speech_prob": 0.0011665972415357828
    },
    {
      "id": 251,
      "seek": 121816,
      "start": 1244.72,
      "end": 1247.52,
      "text": " I'm going to look, this is my first time actually seeing it.",
      "tokens": [
        51692,
        286,
        478,
        516,
        281,
        574,
        11,
        341,
        307,
        452,
        700,
        565,
        767,
        2577,
        309,
        13,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22051420211791992,
      "compression_ratio": 1.5529953917050692,
      "no_speech_prob": 0.0011665972415357828
    },
    {
      "id": 252,
      "seek": 124752,
      "start": 1247.52,
      "end": 1249.28,
      "text": " So I'm going to look deeper into it.",
      "tokens": [
        50364,
        407,
        286,
        478,
        516,
        281,
        574,
        7731,
        666,
        309,
        13,
        50452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2339208098663681,
      "compression_ratio": 1.577319587628866,
      "no_speech_prob": 0.00016003380005713552
    },
    {
      "id": 253,
      "seek": 124752,
      "start": 1249.28,
      "end": 1251.12,
      "text": " And I think our meetings tomorrow.",
      "tokens": [
        50452,
        400,
        286,
        519,
        527,
        8410,
        4153,
        13,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2339208098663681,
      "compression_ratio": 1.577319587628866,
      "no_speech_prob": 0.00016003380005713552
    },
    {
      "id": 254,
      "seek": 124752,
      "start": 1251.6,
      "end": 1252.0,
      "text": " Yeah.",
      "tokens": [
        50568,
        865,
        13,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2339208098663681,
      "compression_ratio": 1.577319587628866,
      "no_speech_prob": 0.00016003380005713552
    },
    {
      "id": 255,
      "seek": 124752,
      "start": 1252.0,
      "end": 1252.56,
      "text": " Yeah.",
      "tokens": [
        50588,
        865,
        13,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2339208098663681,
      "compression_ratio": 1.577319587628866,
      "no_speech_prob": 0.00016003380005713552
    },
    {
      "id": 256,
      "seek": 124752,
      "start": 1252.56,
      "end": 1255.92,
      "text": " And let me know what we what to do.",
      "tokens": [
        50616,
        400,
        718,
        385,
        458,
        437,
        321,
        437,
        281,
        360,
        13,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2339208098663681,
      "compression_ratio": 1.577319587628866,
      "no_speech_prob": 0.00016003380005713552
    },
    {
      "id": 257,
      "seek": 124752,
      "start": 1255.92,
      "end": 1263.76,
      "text": " But I think it's a really good critique of the of the sample that's like really on point.",
      "tokens": [
        50784,
        583,
        286,
        519,
        309,
        311,
        257,
        534,
        665,
        25673,
        295,
        264,
        295,
        264,
        6889,
        300,
        311,
        411,
        534,
        322,
        935,
        13,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2339208098663681,
      "compression_ratio": 1.577319587628866,
      "no_speech_prob": 0.00016003380005713552
    },
    {
      "id": 258,
      "seek": 124752,
      "start": 1263.76,
      "end": 1275.76,
      "text": " I just think that the problems that we're seeing with those features should also have a problem.",
      "tokens": [
        51176,
        286,
        445,
        519,
        300,
        264,
        2740,
        300,
        321,
        434,
        2577,
        365,
        729,
        4122,
        820,
        611,
        362,
        257,
        1154,
        13,
        51776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2339208098663681,
      "compression_ratio": 1.577319587628866,
      "no_speech_prob": 0.00016003380005713552
    },
    {
      "id": 259,
      "seek": 127576,
      "start": 1275.84,
      "end": 1281.84,
      "text": " Like notifications for enterprise level participants would skate that would scale that finding kind of right.",
      "tokens": [
        50368,
        1743,
        13426,
        337,
        14132,
        1496,
        10503,
        576,
        18237,
        300,
        576,
        4373,
        300,
        5006,
        733,
        295,
        558,
        13,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17950065463196999,
      "compression_ratio": 1.7773109243697478,
      "no_speech_prob": 0.001643517753109336
    },
    {
      "id": 260,
      "seek": 127576,
      "start": 1281.84,
      "end": 1282.64,
      "text": " Definitely.",
      "tokens": [
        50668,
        12151,
        13,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17950065463196999,
      "compression_ratio": 1.7773109243697478,
      "no_speech_prob": 0.001643517753109336
    },
    {
      "id": 261,
      "seek": 127576,
      "start": 1282.64,
      "end": 1283.04,
      "text": " Yes.",
      "tokens": [
        50708,
        1079,
        13,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17950065463196999,
      "compression_ratio": 1.7773109243697478,
      "no_speech_prob": 0.001643517753109336
    },
    {
      "id": 262,
      "seek": 127576,
      "start": 1283.68,
      "end": 1289.44,
      "text": " I was looking more at slide seven of the ones that are attractive because I figured the ones that are",
      "tokens": [
        50760,
        286,
        390,
        1237,
        544,
        412,
        4137,
        3407,
        295,
        264,
        2306,
        300,
        366,
        12609,
        570,
        286,
        8932,
        264,
        2306,
        300,
        366,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17950065463196999,
      "compression_ratio": 1.7773109243697478,
      "no_speech_prob": 0.001643517753109336
    },
    {
      "id": 263,
      "seek": 127576,
      "start": 1289.44,
      "end": 1291.6,
      "text": " said they're set at week there.",
      "tokens": [
        51048,
        848,
        436,
        434,
        992,
        412,
        1243,
        456,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17950065463196999,
      "compression_ratio": 1.7773109243697478,
      "no_speech_prob": 0.001643517753109336
    },
    {
      "id": 264,
      "seek": 127576,
      "start": 1291.6,
      "end": 1294.96,
      "text": " I would have thought that they would be higher up for enterprise users.",
      "tokens": [
        51156,
        286,
        576,
        362,
        1194,
        300,
        436,
        576,
        312,
        2946,
        493,
        337,
        14132,
        5022,
        13,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17950065463196999,
      "compression_ratio": 1.7773109243697478,
      "no_speech_prob": 0.001643517753109336
    },
    {
      "id": 265,
      "seek": 127576,
      "start": 1294.96,
      "end": 1301.44,
      "text": " But the findings that in slide eight definitely relate to all I totally agree.",
      "tokens": [
        51324,
        583,
        264,
        16483,
        300,
        294,
        4137,
        3180,
        2138,
        10961,
        281,
        439,
        286,
        3879,
        3986,
        13,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17950065463196999,
      "compression_ratio": 1.7773109243697478,
      "no_speech_prob": 0.001643517753109336
    },
    {
      "id": 266,
      "seek": 127576,
      "start": 1302.72,
      "end": 1303.2,
      "text": " Yeah.",
      "tokens": [
        51712,
        865,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17950065463196999,
      "compression_ratio": 1.7773109243697478,
      "no_speech_prob": 0.001643517753109336
    },
    {
      "id": 267,
      "seek": 127576,
      "start": 1303.2,
      "end": 1303.68,
      "text": " Yeah.",
      "tokens": [
        51736,
        865,
        13,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17950065463196999,
      "compression_ratio": 1.7773109243697478,
      "no_speech_prob": 0.001643517753109336
    },
    {
      "id": 268,
      "seek": 130368,
      "start": 1303.76,
      "end": 1305.3600000000001,
      "text": " So we can decide.",
      "tokens": [
        50368,
        407,
        321,
        393,
        4536,
        13,
        50448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16092407819136834,
      "compression_ratio": 1.7219730941704037,
      "no_speech_prob": 0.00032366139930672944
    },
    {
      "id": 269,
      "seek": 130368,
      "start": 1305.3600000000001,
      "end": 1307.92,
      "text": " I think the thing is we didn't get a clear.",
      "tokens": [
        50448,
        286,
        519,
        264,
        551,
        307,
        321,
        994,
        380,
        483,
        257,
        1850,
        13,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16092407819136834,
      "compression_ratio": 1.7219730941704037,
      "no_speech_prob": 0.00032366139930672944
    },
    {
      "id": 270,
      "seek": 130368,
      "start": 1307.92,
      "end": 1311.2,
      "text": " I mean, I thought we might get a clear like champion here.",
      "tokens": [
        50576,
        286,
        914,
        11,
        286,
        1194,
        321,
        1062,
        483,
        257,
        1850,
        411,
        10971,
        510,
        13,
        50740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16092407819136834,
      "compression_ratio": 1.7219730941704037,
      "no_speech_prob": 0.00032366139930672944
    },
    {
      "id": 271,
      "seek": 130368,
      "start": 1312.4,
      "end": 1318.16,
      "text": " So that's like important that we don't want to like sprint towards any one of these particular visions.",
      "tokens": [
        50800,
        407,
        300,
        311,
        411,
        1021,
        300,
        321,
        500,
        380,
        528,
        281,
        411,
        25075,
        3030,
        604,
        472,
        295,
        613,
        1729,
        30746,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16092407819136834,
      "compression_ratio": 1.7219730941704037,
      "no_speech_prob": 0.00032366139930672944
    },
    {
      "id": 272,
      "seek": 130368,
      "start": 1318.88,
      "end": 1325.76,
      "text": " And I think that like this AI assisted is the way that we want to be thinking about it.",
      "tokens": [
        51124,
        400,
        286,
        519,
        300,
        411,
        341,
        7318,
        30291,
        307,
        264,
        636,
        300,
        321,
        528,
        281,
        312,
        1953,
        466,
        309,
        13,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16092407819136834,
      "compression_ratio": 1.7219730941704037,
      "no_speech_prob": 0.00032366139930672944
    },
    {
      "id": 273,
      "seek": 130368,
      "start": 1327.6000000000001,
      "end": 1331.3600000000001,
      "text": " Like yeah, behind the scenes, they just wanted behind the scenes.",
      "tokens": [
        51560,
        1743,
        1338,
        11,
        2261,
        264,
        8026,
        11,
        436,
        445,
        1415,
        2261,
        264,
        8026,
        13,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16092407819136834,
      "compression_ratio": 1.7219730941704037,
      "no_speech_prob": 0.00032366139930672944
    },
    {
      "id": 274,
      "seek": 130368,
      "start": 1333.1200000000001,
      "end": 1333.44,
      "text": " Yeah.",
      "tokens": [
        51836,
        865,
        13,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16092407819136834,
      "compression_ratio": 1.7219730941704037,
      "no_speech_prob": 0.00032366139930672944
    },
    {
      "id": 275,
      "seek": 133368,
      "start": 1334.5600000000002,
      "end": 1337.92,
      "text": " Okay, I have some more questions, but I don't want to take up a ton of time.",
      "tokens": [
        50408,
        1033,
        11,
        286,
        362,
        512,
        544,
        1651,
        11,
        457,
        286,
        500,
        380,
        528,
        281,
        747,
        493,
        257,
        2952,
        295,
        565,
        13,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 276,
      "seek": 133368,
      "start": 1337.92,
      "end": 1338.4,
      "text": " Okay.",
      "tokens": [
        50576,
        1033,
        13,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 277,
      "seek": 133368,
      "start": 1338.4,
      "end": 1339.52,
      "text": " I'm tomorrow.",
      "tokens": [
        50600,
        286,
        478,
        4153,
        13,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 278,
      "seek": 133368,
      "start": 1340.5600000000002,
      "end": 1342.24,
      "text": " Cool everyone, don't you care?",
      "tokens": [
        50708,
        8561,
        1518,
        11,
        500,
        380,
        291,
        1127,
        30,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 279,
      "seek": 133368,
      "start": 1342.24,
      "end": 1342.72,
      "text": " Yeah.",
      "tokens": [
        50792,
        865,
        13,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 280,
      "seek": 133368,
      "start": 1344.48,
      "end": 1346.5600000000002,
      "text": " And let me know if you want to seek today too.",
      "tokens": [
        50904,
        400,
        718,
        385,
        458,
        498,
        291,
        528,
        281,
        8075,
        965,
        886,
        13,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 281,
      "seek": 133368,
      "start": 1347.8400000000001,
      "end": 1348.16,
      "text": " Okay.",
      "tokens": [
        51072,
        1033,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 282,
      "seek": 133368,
      "start": 1349.44,
      "end": 1349.68,
      "text": " Yeah.",
      "tokens": [
        51152,
        865,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 283,
      "seek": 133368,
      "start": 1352.3200000000002,
      "end": 1354.0800000000002,
      "text": " And then or just slack about it.",
      "tokens": [
        51296,
        400,
        550,
        420,
        445,
        29767,
        466,
        309,
        13,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 284,
      "seek": 133368,
      "start": 1354.0800000000002,
      "end": 1358.5600000000002,
      "text": " And then the other study I'm working on is this conversational AI study,",
      "tokens": [
        51384,
        400,
        550,
        264,
        661,
        2979,
        286,
        478,
        1364,
        322,
        307,
        341,
        2615,
        1478,
        7318,
        2979,
        11,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 285,
      "seek": 133368,
      "start": 1358.5600000000002,
      "end": 1362.3200000000002,
      "text": " which is like a team of researchers and I'm working with ops folks.",
      "tokens": [
        51608,
        597,
        307,
        411,
        257,
        1469,
        295,
        10309,
        293,
        286,
        478,
        1364,
        365,
        44663,
        4024,
        13,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27458480308795796,
      "compression_ratio": 1.605263157894737,
      "no_speech_prob": 0.0002439608797430992
    },
    {
      "id": 286,
      "seek": 136232,
      "start": 1363.28,
      "end": 1368.8799999999999,
      "text": " And we were asking we did like an intro interview and then they're doing a diary study",
      "tokens": [
        50412,
        400,
        321,
        645,
        3365,
        321,
        630,
        411,
        364,
        12897,
        4049,
        293,
        550,
        436,
        434,
        884,
        257,
        26492,
        2979,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15890184692714526,
      "compression_ratio": 1.7162162162162162,
      "no_speech_prob": 0.00037120789056643844
    },
    {
      "id": 287,
      "seek": 136232,
      "start": 1368.8799999999999,
      "end": 1374.24,
      "text": " where every two to three days they let us know the tasks that they performed with conversational AI",
      "tokens": [
        50692,
        689,
        633,
        732,
        281,
        1045,
        1708,
        436,
        718,
        505,
        458,
        264,
        9608,
        300,
        436,
        10332,
        365,
        2615,
        1478,
        7318,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15890184692714526,
      "compression_ratio": 1.7162162162162162,
      "no_speech_prob": 0.00037120789056643844
    },
    {
      "id": 288,
      "seek": 136232,
      "start": 1375.04,
      "end": 1377.84,
      "text": " and how it went and they're giving a screenshots of those.",
      "tokens": [
        51000,
        293,
        577,
        309,
        1437,
        293,
        436,
        434,
        2902,
        257,
        40661,
        295,
        729,
        13,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15890184692714526,
      "compression_ratio": 1.7162162162162162,
      "no_speech_prob": 0.00037120789056643844
    },
    {
      "id": 289,
      "seek": 136232,
      "start": 1379.2,
      "end": 1385.2,
      "text": " And so we're getting a sense of how we might use conversational AI in the app space.",
      "tokens": [
        51208,
        400,
        370,
        321,
        434,
        1242,
        257,
        2020,
        295,
        577,
        321,
        1062,
        764,
        2615,
        1478,
        7318,
        294,
        264,
        724,
        1901,
        13,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15890184692714526,
      "compression_ratio": 1.7162162162162162,
      "no_speech_prob": 0.00037120789056643844
    },
    {
      "id": 290,
      "seek": 136232,
      "start": 1386.0,
      "end": 1389.4399999999998,
      "text": " Although we think it's not related to performance.",
      "tokens": [
        51548,
        5780,
        321,
        519,
        309,
        311,
        406,
        4077,
        281,
        3389,
        13,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15890184692714526,
      "compression_ratio": 1.7162162162162162,
      "no_speech_prob": 0.00037120789056643844
    },
    {
      "id": 291,
      "seek": 138944,
      "start": 1389.44,
      "end": 1395.76,
      "text": " Automations like we got a signal that they that's inefficient use of their time.",
      "tokens": [
        50364,
        24619,
        763,
        411,
        321,
        658,
        257,
        6358,
        300,
        436,
        300,
        311,
        43495,
        764,
        295,
        641,
        565,
        13,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19907008684598482,
      "compression_ratio": 1.6305418719211822,
      "no_speech_prob": 0.0033811088651418686
    },
    {
      "id": 292,
      "seek": 138944,
      "start": 1397.1200000000001,
      "end": 1403.2,
      "text": " It's more like it looks more like they like it like as an idea generator or like",
      "tokens": [
        50748,
        467,
        311,
        544,
        411,
        309,
        1542,
        544,
        411,
        436,
        411,
        309,
        411,
        382,
        364,
        1558,
        19265,
        420,
        411,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19907008684598482,
      "compression_ratio": 1.6305418719211822,
      "no_speech_prob": 0.0033811088651418686
    },
    {
      "id": 293,
      "seek": 138944,
      "start": 1403.8400000000001,
      "end": 1407.8400000000001,
      "text": " getting the right language to use for documentation searches, stuff like that.",
      "tokens": [
        51084,
        1242,
        264,
        558,
        2856,
        281,
        764,
        337,
        14333,
        26701,
        11,
        1507,
        411,
        300,
        13,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19907008684598482,
      "compression_ratio": 1.6305418719211822,
      "no_speech_prob": 0.0033811088651418686
    },
    {
      "id": 294,
      "seek": 138944,
      "start": 1409.28,
      "end": 1416.88,
      "text": " Anyway, but I'm threading the like really technical example tasks in that thread I linked.",
      "tokens": [
        51356,
        5684,
        11,
        457,
        286,
        478,
        7207,
        278,
        264,
        411,
        534,
        6191,
        1365,
        9608,
        294,
        300,
        7207,
        286,
        9408,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19907008684598482,
      "compression_ratio": 1.6305418719211822,
      "no_speech_prob": 0.0033811088651418686
    },
    {
      "id": 295,
      "seek": 141688,
      "start": 1417.5200000000002,
      "end": 1424.24,
      "text": " And we'll we'll be doing the follow up interviews with them in the second and third week of January.",
      "tokens": [
        50396,
        400,
        321,
        603,
        321,
        603,
        312,
        884,
        264,
        1524,
        493,
        12318,
        365,
        552,
        294,
        264,
        1150,
        293,
        2636,
        1243,
        295,
        7061,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12143946667106784,
      "compression_ratio": 1.683127572016461,
      "no_speech_prob": 0.0008596761617809534
    },
    {
      "id": 296,
      "seek": 141688,
      "start": 1424.24,
      "end": 1429.2800000000002,
      "text": " And so we'll be asking people to like give me follow up questions to ask about those tasks.",
      "tokens": [
        50732,
        400,
        370,
        321,
        603,
        312,
        3365,
        561,
        281,
        411,
        976,
        385,
        1524,
        493,
        1651,
        281,
        1029,
        466,
        729,
        9608,
        13,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12143946667106784,
      "compression_ratio": 1.683127572016461,
      "no_speech_prob": 0.0008596761617809534
    },
    {
      "id": 297,
      "seek": 141688,
      "start": 1430.96,
      "end": 1432.64,
      "text": " Trying to put that on your radar.",
      "tokens": [
        51068,
        20180,
        281,
        829,
        300,
        322,
        428,
        16544,
        13,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12143946667106784,
      "compression_ratio": 1.683127572016461,
      "no_speech_prob": 0.0008596761617809534
    },
    {
      "id": 298,
      "seek": 141688,
      "start": 1433.7600000000002,
      "end": 1441.0400000000002,
      "text": " And then the next thing is I was initially thinking that we would run that shared resources",
      "tokens": [
        51208,
        400,
        550,
        264,
        958,
        551,
        307,
        286,
        390,
        9105,
        1953,
        300,
        321,
        576,
        1190,
        300,
        5507,
        3593,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12143946667106784,
      "compression_ratio": 1.683127572016461,
      "no_speech_prob": 0.0008596761617809534
    },
    {
      "id": 299,
      "seek": 141688,
      "start": 1441.0400000000002,
      "end": 1445.92,
      "text": " workshop at the summit, but I think we should do it after the summit because it seems like",
      "tokens": [
        51572,
        13541,
        412,
        264,
        21564,
        11,
        457,
        286,
        519,
        321,
        820,
        360,
        309,
        934,
        264,
        21564,
        570,
        309,
        2544,
        411,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12143946667106784,
      "compression_ratio": 1.683127572016461,
      "no_speech_prob": 0.0008596761617809534
    },
    {
      "id": 300,
      "seek": 144592,
      "start": 1446.48,
      "end": 1450.8000000000002,
      "text": " I'll be like the only nerd being like, hey, let's work.",
      "tokens": [
        50392,
        286,
        603,
        312,
        411,
        264,
        787,
        23229,
        885,
        411,
        11,
        4177,
        11,
        718,
        311,
        589,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33529016448230275,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0007564367260783911
    },
    {
      "id": 301,
      "seek": 144592,
      "start": 1457.3600000000001,
      "end": 1462.4,
      "text": " But let me know if you want to go rock climbing because there's a rock climbing issue that someone created.",
      "tokens": [
        50936,
        583,
        718,
        385,
        458,
        498,
        291,
        528,
        281,
        352,
        3727,
        14780,
        570,
        456,
        311,
        257,
        3727,
        14780,
        2734,
        300,
        1580,
        2942,
        13,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33529016448230275,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0007564367260783911
    },
    {
      "id": 302,
      "seek": 144592,
      "start": 1463.3600000000001,
      "end": 1463.6000000000001,
      "text": " Okay.",
      "tokens": [
        51236,
        1033,
        13,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33529016448230275,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0007564367260783911
    },
    {
      "id": 303,
      "seek": 144592,
      "start": 1465.44,
      "end": 1466.48,
      "text": " Work or rock climbing.",
      "tokens": [
        51340,
        6603,
        420,
        3727,
        14780,
        13,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33529016448230275,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0007564367260783911
    },
    {
      "id": 304,
      "seek": 144592,
      "start": 1467.3600000000001,
      "end": 1468.16,
      "text": " That's all I've got.",
      "tokens": [
        51436,
        663,
        311,
        439,
        286,
        600,
        658,
        13,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33529016448230275,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0007564367260783911
    },
    {
      "id": 305,
      "seek": 144592,
      "start": 1469.2,
      "end": 1471.1200000000001,
      "text": " We can have the workshop while rock climbing.",
      "tokens": [
        51528,
        492,
        393,
        362,
        264,
        13541,
        1339,
        3727,
        14780,
        13,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33529016448230275,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0007564367260783911
    },
    {
      "id": 306,
      "seek": 144592,
      "start": 1472.0,
      "end": 1472.96,
      "text": " That's a real challenge.",
      "tokens": [
        51668,
        663,
        311,
        257,
        957,
        3430,
        13,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33529016448230275,
      "compression_ratio": 1.6136363636363635,
      "no_speech_prob": 0.0007564367260783911
    },
    {
      "id": 307,
      "seek": 147592,
      "start": 1476.4,
      "end": 1479.68,
      "text": " Okay, we're too happy with that.",
      "tokens": [
        50388,
        1033,
        11,
        321,
        434,
        886,
        2055,
        365,
        300,
        13,
        50552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2890716734386626,
      "compression_ratio": 1.4223602484472049,
      "no_speech_prob": 0.006450782064348459
    },
    {
      "id": 308,
      "seek": 147592,
      "start": 1488.88,
      "end": 1494.96,
      "text": " But I think it's a good idea because yeah, you know, maybe some of us will also take some time",
      "tokens": [
        51012,
        583,
        286,
        519,
        309,
        311,
        257,
        665,
        1558,
        570,
        1338,
        11,
        291,
        458,
        11,
        1310,
        512,
        295,
        505,
        486,
        611,
        747,
        512,
        565,
        51316
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2890716734386626,
      "compression_ratio": 1.4223602484472049,
      "no_speech_prob": 0.006450782064348459
    },
    {
      "id": 309,
      "seek": 147592,
      "start": 1494.96,
      "end": 1501.1200000000001,
      "text": " off after summit or before right and some traveling. I think it's good. Well, once it gets confirmed,",
      "tokens": [
        51316,
        766,
        934,
        21564,
        420,
        949,
        558,
        293,
        512,
        9712,
        13,
        286,
        519,
        309,
        311,
        665,
        13,
        1042,
        11,
        1564,
        309,
        2170,
        11341,
        11,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2890716734386626,
      "compression_ratio": 1.4223602484472049,
      "no_speech_prob": 0.006450782064348459
    },
    {
      "id": 310,
      "seek": 150112,
      "start": 1501.76,
      "end": 1504.4799999999998,
      "text": " we can play in the round the summit for that.",
      "tokens": [
        50396,
        321,
        393,
        862,
        294,
        264,
        3098,
        264,
        21564,
        337,
        300,
        13,
        50532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 311,
      "seek": 150112,
      "start": 1504.4799999999998,
      "end": 1507.52,
      "text": " And if not, we'll just, you know, pick a date in Q.",
      "tokens": [
        50532,
        400,
        498,
        406,
        11,
        321,
        603,
        445,
        11,
        291,
        458,
        11,
        1888,
        257,
        4002,
        294,
        1249,
        13,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 312,
      "seek": 150112,
      "start": 1508.4799999999998,
      "end": 1510.3999999999999,
      "text": " Is it going to be Q2? Things going to be Q2, right?",
      "tokens": [
        50732,
        1119,
        309,
        516,
        281,
        312,
        1249,
        17,
        30,
        9514,
        516,
        281,
        312,
        1249,
        17,
        11,
        558,
        30,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 313,
      "seek": 150112,
      "start": 1510.9599999999998,
      "end": 1512.0,
      "text": " Yeah, kind of Q2.",
      "tokens": [
        50856,
        865,
        11,
        733,
        295,
        1249,
        17,
        13,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 314,
      "seek": 150112,
      "start": 1512.0,
      "end": 1514.4799999999998,
      "text": " Yeah, I think it's a safer.",
      "tokens": [
        50908,
        865,
        11,
        286,
        519,
        309,
        311,
        257,
        15856,
        13,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 315,
      "seek": 150112,
      "start": 1515.4399999999998,
      "end": 1516.6399999999999,
      "text": " Anyway, no?",
      "tokens": [
        51080,
        5684,
        11,
        572,
        30,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 316,
      "seek": 150112,
      "start": 1517.6,
      "end": 1517.84,
      "text": " Okay.",
      "tokens": [
        51188,
        1033,
        13,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 317,
      "seek": 150112,
      "start": 1518.8799999999999,
      "end": 1522.6399999999999,
      "text": " I think that's that, right? We'll, it's already off.",
      "tokens": [
        51252,
        286,
        519,
        300,
        311,
        300,
        11,
        558,
        30,
        492,
        603,
        11,
        309,
        311,
        1217,
        766,
        13,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 318,
      "seek": 150112,
      "start": 1524.7199999999998,
      "end": 1525.52,
      "text": " Anything else?",
      "tokens": [
        51544,
        11998,
        1646,
        30,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 319,
      "seek": 150112,
      "start": 1525.52,
      "end": 1528.7199999999998,
      "text": " We didn't discuss. We'd like to share before wrap up for the year.",
      "tokens": [
        51584,
        492,
        994,
        380,
        2248,
        13,
        492,
        1116,
        411,
        281,
        2073,
        949,
        7019,
        493,
        337,
        264,
        1064,
        13,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40203353881835935,
      "compression_ratio": 1.5605381165919283,
      "no_speech_prob": 0.028042294085025787
    },
    {
      "id": 320,
      "seek": 152872,
      "start": 1528.8,
      "end": 1529.28,
      "text": " Goodness.",
      "tokens": [
        50368,
        2205,
        1287,
        13,
        50392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38943556583288946,
      "compression_ratio": 1.4435483870967742,
      "no_speech_prob": 0.04785911738872528
    },
    {
      "id": 321,
      "seek": 152872,
      "start": 1533.28,
      "end": 1535.68,
      "text": " And thank you, Emily, for recording this.",
      "tokens": [
        50592,
        400,
        1309,
        291,
        11,
        15034,
        11,
        337,
        6613,
        341,
        13,
        50712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38943556583288946,
      "compression_ratio": 1.4435483870967742,
      "no_speech_prob": 0.04785911738872528
    },
    {
      "id": 322,
      "seek": 152872,
      "start": 1536.8,
      "end": 1538.96,
      "text": " And yeah, enjoy the rest of your day.",
      "tokens": [
        50768,
        400,
        1338,
        11,
        2103,
        264,
        1472,
        295,
        428,
        786,
        13,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38943556583288946,
      "compression_ratio": 1.4435483870967742,
      "no_speech_prob": 0.04785911738872528
    },
    {
      "id": 323,
      "seek": 152872,
      "start": 1539.52,
      "end": 1540.08,
      "text": " I'll see you later.",
      "tokens": [
        50904,
        286,
        603,
        536,
        291,
        1780,
        13,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38943556583288946,
      "compression_ratio": 1.4435483870967742,
      "no_speech_prob": 0.04785911738872528
    },
    {
      "id": 324,
      "seek": 152872,
      "start": 1540.08,
      "end": 1541.3600000000001,
      "text": " I'll see you later. See you next year.",
      "tokens": [
        50932,
        286,
        603,
        536,
        291,
        1780,
        13,
        3008,
        291,
        958,
        1064,
        13,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38943556583288946,
      "compression_ratio": 1.4435483870967742,
      "no_speech_prob": 0.04785911738872528
    },
    {
      "id": 325,
      "seek": 152872,
      "start": 1542.16,
      "end": 1543.6000000000001,
      "text": " Enjoy your time off.",
      "tokens": [
        51036,
        15411,
        428,
        565,
        766,
        13,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38943556583288946,
      "compression_ratio": 1.4435483870967742,
      "no_speech_prob": 0.04785911738872528
    },
    {
      "id": 326,
      "seek": 152872,
      "start": 1544.72,
      "end": 1545.2,
      "text": " Bye.",
      "tokens": [
        51164,
        4621,
        13,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38943556583288946,
      "compression_ratio": 1.4435483870967742,
      "no_speech_prob": 0.04785911738872528
    },
    {
      "id": 327,
      "seek": 152872,
      "start": 1545.2,
      "end": 1546.0,
      "text": " Bye.",
      "tokens": [
        51188,
        4621,
        13,
        51228
      ],
      "temperature": 0.0,
      "avg_logprob": -0.38943556583288946,
      "compression_ratio": 1.4435483870967742,
      "no_speech_prob": 0.04785911738872528
    }
  ]
}