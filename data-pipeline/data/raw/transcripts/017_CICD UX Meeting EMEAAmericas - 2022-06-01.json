{
  "title": "CI/CD UX Meeting (EMEA/Americas) - 2022-06-01",
  "video_id": "iWhQcheOUnI",
  "url": "https://www.youtube.com/watch?v=iWhQcheOUnI",
  "transcript": " So this is the June 1st, the SACB U.S. meeting, America's Europe version. A couple of heads up FYIs for me as usual. Not as many I guess as the last few weeks, but if you haven't completed your required training, secure training, please do so. The SAP. I think we are at 64% completion. First, we shared a message earlier this week or today. So please complete that if you haven't. So I'm going to send a reminder in our chat as well. I don't think there's any updates for OKRs. You know, you're going to meet tomorrow, but if there's anything you'd like to share here before or next one I want about OKRs. No. OK. I thought that Nadia left some updates about her OKRs, jobs, freedom, etc. So I think I would just track. But on my duration day, we have a date right to next Friday, the 10th. I would like everyone in our team to contribute to that. So at least one component migration. It's I'm not going to say it's easy because it can be pretty complex if you have to set up GDK, but last time the instructions, at least to me, they were really helpful. And it's also a good way for us to play around with the product and then migrate those components, like the especially buttons that are outdated or incorrect in the Y in your product areas. So please get us some time if you can to contribute. And if you get at least three Merge requests created and merged, you can expense them up to $25. So that's awesome. I had lunch last time. Comfort by pajamas components. And that's really fun. And also if you're not able to create the components, I also recommend, you know, joining the flat channel and being available to review those components because there's quite some amars coming from engineers and those needs to be reviewed by designer. Right. So that's for you, Gina. And I'll send everybody else a reminder that you also need reviewers for those amars. And there's an issue in leak here for the issue with my questions and also the guidelines for how to contribute that Tori has put together. So I'll not see if you have any questions. All right. Awesome. And then, Max team is about the MR reviews. So we make sure to check if the boat is assigning, like if you're the person being assigned by the boat because sometimes the developers will ask the random person that is not the random person suggested for that or see some instances for that in our team. So please double check if you're actually being suggested by the roulette before leaving in a mariner if that's not you assign it to the designer. Right. That is, that is being randomly suggested by the roulette. And then last one, I promise, in case you missed it, the UX cloud fan box is available right for every part of us to play around with the product and also set up this test in areas and other that will, is going to go through that pretty soon. And there are also guidelines in the handbook about how to get access and how to set up those test projects. So with that, I'm done with my initial announcement. So if you have any questions, if you're free to voice those, we'll do our voice over to you, Jim. Okay. I'm excited to use the UX cloud sandbox, by the way. For, I just wanted to update because I've been talking about artifacts for pipeline insights so often. I've had five sessions out of the eight that I'm doing in its moderated sessions. And there's been a lot of findings that overlap with pipeline execution and pipeline authoring, which I've already looped with the go and Nadia into. But I'm going to make sure to tag everyone. I'm going to do like a summary in the actual research issue so that I can just ping. I think, hi, Anna, you had done that before and it worked really well. Like you had different threads for overlocking insights. But for early findings, I figured it would be interesting to tell you about them. So we were validating if this artifacts page was something that we should move forward with. And it turns out that it would be really helpful for developers and for DevOps engineers, like software developers and DevOps. And we would have it at the project level. And a lot of them actually asked if it was going to also be at the group level. So that's something for us to look into after as well. And the main job that it will help them do is when they're debugging failures in pipelines and jobs. If they need further clarification of why something failed, sometimes it does have to link back to artifacts. And then some other things that I learned is the file name of the artifacts. So it's usually like a file like getlab.png or whatever it is. The file name and the file extension are the things that they use to identify them. That is something that I was not using in the design. Because today like in our drop down, we don't add the file extensions when you look at a pipeline. So that's something that I'll be adding. And then the other thing is we were looking at expired artifacts. Which means like if you have getlab assets sets this automatic expiration date for pipelines that include artifacts so that we don't have a massive amount of storage. And so when those expire, sometimes there's pipelines that depend on those artifacts. And then those pipelines will fail because the artifact is expired. So you have to go back and rerun that initial pipeline. But they're only important when that dependent, like dependable track happens. Otherwise they don't care about them. So that was interesting too. Because I was listing all of the expired artifacts. Hi Anna, do you want to voice even though you're still typing sorry? Yeah, I know. I think it you kind of answer to my question. I was wondering if there is so far, if you heard any insights about those pipelines, those jobs and the artifacts are to facts being related to a release or that deploy job at the and why that would be important to debug at the group level. That's related to the link, the issue at a year for organizational level environment page. And one of the jobs and also the tasks that you would go over with a page like that at the higher level is similar to what you're mentioning. So being able to move things out of a release, for example, debug a failed deployment pipeline and see the status of what goes into production, but also where is that in the flow, etc. So the summary, if you heard anything related particularly to releases so far. Yeah, the one thing I did here is the dependent pipelines type of thing. I also have heard sometimes. So the artifacts that we're talking about though are usually just passed between pipelines. They're not used to be deployed out into whatever. They're usually used as like reports or like logging kind of. So I haven't found anything that really overlaps with things that are going to be deployed and released. I'm going to check back though. Yeah, that sounds good. If you see anything, then just being me in the research issue and I'll have a look because when talking to people about environments and for example, when I asked them, where would you go to see the status of your latest deployment or where would you go to debug? I don't know, a deploy pipeline that has failed. They would always go to the pipelines overview. They would not go not always, but I would say like 70% of them would just navigate back to pipelines to see that. And we have been talking the release team in implementing a view of environments at a good level. But if the pipeline view already solves that problem, I think it'll be interesting. I'm going to be able to connect with insights so we don't build two separate things when it's the same persona navigating. Maybe just completed different tasks. And like, what I'm thinking. No, I understand what you're saying. We had, I had the similar thought of like, should this really be a separate page or should this be integrated into the pipelines page already. And it's really hard with performance as well because the page is like so. There's so much there. But yeah, I'll let you know. I'll keep you updated. Awesome. And then I'll share later with you the follow share already the link here. But I'm working on some of the prototypes. I want to have that added to the issue. I'll share with you so you can see how that relates to or how that might relate to what you're investing in. Okay. Sounds good. Nothing. Yeah. Hi, Any of your comments about wanting to see things at an organizational level for environments is something I've seen in other research I've done too. So I help out with the enablement group. And for global search, we found a lot of people talking about when I search for something in gate lab, I just want to be able to search within my organization, not just like a specific project or a specific group, but just like everything for my company that they, you know, they have. So that seems to be a common theme that I've been noticing. Yeah, that's a good to call out to Will. And like my first thought is like performance exactly what Gina just mentioned, that's, you know, in the past, why we kept separating things at the group level or project level or, you know, environment supply, it's also because we cannot support all this data. I think we can, but there's a lot that needs to be fixed in the back ends for that to happen. And then for example, if you go to the environment dashboard, which is not the environment page, no, but we have something separate here. I'm going to drop a link here in our agenda. Okay, wait, this is where ideally you would go, you know, to track environments across multiple projects or different groups, but then you can only show three environments per project at a time. So yeah, that's why people, as I mentioned before, they just go to the pipeline stage. And I, if you can, Russian Slater will do those the insights. This will be helpful because Chris also asked me to start looking at this environment at the group level. And that's why I'm like, let's validate that. Let's have the jobs to be done first because my gut feeling, my experience with GitLab safe, we don't need that. We kind of, if we are able to highlight some information, I'll give people the ability to filter or search whatever in places when they're ready. And go today, maybe that's a low-hanging fruit rather than a redesign. Anyways, let's me brainstorming our stuff here. Okay, yeah, thanks for sharing. Yeah, and Gina, sorry for the collaboration traffic that I'm contributing to, I guess. So that's better. I love collaboration. Well, thank you. All right, I'm going to, I'll finish up with the last thing. I'm working on validating the new list view for the runner admin view. And hyana, I'm going to start recruiting next, my goal is next week. I have a discussion guide that's working progress right now. But I'm going to mix unmoderated and moderated. So I'm going to only interview some of our internal GitLab team members so that I'm not like waiting on like recruiting the enterprise customers, which has taken a while with the artifact stuff. So I'll do a mix and I'm starting with validating like a very small portion of the list. All right, thank Gina. I'll share the list of participants that I use for the environments that I research because remember that some of them mention runners as well. So I want to have a look there and see if any of those are going to be useful to you. Let me find that now. Yeah, actually you, you share that with me, right? Will. Thanks. So it still should be somewhere in the comments that I would think. Yeah, yeah, here's that with me. I share it with Gadi as well here. Here. And let's see. Here, Gina. Thank you. I think there were at least two of them mention runners. I think that's the one time I pinged you that I that I love you in the comment section. Okay. I think you need to act this. Let me add you to it. I do. Yeah. Hmm. Got it. All right. Awesome. Thank you. I'll look into that. All right. So I guess I'm next. I'm out of office on Monday. It's six to the public holiday here in the Netherlands. And I'm also out of office in June. 14th of 23rd. You've already mentioned that to all of you. There's no one of ones, but there's a covers issue at the link here again. And it's your working progress, but you're a very issue. You can see my backup will be soon. I'm going to have a backup. A fine. June. June. 14th. Okay. And then next week, Chris and Chris and I are going to participate in the UX road mapping workshop. That's part of the Q2KR next week on Thursday. I added the incorrect links here. So that's that. I'm finishing reading the 10 book page. And we'll see what's going to happen there. We're going to be the first ones doing that workshop. That's cool. And then other than environments. So I have to add in that here, but I have to wrap up the insights on the research that I conducted. And then also being helping collaborating with Chris and Will on the benchmarking for release. So I also wrapped that up just think I have an hour ago. Trying to determine which tasks happened in the UI and API. So that will know how to set up the test environment, but also the tasks that are going to go through. Maybe we'll maybe we'll talk about that later, but anything you'd like to add about the benchmark for you. No, we had a we had a very in-depth discussion about it a couple hours ago between you, myself and Chris. So we've still got a lot of things to figure out in the coming weeks, but it was good to catch up. There are a couple of dates here from Package and Firefly and Altany. So Katie and Nadia had their session earlier today. So please have a look and leave comments if you have any. And we stayed out of office this whole week. She'll be back next week. Yeah, next week on Monday. So we're going to skip back on execution this week. And then over to Will for the research efforts. Nice. So I'm out of office this Friday. I'll be back on Monday to catch up on things. And as I spoke to a minute ago, I met with Pion and Chris to talk through different release topics. Specifically the usability benchmarking study. I've linked to the mural that has been updated a little bit since we last spoke. So there's a list of I think 31 different tasks that we could potentially do. And we'll need to narrow that down in probably the next week or so. So I'll be helping out with that. And then creating a UX sandbox project. I've been speaking with one of the other researchers who's done that. And he had a lot of content that went into that handbook page that I can actually link to. So I'll add that page in just a moment. But yeah, that's kind of it for me at the moment. Any comments or questions? I comment. I didn't already mentioned this in Slack, but for the tasks that we added to the the mural board. I think there are a couple of things here that we cannot do with the product today. So what do we do with those tasks that we remove them? Do we leave them there? What's kind of like because we're not going to assess it, right? The usability if we cannot perform that particular task. Yeah, that's a good question. I think we'll just have to move on because we can't really assess them if we can't actually create an environment where participants could actually complete the task. We could make note in the report that we wanted to do these tasks and list them out, but then say that this would be something to get at it the future if we have time. Because the usability benchmark is not just like a one and done thing. You can do it. I think roughly once a year is what the handbook talks about. So yeah, I think that would just like get added to a backlog in a sense. That makes sense. And I'm referring to a creator release audit checklist in particular. I actually had that one sticky and the task. And I'm like, how did I do that today? And I think that's a good way to find out is checking the delivery team because they're the ones that produce with GitLab. But I know that it's a manual task, maybe don't outside of GitLab. So do we measure that? Do we track that particular scenario? But I can investigate about this sticky, create release audit checklist. Okay, yeah, that'd be great. Do you want me to speak to Erica's stuff? So she's got her prioritization issue still there. She's included a link to the field notes that she took in a summary that she did based on her experience at QPON that I think was about a week or two ago. So definitely check that out if you haven't already. I've seen some of the documentation that she's already shared and it's very extensive. So I would recommend it. Hi, Anna, did you want to voice your comment? Yeah, so I haven't had a chance to get her feedback yet. So I'm just a synchronously saying well, and I'll also leave you the video. Thank you, Erica, for moving back my reminder, like by one day because she created right, we want to see like the product designer and myself to go over the dock and then provide her with feedback and everything. I haven't done that yet. So it's in my list and it's awesome that she shares those insights without having a chance to see another little more from her experience as well from QPON. And then it looks like she's working on the analysis and report for the QPON product direction survey. She shared that with the research team late yesterday and I provided some feedback just kind of in an early review state. But that's at a point where I think it's pretty close to being shared out more broadly. And then she's also waiting for Tim to review the shared resource library and CI templates report and then creating actual insights as well. Erica, it helped me if you're watching this. Thank you. She had helped me with a promotional game for a job to be done survey that we're doing for Art of Acts. And it was really, she had this like whole document of how to easily pull in the block basically to call tricks. And so I wanted to ask and I can just paint, I can ask her an issue or something. If that would be something that we could add to the handbook because I think a lot of people would use that for surveys if it's like a normal thing to follow. I think I know a little bit about what you're describing. Could you like explain a little bit more by what you mean that like she was able to pull in the whole block into call tricks? Yeah, in Qualtrics you can use, I think it's called like shared questions maybe that your organization can use. And there was one specifically that was created by, it must be from the research team. That was for this promotional game so that participants would be given and like get put into a game to win $60 Amazon gift cards. Okay. I can, let me actually just get the dog. We can give a she shared it with me. Here it is. Oh, yes, I, I've seen this exact thing. And actually made the same exact comment to her. I was like, wow, this is really good. You should put this in the handbook. And I forget what she told me at the time. I think she was maybe like, I want to pilot this or like test it out a little bit more before I put it in there. But yeah, I was, I had the same thought as you did. I was because I made it so it was so easy to just put it in there. So all, maybe I'll just catch off with her and see who would be useful. Sorry. Okay. Cool. I think that's all I've got or I guess all the air goes cut. So anything else I think before we wrap up I think it's gonna be better here today. Okay. No, no, that's it. Thank you for joining me for a brainstorming and chatting. See you next time. Thanks. Bye. Bye.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 11.36,
      "text": " So this is the June 1st, the SACB U.S. meeting, America's Europe version.",
      "tokens": [
        50364,
        407,
        341,
        307,
        264,
        6928,
        502,
        372,
        11,
        264,
        318,
        4378,
        33,
        624,
        13,
        50,
        13,
        3440,
        11,
        3374,
        311,
        3315,
        3037,
        13,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.504665766006861,
      "compression_ratio": 1.3475935828877006,
      "no_speech_prob": 0.1847681850194931
    },
    {
      "id": 1,
      "seek": 0,
      "start": 11.36,
      "end": 15.84,
      "text": " A couple of heads up FYIs for me as usual.",
      "tokens": [
        50932,
        316,
        1916,
        295,
        8050,
        493,
        42730,
        6802,
        337,
        385,
        382,
        7713,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.504665766006861,
      "compression_ratio": 1.3475935828877006,
      "no_speech_prob": 0.1847681850194931
    },
    {
      "id": 2,
      "seek": 0,
      "start": 15.84,
      "end": 22.32,
      "text": " Not as many I guess as the last few weeks, but if you haven't completed your required",
      "tokens": [
        51156,
        1726,
        382,
        867,
        286,
        2041,
        382,
        264,
        1036,
        1326,
        3259,
        11,
        457,
        498,
        291,
        2378,
        380,
        7365,
        428,
        4739,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.504665766006861,
      "compression_ratio": 1.3475935828877006,
      "no_speech_prob": 0.1847681850194931
    },
    {
      "id": 3,
      "seek": 0,
      "start": 22.32,
      "end": 24.92,
      "text": " training, secure training, please do so.",
      "tokens": [
        51480,
        3097,
        11,
        7144,
        3097,
        11,
        1767,
        360,
        370,
        13,
        51610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.504665766006861,
      "compression_ratio": 1.3475935828877006,
      "no_speech_prob": 0.1847681850194931
    },
    {
      "id": 4,
      "seek": 0,
      "start": 24.92,
      "end": 25.92,
      "text": " The SAP.",
      "tokens": [
        51610,
        440,
        27743,
        13,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.504665766006861,
      "compression_ratio": 1.3475935828877006,
      "no_speech_prob": 0.1847681850194931
    },
    {
      "id": 5,
      "seek": 2592,
      "start": 25.92,
      "end": 28.8,
      "text": " I think we are at 64% completion.",
      "tokens": [
        50364,
        286,
        519,
        321,
        366,
        412,
        12145,
        4,
        19372,
        13,
        50508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526510728144013,
      "compression_ratio": 1.5427350427350428,
      "no_speech_prob": 0.044028401374816895
    },
    {
      "id": 6,
      "seek": 2592,
      "start": 28.8,
      "end": 32.800000000000004,
      "text": " First, we shared a message earlier this week or today.",
      "tokens": [
        50508,
        2386,
        11,
        321,
        5507,
        257,
        3636,
        3071,
        341,
        1243,
        420,
        965,
        13,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526510728144013,
      "compression_ratio": 1.5427350427350428,
      "no_speech_prob": 0.044028401374816895
    },
    {
      "id": 7,
      "seek": 2592,
      "start": 32.800000000000004,
      "end": 34.64,
      "text": " So please complete that if you haven't.",
      "tokens": [
        50708,
        407,
        1767,
        3566,
        300,
        498,
        291,
        2378,
        380,
        13,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526510728144013,
      "compression_ratio": 1.5427350427350428,
      "no_speech_prob": 0.044028401374816895
    },
    {
      "id": 8,
      "seek": 2592,
      "start": 34.64,
      "end": 39.2,
      "text": " So I'm going to send a reminder in our chat as well.",
      "tokens": [
        50800,
        407,
        286,
        478,
        516,
        281,
        2845,
        257,
        13548,
        294,
        527,
        5081,
        382,
        731,
        13,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526510728144013,
      "compression_ratio": 1.5427350427350428,
      "no_speech_prob": 0.044028401374816895
    },
    {
      "id": 9,
      "seek": 2592,
      "start": 39.2,
      "end": 41.760000000000005,
      "text": " I don't think there's any updates for OKRs.",
      "tokens": [
        51028,
        286,
        500,
        380,
        519,
        456,
        311,
        604,
        9205,
        337,
        2264,
        49,
        82,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526510728144013,
      "compression_ratio": 1.5427350427350428,
      "no_speech_prob": 0.044028401374816895
    },
    {
      "id": 10,
      "seek": 2592,
      "start": 41.760000000000005,
      "end": 47.36,
      "text": " You know, you're going to meet tomorrow, but if there's anything you'd like to share here",
      "tokens": [
        51156,
        509,
        458,
        11,
        291,
        434,
        516,
        281,
        1677,
        4153,
        11,
        457,
        498,
        456,
        311,
        1340,
        291,
        1116,
        411,
        281,
        2073,
        510,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526510728144013,
      "compression_ratio": 1.5427350427350428,
      "no_speech_prob": 0.044028401374816895
    },
    {
      "id": 11,
      "seek": 2592,
      "start": 47.36,
      "end": 51.28,
      "text": " before or next one I want about OKRs.",
      "tokens": [
        51436,
        949,
        420,
        958,
        472,
        286,
        528,
        466,
        2264,
        49,
        82,
        13,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526510728144013,
      "compression_ratio": 1.5427350427350428,
      "no_speech_prob": 0.044028401374816895
    },
    {
      "id": 12,
      "seek": 2592,
      "start": 51.28,
      "end": 52.28,
      "text": " No.",
      "tokens": [
        51632,
        883,
        13,
        51682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526510728144013,
      "compression_ratio": 1.5427350427350428,
      "no_speech_prob": 0.044028401374816895
    },
    {
      "id": 13,
      "seek": 2592,
      "start": 52.28,
      "end": 53.28,
      "text": " OK.",
      "tokens": [
        51682,
        2264,
        13,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3526510728144013,
      "compression_ratio": 1.5427350427350428,
      "no_speech_prob": 0.044028401374816895
    },
    {
      "id": 14,
      "seek": 5328,
      "start": 53.28,
      "end": 59.6,
      "text": " I thought that Nadia left some updates about her OKRs, jobs, freedom, etc.",
      "tokens": [
        50364,
        286,
        1194,
        300,
        23269,
        654,
        1411,
        512,
        9205,
        466,
        720,
        2264,
        49,
        82,
        11,
        4782,
        11,
        5645,
        11,
        5183,
        13,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45112039510486196,
      "compression_ratio": 1.4917355371900827,
      "no_speech_prob": 0.010803110897541046
    },
    {
      "id": 15,
      "seek": 5328,
      "start": 59.6,
      "end": 63.120000000000005,
      "text": " So I think I would just track.",
      "tokens": [
        50680,
        407,
        286,
        519,
        286,
        576,
        445,
        2837,
        13,
        50856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45112039510486196,
      "compression_ratio": 1.4917355371900827,
      "no_speech_prob": 0.010803110897541046
    },
    {
      "id": 16,
      "seek": 5328,
      "start": 63.120000000000005,
      "end": 68.24000000000001,
      "text": " But on my duration day, we have a date right to next Friday, the 10th.",
      "tokens": [
        50856,
        583,
        322,
        452,
        16365,
        786,
        11,
        321,
        362,
        257,
        4002,
        558,
        281,
        958,
        6984,
        11,
        264,
        1266,
        392,
        13,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45112039510486196,
      "compression_ratio": 1.4917355371900827,
      "no_speech_prob": 0.010803110897541046
    },
    {
      "id": 17,
      "seek": 5328,
      "start": 68.24000000000001,
      "end": 71.52000000000001,
      "text": " I would like everyone in our team to contribute to that.",
      "tokens": [
        51112,
        286,
        576,
        411,
        1518,
        294,
        527,
        1469,
        281,
        10586,
        281,
        300,
        13,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45112039510486196,
      "compression_ratio": 1.4917355371900827,
      "no_speech_prob": 0.010803110897541046
    },
    {
      "id": 18,
      "seek": 5328,
      "start": 71.52000000000001,
      "end": 74.32,
      "text": " So at least one component migration.",
      "tokens": [
        51276,
        407,
        412,
        1935,
        472,
        6542,
        17011,
        13,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45112039510486196,
      "compression_ratio": 1.4917355371900827,
      "no_speech_prob": 0.010803110897541046
    },
    {
      "id": 19,
      "seek": 5328,
      "start": 74.32,
      "end": 78.16,
      "text": " It's I'm not going to say it's easy because it can be pretty complex if you have to set up",
      "tokens": [
        51416,
        467,
        311,
        286,
        478,
        406,
        516,
        281,
        584,
        309,
        311,
        1858,
        570,
        309,
        393,
        312,
        1238,
        3997,
        498,
        291,
        362,
        281,
        992,
        493,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.45112039510486196,
      "compression_ratio": 1.4917355371900827,
      "no_speech_prob": 0.010803110897541046
    },
    {
      "id": 20,
      "seek": 7816,
      "start": 79.03999999999999,
      "end": 84.8,
      "text": " GDK, but last time the instructions, at least to me, they were really helpful.",
      "tokens": [
        50408,
        460,
        35,
        42,
        11,
        457,
        1036,
        565,
        264,
        9415,
        11,
        412,
        1935,
        281,
        385,
        11,
        436,
        645,
        534,
        4961,
        13,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24773020744323732,
      "compression_ratio": 1.5285714285714285,
      "no_speech_prob": 0.03765241056680679
    },
    {
      "id": 21,
      "seek": 7816,
      "start": 85.52,
      "end": 92.16,
      "text": " And it's also a good way for us to play around with the product and then migrate those components,",
      "tokens": [
        50732,
        400,
        309,
        311,
        611,
        257,
        665,
        636,
        337,
        505,
        281,
        862,
        926,
        365,
        264,
        1674,
        293,
        550,
        31821,
        729,
        6677,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24773020744323732,
      "compression_ratio": 1.5285714285714285,
      "no_speech_prob": 0.03765241056680679
    },
    {
      "id": 22,
      "seek": 7816,
      "start": 92.16,
      "end": 98.64,
      "text": " like the especially buttons that are outdated or incorrect in the Y in your product areas.",
      "tokens": [
        51064,
        411,
        264,
        2318,
        9905,
        300,
        366,
        36313,
        420,
        18424,
        294,
        264,
        398,
        294,
        428,
        1674,
        3179,
        13,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24773020744323732,
      "compression_ratio": 1.5285714285714285,
      "no_speech_prob": 0.03765241056680679
    },
    {
      "id": 23,
      "seek": 7816,
      "start": 98.64,
      "end": 102.96,
      "text": " So please get us some time if you can to contribute.",
      "tokens": [
        51388,
        407,
        1767,
        483,
        505,
        512,
        565,
        498,
        291,
        393,
        281,
        10586,
        13,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24773020744323732,
      "compression_ratio": 1.5285714285714285,
      "no_speech_prob": 0.03765241056680679
    },
    {
      "id": 24,
      "seek": 10296,
      "start": 103.03999999999999,
      "end": 108.88,
      "text": " And if you get at least three Merge requests created and merged,",
      "tokens": [
        50368,
        400,
        498,
        291,
        483,
        412,
        1935,
        1045,
        6124,
        432,
        12475,
        2942,
        293,
        36427,
        11,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30872686409655914,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.00579278077930212
    },
    {
      "id": 25,
      "seek": 10296,
      "start": 108.88,
      "end": 111.28,
      "text": " you can expense them up to $25.",
      "tokens": [
        50660,
        291,
        393,
        18406,
        552,
        493,
        281,
        1848,
        6074,
        13,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30872686409655914,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.00579278077930212
    },
    {
      "id": 26,
      "seek": 10296,
      "start": 111.28,
      "end": 112.55999999999999,
      "text": " So that's awesome.",
      "tokens": [
        50780,
        407,
        300,
        311,
        3476,
        13,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30872686409655914,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.00579278077930212
    },
    {
      "id": 27,
      "seek": 10296,
      "start": 112.55999999999999,
      "end": 114.16,
      "text": " I had lunch last time.",
      "tokens": [
        50844,
        286,
        632,
        6349,
        1036,
        565,
        13,
        50924
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30872686409655914,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.00579278077930212
    },
    {
      "id": 28,
      "seek": 10296,
      "start": 115.19999999999999,
      "end": 117.91999999999999,
      "text": " Comfort by pajamas components.",
      "tokens": [
        50976,
        2432,
        2728,
        538,
        43625,
        6677,
        13,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30872686409655914,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.00579278077930212
    },
    {
      "id": 29,
      "seek": 10296,
      "start": 117.91999999999999,
      "end": 119.28,
      "text": " And that's really fun.",
      "tokens": [
        51112,
        400,
        300,
        311,
        534,
        1019,
        13,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30872686409655914,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.00579278077930212
    },
    {
      "id": 30,
      "seek": 10296,
      "start": 119.28,
      "end": 125.67999999999999,
      "text": " And also if you're not able to create the components, I also recommend, you know,",
      "tokens": [
        51180,
        400,
        611,
        498,
        291,
        434,
        406,
        1075,
        281,
        1884,
        264,
        6677,
        11,
        286,
        611,
        2748,
        11,
        291,
        458,
        11,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30872686409655914,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.00579278077930212
    },
    {
      "id": 31,
      "seek": 12568,
      "start": 125.76,
      "end": 134.4,
      "text": " joining the flat channel and being available to review those components because there's",
      "tokens": [
        50368,
        5549,
        264,
        4962,
        2269,
        293,
        885,
        2435,
        281,
        3131,
        729,
        6677,
        570,
        456,
        311,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30773392590609466,
      "compression_ratio": 1.6506550218340612,
      "no_speech_prob": 0.0018766667926684022
    },
    {
      "id": 32,
      "seek": 12568,
      "start": 135.04000000000002,
      "end": 141.12,
      "text": " quite some amars coming from engineers and those needs to be reviewed by designer.",
      "tokens": [
        50832,
        1596,
        512,
        669,
        685,
        1348,
        490,
        11955,
        293,
        729,
        2203,
        281,
        312,
        18429,
        538,
        11795,
        13,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30773392590609466,
      "compression_ratio": 1.6506550218340612,
      "no_speech_prob": 0.0018766667926684022
    },
    {
      "id": 33,
      "seek": 12568,
      "start": 141.12,
      "end": 143.36,
      "text": " Right. So that's for you, Gina.",
      "tokens": [
        51136,
        1779,
        13,
        407,
        300,
        311,
        337,
        291,
        11,
        34711,
        13,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30773392590609466,
      "compression_ratio": 1.6506550218340612,
      "no_speech_prob": 0.0018766667926684022
    },
    {
      "id": 34,
      "seek": 12568,
      "start": 143.36,
      "end": 149.84,
      "text": " And I'll send everybody else a reminder that you also need reviewers for those amars.",
      "tokens": [
        51248,
        400,
        286,
        603,
        2845,
        2201,
        1646,
        257,
        13548,
        300,
        291,
        611,
        643,
        45837,
        337,
        729,
        669,
        685,
        13,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30773392590609466,
      "compression_ratio": 1.6506550218340612,
      "no_speech_prob": 0.0018766667926684022
    },
    {
      "id": 35,
      "seek": 12568,
      "start": 151.12,
      "end": 155.28,
      "text": " And there's an issue in leak here for the issue with my questions and also the guidelines",
      "tokens": [
        51636,
        400,
        456,
        311,
        364,
        2734,
        294,
        17143,
        510,
        337,
        264,
        2734,
        365,
        452,
        1651,
        293,
        611,
        264,
        12470,
        51844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30773392590609466,
      "compression_ratio": 1.6506550218340612,
      "no_speech_prob": 0.0018766667926684022
    },
    {
      "id": 36,
      "seek": 15528,
      "start": 155.28,
      "end": 160.48,
      "text": " for how to contribute that Tori has put together. So I'll not see if you have any questions.",
      "tokens": [
        50364,
        337,
        577,
        281,
        10586,
        300,
        314,
        7386,
        575,
        829,
        1214,
        13,
        407,
        286,
        603,
        406,
        536,
        498,
        291,
        362,
        604,
        1651,
        13,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3362759181431362,
      "compression_ratio": 1.417142857142857,
      "no_speech_prob": 0.0004708461929112673
    },
    {
      "id": 37,
      "seek": 15528,
      "start": 166.48,
      "end": 167.84,
      "text": " All right. Awesome.",
      "tokens": [
        50924,
        1057,
        558,
        13,
        10391,
        13,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3362759181431362,
      "compression_ratio": 1.417142857142857,
      "no_speech_prob": 0.0004708461929112673
    },
    {
      "id": 38,
      "seek": 15528,
      "start": 169.76,
      "end": 170.08,
      "text": " And then,",
      "tokens": [
        51088,
        400,
        550,
        11,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3362759181431362,
      "compression_ratio": 1.417142857142857,
      "no_speech_prob": 0.0004708461929112673
    },
    {
      "id": 39,
      "seek": 15528,
      "start": 171.6,
      "end": 175.44,
      "text": " Max team is about the MR reviews.",
      "tokens": [
        51180,
        7402,
        1469,
        307,
        466,
        264,
        9808,
        10229,
        13,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3362759181431362,
      "compression_ratio": 1.417142857142857,
      "no_speech_prob": 0.0004708461929112673
    },
    {
      "id": 40,
      "seek": 15528,
      "start": 175.44,
      "end": 180.56,
      "text": " So we make sure to check if the boat is assigning, like if you're the person being assigned",
      "tokens": [
        51372,
        407,
        321,
        652,
        988,
        281,
        1520,
        498,
        264,
        6582,
        307,
        49602,
        11,
        411,
        498,
        291,
        434,
        264,
        954,
        885,
        13279,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3362759181431362,
      "compression_ratio": 1.417142857142857,
      "no_speech_prob": 0.0004708461929112673
    },
    {
      "id": 41,
      "seek": 18056,
      "start": 180.72,
      "end": 186.24,
      "text": " by the boat because sometimes the developers will ask the random person that is not the random",
      "tokens": [
        50372,
        538,
        264,
        6582,
        570,
        2171,
        264,
        8849,
        486,
        1029,
        264,
        4974,
        954,
        300,
        307,
        406,
        264,
        4974,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2957091170750307,
      "compression_ratio": 1.8038277511961722,
      "no_speech_prob": 0.006141967140138149
    },
    {
      "id": 42,
      "seek": 18056,
      "start": 186.24,
      "end": 190.16,
      "text": " person suggested for that or see some instances for that in our team.",
      "tokens": [
        50648,
        954,
        10945,
        337,
        300,
        420,
        536,
        512,
        14519,
        337,
        300,
        294,
        527,
        1469,
        13,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2957091170750307,
      "compression_ratio": 1.8038277511961722,
      "no_speech_prob": 0.006141967140138149
    },
    {
      "id": 43,
      "seek": 18056,
      "start": 190.16,
      "end": 196.32,
      "text": " So please double check if you're actually being suggested by the roulette before leaving",
      "tokens": [
        50844,
        407,
        1767,
        3834,
        1520,
        498,
        291,
        434,
        767,
        885,
        10945,
        538,
        264,
        18450,
        36563,
        949,
        5012,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2957091170750307,
      "compression_ratio": 1.8038277511961722,
      "no_speech_prob": 0.006141967140138149
    },
    {
      "id": 44,
      "seek": 18056,
      "start": 196.32,
      "end": 201.28,
      "text": " in a mariner if that's not you assign it to the designer.",
      "tokens": [
        51152,
        294,
        257,
        1849,
        4564,
        498,
        300,
        311,
        406,
        291,
        6269,
        309,
        281,
        264,
        11795,
        13,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2957091170750307,
      "compression_ratio": 1.8038277511961722,
      "no_speech_prob": 0.006141967140138149
    },
    {
      "id": 45,
      "seek": 18056,
      "start": 201.28,
      "end": 205.28,
      "text": " Right. That is, that is being randomly suggested by the roulette.",
      "tokens": [
        51400,
        1779,
        13,
        663,
        307,
        11,
        300,
        307,
        885,
        16979,
        10945,
        538,
        264,
        18450,
        36563,
        13,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2957091170750307,
      "compression_ratio": 1.8038277511961722,
      "no_speech_prob": 0.006141967140138149
    },
    {
      "id": 46,
      "seek": 20528,
      "start": 206.24,
      "end": 208.16,
      "text": " And then last one, I promise,",
      "tokens": [
        50412,
        400,
        550,
        1036,
        472,
        11,
        286,
        6228,
        11,
        50508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30256149004090505,
      "compression_ratio": 1.624031007751938,
      "no_speech_prob": 0.018093448132276535
    },
    {
      "id": 47,
      "seek": 20528,
      "start": 208.88,
      "end": 214.88,
      "text": " in case you missed it, the UX cloud fan box is available right for every part of us to play around",
      "tokens": [
        50544,
        294,
        1389,
        291,
        6721,
        309,
        11,
        264,
        40176,
        4588,
        3429,
        2424,
        307,
        2435,
        558,
        337,
        633,
        644,
        295,
        505,
        281,
        862,
        926,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30256149004090505,
      "compression_ratio": 1.624031007751938,
      "no_speech_prob": 0.018093448132276535
    },
    {
      "id": 48,
      "seek": 20528,
      "start": 214.88,
      "end": 221.28,
      "text": " with the product and also set up this test in areas and other that will, is going to go through",
      "tokens": [
        50844,
        365,
        264,
        1674,
        293,
        611,
        992,
        493,
        341,
        1500,
        294,
        3179,
        293,
        661,
        300,
        486,
        11,
        307,
        516,
        281,
        352,
        807,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30256149004090505,
      "compression_ratio": 1.624031007751938,
      "no_speech_prob": 0.018093448132276535
    },
    {
      "id": 49,
      "seek": 20528,
      "start": 221.28,
      "end": 226.48,
      "text": " that pretty soon. And there are also guidelines in the handbook about how to get access and how",
      "tokens": [
        51164,
        300,
        1238,
        2321,
        13,
        400,
        456,
        366,
        611,
        12470,
        294,
        264,
        1011,
        2939,
        466,
        577,
        281,
        483,
        2105,
        293,
        577,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30256149004090505,
      "compression_ratio": 1.624031007751938,
      "no_speech_prob": 0.018093448132276535
    },
    {
      "id": 50,
      "seek": 20528,
      "start": 226.48,
      "end": 234.32,
      "text": " to set up those test projects. So with that, I'm done with my initial announcement. So if you have",
      "tokens": [
        51424,
        281,
        992,
        493,
        729,
        1500,
        4455,
        13,
        407,
        365,
        300,
        11,
        286,
        478,
        1096,
        365,
        452,
        5883,
        12847,
        13,
        407,
        498,
        291,
        362,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30256149004090505,
      "compression_ratio": 1.624031007751938,
      "no_speech_prob": 0.018093448132276535
    },
    {
      "id": 51,
      "seek": 23432,
      "start": 234.32,
      "end": 237.51999999999998,
      "text": " any questions, if you're free to voice those, we'll do our voice over to you, Jim.",
      "tokens": [
        50364,
        604,
        1651,
        11,
        498,
        291,
        434,
        1737,
        281,
        3177,
        729,
        11,
        321,
        603,
        360,
        527,
        3177,
        670,
        281,
        291,
        11,
        6637,
        13,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43367640177408856,
      "compression_ratio": 1.3785310734463276,
      "no_speech_prob": 0.0003520383615978062
    },
    {
      "id": 52,
      "seek": 23432,
      "start": 241.51999999999998,
      "end": 246.23999999999998,
      "text": " Okay. I'm excited to use the UX cloud sandbox, by the way.",
      "tokens": [
        50724,
        1033,
        13,
        286,
        478,
        2919,
        281,
        764,
        264,
        40176,
        4588,
        42115,
        11,
        538,
        264,
        636,
        13,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43367640177408856,
      "compression_ratio": 1.3785310734463276,
      "no_speech_prob": 0.0003520383615978062
    },
    {
      "id": 53,
      "seek": 23432,
      "start": 248.56,
      "end": 256.64,
      "text": " For, I just wanted to update because I've been talking about artifacts for pipeline insights so often.",
      "tokens": [
        51076,
        1171,
        11,
        286,
        445,
        1415,
        281,
        5623,
        570,
        286,
        600,
        668,
        1417,
        466,
        24617,
        337,
        15517,
        14310,
        370,
        2049,
        13,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.43367640177408856,
      "compression_ratio": 1.3785310734463276,
      "no_speech_prob": 0.0003520383615978062
    },
    {
      "id": 54,
      "seek": 25664,
      "start": 257.2,
      "end": 264.56,
      "text": " I've had five sessions out of the eight that I'm doing in its moderated sessions.",
      "tokens": [
        50392,
        286,
        600,
        632,
        1732,
        11081,
        484,
        295,
        264,
        3180,
        300,
        286,
        478,
        884,
        294,
        1080,
        10494,
        770,
        11081,
        13,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2093733082646909,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.01910136267542839
    },
    {
      "id": 55,
      "seek": 25664,
      "start": 265.12,
      "end": 270.0,
      "text": " And there's been a lot of findings that overlap with pipeline execution and pipeline",
      "tokens": [
        50788,
        400,
        456,
        311,
        668,
        257,
        688,
        295,
        16483,
        300,
        19959,
        365,
        15517,
        15058,
        293,
        15517,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2093733082646909,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.01910136267542839
    },
    {
      "id": 56,
      "seek": 25664,
      "start": 270.0,
      "end": 277.28,
      "text": " authoring, which I've already looped with the go and Nadia into. But I'm going to make sure to tag",
      "tokens": [
        51032,
        3793,
        278,
        11,
        597,
        286,
        600,
        1217,
        6367,
        292,
        365,
        264,
        352,
        293,
        23269,
        654,
        666,
        13,
        583,
        286,
        478,
        516,
        281,
        652,
        988,
        281,
        6162,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2093733082646909,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.01910136267542839
    },
    {
      "id": 57,
      "seek": 25664,
      "start": 277.91999999999996,
      "end": 284.0,
      "text": " everyone. I'm going to do like a summary in the actual research issue so that I can just ping.",
      "tokens": [
        51428,
        1518,
        13,
        286,
        478,
        516,
        281,
        360,
        411,
        257,
        12691,
        294,
        264,
        3539,
        2132,
        2734,
        370,
        300,
        286,
        393,
        445,
        26151,
        13,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2093733082646909,
      "compression_ratio": 1.6071428571428572,
      "no_speech_prob": 0.01910136267542839
    },
    {
      "id": 58,
      "seek": 28400,
      "start": 284.96,
      "end": 289.2,
      "text": " I think, hi, Anna, you had done that before and it worked really well. Like you had different threads",
      "tokens": [
        50412,
        286,
        519,
        11,
        4879,
        11,
        12899,
        11,
        291,
        632,
        1096,
        300,
        949,
        293,
        309,
        2732,
        534,
        731,
        13,
        1743,
        291,
        632,
        819,
        19314,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17375042859245748,
      "compression_ratio": 1.5848214285714286,
      "no_speech_prob": 0.0010542491218075156
    },
    {
      "id": 59,
      "seek": 28400,
      "start": 289.92,
      "end": 296.8,
      "text": " for overlocking insights. But for early findings, I figured it would be interesting to",
      "tokens": [
        50660,
        337,
        670,
        4102,
        278,
        14310,
        13,
        583,
        337,
        2440,
        16483,
        11,
        286,
        8932,
        309,
        576,
        312,
        1880,
        281,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17375042859245748,
      "compression_ratio": 1.5848214285714286,
      "no_speech_prob": 0.0010542491218075156
    },
    {
      "id": 60,
      "seek": 28400,
      "start": 298.16,
      "end": 304.24,
      "text": " tell you about them. So we were validating if this artifacts page was",
      "tokens": [
        51072,
        980,
        291,
        466,
        552,
        13,
        407,
        321,
        645,
        7363,
        990,
        498,
        341,
        24617,
        3028,
        390,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17375042859245748,
      "compression_ratio": 1.5848214285714286,
      "no_speech_prob": 0.0010542491218075156
    },
    {
      "id": 61,
      "seek": 28400,
      "start": 304.96,
      "end": 309.28,
      "text": " something that we should move forward with. And it turns out that it would be really helpful for",
      "tokens": [
        51412,
        746,
        300,
        321,
        820,
        1286,
        2128,
        365,
        13,
        400,
        309,
        4523,
        484,
        300,
        309,
        576,
        312,
        534,
        4961,
        337,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17375042859245748,
      "compression_ratio": 1.5848214285714286,
      "no_speech_prob": 0.0010542491218075156
    },
    {
      "id": 62,
      "seek": 30928,
      "start": 309.35999999999996,
      "end": 317.52,
      "text": " developers and for DevOps engineers, like software developers and DevOps. And we would have it at the",
      "tokens": [
        50368,
        8849,
        293,
        337,
        43051,
        11955,
        11,
        411,
        4722,
        8849,
        293,
        43051,
        13,
        400,
        321,
        576,
        362,
        309,
        412,
        264,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1046907901763916,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.0005873340414837003
    },
    {
      "id": 63,
      "seek": 30928,
      "start": 317.52,
      "end": 322.55999999999995,
      "text": " project level. And a lot of them actually asked if it was going to also be at the group level. So",
      "tokens": [
        50776,
        1716,
        1496,
        13,
        400,
        257,
        688,
        295,
        552,
        767,
        2351,
        498,
        309,
        390,
        516,
        281,
        611,
        312,
        412,
        264,
        1594,
        1496,
        13,
        407,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1046907901763916,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.0005873340414837003
    },
    {
      "id": 64,
      "seek": 30928,
      "start": 322.55999999999995,
      "end": 330.15999999999997,
      "text": " that's something for us to look into after as well. And the main job that it will help them do",
      "tokens": [
        51028,
        300,
        311,
        746,
        337,
        505,
        281,
        574,
        666,
        934,
        382,
        731,
        13,
        400,
        264,
        2135,
        1691,
        300,
        309,
        486,
        854,
        552,
        360,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1046907901763916,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.0005873340414837003
    },
    {
      "id": 65,
      "seek": 30928,
      "start": 330.15999999999997,
      "end": 336.64,
      "text": " is when they're debugging failures in pipelines and jobs. If they need further clarification of why",
      "tokens": [
        51408,
        307,
        562,
        436,
        434,
        45592,
        20774,
        294,
        40168,
        293,
        4782,
        13,
        759,
        436,
        643,
        3052,
        34449,
        295,
        983,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1046907901763916,
      "compression_ratio": 1.628099173553719,
      "no_speech_prob": 0.0005873340414837003
    },
    {
      "id": 66,
      "seek": 33664,
      "start": 336.64,
      "end": 343.28,
      "text": " something failed, sometimes it does have to link back to artifacts. And then some other things",
      "tokens": [
        50364,
        746,
        7612,
        11,
        2171,
        309,
        775,
        362,
        281,
        2113,
        646,
        281,
        24617,
        13,
        400,
        550,
        512,
        661,
        721,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1225288675186482,
      "compression_ratio": 1.7363636363636363,
      "no_speech_prob": 0.00046080537140369415
    },
    {
      "id": 67,
      "seek": 33664,
      "start": 343.28,
      "end": 350.32,
      "text": " that I learned is the file name of the artifacts. So it's usually like a file like getlab.png or",
      "tokens": [
        50696,
        300,
        286,
        3264,
        307,
        264,
        3991,
        1315,
        295,
        264,
        24617,
        13,
        407,
        309,
        311,
        2673,
        411,
        257,
        3991,
        411,
        483,
        44990,
        13,
        79,
        872,
        420,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1225288675186482,
      "compression_ratio": 1.7363636363636363,
      "no_speech_prob": 0.00046080537140369415
    },
    {
      "id": 68,
      "seek": 33664,
      "start": 350.32,
      "end": 356.8,
      "text": " whatever it is. The file name and the file extension are the things that they use to identify them.",
      "tokens": [
        51048,
        2035,
        309,
        307,
        13,
        440,
        3991,
        1315,
        293,
        264,
        3991,
        10320,
        366,
        264,
        721,
        300,
        436,
        764,
        281,
        5876,
        552,
        13,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1225288675186482,
      "compression_ratio": 1.7363636363636363,
      "no_speech_prob": 0.00046080537140369415
    },
    {
      "id": 69,
      "seek": 33664,
      "start": 357.59999999999997,
      "end": 363.68,
      "text": " That is something that I was not using in the design. Because today like in our drop down,",
      "tokens": [
        51412,
        663,
        307,
        746,
        300,
        286,
        390,
        406,
        1228,
        294,
        264,
        1715,
        13,
        1436,
        965,
        411,
        294,
        527,
        3270,
        760,
        11,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1225288675186482,
      "compression_ratio": 1.7363636363636363,
      "no_speech_prob": 0.00046080537140369415
    },
    {
      "id": 70,
      "seek": 36368,
      "start": 363.68,
      "end": 369.36,
      "text": " we don't add the file extensions when you look at a pipeline. So that's something that I'll be adding.",
      "tokens": [
        50364,
        321,
        500,
        380,
        909,
        264,
        3991,
        25129,
        562,
        291,
        574,
        412,
        257,
        15517,
        13,
        407,
        300,
        311,
        746,
        300,
        286,
        603,
        312,
        5127,
        13,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14798495474826084,
      "compression_ratio": 1.7130434782608697,
      "no_speech_prob": 0.0003747673472389579
    },
    {
      "id": 71,
      "seek": 36368,
      "start": 370.08,
      "end": 375.6,
      "text": " And then the other thing is we were looking at expired artifacts. Which means like if you have",
      "tokens": [
        50684,
        400,
        550,
        264,
        661,
        551,
        307,
        321,
        645,
        1237,
        412,
        36587,
        24617,
        13,
        3013,
        1355,
        411,
        498,
        291,
        362,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14798495474826084,
      "compression_ratio": 1.7130434782608697,
      "no_speech_prob": 0.0003747673472389579
    },
    {
      "id": 72,
      "seek": 36368,
      "start": 376.8,
      "end": 382.64,
      "text": " getlab assets sets this automatic expiration date for pipelines that include artifacts so that we",
      "tokens": [
        51020,
        483,
        44990,
        9769,
        6352,
        341,
        12509,
        39657,
        4002,
        337,
        40168,
        300,
        4090,
        24617,
        370,
        300,
        321,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14798495474826084,
      "compression_ratio": 1.7130434782608697,
      "no_speech_prob": 0.0003747673472389579
    },
    {
      "id": 73,
      "seek": 36368,
      "start": 382.64,
      "end": 389.36,
      "text": " don't have a massive amount of storage. And so when those expire, sometimes there's pipelines that",
      "tokens": [
        51312,
        500,
        380,
        362,
        257,
        5994,
        2372,
        295,
        6725,
        13,
        400,
        370,
        562,
        729,
        45447,
        11,
        2171,
        456,
        311,
        40168,
        300,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14798495474826084,
      "compression_ratio": 1.7130434782608697,
      "no_speech_prob": 0.0003747673472389579
    },
    {
      "id": 74,
      "seek": 38936,
      "start": 389.36,
      "end": 395.12,
      "text": " depend on those artifacts. And then those pipelines will fail because the artifact is expired.",
      "tokens": [
        50364,
        5672,
        322,
        729,
        24617,
        13,
        400,
        550,
        729,
        40168,
        486,
        3061,
        570,
        264,
        34806,
        307,
        36587,
        13,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14174464299128606,
      "compression_ratio": 1.564516129032258,
      "no_speech_prob": 0.0001645166048547253
    },
    {
      "id": 75,
      "seek": 38936,
      "start": 395.68,
      "end": 402.88,
      "text": " So you have to go back and rerun that initial pipeline. But they're only important when that",
      "tokens": [
        50680,
        407,
        291,
        362,
        281,
        352,
        646,
        293,
        43819,
        409,
        300,
        5883,
        15517,
        13,
        583,
        436,
        434,
        787,
        1021,
        562,
        300,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14174464299128606,
      "compression_ratio": 1.564516129032258,
      "no_speech_prob": 0.0001645166048547253
    },
    {
      "id": 76,
      "seek": 38936,
      "start": 402.88,
      "end": 409.68,
      "text": " dependent, like dependable track happens. Otherwise they don't care about them. So that was interesting",
      "tokens": [
        51040,
        12334,
        11,
        411,
        5672,
        712,
        2837,
        2314,
        13,
        10328,
        436,
        500,
        380,
        1127,
        466,
        552,
        13,
        407,
        300,
        390,
        1880,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14174464299128606,
      "compression_ratio": 1.564516129032258,
      "no_speech_prob": 0.0001645166048547253
    },
    {
      "id": 77,
      "seek": 40968,
      "start": 409.76,
      "end": 412.72,
      "text": " too. Because I was listing all of the expired artifacts.",
      "tokens": [
        50368,
        886,
        13,
        1436,
        286,
        390,
        22161,
        439,
        295,
        264,
        36587,
        24617,
        13,
        50516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32232139683976957,
      "compression_ratio": 1.4854368932038835,
      "no_speech_prob": 0.007932611741125584
    },
    {
      "id": 78,
      "seek": 40968,
      "start": 415.76,
      "end": 420.24,
      "text": " Hi Anna, do you want to voice even though you're still typing sorry?",
      "tokens": [
        50668,
        2421,
        12899,
        11,
        360,
        291,
        528,
        281,
        3177,
        754,
        1673,
        291,
        434,
        920,
        18444,
        2597,
        30,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32232139683976957,
      "compression_ratio": 1.4854368932038835,
      "no_speech_prob": 0.007932611741125584
    },
    {
      "id": 79,
      "seek": 40968,
      "start": 420.24,
      "end": 425.76,
      "text": " Yeah, I know. I think it you kind of answer to my question. I was wondering if there is",
      "tokens": [
        50892,
        865,
        11,
        286,
        458,
        13,
        286,
        519,
        309,
        291,
        733,
        295,
        1867,
        281,
        452,
        1168,
        13,
        286,
        390,
        6359,
        498,
        456,
        307,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32232139683976957,
      "compression_ratio": 1.4854368932038835,
      "no_speech_prob": 0.007932611741125584
    },
    {
      "id": 80,
      "seek": 40968,
      "start": 426.96000000000004,
      "end": 434.24,
      "text": " so far, if you heard any insights about those pipelines, those jobs and the artifacts are to",
      "tokens": [
        51228,
        370,
        1400,
        11,
        498,
        291,
        2198,
        604,
        14310,
        466,
        729,
        40168,
        11,
        729,
        4782,
        293,
        264,
        24617,
        366,
        281,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32232139683976957,
      "compression_ratio": 1.4854368932038835,
      "no_speech_prob": 0.007932611741125584
    },
    {
      "id": 81,
      "seek": 43424,
      "start": 434.24,
      "end": 442.32,
      "text": " facts being related to a release or that deploy job at the and why that would be important to debug",
      "tokens": [
        50364,
        9130,
        885,
        4077,
        281,
        257,
        4374,
        420,
        300,
        7274,
        1691,
        412,
        264,
        293,
        983,
        300,
        576,
        312,
        1021,
        281,
        24083,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24464444146640058,
      "compression_ratio": 1.5621621621621622,
      "no_speech_prob": 0.0006918967701494694
    },
    {
      "id": 82,
      "seek": 43424,
      "start": 442.32,
      "end": 449.28000000000003,
      "text": " at the group level. That's related to the link, the issue at a year for organizational level",
      "tokens": [
        50768,
        412,
        264,
        1594,
        1496,
        13,
        663,
        311,
        4077,
        281,
        264,
        2113,
        11,
        264,
        2734,
        412,
        257,
        1064,
        337,
        24730,
        1496,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24464444146640058,
      "compression_ratio": 1.5621621621621622,
      "no_speech_prob": 0.0006918967701494694
    },
    {
      "id": 83,
      "seek": 43424,
      "start": 449.28000000000003,
      "end": 456.96000000000004,
      "text": " environment page. And one of the jobs and also the tasks that you would go over with a page like",
      "tokens": [
        51116,
        2823,
        3028,
        13,
        400,
        472,
        295,
        264,
        4782,
        293,
        611,
        264,
        9608,
        300,
        291,
        576,
        352,
        670,
        365,
        257,
        3028,
        411,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24464444146640058,
      "compression_ratio": 1.5621621621621622,
      "no_speech_prob": 0.0006918967701494694
    },
    {
      "id": 84,
      "seek": 45696,
      "start": 457.03999999999996,
      "end": 465.68,
      "text": " that at the higher level is similar to what you're mentioning. So being able to move things",
      "tokens": [
        50368,
        300,
        412,
        264,
        2946,
        1496,
        307,
        2531,
        281,
        437,
        291,
        434,
        18315,
        13,
        407,
        885,
        1075,
        281,
        1286,
        721,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23632093576284555,
      "compression_ratio": 1.5523809523809524,
      "no_speech_prob": 0.0028859288431704044
    },
    {
      "id": 85,
      "seek": 45696,
      "start": 465.68,
      "end": 472.88,
      "text": " out of a release, for example, debug a failed deployment pipeline and see the status of",
      "tokens": [
        50800,
        484,
        295,
        257,
        4374,
        11,
        337,
        1365,
        11,
        24083,
        257,
        7612,
        19317,
        15517,
        293,
        536,
        264,
        6558,
        295,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23632093576284555,
      "compression_ratio": 1.5523809523809524,
      "no_speech_prob": 0.0028859288431704044
    },
    {
      "id": 86,
      "seek": 45696,
      "start": 474.08,
      "end": 478.88,
      "text": " what goes into production, but also where is that in the flow, etc. So the summary,",
      "tokens": [
        51220,
        437,
        1709,
        666,
        4265,
        11,
        457,
        611,
        689,
        307,
        300,
        294,
        264,
        3095,
        11,
        5183,
        13,
        407,
        264,
        12691,
        11,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23632093576284555,
      "compression_ratio": 1.5523809523809524,
      "no_speech_prob": 0.0028859288431704044
    },
    {
      "id": 87,
      "seek": 45696,
      "start": 480.0,
      "end": 484.56,
      "text": " if you heard anything related particularly to releases so far.",
      "tokens": [
        51516,
        498,
        291,
        2198,
        1340,
        4077,
        4098,
        281,
        16952,
        370,
        1400,
        13,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23632093576284555,
      "compression_ratio": 1.5523809523809524,
      "no_speech_prob": 0.0028859288431704044
    },
    {
      "id": 88,
      "seek": 48456,
      "start": 485.12,
      "end": 495.52,
      "text": " Yeah, the one thing I did here is the dependent pipelines type of thing. I also have heard",
      "tokens": [
        50392,
        865,
        11,
        264,
        472,
        551,
        286,
        630,
        510,
        307,
        264,
        12334,
        40168,
        2010,
        295,
        551,
        13,
        286,
        611,
        362,
        2198,
        50912
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19333416865422176,
      "compression_ratio": 1.5519125683060109,
      "no_speech_prob": 0.0006310598109848797
    },
    {
      "id": 89,
      "seek": 48456,
      "start": 496.72,
      "end": 504.4,
      "text": " sometimes. So the artifacts that we're talking about though are usually just passed between",
      "tokens": [
        50972,
        2171,
        13,
        407,
        264,
        24617,
        300,
        321,
        434,
        1417,
        466,
        1673,
        366,
        2673,
        445,
        4678,
        1296,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19333416865422176,
      "compression_ratio": 1.5519125683060109,
      "no_speech_prob": 0.0006310598109848797
    },
    {
      "id": 90,
      "seek": 48456,
      "start": 504.4,
      "end": 512.32,
      "text": " pipelines. They're not used to be deployed out into whatever. They're usually used as like reports or",
      "tokens": [
        51356,
        40168,
        13,
        814,
        434,
        406,
        1143,
        281,
        312,
        17826,
        484,
        666,
        2035,
        13,
        814,
        434,
        2673,
        1143,
        382,
        411,
        7122,
        420,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19333416865422176,
      "compression_ratio": 1.5519125683060109,
      "no_speech_prob": 0.0006310598109848797
    },
    {
      "id": 91,
      "seek": 51232,
      "start": 513.2800000000001,
      "end": 522.6400000000001,
      "text": " like logging kind of. So I haven't found anything that really overlaps with things that are going",
      "tokens": [
        50412,
        411,
        27991,
        733,
        295,
        13,
        407,
        286,
        2378,
        380,
        1352,
        1340,
        300,
        534,
        15986,
        2382,
        365,
        721,
        300,
        366,
        516,
        50880
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21123485004200654,
      "compression_ratio": 1.5251396648044693,
      "no_speech_prob": 0.000884041772224009
    },
    {
      "id": 92,
      "seek": 51232,
      "start": 522.6400000000001,
      "end": 530.4000000000001,
      "text": " to be deployed and released. I'm going to check back though. Yeah, that sounds good. If you",
      "tokens": [
        50880,
        281,
        312,
        17826,
        293,
        4736,
        13,
        286,
        478,
        516,
        281,
        1520,
        646,
        1673,
        13,
        865,
        11,
        300,
        3263,
        665,
        13,
        759,
        291,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21123485004200654,
      "compression_ratio": 1.5251396648044693,
      "no_speech_prob": 0.000884041772224009
    },
    {
      "id": 93,
      "seek": 51232,
      "start": 530.4000000000001,
      "end": 536.24,
      "text": " see anything, then just being me in the research issue and I'll have a look because",
      "tokens": [
        51268,
        536,
        1340,
        11,
        550,
        445,
        885,
        385,
        294,
        264,
        2132,
        2734,
        293,
        286,
        603,
        362,
        257,
        574,
        570,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21123485004200654,
      "compression_ratio": 1.5251396648044693,
      "no_speech_prob": 0.000884041772224009
    },
    {
      "id": 94,
      "seek": 53624,
      "start": 536.64,
      "end": 544.32,
      "text": " when talking to people about environments and for example, when I asked them, where would you go",
      "tokens": [
        50384,
        562,
        1417,
        281,
        561,
        466,
        12388,
        293,
        337,
        1365,
        11,
        562,
        286,
        2351,
        552,
        11,
        689,
        576,
        291,
        352,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20368271288664444,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 0.0027597181033343077
    },
    {
      "id": 95,
      "seek": 53624,
      "start": 544.32,
      "end": 551.44,
      "text": " to see the status of your latest deployment or where would you go to debug? I don't know,",
      "tokens": [
        50768,
        281,
        536,
        264,
        6558,
        295,
        428,
        6792,
        19317,
        420,
        689,
        576,
        291,
        352,
        281,
        24083,
        30,
        286,
        500,
        380,
        458,
        11,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20368271288664444,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 0.0027597181033343077
    },
    {
      "id": 96,
      "seek": 53624,
      "start": 552.8,
      "end": 557.28,
      "text": " a deploy pipeline that has failed. They would always go to the pipelines overview. They would not",
      "tokens": [
        51192,
        257,
        7274,
        15517,
        300,
        575,
        7612,
        13,
        814,
        576,
        1009,
        352,
        281,
        264,
        40168,
        12492,
        13,
        814,
        576,
        406,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20368271288664444,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 0.0027597181033343077
    },
    {
      "id": 97,
      "seek": 53624,
      "start": 557.28,
      "end": 564.72,
      "text": " go not always, but I would say like 70% of them would just navigate back to pipelines to see that.",
      "tokens": [
        51416,
        352,
        406,
        1009,
        11,
        457,
        286,
        576,
        584,
        411,
        5285,
        4,
        295,
        552,
        576,
        445,
        12350,
        646,
        281,
        40168,
        281,
        536,
        300,
        13,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20368271288664444,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 0.0027597181033343077
    },
    {
      "id": 98,
      "seek": 56472,
      "start": 564.72,
      "end": 571.36,
      "text": " And we have been talking the release team in implementing a view of environments at a good level.",
      "tokens": [
        50364,
        400,
        321,
        362,
        668,
        1417,
        264,
        4374,
        1469,
        294,
        18114,
        257,
        1910,
        295,
        12388,
        412,
        257,
        665,
        1496,
        13,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23516532966682502,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.0008980768034234643
    },
    {
      "id": 99,
      "seek": 56472,
      "start": 571.36,
      "end": 576.48,
      "text": " But if the pipeline view already solves that problem, I think it'll be interesting.",
      "tokens": [
        50696,
        583,
        498,
        264,
        15517,
        1910,
        1217,
        39890,
        300,
        1154,
        11,
        286,
        519,
        309,
        603,
        312,
        1880,
        13,
        50952
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23516532966682502,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.0008980768034234643
    },
    {
      "id": 100,
      "seek": 56472,
      "start": 576.48,
      "end": 583.0400000000001,
      "text": " I'm going to be able to connect with insights so we don't build two separate things when it's",
      "tokens": [
        50952,
        286,
        478,
        516,
        281,
        312,
        1075,
        281,
        1745,
        365,
        14310,
        370,
        321,
        500,
        380,
        1322,
        732,
        4994,
        721,
        562,
        309,
        311,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23516532966682502,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.0008980768034234643
    },
    {
      "id": 101,
      "seek": 56472,
      "start": 583.0400000000001,
      "end": 588.24,
      "text": " the same persona navigating. Maybe just completed different tasks. And like, what I'm thinking.",
      "tokens": [
        51280,
        264,
        912,
        12184,
        32054,
        13,
        2704,
        445,
        7365,
        819,
        9608,
        13,
        400,
        411,
        11,
        437,
        286,
        478,
        1953,
        13,
        51540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23516532966682502,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.0008980768034234643
    },
    {
      "id": 102,
      "seek": 56472,
      "start": 589.0400000000001,
      "end": 593.76,
      "text": " No, I understand what you're saying. We had, I had the similar thought of like, should this really",
      "tokens": [
        51580,
        883,
        11,
        286,
        1223,
        437,
        291,
        434,
        1566,
        13,
        492,
        632,
        11,
        286,
        632,
        264,
        2531,
        1194,
        295,
        411,
        11,
        820,
        341,
        534,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23516532966682502,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.0008980768034234643
    },
    {
      "id": 103,
      "seek": 59376,
      "start": 593.76,
      "end": 599.6,
      "text": " be a separate page or should this be integrated into the pipelines page already. And it's really",
      "tokens": [
        50364,
        312,
        257,
        4994,
        3028,
        420,
        820,
        341,
        312,
        10919,
        666,
        264,
        40168,
        3028,
        1217,
        13,
        400,
        309,
        311,
        534,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24757338584737576,
      "compression_ratio": 1.631578947368421,
      "no_speech_prob": 0.0011052375193685293
    },
    {
      "id": 104,
      "seek": 59376,
      "start": 599.6,
      "end": 607.52,
      "text": " hard with performance as well because the page is like so. There's so much there. But yeah, I'll",
      "tokens": [
        50656,
        1152,
        365,
        3389,
        382,
        731,
        570,
        264,
        3028,
        307,
        411,
        370,
        13,
        821,
        311,
        370,
        709,
        456,
        13,
        583,
        1338,
        11,
        286,
        603,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24757338584737576,
      "compression_ratio": 1.631578947368421,
      "no_speech_prob": 0.0011052375193685293
    },
    {
      "id": 105,
      "seek": 59376,
      "start": 607.52,
      "end": 612.56,
      "text": " let you know. I'll keep you updated. Awesome. And then I'll share later with you the",
      "tokens": [
        51052,
        718,
        291,
        458,
        13,
        286,
        603,
        1066,
        291,
        10588,
        13,
        10391,
        13,
        400,
        550,
        286,
        603,
        2073,
        1780,
        365,
        291,
        264,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24757338584737576,
      "compression_ratio": 1.631578947368421,
      "no_speech_prob": 0.0011052375193685293
    },
    {
      "id": 106,
      "seek": 59376,
      "start": 613.6,
      "end": 619.6,
      "text": " follow share already the link here. But I'm working on some of the prototypes. I want to have",
      "tokens": [
        51356,
        1524,
        2073,
        1217,
        264,
        2113,
        510,
        13,
        583,
        286,
        478,
        1364,
        322,
        512,
        295,
        264,
        42197,
        13,
        286,
        528,
        281,
        362,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24757338584737576,
      "compression_ratio": 1.631578947368421,
      "no_speech_prob": 0.0011052375193685293
    },
    {
      "id": 107,
      "seek": 61960,
      "start": 619.6,
      "end": 625.12,
      "text": " that added to the issue. I'll share with you so you can see how that relates to or how that might",
      "tokens": [
        50364,
        300,
        3869,
        281,
        264,
        2734,
        13,
        286,
        603,
        2073,
        365,
        291,
        370,
        291,
        393,
        536,
        577,
        300,
        16155,
        281,
        420,
        577,
        300,
        1062,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2102815494980923,
      "compression_ratio": 1.5520361990950227,
      "no_speech_prob": 0.0010589529993012547
    },
    {
      "id": 108,
      "seek": 61960,
      "start": 625.12,
      "end": 631.2,
      "text": " relate to what you're investing in. Okay. Sounds good. Nothing.",
      "tokens": [
        50640,
        10961,
        281,
        437,
        291,
        434,
        10978,
        294,
        13,
        1033,
        13,
        14576,
        665,
        13,
        6693,
        13,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2102815494980923,
      "compression_ratio": 1.5520361990950227,
      "no_speech_prob": 0.0010589529993012547
    },
    {
      "id": 109,
      "seek": 61960,
      "start": 633.12,
      "end": 639.9200000000001,
      "text": " Yeah. Hi, Any of your comments about wanting to see things at an organizational level for",
      "tokens": [
        51040,
        865,
        13,
        2421,
        11,
        2639,
        295,
        428,
        3053,
        466,
        7935,
        281,
        536,
        721,
        412,
        364,
        24730,
        1496,
        337,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2102815494980923,
      "compression_ratio": 1.5520361990950227,
      "no_speech_prob": 0.0010589529993012547
    },
    {
      "id": 110,
      "seek": 61960,
      "start": 639.9200000000001,
      "end": 648.4,
      "text": " environments is something I've seen in other research I've done too. So I help out with the",
      "tokens": [
        51380,
        12388,
        307,
        746,
        286,
        600,
        1612,
        294,
        661,
        2132,
        286,
        600,
        1096,
        886,
        13,
        407,
        286,
        854,
        484,
        365,
        264,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2102815494980923,
      "compression_ratio": 1.5520361990950227,
      "no_speech_prob": 0.0010589529993012547
    },
    {
      "id": 111,
      "seek": 64840,
      "start": 648.4,
      "end": 658.56,
      "text": " enablement group. And for global search, we found a lot of people talking about when I search for",
      "tokens": [
        50364,
        9528,
        518,
        1594,
        13,
        400,
        337,
        4338,
        3164,
        11,
        321,
        1352,
        257,
        688,
        295,
        561,
        1417,
        466,
        562,
        286,
        3164,
        337,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13549887793404716,
      "compression_ratio": 1.5783783783783785,
      "no_speech_prob": 0.0013109773863106966
    },
    {
      "id": 112,
      "seek": 64840,
      "start": 658.56,
      "end": 665.12,
      "text": " something in gate lab, I just want to be able to search within my organization, not just like a",
      "tokens": [
        50872,
        746,
        294,
        8539,
        2715,
        11,
        286,
        445,
        528,
        281,
        312,
        1075,
        281,
        3164,
        1951,
        452,
        4475,
        11,
        406,
        445,
        411,
        257,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13549887793404716,
      "compression_ratio": 1.5783783783783785,
      "no_speech_prob": 0.0013109773863106966
    },
    {
      "id": 113,
      "seek": 64840,
      "start": 665.12,
      "end": 670.9599999999999,
      "text": " specific project or a specific group, but just like everything for my company that they, you know,",
      "tokens": [
        51200,
        2685,
        1716,
        420,
        257,
        2685,
        1594,
        11,
        457,
        445,
        411,
        1203,
        337,
        452,
        2237,
        300,
        436,
        11,
        291,
        458,
        11,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13549887793404716,
      "compression_ratio": 1.5783783783783785,
      "no_speech_prob": 0.0013109773863106966
    },
    {
      "id": 114,
      "seek": 67096,
      "start": 671.0400000000001,
      "end": 680.4000000000001,
      "text": " they have. So that seems to be a common theme that I've been noticing. Yeah, that's a good to call",
      "tokens": [
        50368,
        436,
        362,
        13,
        407,
        300,
        2544,
        281,
        312,
        257,
        2689,
        6314,
        300,
        286,
        600,
        668,
        21814,
        13,
        865,
        11,
        300,
        311,
        257,
        665,
        281,
        818,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24609500803845993,
      "compression_ratio": 1.5738396624472575,
      "no_speech_prob": 0.0016462423373013735
    },
    {
      "id": 115,
      "seek": 67096,
      "start": 680.4000000000001,
      "end": 686.88,
      "text": " out to Will. And like my first thought is like performance exactly what Gina just mentioned,",
      "tokens": [
        50836,
        484,
        281,
        3099,
        13,
        400,
        411,
        452,
        700,
        1194,
        307,
        411,
        3389,
        2293,
        437,
        34711,
        445,
        2835,
        11,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24609500803845993,
      "compression_ratio": 1.5738396624472575,
      "no_speech_prob": 0.0016462423373013735
    },
    {
      "id": 116,
      "seek": 67096,
      "start": 686.88,
      "end": 693.9200000000001,
      "text": " that's, you know, in the past, why we kept separating things at the group level or project level",
      "tokens": [
        51160,
        300,
        311,
        11,
        291,
        458,
        11,
        294,
        264,
        1791,
        11,
        983,
        321,
        4305,
        29279,
        721,
        412,
        264,
        1594,
        1496,
        420,
        1716,
        1496,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24609500803845993,
      "compression_ratio": 1.5738396624472575,
      "no_speech_prob": 0.0016462423373013735
    },
    {
      "id": 117,
      "seek": 67096,
      "start": 693.9200000000001,
      "end": 699.84,
      "text": " or, you know, environment supply, it's also because we cannot support all this data.",
      "tokens": [
        51512,
        420,
        11,
        291,
        458,
        11,
        2823,
        5847,
        11,
        309,
        311,
        611,
        570,
        321,
        2644,
        1406,
        439,
        341,
        1412,
        13,
        51808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24609500803845993,
      "compression_ratio": 1.5738396624472575,
      "no_speech_prob": 0.0016462423373013735
    },
    {
      "id": 118,
      "seek": 69984,
      "start": 700.8000000000001,
      "end": 707.6800000000001,
      "text": " I think we can, but there's a lot that needs to be fixed in the back ends for that to happen.",
      "tokens": [
        50412,
        286,
        519,
        321,
        393,
        11,
        457,
        456,
        311,
        257,
        688,
        300,
        2203,
        281,
        312,
        6806,
        294,
        264,
        646,
        5314,
        337,
        300,
        281,
        1051,
        13,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16810729405651353,
      "compression_ratio": 1.5593220338983051,
      "no_speech_prob": 0.0014690178213641047
    },
    {
      "id": 119,
      "seek": 69984,
      "start": 707.6800000000001,
      "end": 712.24,
      "text": " And then for example, if you go to the environment dashboard, which is not the environment page,",
      "tokens": [
        50756,
        400,
        550,
        337,
        1365,
        11,
        498,
        291,
        352,
        281,
        264,
        2823,
        18342,
        11,
        597,
        307,
        406,
        264,
        2823,
        3028,
        11,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16810729405651353,
      "compression_ratio": 1.5593220338983051,
      "no_speech_prob": 0.0014690178213641047
    },
    {
      "id": 120,
      "seek": 69984,
      "start": 713.12,
      "end": 720.24,
      "text": " no, but we have something separate here. I'm going to drop a link here in our agenda.",
      "tokens": [
        51028,
        572,
        11,
        457,
        321,
        362,
        746,
        4994,
        510,
        13,
        286,
        478,
        516,
        281,
        3270,
        257,
        2113,
        510,
        294,
        527,
        9829,
        13,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16810729405651353,
      "compression_ratio": 1.5593220338983051,
      "no_speech_prob": 0.0014690178213641047
    },
    {
      "id": 121,
      "seek": 72024,
      "start": 721.2,
      "end": 731.36,
      "text": " Okay, wait, this is where ideally you would go, you know, to track environments across",
      "tokens": [
        50412,
        1033,
        11,
        1699,
        11,
        341,
        307,
        689,
        22915,
        291,
        576,
        352,
        11,
        291,
        458,
        11,
        281,
        2837,
        12388,
        2108,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19056867150699391,
      "compression_ratio": 1.4789473684210526,
      "no_speech_prob": 0.00395131716504693
    },
    {
      "id": 122,
      "seek": 72024,
      "start": 732.48,
      "end": 737.04,
      "text": " multiple projects or different groups, but then you can only show three environments per project",
      "tokens": [
        50976,
        3866,
        4455,
        420,
        819,
        3935,
        11,
        457,
        550,
        291,
        393,
        787,
        855,
        1045,
        12388,
        680,
        1716,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19056867150699391,
      "compression_ratio": 1.4789473684210526,
      "no_speech_prob": 0.00395131716504693
    },
    {
      "id": 123,
      "seek": 72024,
      "start": 737.76,
      "end": 744.16,
      "text": " at a time. So yeah, that's why people, as I mentioned before, they just go to the pipeline stage.",
      "tokens": [
        51240,
        412,
        257,
        565,
        13,
        407,
        1338,
        11,
        300,
        311,
        983,
        561,
        11,
        382,
        286,
        2835,
        949,
        11,
        436,
        445,
        352,
        281,
        264,
        15517,
        3233,
        13,
        51560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19056867150699391,
      "compression_ratio": 1.4789473684210526,
      "no_speech_prob": 0.00395131716504693
    },
    {
      "id": 124,
      "seek": 74416,
      "start": 744.8,
      "end": 751.28,
      "text": " And I, if you can, Russian Slater will do those the insights. This will be helpful because",
      "tokens": [
        50396,
        400,
        286,
        11,
        498,
        291,
        393,
        11,
        7220,
        6187,
        771,
        486,
        360,
        729,
        264,
        14310,
        13,
        639,
        486,
        312,
        4961,
        570,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27407112506904985,
      "compression_ratio": 1.517786561264822,
      "no_speech_prob": 0.011626679450273514
    },
    {
      "id": 125,
      "seek": 74416,
      "start": 752.0,
      "end": 758.3199999999999,
      "text": " Chris also asked me to start looking at this environment at the group level. And that's why I'm",
      "tokens": [
        50756,
        6688,
        611,
        2351,
        385,
        281,
        722,
        1237,
        412,
        341,
        2823,
        412,
        264,
        1594,
        1496,
        13,
        400,
        300,
        311,
        983,
        286,
        478,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27407112506904985,
      "compression_ratio": 1.517786561264822,
      "no_speech_prob": 0.011626679450273514
    },
    {
      "id": 126,
      "seek": 74416,
      "start": 758.3199999999999,
      "end": 763.12,
      "text": " like, let's validate that. Let's have the jobs to be done first because my gut feeling, my experience",
      "tokens": [
        51072,
        411,
        11,
        718,
        311,
        29562,
        300,
        13,
        961,
        311,
        362,
        264,
        4782,
        281,
        312,
        1096,
        700,
        570,
        452,
        5228,
        2633,
        11,
        452,
        1752,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27407112506904985,
      "compression_ratio": 1.517786561264822,
      "no_speech_prob": 0.011626679450273514
    },
    {
      "id": 127,
      "seek": 74416,
      "start": 763.12,
      "end": 770.0,
      "text": " with GitLab safe, we don't need that. We kind of, if we are able to highlight some information,",
      "tokens": [
        51312,
        365,
        16939,
        37880,
        3273,
        11,
        321,
        500,
        380,
        643,
        300,
        13,
        492,
        733,
        295,
        11,
        498,
        321,
        366,
        1075,
        281,
        5078,
        512,
        1589,
        11,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27407112506904985,
      "compression_ratio": 1.517786561264822,
      "no_speech_prob": 0.011626679450273514
    },
    {
      "id": 128,
      "seek": 77000,
      "start": 770.0,
      "end": 773.44,
      "text": " I'll give people the ability to filter or search whatever in places when they're ready.",
      "tokens": [
        50364,
        286,
        603,
        976,
        561,
        264,
        3485,
        281,
        6608,
        420,
        3164,
        2035,
        294,
        3190,
        562,
        436,
        434,
        1919,
        13,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35843120477138424,
      "compression_ratio": 1.4656862745098038,
      "no_speech_prob": 0.028371645137667656
    },
    {
      "id": 129,
      "seek": 77000,
      "start": 775.04,
      "end": 780.64,
      "text": " And go today, maybe that's a low-hanging fruit rather than a redesign.",
      "tokens": [
        50616,
        400,
        352,
        965,
        11,
        1310,
        300,
        311,
        257,
        2295,
        12,
        71,
        9741,
        6773,
        2831,
        813,
        257,
        39853,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35843120477138424,
      "compression_ratio": 1.4656862745098038,
      "no_speech_prob": 0.028371645137667656
    },
    {
      "id": 130,
      "seek": 77000,
      "start": 781.28,
      "end": 784.0,
      "text": " Anyways, let's me brainstorming our stuff here.",
      "tokens": [
        50928,
        15585,
        11,
        718,
        311,
        385,
        35245,
        278,
        527,
        1507,
        510,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35843120477138424,
      "compression_ratio": 1.4656862745098038,
      "no_speech_prob": 0.028371645137667656
    },
    {
      "id": 131,
      "seek": 77000,
      "start": 786.32,
      "end": 795.28,
      "text": " Okay, yeah, thanks for sharing. Yeah, and Gina, sorry for the collaboration traffic that I'm",
      "tokens": [
        51180,
        1033,
        11,
        1338,
        11,
        3231,
        337,
        5414,
        13,
        865,
        11,
        293,
        34711,
        11,
        2597,
        337,
        264,
        9363,
        6419,
        300,
        286,
        478,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35843120477138424,
      "compression_ratio": 1.4656862745098038,
      "no_speech_prob": 0.028371645137667656
    },
    {
      "id": 132,
      "seek": 79528,
      "start": 795.92,
      "end": 801.28,
      "text": " contributing to, I guess. So that's better. I love collaboration.",
      "tokens": [
        50396,
        19270,
        281,
        11,
        286,
        2041,
        13,
        407,
        300,
        311,
        1101,
        13,
        286,
        959,
        9363,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22272109985351562,
      "compression_ratio": 1.4739884393063585,
      "no_speech_prob": 0.0022826564963907003
    },
    {
      "id": 133,
      "seek": 79528,
      "start": 804.9599999999999,
      "end": 810.8,
      "text": " Well, thank you. All right, I'm going to, I'll finish up with the last thing. I'm working on",
      "tokens": [
        50848,
        1042,
        11,
        1309,
        291,
        13,
        1057,
        558,
        11,
        286,
        478,
        516,
        281,
        11,
        286,
        603,
        2413,
        493,
        365,
        264,
        1036,
        551,
        13,
        286,
        478,
        1364,
        322,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22272109985351562,
      "compression_ratio": 1.4739884393063585,
      "no_speech_prob": 0.0022826564963907003
    },
    {
      "id": 134,
      "seek": 79528,
      "start": 810.8,
      "end": 819.4399999999999,
      "text": " validating the new list view for the runner admin view. And hyana, I'm going to start recruiting",
      "tokens": [
        51140,
        7363,
        990,
        264,
        777,
        1329,
        1910,
        337,
        264,
        24376,
        24236,
        1910,
        13,
        400,
        2477,
        2095,
        11,
        286,
        478,
        516,
        281,
        722,
        25987,
        51572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22272109985351562,
      "compression_ratio": 1.4739884393063585,
      "no_speech_prob": 0.0022826564963907003
    },
    {
      "id": 135,
      "seek": 81944,
      "start": 820.32,
      "end": 826.0,
      "text": " next, my goal is next week. I have a discussion guide that's working progress right now.",
      "tokens": [
        50408,
        958,
        11,
        452,
        3387,
        307,
        958,
        1243,
        13,
        286,
        362,
        257,
        5017,
        5934,
        300,
        311,
        1364,
        4205,
        558,
        586,
        13,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13399154019643025,
      "compression_ratio": 1.5324074074074074,
      "no_speech_prob": 0.002881846623495221
    },
    {
      "id": 136,
      "seek": 81944,
      "start": 826.8000000000001,
      "end": 832.0,
      "text": " But I'm going to mix unmoderated and moderated. So I'm going to only",
      "tokens": [
        50732,
        583,
        286,
        478,
        516,
        281,
        2890,
        517,
        8014,
        260,
        770,
        293,
        10494,
        770,
        13,
        407,
        286,
        478,
        516,
        281,
        787,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13399154019643025,
      "compression_ratio": 1.5324074074074074,
      "no_speech_prob": 0.002881846623495221
    },
    {
      "id": 137,
      "seek": 81944,
      "start": 832.6400000000001,
      "end": 839.2,
      "text": " interview some of our internal GitLab team members so that I'm not like waiting on",
      "tokens": [
        51024,
        4049,
        512,
        295,
        527,
        6920,
        16939,
        37880,
        1469,
        2679,
        370,
        300,
        286,
        478,
        406,
        411,
        3806,
        322,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13399154019643025,
      "compression_ratio": 1.5324074074074074,
      "no_speech_prob": 0.002881846623495221
    },
    {
      "id": 138,
      "seek": 81944,
      "start": 841.12,
      "end": 846.32,
      "text": " like recruiting the enterprise customers, which has taken a while with the artifact stuff.",
      "tokens": [
        51448,
        411,
        25987,
        264,
        14132,
        4581,
        11,
        597,
        575,
        2726,
        257,
        1339,
        365,
        264,
        34806,
        1507,
        13,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13399154019643025,
      "compression_ratio": 1.5324074074074074,
      "no_speech_prob": 0.002881846623495221
    },
    {
      "id": 139,
      "seek": 84632,
      "start": 847.2800000000001,
      "end": 852.24,
      "text": " So I'll do a mix and I'm starting with validating like a very small portion of the list.",
      "tokens": [
        50412,
        407,
        286,
        603,
        360,
        257,
        2890,
        293,
        286,
        478,
        2891,
        365,
        7363,
        990,
        411,
        257,
        588,
        1359,
        8044,
        295,
        264,
        1329,
        13,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15564211739434136,
      "compression_ratio": 1.5829596412556053,
      "no_speech_prob": 0.001151474891230464
    },
    {
      "id": 140,
      "seek": 84632,
      "start": 854.1600000000001,
      "end": 860.1600000000001,
      "text": " All right, thank Gina. I'll share the list of participants that I use for the",
      "tokens": [
        50756,
        1057,
        558,
        11,
        1309,
        34711,
        13,
        286,
        603,
        2073,
        264,
        1329,
        295,
        10503,
        300,
        286,
        764,
        337,
        264,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15564211739434136,
      "compression_ratio": 1.5829596412556053,
      "no_speech_prob": 0.001151474891230464
    },
    {
      "id": 141,
      "seek": 84632,
      "start": 860.1600000000001,
      "end": 864.72,
      "text": " environments that I research because remember that some of them mention runners as well. So",
      "tokens": [
        51056,
        12388,
        300,
        286,
        2132,
        570,
        1604,
        300,
        512,
        295,
        552,
        2152,
        33892,
        382,
        731,
        13,
        407,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15564211739434136,
      "compression_ratio": 1.5829596412556053,
      "no_speech_prob": 0.001151474891230464
    },
    {
      "id": 142,
      "seek": 84632,
      "start": 865.5200000000001,
      "end": 871.6,
      "text": " I want to have a look there and see if any of those are going to be useful to you. Let me find",
      "tokens": [
        51324,
        286,
        528,
        281,
        362,
        257,
        574,
        456,
        293,
        536,
        498,
        604,
        295,
        729,
        366,
        516,
        281,
        312,
        4420,
        281,
        291,
        13,
        961,
        385,
        915,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15564211739434136,
      "compression_ratio": 1.5829596412556053,
      "no_speech_prob": 0.001151474891230464
    },
    {
      "id": 143,
      "seek": 87160,
      "start": 871.76,
      "end": 876.0,
      "text": " that now. Yeah, actually you, you share that with me, right? Will.",
      "tokens": [
        50372,
        300,
        586,
        13,
        865,
        11,
        767,
        291,
        11,
        291,
        2073,
        300,
        365,
        385,
        11,
        558,
        30,
        3099,
        13,
        50584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4176646509478169,
      "compression_ratio": 1.4482758620689655,
      "no_speech_prob": 0.005337911192327738
    },
    {
      "id": 144,
      "seek": 87160,
      "start": 878.8000000000001,
      "end": 883.52,
      "text": " Thanks. So it still should be somewhere in the comments that I would think.",
      "tokens": [
        50724,
        2561,
        13,
        407,
        309,
        920,
        820,
        312,
        4079,
        294,
        264,
        3053,
        300,
        286,
        576,
        519,
        13,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4176646509478169,
      "compression_ratio": 1.4482758620689655,
      "no_speech_prob": 0.005337911192327738
    },
    {
      "id": 145,
      "seek": 87160,
      "start": 884.32,
      "end": 890.0,
      "text": " Yeah, yeah, here's that with me. I share it with Gadi as well here.",
      "tokens": [
        51000,
        865,
        11,
        1338,
        11,
        510,
        311,
        300,
        365,
        385,
        13,
        286,
        2073,
        309,
        365,
        460,
        5688,
        382,
        731,
        510,
        13,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4176646509478169,
      "compression_ratio": 1.4482758620689655,
      "no_speech_prob": 0.005337911192327738
    },
    {
      "id": 146,
      "seek": 89000,
      "start": 890.96,
      "end": 891.52,
      "text": " Here.",
      "tokens": [
        50412,
        1692,
        13,
        50440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40824974907769096,
      "compression_ratio": 1.5636363636363637,
      "no_speech_prob": 0.014938626438379288
    },
    {
      "id": 147,
      "seek": 89000,
      "start": 893.44,
      "end": 895.52,
      "text": " And let's see.",
      "tokens": [
        50536,
        400,
        718,
        311,
        536,
        13,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40824974907769096,
      "compression_ratio": 1.5636363636363637,
      "no_speech_prob": 0.014938626438379288
    },
    {
      "id": 148,
      "seek": 89000,
      "start": 896.8,
      "end": 903.92,
      "text": " Here, Gina. Thank you. I think there were at least two of them mention runners. I think that's the",
      "tokens": [
        50704,
        1692,
        11,
        34711,
        13,
        1044,
        291,
        13,
        286,
        519,
        456,
        645,
        412,
        1935,
        732,
        295,
        552,
        2152,
        33892,
        13,
        286,
        519,
        300,
        311,
        264,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40824974907769096,
      "compression_ratio": 1.5636363636363637,
      "no_speech_prob": 0.014938626438379288
    },
    {
      "id": 149,
      "seek": 89000,
      "start": 903.92,
      "end": 910.0,
      "text": " one time I pinged you that I that I love you in the comment section. Okay.",
      "tokens": [
        51060,
        472,
        565,
        286,
        26151,
        292,
        291,
        300,
        286,
        300,
        286,
        959,
        291,
        294,
        264,
        2871,
        3541,
        13,
        1033,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40824974907769096,
      "compression_ratio": 1.5636363636363637,
      "no_speech_prob": 0.014938626438379288
    },
    {
      "id": 150,
      "seek": 89000,
      "start": 911.92,
      "end": 914.64,
      "text": " I think you need to act this. Let me add you to it. I do. Yeah.",
      "tokens": [
        51460,
        286,
        519,
        291,
        643,
        281,
        605,
        341,
        13,
        961,
        385,
        909,
        291,
        281,
        309,
        13,
        286,
        360,
        13,
        865,
        13,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.40824974907769096,
      "compression_ratio": 1.5636363636363637,
      "no_speech_prob": 0.014938626438379288
    },
    {
      "id": 151,
      "seek": 92000,
      "start": 920.0,
      "end": 927.44,
      "text": " Hmm. Got it. All right. Awesome. Thank you. I'll look into that.",
      "tokens": [
        50364,
        8239,
        13,
        5803,
        309,
        13,
        1057,
        558,
        13,
        10391,
        13,
        1044,
        291,
        13,
        286,
        603,
        574,
        666,
        300,
        13,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30706898709560965,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.004793884698301554
    },
    {
      "id": 152,
      "seek": 92000,
      "start": 930.24,
      "end": 930.64,
      "text": " All right.",
      "tokens": [
        50876,
        1057,
        558,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30706898709560965,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.004793884698301554
    },
    {
      "id": 153,
      "seek": 92000,
      "start": 933.6,
      "end": 938.16,
      "text": " So I guess I'm next. I'm out of office on Monday.",
      "tokens": [
        51044,
        407,
        286,
        2041,
        286,
        478,
        958,
        13,
        286,
        478,
        484,
        295,
        3398,
        322,
        8138,
        13,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30706898709560965,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.004793884698301554
    },
    {
      "id": 154,
      "seek": 92000,
      "start": 938.16,
      "end": 942.96,
      "text": " It's six to the public holiday here in the Netherlands. And I'm also out of office in June.",
      "tokens": [
        51272,
        467,
        311,
        2309,
        281,
        264,
        1908,
        9960,
        510,
        294,
        264,
        20873,
        13,
        400,
        286,
        478,
        611,
        484,
        295,
        3398,
        294,
        6928,
        13,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30706898709560965,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.004793884698301554
    },
    {
      "id": 155,
      "seek": 92000,
      "start": 943.6,
      "end": 949.04,
      "text": " 14th of 23rd. You've already mentioned that to all of you. There's no one of ones,",
      "tokens": [
        51544,
        3499,
        392,
        295,
        6673,
        7800,
        13,
        509,
        600,
        1217,
        2835,
        300,
        281,
        439,
        295,
        291,
        13,
        821,
        311,
        572,
        472,
        295,
        2306,
        11,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30706898709560965,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.004793884698301554
    },
    {
      "id": 156,
      "seek": 94904,
      "start": 949.04,
      "end": 957.5999999999999,
      "text": " but there's a covers issue at the link here again. And it's your working progress, but",
      "tokens": [
        50364,
        457,
        456,
        311,
        257,
        10538,
        2734,
        412,
        264,
        2113,
        510,
        797,
        13,
        400,
        309,
        311,
        428,
        1364,
        4205,
        11,
        457,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4552422065239448,
      "compression_ratio": 1.4835164835164836,
      "no_speech_prob": 0.0014253208646550775
    },
    {
      "id": 157,
      "seek": 94904,
      "start": 958.48,
      "end": 964.7199999999999,
      "text": " you're a very issue. You can see my backup will be soon. I'm going to have a backup.",
      "tokens": [
        50836,
        291,
        434,
        257,
        588,
        2734,
        13,
        509,
        393,
        536,
        452,
        14807,
        486,
        312,
        2321,
        13,
        286,
        478,
        516,
        281,
        362,
        257,
        14807,
        13,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4552422065239448,
      "compression_ratio": 1.4835164835164836,
      "no_speech_prob": 0.0014253208646550775
    },
    {
      "id": 158,
      "seek": 94904,
      "start": 965.4399999999999,
      "end": 974.56,
      "text": " A fine. June. June. 14th. Okay. And then next week, Chris and Chris and I are going to participate",
      "tokens": [
        51184,
        316,
        2489,
        13,
        6928,
        13,
        6928,
        13,
        3499,
        392,
        13,
        1033,
        13,
        400,
        550,
        958,
        1243,
        11,
        6688,
        293,
        6688,
        293,
        286,
        366,
        516,
        281,
        8197,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.4552422065239448,
      "compression_ratio": 1.4835164835164836,
      "no_speech_prob": 0.0014253208646550775
    },
    {
      "id": 159,
      "seek": 97456,
      "start": 974.64,
      "end": 980.9599999999999,
      "text": " in the UX road mapping workshop. That's part of the Q2KR next week on Thursday.",
      "tokens": [
        50368,
        294,
        264,
        40176,
        3060,
        18350,
        13541,
        13,
        663,
        311,
        644,
        295,
        264,
        1249,
        17,
        42,
        49,
        958,
        1243,
        322,
        10383,
        13,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31803880419049946,
      "compression_ratio": 1.6318181818181818,
      "no_speech_prob": 0.007038760930299759
    },
    {
      "id": 160,
      "seek": 97456,
      "start": 982.0,
      "end": 988.9599999999999,
      "text": " I added the incorrect links here. So that's that. I'm finishing reading the 10 book page.",
      "tokens": [
        50736,
        286,
        3869,
        264,
        18424,
        6123,
        510,
        13,
        407,
        300,
        311,
        300,
        13,
        286,
        478,
        12693,
        3760,
        264,
        1266,
        1446,
        3028,
        13,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31803880419049946,
      "compression_ratio": 1.6318181818181818,
      "no_speech_prob": 0.007038760930299759
    },
    {
      "id": 161,
      "seek": 97456,
      "start": 990.8,
      "end": 995.68,
      "text": " And we'll see what's going to happen there. We're going to be the first ones doing that workshop.",
      "tokens": [
        51176,
        400,
        321,
        603,
        536,
        437,
        311,
        516,
        281,
        1051,
        456,
        13,
        492,
        434,
        516,
        281,
        312,
        264,
        700,
        2306,
        884,
        300,
        13541,
        13,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31803880419049946,
      "compression_ratio": 1.6318181818181818,
      "no_speech_prob": 0.007038760930299759
    },
    {
      "id": 162,
      "seek": 97456,
      "start": 996.4,
      "end": 1001.8399999999999,
      "text": " That's cool. And then other than environments. So I have to add in that here, but I have to",
      "tokens": [
        51456,
        663,
        311,
        1627,
        13,
        400,
        550,
        661,
        813,
        12388,
        13,
        407,
        286,
        362,
        281,
        909,
        294,
        300,
        510,
        11,
        457,
        286,
        362,
        281,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31803880419049946,
      "compression_ratio": 1.6318181818181818,
      "no_speech_prob": 0.007038760930299759
    },
    {
      "id": 163,
      "seek": 100184,
      "start": 1002.0,
      "end": 1011.2800000000001,
      "text": " wrap up the insights on the research that I conducted. And then also being helping",
      "tokens": [
        50372,
        7019,
        493,
        264,
        14310,
        322,
        264,
        2132,
        300,
        286,
        13809,
        13,
        400,
        550,
        611,
        885,
        4315,
        50836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2834100127220154,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.003450718242675066
    },
    {
      "id": 164,
      "seek": 100184,
      "start": 1011.84,
      "end": 1017.9200000000001,
      "text": " collaborating with Chris and Will on the benchmarking for release. So I also wrapped that up just",
      "tokens": [
        50864,
        30188,
        365,
        6688,
        293,
        3099,
        322,
        264,
        18927,
        278,
        337,
        4374,
        13,
        407,
        286,
        611,
        14226,
        300,
        493,
        445,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2834100127220154,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.003450718242675066
    },
    {
      "id": 165,
      "seek": 100184,
      "start": 1018.64,
      "end": 1026.8,
      "text": " think I have an hour ago. Trying to determine which tasks happened in the UI and API. So that",
      "tokens": [
        51204,
        519,
        286,
        362,
        364,
        1773,
        2057,
        13,
        20180,
        281,
        6997,
        597,
        9608,
        2011,
        294,
        264,
        15682,
        293,
        9362,
        13,
        407,
        300,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2834100127220154,
      "compression_ratio": 1.46524064171123,
      "no_speech_prob": 0.003450718242675066
    },
    {
      "id": 166,
      "seek": 102680,
      "start": 1027.52,
      "end": 1033.04,
      "text": " will know how to set up the test environment, but also the tasks that are going to go through.",
      "tokens": [
        50400,
        486,
        458,
        577,
        281,
        992,
        493,
        264,
        1500,
        2823,
        11,
        457,
        611,
        264,
        9608,
        300,
        366,
        516,
        281,
        352,
        807,
        13,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28042782677544487,
      "compression_ratio": 1.5593220338983051,
      "no_speech_prob": 0.0036662532947957516
    },
    {
      "id": 167,
      "seek": 102680,
      "start": 1036.24,
      "end": 1042.24,
      "text": " Maybe we'll maybe we'll talk about that later, but anything you'd like to add about the benchmark",
      "tokens": [
        50836,
        2704,
        321,
        603,
        1310,
        321,
        603,
        751,
        466,
        300,
        1780,
        11,
        457,
        1340,
        291,
        1116,
        411,
        281,
        909,
        466,
        264,
        18927,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28042782677544487,
      "compression_ratio": 1.5593220338983051,
      "no_speech_prob": 0.0036662532947957516
    },
    {
      "id": 168,
      "seek": 102680,
      "start": 1042.24,
      "end": 1050.48,
      "text": " for you. No, we had a we had a very in-depth discussion about it a couple hours ago",
      "tokens": [
        51136,
        337,
        291,
        13,
        883,
        11,
        321,
        632,
        257,
        321,
        632,
        257,
        588,
        294,
        12,
        25478,
        5017,
        466,
        309,
        257,
        1916,
        2496,
        2057,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28042782677544487,
      "compression_ratio": 1.5593220338983051,
      "no_speech_prob": 0.0036662532947957516
    },
    {
      "id": 169,
      "seek": 105048,
      "start": 1051.2,
      "end": 1059.6,
      "text": " between you, myself and Chris. So we've still got a lot of things to figure out in the coming weeks,",
      "tokens": [
        50400,
        1296,
        291,
        11,
        2059,
        293,
        6688,
        13,
        407,
        321,
        600,
        920,
        658,
        257,
        688,
        295,
        721,
        281,
        2573,
        484,
        294,
        264,
        1348,
        3259,
        11,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2557147145271301,
      "compression_ratio": 1.3652694610778444,
      "no_speech_prob": 0.011302076280117035
    },
    {
      "id": 170,
      "seek": 105048,
      "start": 1059.6,
      "end": 1062.32,
      "text": " but it was good to catch up.",
      "tokens": [
        50820,
        457,
        309,
        390,
        665,
        281,
        3745,
        493,
        13,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2557147145271301,
      "compression_ratio": 1.3652694610778444,
      "no_speech_prob": 0.011302076280117035
    },
    {
      "id": 171,
      "seek": 105048,
      "start": 1068.64,
      "end": 1076.24,
      "text": " There are a couple of dates here from Package and Firefly and Altany. So Katie and Nadia had their",
      "tokens": [
        51272,
        821,
        366,
        257,
        1916,
        295,
        11691,
        510,
        490,
        18466,
        609,
        293,
        7652,
        14061,
        293,
        15992,
        1325,
        13,
        407,
        19602,
        293,
        23269,
        654,
        632,
        641,
        51652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2557147145271301,
      "compression_ratio": 1.3652694610778444,
      "no_speech_prob": 0.011302076280117035
    },
    {
      "id": 172,
      "seek": 107624,
      "start": 1076.32,
      "end": 1081.84,
      "text": " session earlier today. So please have a look and leave comments if you have any.",
      "tokens": [
        50368,
        5481,
        3071,
        965,
        13,
        407,
        1767,
        362,
        257,
        574,
        293,
        1856,
        3053,
        498,
        291,
        362,
        604,
        13,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2554892150449081,
      "compression_ratio": 1.5027027027027027,
      "no_speech_prob": 0.004522707778960466
    },
    {
      "id": 173,
      "seek": 107624,
      "start": 1083.76,
      "end": 1091.76,
      "text": " And we stayed out of office this whole week. She'll be back next week. Yeah, next week on Monday.",
      "tokens": [
        50740,
        400,
        321,
        9181,
        484,
        295,
        3398,
        341,
        1379,
        1243,
        13,
        1240,
        603,
        312,
        646,
        958,
        1243,
        13,
        865,
        11,
        958,
        1243,
        322,
        8138,
        13,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2554892150449081,
      "compression_ratio": 1.5027027027027027,
      "no_speech_prob": 0.004522707778960466
    },
    {
      "id": 174,
      "seek": 107624,
      "start": 1091.76,
      "end": 1098.4,
      "text": " So we're going to skip back on execution this week. And then over to Will for the research efforts.",
      "tokens": [
        51140,
        407,
        321,
        434,
        516,
        281,
        10023,
        646,
        322,
        15058,
        341,
        1243,
        13,
        400,
        550,
        670,
        281,
        3099,
        337,
        264,
        2132,
        6484,
        13,
        51472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2554892150449081,
      "compression_ratio": 1.5027027027027027,
      "no_speech_prob": 0.004522707778960466
    },
    {
      "id": 175,
      "seek": 109840,
      "start": 1099.2,
      "end": 1109.3600000000001,
      "text": " Nice. So I'm out of office this Friday. I'll be back on Monday to catch up on things.",
      "tokens": [
        50404,
        5490,
        13,
        407,
        286,
        478,
        484,
        295,
        3398,
        341,
        6984,
        13,
        286,
        603,
        312,
        646,
        322,
        8138,
        281,
        3745,
        493,
        322,
        721,
        13,
        50912
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23441882631671962,
      "compression_ratio": 1.3891891891891892,
      "no_speech_prob": 0.006698585581034422
    },
    {
      "id": 176,
      "seek": 109840,
      "start": 1110.24,
      "end": 1119.68,
      "text": " And as I spoke to a minute ago, I met with Pion and Chris to talk through different release topics.",
      "tokens": [
        50956,
        400,
        382,
        286,
        7179,
        281,
        257,
        3456,
        2057,
        11,
        286,
        1131,
        365,
        430,
        313,
        293,
        6688,
        281,
        751,
        807,
        819,
        4374,
        8378,
        13,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23441882631671962,
      "compression_ratio": 1.3891891891891892,
      "no_speech_prob": 0.006698585581034422
    },
    {
      "id": 177,
      "seek": 109840,
      "start": 1121.0400000000002,
      "end": 1125.92,
      "text": " Specifically the usability benchmarking study. I've linked to the mural",
      "tokens": [
        51496,
        26058,
        264,
        46878,
        18927,
        278,
        2979,
        13,
        286,
        600,
        9408,
        281,
        264,
        40595,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23441882631671962,
      "compression_ratio": 1.3891891891891892,
      "no_speech_prob": 0.006698585581034422
    },
    {
      "id": 178,
      "seek": 112592,
      "start": 1126.0800000000002,
      "end": 1134.88,
      "text": " that has been updated a little bit since we last spoke. So there's a list of I think 31 different",
      "tokens": [
        50372,
        300,
        575,
        668,
        10588,
        257,
        707,
        857,
        1670,
        321,
        1036,
        7179,
        13,
        407,
        456,
        311,
        257,
        1329,
        295,
        286,
        519,
        10353,
        819,
        50812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11317810331072126,
      "compression_ratio": 1.4627659574468086,
      "no_speech_prob": 0.004854988772422075
    },
    {
      "id": 179,
      "seek": 112592,
      "start": 1134.88,
      "end": 1143.52,
      "text": " tasks that we could potentially do. And we'll need to narrow that down in probably the next week or so.",
      "tokens": [
        50812,
        9608,
        300,
        321,
        727,
        7263,
        360,
        13,
        400,
        321,
        603,
        643,
        281,
        9432,
        300,
        760,
        294,
        1391,
        264,
        958,
        1243,
        420,
        370,
        13,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11317810331072126,
      "compression_ratio": 1.4627659574468086,
      "no_speech_prob": 0.004854988772422075
    },
    {
      "id": 180,
      "seek": 112592,
      "start": 1146.48,
      "end": 1153.76,
      "text": " So I'll be helping out with that. And then creating a UX sandbox project.",
      "tokens": [
        51392,
        407,
        286,
        603,
        312,
        4315,
        484,
        365,
        300,
        13,
        400,
        550,
        4084,
        257,
        40176,
        42115,
        1716,
        13,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11317810331072126,
      "compression_ratio": 1.4627659574468086,
      "no_speech_prob": 0.004854988772422075
    },
    {
      "id": 181,
      "seek": 115376,
      "start": 1154.08,
      "end": 1160.8,
      "text": " I've been speaking with one of the other researchers who's done that. And he had a lot of content",
      "tokens": [
        50380,
        286,
        600,
        668,
        4124,
        365,
        472,
        295,
        264,
        661,
        10309,
        567,
        311,
        1096,
        300,
        13,
        400,
        415,
        632,
        257,
        688,
        295,
        2701,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14982881937941459,
      "compression_ratio": 1.4972972972972973,
      "no_speech_prob": 0.0038952212780714035
    },
    {
      "id": 182,
      "seek": 115376,
      "start": 1160.8,
      "end": 1168.96,
      "text": " that went into that handbook page that I can actually link to. So I'll add that page in just a moment.",
      "tokens": [
        50716,
        300,
        1437,
        666,
        300,
        1011,
        2939,
        3028,
        300,
        286,
        393,
        767,
        2113,
        281,
        13,
        407,
        286,
        603,
        909,
        300,
        3028,
        294,
        445,
        257,
        1623,
        13,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14982881937941459,
      "compression_ratio": 1.4972972972972973,
      "no_speech_prob": 0.0038952212780714035
    },
    {
      "id": 183,
      "seek": 115376,
      "start": 1171.44,
      "end": 1178.24,
      "text": " But yeah, that's kind of it for me at the moment. Any comments or questions?",
      "tokens": [
        51248,
        583,
        1338,
        11,
        300,
        311,
        733,
        295,
        309,
        337,
        385,
        412,
        264,
        1623,
        13,
        2639,
        3053,
        420,
        1651,
        30,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14982881937941459,
      "compression_ratio": 1.4972972972972973,
      "no_speech_prob": 0.0038952212780714035
    },
    {
      "id": 184,
      "seek": 118376,
      "start": 1184.24,
      "end": 1200.0,
      "text": " I comment. I didn't already mentioned this in Slack, but for the tasks that we added to the",
      "tokens": [
        50388,
        286,
        2871,
        13,
        286,
        994,
        380,
        1217,
        2835,
        341,
        294,
        37211,
        11,
        457,
        337,
        264,
        9608,
        300,
        321,
        3869,
        281,
        264,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3039379119873047,
      "compression_ratio": 1.411764705882353,
      "no_speech_prob": 0.004467771388590336
    },
    {
      "id": 185,
      "seek": 118376,
      "start": 1201.28,
      "end": 1209.6,
      "text": " the mural board. I think there are a couple of things here that we cannot do with the product today.",
      "tokens": [
        51240,
        264,
        40595,
        3150,
        13,
        286,
        519,
        456,
        366,
        257,
        1916,
        295,
        721,
        510,
        300,
        321,
        2644,
        360,
        365,
        264,
        1674,
        965,
        13,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3039379119873047,
      "compression_ratio": 1.411764705882353,
      "no_speech_prob": 0.004467771388590336
    },
    {
      "id": 186,
      "seek": 120960,
      "start": 1210.08,
      "end": 1217.1999999999998,
      "text": " So what do we do with those tasks that we remove them? Do we leave them there? What's kind of like",
      "tokens": [
        50388,
        407,
        437,
        360,
        321,
        360,
        365,
        729,
        9608,
        300,
        321,
        4159,
        552,
        30,
        1144,
        321,
        1856,
        552,
        456,
        30,
        708,
        311,
        733,
        295,
        411,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19903258005777993,
      "compression_ratio": 1.4820512820512821,
      "no_speech_prob": 0.006145230028778315
    },
    {
      "id": 187,
      "seek": 120960,
      "start": 1219.36,
      "end": 1223.52,
      "text": " because we're not going to assess it, right? The usability if we cannot perform that particular task.",
      "tokens": [
        50852,
        570,
        321,
        434,
        406,
        516,
        281,
        5877,
        309,
        11,
        558,
        30,
        440,
        46878,
        498,
        321,
        2644,
        2042,
        300,
        1729,
        5633,
        13,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19903258005777993,
      "compression_ratio": 1.4820512820512821,
      "no_speech_prob": 0.006145230028778315
    },
    {
      "id": 188,
      "seek": 120960,
      "start": 1225.1999999999998,
      "end": 1234.9599999999998,
      "text": " Yeah, that's a good question. I think we'll just have to move on because we can't really",
      "tokens": [
        51144,
        865,
        11,
        300,
        311,
        257,
        665,
        1168,
        13,
        286,
        519,
        321,
        603,
        445,
        362,
        281,
        1286,
        322,
        570,
        321,
        393,
        380,
        534,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19903258005777993,
      "compression_ratio": 1.4820512820512821,
      "no_speech_prob": 0.006145230028778315
    },
    {
      "id": 189,
      "seek": 123496,
      "start": 1234.96,
      "end": 1241.3600000000001,
      "text": " assess them if we can't actually create an environment where participants could actually complete the",
      "tokens": [
        50364,
        5877,
        552,
        498,
        321,
        393,
        380,
        767,
        1884,
        364,
        2823,
        689,
        10503,
        727,
        767,
        3566,
        264,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1984553337097168,
      "compression_ratio": 1.5625,
      "no_speech_prob": 0.002906025154516101
    },
    {
      "id": 190,
      "seek": 123496,
      "start": 1241.3600000000001,
      "end": 1250.96,
      "text": " task. We could make note in the report that we wanted to do these tasks and list them out, but then",
      "tokens": [
        50684,
        5633,
        13,
        492,
        727,
        652,
        3637,
        294,
        264,
        2275,
        300,
        321,
        1415,
        281,
        360,
        613,
        9608,
        293,
        1329,
        552,
        484,
        11,
        457,
        550,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1984553337097168,
      "compression_ratio": 1.5625,
      "no_speech_prob": 0.002906025154516101
    },
    {
      "id": 191,
      "seek": 123496,
      "start": 1251.8400000000001,
      "end": 1258.64,
      "text": " say that this would be something to get at it the future if we have time.",
      "tokens": [
        51208,
        584,
        300,
        341,
        576,
        312,
        746,
        281,
        483,
        412,
        309,
        264,
        2027,
        498,
        321,
        362,
        565,
        13,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1984553337097168,
      "compression_ratio": 1.5625,
      "no_speech_prob": 0.002906025154516101
    },
    {
      "id": 192,
      "seek": 125864,
      "start": 1259.3600000000001,
      "end": 1266.3200000000002,
      "text": " Because the usability benchmark is not just like a one and done thing. You can do it. I think roughly",
      "tokens": [
        50400,
        1436,
        264,
        46878,
        18927,
        307,
        406,
        445,
        411,
        257,
        472,
        293,
        1096,
        551,
        13,
        509,
        393,
        360,
        309,
        13,
        286,
        519,
        9810,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2425099986873261,
      "compression_ratio": 1.5025641025641026,
      "no_speech_prob": 0.006533265579491854
    },
    {
      "id": 193,
      "seek": 125864,
      "start": 1266.3200000000002,
      "end": 1275.1200000000001,
      "text": " once a year is what the handbook talks about. So yeah, I think that would just like get added to",
      "tokens": [
        50748,
        1564,
        257,
        1064,
        307,
        437,
        264,
        1011,
        2939,
        6686,
        466,
        13,
        407,
        1338,
        11,
        286,
        519,
        300,
        576,
        445,
        411,
        483,
        3869,
        281,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2425099986873261,
      "compression_ratio": 1.5025641025641026,
      "no_speech_prob": 0.006533265579491854
    },
    {
      "id": 194,
      "seek": 125864,
      "start": 1275.1200000000001,
      "end": 1284.3200000000002,
      "text": " a backlog in a sense. That makes sense. And I'm referring to a creator release audit checklist",
      "tokens": [
        51188,
        257,
        47364,
        294,
        257,
        2020,
        13,
        663,
        1669,
        2020,
        13,
        400,
        286,
        478,
        13761,
        281,
        257,
        14181,
        4374,
        17748,
        30357,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2425099986873261,
      "compression_ratio": 1.5025641025641026,
      "no_speech_prob": 0.006533265579491854
    },
    {
      "id": 195,
      "seek": 128432,
      "start": 1284.3999999999999,
      "end": 1290.8799999999999,
      "text": " in particular. I actually had that one sticky and the task. And I'm like, how did I do that today?",
      "tokens": [
        50368,
        294,
        1729,
        13,
        286,
        767,
        632,
        300,
        472,
        14470,
        293,
        264,
        5633,
        13,
        400,
        286,
        478,
        411,
        11,
        577,
        630,
        286,
        360,
        300,
        965,
        30,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24370269286326873,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0036693972069770098
    },
    {
      "id": 196,
      "seek": 128432,
      "start": 1290.8799999999999,
      "end": 1298.32,
      "text": " And I think that's a good way to find out is checking the delivery team because they're the ones that",
      "tokens": [
        50692,
        400,
        286,
        519,
        300,
        311,
        257,
        665,
        636,
        281,
        915,
        484,
        307,
        8568,
        264,
        8982,
        1469,
        570,
        436,
        434,
        264,
        2306,
        300,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24370269286326873,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0036693972069770098
    },
    {
      "id": 197,
      "seek": 128432,
      "start": 1299.2,
      "end": 1305.52,
      "text": " produce with GitLab. But I know that it's a manual task, maybe don't outside of GitLab.",
      "tokens": [
        51108,
        5258,
        365,
        16939,
        37880,
        13,
        583,
        286,
        458,
        300,
        309,
        311,
        257,
        9688,
        5633,
        11,
        1310,
        500,
        380,
        2380,
        295,
        16939,
        37880,
        13,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24370269286326873,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0036693972069770098
    },
    {
      "id": 198,
      "seek": 130552,
      "start": 1306.08,
      "end": 1312.08,
      "text": " So do we measure that? Do we track that particular scenario?",
      "tokens": [
        50392,
        407,
        360,
        321,
        3481,
        300,
        30,
        1144,
        321,
        2837,
        300,
        1729,
        9005,
        30,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465377981012518,
      "compression_ratio": 1.3333333333333333,
      "no_speech_prob": 0.00906789768487215
    },
    {
      "id": 199,
      "seek": 130552,
      "start": 1313.68,
      "end": 1318.56,
      "text": " But I can investigate about this sticky, create release audit checklist.",
      "tokens": [
        50772,
        583,
        286,
        393,
        15013,
        466,
        341,
        14470,
        11,
        1884,
        4374,
        17748,
        30357,
        13,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465377981012518,
      "compression_ratio": 1.3333333333333333,
      "no_speech_prob": 0.00906789768487215
    },
    {
      "id": 200,
      "seek": 130552,
      "start": 1319.84,
      "end": 1321.28,
      "text": " Okay, yeah, that'd be great.",
      "tokens": [
        51080,
        1033,
        11,
        1338,
        11,
        300,
        1116,
        312,
        869,
        13,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465377981012518,
      "compression_ratio": 1.3333333333333333,
      "no_speech_prob": 0.00906789768487215
    },
    {
      "id": 201,
      "seek": 130552,
      "start": 1329.12,
      "end": 1334.0,
      "text": " Do you want me to speak to Erica's stuff?",
      "tokens": [
        51544,
        1144,
        291,
        528,
        385,
        281,
        1710,
        281,
        37429,
        311,
        1507,
        30,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465377981012518,
      "compression_ratio": 1.3333333333333333,
      "no_speech_prob": 0.00906789768487215
    },
    {
      "id": 202,
      "seek": 133552,
      "start": 1335.68,
      "end": 1342.8799999999999,
      "text": " So she's got her prioritization issue still there. She's included a link to",
      "tokens": [
        50372,
        407,
        750,
        311,
        658,
        720,
        14846,
        2144,
        2734,
        920,
        456,
        13,
        1240,
        311,
        5556,
        257,
        2113,
        281,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18084426930076197,
      "compression_ratio": 1.4773869346733668,
      "no_speech_prob": 0.005620210897177458
    },
    {
      "id": 203,
      "seek": 133552,
      "start": 1344.4,
      "end": 1350.32,
      "text": " the field notes that she took in a summary that she did based on her experience at QPON",
      "tokens": [
        50808,
        264,
        2519,
        5570,
        300,
        750,
        1890,
        294,
        257,
        12691,
        300,
        750,
        630,
        2361,
        322,
        720,
        1752,
        412,
        1249,
        47,
        1928,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18084426930076197,
      "compression_ratio": 1.4773869346733668,
      "no_speech_prob": 0.005620210897177458
    },
    {
      "id": 204,
      "seek": 133552,
      "start": 1351.76,
      "end": 1354.08,
      "text": " that I think was about a week or two ago.",
      "tokens": [
        51176,
        300,
        286,
        519,
        390,
        466,
        257,
        1243,
        420,
        732,
        2057,
        13,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18084426930076197,
      "compression_ratio": 1.4773869346733668,
      "no_speech_prob": 0.005620210897177458
    },
    {
      "id": 205,
      "seek": 133552,
      "start": 1357.76,
      "end": 1364.72,
      "text": " So definitely check that out if you haven't already. I've seen some of the documentation",
      "tokens": [
        51476,
        407,
        2138,
        1520,
        300,
        484,
        498,
        291,
        2378,
        380,
        1217,
        13,
        286,
        600,
        1612,
        512,
        295,
        264,
        14333,
        51824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18084426930076197,
      "compression_ratio": 1.4773869346733668,
      "no_speech_prob": 0.005620210897177458
    },
    {
      "id": 206,
      "seek": 136472,
      "start": 1364.8,
      "end": 1371.6000000000001,
      "text": " that she's already shared and it's very extensive. So I would recommend it.",
      "tokens": [
        50368,
        300,
        750,
        311,
        1217,
        5507,
        293,
        309,
        311,
        588,
        13246,
        13,
        407,
        286,
        576,
        2748,
        309,
        13,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3356465385073707,
      "compression_ratio": 1.4401913875598087,
      "no_speech_prob": 0.0019197621149942279
    },
    {
      "id": 207,
      "seek": 136472,
      "start": 1374.24,
      "end": 1376.72,
      "text": " Hi, Anna, did you want to voice your comment?",
      "tokens": [
        50840,
        2421,
        11,
        12899,
        11,
        630,
        291,
        528,
        281,
        3177,
        428,
        2871,
        30,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3356465385073707,
      "compression_ratio": 1.4401913875598087,
      "no_speech_prob": 0.0019197621149942279
    },
    {
      "id": 208,
      "seek": 136472,
      "start": 1377.44,
      "end": 1382.16,
      "text": " Yeah, so I haven't had a chance to get her feedback yet. So I'm just a synchronously saying",
      "tokens": [
        51000,
        865,
        11,
        370,
        286,
        2378,
        380,
        632,
        257,
        2931,
        281,
        483,
        720,
        5824,
        1939,
        13,
        407,
        286,
        478,
        445,
        257,
        19331,
        5098,
        1566,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3356465385073707,
      "compression_ratio": 1.4401913875598087,
      "no_speech_prob": 0.0019197621149942279
    },
    {
      "id": 209,
      "seek": 136472,
      "start": 1382.16,
      "end": 1388.8,
      "text": " well, and I'll also leave you the video. Thank you, Erica, for moving back my reminder,",
      "tokens": [
        51236,
        731,
        11,
        293,
        286,
        603,
        611,
        1856,
        291,
        264,
        960,
        13,
        1044,
        291,
        11,
        37429,
        11,
        337,
        2684,
        646,
        452,
        13548,
        11,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3356465385073707,
      "compression_ratio": 1.4401913875598087,
      "no_speech_prob": 0.0019197621149942279
    },
    {
      "id": 210,
      "seek": 138880,
      "start": 1388.8,
      "end": 1394.56,
      "text": " like by one day because she created right, we want to see like the product designer and myself",
      "tokens": [
        50364,
        411,
        538,
        472,
        786,
        570,
        750,
        2942,
        558,
        11,
        321,
        528,
        281,
        536,
        411,
        264,
        1674,
        11795,
        293,
        2059,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2992865244547526,
      "compression_ratio": 1.5772727272727274,
      "no_speech_prob": 0.009006139822304249
    },
    {
      "id": 211,
      "seek": 138880,
      "start": 1395.28,
      "end": 1400.32,
      "text": " to go over the dock and then provide her with feedback and everything. I haven't done that yet.",
      "tokens": [
        50688,
        281,
        352,
        670,
        264,
        20929,
        293,
        550,
        2893,
        720,
        365,
        5824,
        293,
        1203,
        13,
        286,
        2378,
        380,
        1096,
        300,
        1939,
        13,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2992865244547526,
      "compression_ratio": 1.5772727272727274,
      "no_speech_prob": 0.009006139822304249
    },
    {
      "id": 212,
      "seek": 138880,
      "start": 1400.32,
      "end": 1406.8799999999999,
      "text": " So it's in my list and it's awesome that she shares those insights without having a chance to see",
      "tokens": [
        50940,
        407,
        309,
        311,
        294,
        452,
        1329,
        293,
        309,
        311,
        3476,
        300,
        750,
        12182,
        729,
        14310,
        1553,
        1419,
        257,
        2931,
        281,
        536,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2992865244547526,
      "compression_ratio": 1.5772727272727274,
      "no_speech_prob": 0.009006139822304249
    },
    {
      "id": 213,
      "seek": 138880,
      "start": 1407.9199999999998,
      "end": 1410.8799999999999,
      "text": " another little more from her experience as well from QPON.",
      "tokens": [
        51320,
        1071,
        707,
        544,
        490,
        720,
        1752,
        382,
        731,
        490,
        1249,
        47,
        1928,
        13,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2992865244547526,
      "compression_ratio": 1.5772727272727274,
      "no_speech_prob": 0.009006139822304249
    },
    {
      "id": 214,
      "seek": 141088,
      "start": 1411.7600000000002,
      "end": 1421.8400000000001,
      "text": " And then it looks like she's working on the analysis and report for the QPON product direction survey.",
      "tokens": [
        50408,
        400,
        550,
        309,
        1542,
        411,
        750,
        311,
        1364,
        322,
        264,
        5215,
        293,
        2275,
        337,
        264,
        1249,
        47,
        1928,
        1674,
        3513,
        8984,
        13,
        50912
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1769745177116947,
      "compression_ratio": 1.462686567164179,
      "no_speech_prob": 0.002813148545101285
    },
    {
      "id": 215,
      "seek": 141088,
      "start": 1422.64,
      "end": 1431.3600000000001,
      "text": " She shared that with the research team late yesterday and I provided some feedback just kind of",
      "tokens": [
        50952,
        1240,
        5507,
        300,
        365,
        264,
        2132,
        1469,
        3469,
        5186,
        293,
        286,
        5649,
        512,
        5824,
        445,
        733,
        295,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1769745177116947,
      "compression_ratio": 1.462686567164179,
      "no_speech_prob": 0.002813148545101285
    },
    {
      "id": 216,
      "seek": 141088,
      "start": 1431.3600000000001,
      "end": 1440.16,
      "text": " in an early review state. But that's at a point where I think it's pretty close to being shared",
      "tokens": [
        51388,
        294,
        364,
        2440,
        3131,
        1785,
        13,
        583,
        300,
        311,
        412,
        257,
        935,
        689,
        286,
        519,
        309,
        311,
        1238,
        1998,
        281,
        885,
        5507,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1769745177116947,
      "compression_ratio": 1.462686567164179,
      "no_speech_prob": 0.002813148545101285
    },
    {
      "id": 217,
      "seek": 144016,
      "start": 1440.3200000000002,
      "end": 1441.0400000000002,
      "text": " out more broadly.",
      "tokens": [
        50372,
        484,
        544,
        19511,
        13,
        50408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20242544809977214,
      "compression_ratio": 1.4226190476190477,
      "no_speech_prob": 0.0006540570757351816
    },
    {
      "id": 218,
      "seek": 144016,
      "start": 1446.96,
      "end": 1452.96,
      "text": " And then she's also waiting for Tim to review the shared resource library and CI templates",
      "tokens": [
        50704,
        400,
        550,
        750,
        311,
        611,
        3806,
        337,
        7172,
        281,
        3131,
        264,
        5507,
        7684,
        6405,
        293,
        37777,
        21165,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20242544809977214,
      "compression_ratio": 1.4226190476190477,
      "no_speech_prob": 0.0006540570757351816
    },
    {
      "id": 219,
      "seek": 144016,
      "start": 1453.68,
      "end": 1456.4,
      "text": " report and then creating actual insights as well.",
      "tokens": [
        51040,
        2275,
        293,
        550,
        4084,
        3539,
        14310,
        382,
        731,
        13,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20242544809977214,
      "compression_ratio": 1.4226190476190477,
      "no_speech_prob": 0.0006540570757351816
    },
    {
      "id": 220,
      "seek": 144016,
      "start": 1463.1200000000001,
      "end": 1468.5600000000002,
      "text": " Erica, it helped me if you're watching this. Thank you. She had helped me with a",
      "tokens": [
        51512,
        37429,
        11,
        309,
        4254,
        385,
        498,
        291,
        434,
        1976,
        341,
        13,
        1044,
        291,
        13,
        1240,
        632,
        4254,
        385,
        365,
        257,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20242544809977214,
      "compression_ratio": 1.4226190476190477,
      "no_speech_prob": 0.0006540570757351816
    },
    {
      "id": 221,
      "seek": 146856,
      "start": 1469.04,
      "end": 1479.2,
      "text": " promotional game for a job to be done survey that we're doing for Art of Acts. And it was really,",
      "tokens": [
        50388,
        41790,
        1216,
        337,
        257,
        1691,
        281,
        312,
        1096,
        8984,
        300,
        321,
        434,
        884,
        337,
        5735,
        295,
        32363,
        13,
        400,
        309,
        390,
        534,
        11,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22859942118326823,
      "compression_ratio": 1.5183246073298429,
      "no_speech_prob": 0.002685399493202567
    },
    {
      "id": 222,
      "seek": 146856,
      "start": 1479.2,
      "end": 1486.3999999999999,
      "text": " she had this like whole document of how to easily pull in the block basically to call tricks.",
      "tokens": [
        50896,
        750,
        632,
        341,
        411,
        1379,
        4166,
        295,
        577,
        281,
        3612,
        2235,
        294,
        264,
        3461,
        1936,
        281,
        818,
        11733,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22859942118326823,
      "compression_ratio": 1.5183246073298429,
      "no_speech_prob": 0.002685399493202567
    },
    {
      "id": 223,
      "seek": 146856,
      "start": 1487.84,
      "end": 1495.12,
      "text": " And so I wanted to ask and I can just paint, I can ask her an issue or something. If that would be",
      "tokens": [
        51328,
        400,
        370,
        286,
        1415,
        281,
        1029,
        293,
        286,
        393,
        445,
        4225,
        11,
        286,
        393,
        1029,
        720,
        364,
        2734,
        420,
        746,
        13,
        759,
        300,
        576,
        312,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22859942118326823,
      "compression_ratio": 1.5183246073298429,
      "no_speech_prob": 0.002685399493202567
    },
    {
      "id": 224,
      "seek": 149512,
      "start": 1495.12,
      "end": 1499.6,
      "text": " something that we could add to the handbook because I think a lot of people would use that",
      "tokens": [
        50364,
        746,
        300,
        321,
        727,
        909,
        281,
        264,
        1011,
        2939,
        570,
        286,
        519,
        257,
        688,
        295,
        561,
        576,
        764,
        300,
        50588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11792977650960286,
      "compression_ratio": 1.6169154228855722,
      "no_speech_prob": 0.0005568394553847611
    },
    {
      "id": 225,
      "seek": 149512,
      "start": 1500.6399999999999,
      "end": 1504.1599999999999,
      "text": " for surveys if it's like a normal thing to follow.",
      "tokens": [
        50640,
        337,
        22711,
        498,
        309,
        311,
        411,
        257,
        2710,
        551,
        281,
        1524,
        13,
        50816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11792977650960286,
      "compression_ratio": 1.6169154228855722,
      "no_speech_prob": 0.0005568394553847611
    },
    {
      "id": 226,
      "seek": 149512,
      "start": 1511.36,
      "end": 1517.6,
      "text": " I think I know a little bit about what you're describing. Could you like explain a little bit more",
      "tokens": [
        51176,
        286,
        519,
        286,
        458,
        257,
        707,
        857,
        466,
        437,
        291,
        434,
        16141,
        13,
        7497,
        291,
        411,
        2903,
        257,
        707,
        857,
        544,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11792977650960286,
      "compression_ratio": 1.6169154228855722,
      "no_speech_prob": 0.0005568394553847611
    },
    {
      "id": 227,
      "seek": 149512,
      "start": 1517.6,
      "end": 1521.76,
      "text": " by what you mean that like she was able to pull in the whole block into call tricks?",
      "tokens": [
        51488,
        538,
        437,
        291,
        914,
        300,
        411,
        750,
        390,
        1075,
        281,
        2235,
        294,
        264,
        1379,
        3461,
        666,
        818,
        11733,
        30,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11792977650960286,
      "compression_ratio": 1.6169154228855722,
      "no_speech_prob": 0.0005568394553847611
    },
    {
      "id": 228,
      "seek": 152176,
      "start": 1522.32,
      "end": 1529.12,
      "text": " Yeah, in Qualtrics you can use, I think it's called like shared questions maybe that your",
      "tokens": [
        50392,
        865,
        11,
        294,
        13616,
        6903,
        1167,
        291,
        393,
        764,
        11,
        286,
        519,
        309,
        311,
        1219,
        411,
        5507,
        1651,
        1310,
        300,
        428,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19296083571035652,
      "compression_ratio": 1.4977168949771689,
      "no_speech_prob": 6.449535430874676e-05
    },
    {
      "id": 229,
      "seek": 152176,
      "start": 1529.12,
      "end": 1536.72,
      "text": " organization can use. And there was one specifically that was created by, it must be from the research team.",
      "tokens": [
        50732,
        4475,
        393,
        764,
        13,
        400,
        456,
        390,
        472,
        4682,
        300,
        390,
        2942,
        538,
        11,
        309,
        1633,
        312,
        490,
        264,
        2132,
        1469,
        13,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19296083571035652,
      "compression_ratio": 1.4977168949771689,
      "no_speech_prob": 6.449535430874676e-05
    },
    {
      "id": 230,
      "seek": 152176,
      "start": 1538.32,
      "end": 1546.64,
      "text": " That was for this promotional game so that participants would be given and like get put into a game",
      "tokens": [
        51192,
        663,
        390,
        337,
        341,
        41790,
        1216,
        370,
        300,
        10503,
        576,
        312,
        2212,
        293,
        411,
        483,
        829,
        666,
        257,
        1216,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19296083571035652,
      "compression_ratio": 1.4977168949771689,
      "no_speech_prob": 6.449535430874676e-05
    },
    {
      "id": 231,
      "seek": 152176,
      "start": 1546.64,
      "end": 1549.52,
      "text": " to win $60 Amazon gift cards.",
      "tokens": [
        51608,
        281,
        1942,
        1848,
        4550,
        6795,
        5306,
        5632,
        13,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19296083571035652,
      "compression_ratio": 1.4977168949771689,
      "no_speech_prob": 6.449535430874676e-05
    },
    {
      "id": 232,
      "seek": 155176,
      "start": 1552.0,
      "end": 1553.36,
      "text": " Okay.",
      "tokens": [
        50376,
        1033,
        13,
        50444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48694837415540543,
      "compression_ratio": 1.0919540229885059,
      "no_speech_prob": 0.002893964760005474
    },
    {
      "id": 233,
      "seek": 155176,
      "start": 1556.32,
      "end": 1558.4,
      "text": " I can, let me actually just get the dog.",
      "tokens": [
        50592,
        286,
        393,
        11,
        718,
        385,
        767,
        445,
        483,
        264,
        3000,
        13,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48694837415540543,
      "compression_ratio": 1.0919540229885059,
      "no_speech_prob": 0.002893964760005474
    },
    {
      "id": 234,
      "seek": 155176,
      "start": 1558.4,
      "end": 1560.0,
      "text": " We can give a she shared it with me.",
      "tokens": [
        50696,
        492,
        393,
        976,
        257,
        750,
        5507,
        309,
        365,
        385,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48694837415540543,
      "compression_ratio": 1.0919540229885059,
      "no_speech_prob": 0.002893964760005474
    },
    {
      "id": 235,
      "seek": 155176,
      "start": 1562.32,
      "end": 1570.32,
      "text": " Here it is.",
      "tokens": [
        50892,
        1692,
        309,
        307,
        13,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.48694837415540543,
      "compression_ratio": 1.0919540229885059,
      "no_speech_prob": 0.002893964760005474
    },
    {
      "id": 236,
      "seek": 157032,
      "start": 1570.8,
      "end": 1585.9199999999998,
      "text": " Oh, yes, I, I've seen this exact thing. And actually made the same exact comment to her. I was like,",
      "tokens": [
        50388,
        876,
        11,
        2086,
        11,
        286,
        11,
        286,
        600,
        1612,
        341,
        1900,
        551,
        13,
        400,
        767,
        1027,
        264,
        912,
        1900,
        2871,
        281,
        720,
        13,
        286,
        390,
        411,
        11,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1726137528936547,
      "compression_ratio": 1.5837837837837838,
      "no_speech_prob": 0.0028767534531652927
    },
    {
      "id": 237,
      "seek": 157032,
      "start": 1585.9199999999998,
      "end": 1591.4399999999998,
      "text": " wow, this is really good. You should put this in the handbook. And I forget what she told me at",
      "tokens": [
        51144,
        6076,
        11,
        341,
        307,
        534,
        665,
        13,
        509,
        820,
        829,
        341,
        294,
        264,
        1011,
        2939,
        13,
        400,
        286,
        2870,
        437,
        750,
        1907,
        385,
        412,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1726137528936547,
      "compression_ratio": 1.5837837837837838,
      "no_speech_prob": 0.0028767534531652927
    },
    {
      "id": 238,
      "seek": 157032,
      "start": 1591.4399999999998,
      "end": 1596.56,
      "text": " the time. I think she was maybe like, I want to pilot this or like test it out a little bit more",
      "tokens": [
        51420,
        264,
        565,
        13,
        286,
        519,
        750,
        390,
        1310,
        411,
        11,
        286,
        528,
        281,
        9691,
        341,
        420,
        411,
        1500,
        309,
        484,
        257,
        707,
        857,
        544,
        51676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1726137528936547,
      "compression_ratio": 1.5837837837837838,
      "no_speech_prob": 0.0028767534531652927
    },
    {
      "id": 239,
      "seek": 159656,
      "start": 1596.56,
      "end": 1603.28,
      "text": " before I put it in there. But yeah, I was, I had the same thought as you did.",
      "tokens": [
        50364,
        949,
        286,
        829,
        309,
        294,
        456,
        13,
        583,
        1338,
        11,
        286,
        390,
        11,
        286,
        632,
        264,
        912,
        1194,
        382,
        291,
        630,
        13,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33107345244463754,
      "compression_ratio": 1.4966442953020134,
      "no_speech_prob": 0.003193447832018137
    },
    {
      "id": 240,
      "seek": 159656,
      "start": 1604.6399999999999,
      "end": 1611.2,
      "text": " I was because I made it so it was so easy to just put it in there. So all, maybe I'll just catch",
      "tokens": [
        50768,
        286,
        390,
        570,
        286,
        1027,
        309,
        370,
        309,
        390,
        370,
        1858,
        281,
        445,
        829,
        309,
        294,
        456,
        13,
        407,
        439,
        11,
        1310,
        286,
        603,
        445,
        3745,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33107345244463754,
      "compression_ratio": 1.4966442953020134,
      "no_speech_prob": 0.003193447832018137
    },
    {
      "id": 241,
      "seek": 159656,
      "start": 1611.2,
      "end": 1615.52,
      "text": " off with her and see who would be useful. Sorry.",
      "tokens": [
        51096,
        766,
        365,
        720,
        293,
        536,
        567,
        576,
        312,
        4420,
        13,
        4919,
        13,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.33107345244463754,
      "compression_ratio": 1.4966442953020134,
      "no_speech_prob": 0.003193447832018137
    },
    {
      "id": 242,
      "seek": 161552,
      "start": 1615.92,
      "end": 1617.92,
      "text": " Okay.",
      "tokens": [
        50384,
        1033,
        13,
        50484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5473664204279581,
      "compression_ratio": 1.3109243697478992,
      "no_speech_prob": 0.17905299365520477
    },
    {
      "id": 243,
      "seek": 161552,
      "start": 1624.0,
      "end": 1627.6,
      "text": " Cool. I think that's all I've got or I guess all the air goes cut.",
      "tokens": [
        50788,
        8561,
        13,
        286,
        519,
        300,
        311,
        439,
        286,
        600,
        658,
        420,
        286,
        2041,
        439,
        264,
        1988,
        1709,
        1723,
        13,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5473664204279581,
      "compression_ratio": 1.3109243697478992,
      "no_speech_prob": 0.17905299365520477
    },
    {
      "id": 244,
      "seek": 161552,
      "start": 1631.44,
      "end": 1636.56,
      "text": " So anything else I think before we wrap up I think it's gonna be better here today.",
      "tokens": [
        51160,
        407,
        1340,
        1646,
        286,
        519,
        949,
        321,
        7019,
        493,
        286,
        519,
        309,
        311,
        799,
        312,
        1101,
        510,
        965,
        13,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5473664204279581,
      "compression_ratio": 1.3109243697478992,
      "no_speech_prob": 0.17905299365520477
    },
    {
      "id": 245,
      "seek": 163656,
      "start": 1637.36,
      "end": 1638.1599999999999,
      "text": " Okay.",
      "tokens": [
        50404,
        1033,
        13,
        50444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6124682859940962,
      "compression_ratio": 1.1650485436893203,
      "no_speech_prob": 0.03989090770483017
    },
    {
      "id": 246,
      "seek": 163656,
      "start": 1639.36,
      "end": 1644.8,
      "text": " No, no, that's it. Thank you for joining me for a brainstorming and chatting.",
      "tokens": [
        50504,
        883,
        11,
        572,
        11,
        300,
        311,
        309,
        13,
        1044,
        291,
        337,
        5549,
        385,
        337,
        257,
        35245,
        278,
        293,
        24654,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6124682859940962,
      "compression_ratio": 1.1650485436893203,
      "no_speech_prob": 0.03989090770483017
    },
    {
      "id": 247,
      "seek": 163656,
      "start": 1644.8,
      "end": 1646.6399999999999,
      "text": " See you next time.",
      "tokens": [
        50776,
        3008,
        291,
        958,
        565,
        13,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6124682859940962,
      "compression_ratio": 1.1650485436893203,
      "no_speech_prob": 0.03989090770483017
    },
    {
      "id": 248,
      "seek": 163656,
      "start": 1648.24,
      "end": 1649.44,
      "text": " Thanks. Bye.",
      "tokens": [
        50948,
        2561,
        13,
        4621,
        13,
        51008
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6124682859940962,
      "compression_ratio": 1.1650485436893203,
      "no_speech_prob": 0.03989090770483017
    },
    {
      "id": 249,
      "seek": 163656,
      "start": 1650.3999999999999,
      "end": 1652.3999999999999,
      "text": " Bye.",
      "tokens": [
        51056,
        4621,
        13,
        51156
      ],
      "temperature": 0.0,
      "avg_logprob": -0.6124682859940962,
      "compression_ratio": 1.1650485436893203,
      "no_speech_prob": 0.03989090770483017
    }
  ]
}