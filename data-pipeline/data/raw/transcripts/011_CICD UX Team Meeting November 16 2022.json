{
  "title": "CI/CD UX Team Meeting: November 16, 2022",
  "video_id": "z7UyqLajFuE",
  "url": "https://www.youtube.com/watch?v=z7UyqLajFuE",
  "transcript": " I can introduce the date also. This is the CSED UX team meeting on November 16th of 2022. It's almost 2023, which is crazy. Hi, and I'll just I'll leave it to you. All right. Thank you, Gina. I cannot see the agenda. My iPad is acting up. But anyways, I think my first item. It's about severity labels. I'm not mistaken. So just a heads up for product designers. Please don't forget to add severity labels to your UX issues, especially the suspecting ones. The boat will annoy you if you don't. So it's a good way of reminding us to label those issues and accordingly so that we can have help with prioritization. But also, I've seen some issues. You might see Valerie also doing some housekeeping on those on those issues and leaving comments, but there are some issues. There are not label UX, but they do have your extra requirements. So I review one for verify today. And I, I just didn't know about the fact that it was a back in issue, but it changed statings and it changed UI copy. But it didn't have UX or a severity added. So just a reminder. For everyone to please. Make sure that the issues that you and your team are working on. Have the correct labels applied. That's one. And then my other updates about hiring. Have a new product designer joining the pipeline insights team. in the coming months. We don't have a start date yet, but she will take over from five planning sites so that Gina can transition full time to runner. So it's gonna happen. Then we'll say no more about that the start date and yeah, just to onboarding all that everybody know. So that's that for me. Gina, you have a year off next. Yes, there's an issue that I linked here that Amelia had brought up about discussing how to better collaborate with designers but I think it also applies with research and even technical writing, cross stage or cross group. I just mentioned it to this group. I think a few of us have already jumped into it, but I think this group does a really great job of collaborating. So I was encouraging you to share your thoughts if you have time. And I think we were gonna try to start from the bottom of the agenda today, Erica, if you wanted to start. Well, that's a great tie in because working backward from my list, one of the things was that we have, I wanted to like celebrate the. list. One of the things was that we have, I wanted to like celebrate the my my updates today are framed around welcome back Hannah. I wanted to know that Gina and Will actually got sick and like tested such that I couldn't go to the conference. And so Gina like stepped into this leadership position, will really delivered. And we have like four reports, I know amazing, I coupon, four reports that we hammered out because of the data they collected. And then one more on the way which which ties into the issue that Gina just showed about cross stage collaboration. So we we set up like a game we gamified the interviews instead of running them just like in a conversational way. And we were able to get great data. And I think we got actionable data. So we're still working on that report and it's setting up a secret scan which we kind of all want to be working on anyway. So that was really good. Yay! And then I guess my last item too is just asking if if you all would like to open up the H2 Verifying Package Common Screener for solution validation studies. So I just wanted to check if it's worth like making that change with Caitlin. And I linked a PDF of the of what the questions are and is long. But we have like 500 participants in there and some of them have been used. But I think I'll give you time. You can just mention me in the notes to give you time to look at it and just let me know like how many studies we might recruit for. And then my other findings are kind of just an overview of the Q4 prioritization. So the big one is that we have a pre-work issue set up for Q3 to do some pre-work related to a benchmark. Dare I say it for a package? I'm like a nervous. But anyway. So yeah. So we'll hopefully do a benchmark for a package in Q1. Fiscal Year 23 starting in 159 waiting for design and PM resources to kind of come online. But before then I'm just doing work to like kind of crosswalk the stages that have done this before to kind of like make sure what we do is on par. And then we also kind of related to package resources. We put on hold this like cycle of an image study until the new PM joins. So that would be the study that we did kind of with secrets and CI templates where it's like how does it start? What happens next? What happens next? We would use that kind of framework. And so that's on hold for the new PM. We think it's exciting for the new PM to work on. But I think the benchmarks would get priority and then it would go to that study. One more thing to mention about that is Gina has a really cool issue, a research issue around looking at the lifecycle of logs. And so part of me wants to try to fold that into this study. That's no one holds. But I think we're getting feedback that we need to like scope that Gina's study down a little bit. So but does note that I have like a plan because I think it's really smart. Like in foundational research terms. Sorry, I didn't wait for Hannah to say that thanks for the heads up on the benchmark. Yes, sorry, my Google docs keeps, keeps crashing on me. I'm so I can not finish writing my question. So yeah, about package, I have a question for you, Erica. I cannot open the issue now. On my iPad, but the pre-work issue is for the benchmark aid, right? For package. Yes, and correctly. Yes. And it's all things that I want to do. Like I'm comparing the screener questions because I think that and I worked on benchmarks in a lot of previous roles. And one thing we want to see is how much we can compare across stages, which kind of means looking at how comparable the samples are. And did we all use the same screener? And like what's the alignment? In part, I'm doing that so that I'm not making us be too rigorous with like finding a counterbalance sample. But like whatever we've done is an amazing iteration. But we just want us to track it explicitly so we kind of know. So it's mainly me doing the pre-work of like what were the screeners? What's our screener looks like? I actually have our screener drafted. And so whenever Tim had time, he can kind of come in. I think the idea would be we would treat it like a common screener and then be in a position to run the next benchmark. Like we would have 500 participants, so we could select from. If we kind of start rolling it out as soon as we're ready. And so we're just waiting on Tim to have time. So it's like what were the screeners? How are the samples comparing? And that will help us know. Like I think what I'm seeing so far is like we're mainly small medium business samples, which is fine to know, right? But it means we don't have to then stretch to do an enterprise recruit. Kind of we want to be on par. And then I'll be looking at all of the mechanisms that different researchers use to like get feedback. Like Will has this lovely URL approach that he used for jobs to be done like deciding on the tasks. And then working with Tim to figure out like what the team has capacity for. I feel like we'll go more bare bones, which is also okay. But so in a couple weeks when we get back from the Thanksgiving holiday, I'm going to meet with Tim to like give the updates and then see what his thoughts are related to the kind of the next steps. And my plan was just to use those little half hour meetings that I have set up with him. So they don't take too much time. And then the last thing that I'll look at across those stage areas is just like the level at which the tasks were framed. Because that can impact performance too. So I think we'll also help like elevate the research program. With this work. Okay. I'm taking some notes here. Thank you. I think you're for the overview that that clarifies my next couple of questions. And then I just want to say please keep me in the loop. Because if we know a bit ahead of what the UX I'll say like hands on design work for package is going to look like. I need to know to prepare the UX coverage because we won't have UX location for package until next year Q3 Q4. Okay. Yeah. We've made a decision to because team and Victor also Michelle they talk about the deliverable plans for package now. That's for everybody to kind of be aware that they're hiring developers. They don't have for example front end allocation to build UI right now. So we are not going to be hiring a designer for package right now. We move the headcount to a different team and then we won't have a designer for package until next year right once development picks up. But if there is a the research is going on and we have well the hiring for development also picks up and we know that we have a need for package UX deliverables then yeah I'll need to know ahead of time so that we don't work on a coverage or borrow plan or a hiring plan for the for the design backfill for Katie's backfill. But just so you're aware that yeah we're not playing any own deliverables for package because we don't have anyone allocated there. And maybe we work backwards from that too. I don't know. I like really wanted to contribute to the okay R so I'm just kidding or we're trying. But I think I think it would be okay to get those findings and then have the designer as they on board like pick up with them as long as we like set the expectations so everyone knows that that's our plan. This seems okay but we'll let Tim guide us. But thank you for the update. Okay. Keep me keep me the one. Okay well. Sure. Just got a couple updates. I'm using the same prioritization issue in Q4 as I used in Q3. I'm kind of trialing just a longer term prioritization issue that goes two quarters as opposed to one just to see how that process goes. I did add a comment in the issue with just some updates on like what projects we accomplished in Q3 so if you want to check that out you're welcome to do so. And we're still collecting projects for Q4 but I've listed within that comment what projects we're expecting to take on this quarter. Aside from that also met up with Emily on Sunday which was awesome. We got to have dinner. It was nice to just meet another person. I've met like half the people on this call which I never thought when contribute got cancelled for the year but yes just been great to slowly meet more and more team members as a bit a part of the company. And my final update is that I've been reviewing scenarios kind of off and on for Emily's CMS study on environment management and she's been really putting a lot of effort into that over the past couple weeks. Any questions for I turn it over to Emily? Okay Emily you could take it away. Well I'll go a little out of order because I'll get to my critique one at the end but I was mostly curious now that I'm kind of getting to the stage of conducting the CMS interviews with internal users just kind of some of the things you did to recruit people. I know we're using some people from the delivery team who've already offered to volunteer but just any other options to get people into the study I'm looking for so it's like Will and Gina both had to comments around that? Sure so I haven't done this a ton. I did this probably the most like after I started to get lab just because I wasn't sure how to get internal people to begin with and I've like posted on Slack channels just I try to keep like a very concise message of you know who I'm looking for, what dates you know just any like kind of a summary of details about the study and just try to post them on different channels. Sometimes I've like leaned on the PM to try to help direct me to like the right channels to go to but since you're working a lot with the delivery team they might you know help you know where to post or you could just talk to the participants that you have signed up and say like hey you know now that you've gone through this study you know is there someone else on your team that might be good for this? You mine was just plus wanting to what will said I have posted in what's happening at GitLab before that has gotten traction and then I also found that linking to the research issue helps kind of allow them allowing them to get contacts around with the researches about. Awesome sounds good. There's a hyanoilifta comment as well as a puzzling. Yeah I'm trying my my girl dogs are just not loading. I think I wrote down about yeah looking of course in the handbook right we have a section with the internal customers for each stage group and then on which page is that? On the handbook product slash categories and if our release stage you know it's a delivery distribution team security so just echoing what the will and Gina say most of those groups they have their own Slack channel so can drop that same message in there then we need to reach out directly to people. I think for the release the delivery team they have super active so it's easy to find those connections through them and also ask like who is someone that is working or has used xyz feature functionality in the if you know contact with them but in Gina and will they already gave the best tips so just echoing what they say. Cool the second update I wanted to give is we adjusted the deployments navigation so now when you click on the high level deployments you land on the environments page not feature flags because there's a lot of data showing that people would land on feature flags and navigate away as well there was comments about this in our like benchmarking study so that is now in production which is really great and then will I know as you had a comment on that as well. Yes you talked about we did see this a lot in the benchmarking study and I would just constantly see participants like click on the link and know that they weren't going to go to the right place and then they would just like get frustrated and then have to you know use that extra click to go to the right page so I know that's going to be a big time change. Awesome and to do a time to do a little kind of design review I think we still have like 20 minutes so I try I will try not to take up all the time but just wanted to make sure I wasn't taking up too much time so the background of this this has been a long standing issue that's opened that basically we want to design a page that for MVC starts out to host production environments across a group we've seen a lot of research showing that users are having a lot of problems tracking environments at the group level and they're having to go to each project bubble page kind of track statuses on there so kind of crafting up a page here that people would be able to see like a high level summary and then be able to click in and take action if needed. So I hi I think you for telling me to kind of just step back and start from scratch because that really got me started quite well but I'll go ahead and share my screen if I can figure out what screen I have to share this one. Well so how I started this is I really took a step back and went through the research and this page is interesting because it's not a typical flow users wouldn't be going here to complete like a typical flow but I did want to get onto paper kind of like some of the tasks that the research showed that they were looking for. I don't know if I should go into this if this is going to be public but you can kind of take a look at kind of some of this and then just taking a step back and really figuring out so this is like a high level view what do users really want to understand and starting from like the information architecture point of view here not even designing something just trying to figure out from a high level what we should be showing on this page. So with some like a team feedback I've done some like St. Cals with the engineers on this I kind of landed on something like this where we would show kind of production environments a top-level summary of like your environment health across the group so like how many environments are healthy are you having problems with any of them. So a little TBD on what to show in this area but really having that high level summary and then being able to dig down if you need and then when you go into the environment showing an environment level summary of that production environment with like environment health project the deployment the most recent deployment health and then some actions you can take as well as showing that most recent deployment so you have like context of what is going into that environment currently. I've cut it down quite a bit from some of the original proposals because this page we really want to show them what is going on and not bog them down by a bunch of different information that they could kind of dig into and find. So I've kind of moved it into this again as you can see this is like a really big TBD I want to create a nice summary at the top but kind of showing this into like group name environment at the production tier kind of like is the most recent deployment successful is there anything action you have to take and then kind of showing details about the most recent deployment underneath it with options to like view and project and kind of debug problems going that way but by condensing this information down reducing the amount of like pagination you need so being able to show things all on one page and being able to show just the information you need to kind of take the action that you need to take so open to suggestions on this but that's kind of like how I've started this it's still fairly rough so there's like I do want to run this by some users as well but but I would get first feedback look even though this is kind of like a rough low fidelity right now. I had one comment just saying that I thought it looks great I didn't even see this the one that you're showing right now I only saw the IA stuff so I think it I think it looks like with the all the information that you have to deal with which there is a lot like you did a really good job of summarizing that and making it clear. I also the thing that came to mind for the summary view up top I think that this single set component is always good for that type of stuff so if you you could consider using something like that for up there I've seen other pages do that as well and what runner does that and then there's a like a dev ops report type of thing that kind of does it. And that's called the like single stat component. Yeah I'll link it to you from pajamas. Awesome it's pretty flexible too which is great. Then my only other comment was for like this would be adding a new navigation item for for groups and we had to do a similar thing for runner so I would consider talking to the foundation steam just to make sure like I think you have to get approval from them now I can link the handbook page but I also know because they have all their navigation efforts going on it may change so something to be aware of. Yeah I know when we were trying to do billing on the growth team we were running into a similar thing there was like a process in adding something to the nav so I will definitely kind of communicate to this idea with them and see how to go from there. Okay yeah. Erica I think you had the next comment. Yes thanks for sharing this I love that you're sharing that's in this in this meeting. So one thing that we're we've learned about the workflow with CI CD variables and the subset of those are secrets is that one of the reasons people want to use the unprotected values is because they tend to use the wrong ones per environment because it's confusing. So yeah like a subset of that finding is that they use different secrets values for the different environments. So I think you could add clarity here if there's like a light touch way to even like allow people to dig into the different variables that are being used in different environments. I do I think that would help them and it feels like if we're going to do an overview like that that that would be something to highlight or think about. I can definitely think into that I'm still in the process of trying to figure out what is the best information to show here what should be still cut out because some of this deployment information is just kind of copied over from the environment index page. So definitely want to do a bit more exploration on like is this the right amount of information and if there's additional information like you said the kind of secrets how do you show that here. So thanks for bringing that to my attention. Well thank you all for the feedback by the way I see Will is next. Yeah I think for the summary view some of the things that could be helpful is just being able to identify not just like how many environments are in a successful status but also if there's ones that are like pending or if there are ones that are like failing or having some sort of like difficulties just so that people can like easily like click into those and be taken to those somehow and then also I like how in your design you're not like using that care at Sasha Cordian style menu that that we currently have just because it's nice to be able to just see some of the specific data that users were having to like really stumble around to try to find. Awesome yeah thank you that was kind of I know a lot of our research has shown those collapsible sections when you're trying to find a high level view of everything was just not working out right so I was trying my best not to even collapse any information and just if there's information you that needs to be hidden maybe it's not the right place to put it on this page so appreciate and you're welcome. Then hi and I think you have the last comments. Yeah so just post one on what we'll say about showing information without using that awful pattern of what you're expanding collapsing it just hides all the info that it's essential in this page pretty much in both in this case the group but also the the project level environments view and also plus one on the summary block I think this sort of give users that add what understanding of how their environments are doing across the board and that's important of course not only for the developers but you know the managers the the director of buyer percent anyways anyone really that is interested in how the application is doing at the higher level so I think that's that's going to be a great addition addition and I have a couple of follow-up questions Emily and I'm sure if you have the time but you know I think those those are just the things I was thinking of while looking at the prototypes what type of environments will be displayed on this overview just like the protected environments production only and also I was wondering how would users set up this overview. Has the team considered if this would be something that would be just pre-populated you know coming from all the projects that have the have the environments that meet a specific criteria or we users be able to let's say manage and customize that view based on what's important for them to see you know for each project. Yeah so this is a good question for MVC we've really landed on we want to show just production tier environments and then figuring out later we'll need to scale this up to show the different tiers but kind of pre-populate this based on like tier of environments this is actually where the empty state comes in I don't think I'm the one that designed the empty state I kind of grabbed it from one of the others but if you don't aren't using environment tiers using this empty state to kind of encourage users to kind of set that up so that they can pre-populate this page but also use this feature which we don't have any area now where we're really encouraging them to do so so having the empty state is both a bonus of setting up this but also encouraging people to use environment tiers so hopefully that answers your question for MVC we are just going to stick with production tier environments and to set it up would be enabling tiers in your environments to show them pre-populated on this page. Yeah thanks that answers my question I think following up to that and thinking about too is that when you have the chance look at how the MVC plus would look like because for example if I'm not mistaken you can have multiple environments under the same tier right so if you set it up in the CI file you can have I don't know different production environments, label production but put a different name right so how would that look like in the UI how would users customize so I think it would be a good step for you there to see how this page would grow uh because we're not the challenges that we had with the current environments pages that while designing and also coding it we were not thinking of how that page would scale so I think you have the the ability here to predict some of the edgegates but also to avoid you know I'm happy and happy bets in the UI in the overall UX. Yeah for sure yeah that's something and where I'm early enough into the designs here now that I have to kind of build out what does like unhealthy environments look like what happens when you have like a lot on this page so I think we still have quite a bit of time to kind of build out all these educations and then once we start showing more than just the production tier how do you set that up what does that view look like and everything like that so I think there's lots of work to be done on this page but it'll be good work to finally get out to users. Yeah awesome and then my next point is about that it seems like if you move forward with this approach right up for left environments we could potentially deprecate the environment's dashboard view. What are the team discussions about it if there's any discussion going on around deprecating or replacing the page if they were off this group view? Yeah so there hasn't been any like official conversations going on but I have chatted with like Andrew on the team of the reasons of moving away from it and just the performance issues on that page were so hard to sort out that that's kind of where this idea has come from and kind of like why we might be moving forward with this and some of the performance issues are really hard to kind of solve for but I think we need like some written out kind of conversation with the PMs and everyone on that team to figure out is this a like a replacement can they work together what are the main pros of this pros of the environment dashboard and really sort that plan out as well. Awesome yeah I think that that would be you know a good I'm going to put that justification right for deprecating or moving away from that environment dashboard view. There's no traffic there as far as I know and to your point there's so many restrictions in terms of the performance of that page that you know I would say if you can it also when you have the decisions and conversations with the team putting the proposal to right that how this page will work potentially solve the jobs we don't solve the problems that the environment's dashboard view does not solve right. Thank you and then no sorry go ahead. No I just say thank you that's like something I definitely have to think on so we'll get that written up. Awesome and then my last thing back is just about the UI and then if I let me zoom in here yeah um when I did the validation for the environment's uh uh page right um I learned that uh that information about the commit message it's irrelevant to users or it's usually irrelevant when that commit is merging or branch or anything into master because it often shows that same you know the folk message merge branch and then branch name and that's not readable and that's not a very informative to users um so my feedback here would be like check in the um the insights I don't remember correctly now what what's the most relevant information that that we should be displaying here to users and see how you know and if it could be um if it could replace the merge branch message um because that's what we have today in the environment's page it's just the same message everywhere with the link um and there's already so much I think you can use that space um in uh in a in a more a different way rather than just showing this message yeah I agree I think there's stuff we can especially that if we can save real estate on anything in this page and take out uh things that they don't need at this viewpoint um something I'm working towards right now so that's great to know that's something we can potentially take out of this awesome well thanks everyone for your feedback I want to give Gina enough time for her points as well but I appreciate uh kind of taking the time to let me walk through that so thanks Emily I have one other question for you I noticed that the the way that you were like for each row there was kind of like many columns of metadata in there like the job like all that's up have you heard I got any feedback around how that impacts like scanability I guess across different deployments yeah because it is a lot of information so as like a side note I've kind of added these in here to this I'm still considering it like a low fidelity I've just added in what we have on the environment index page and I'm planning in like the next version of this to kind of go through see what information we can remove from there see what information is like the most important um based on conversation with the engineers to kind of for MVC start with what we have and kind of take away from that if possible just so we can reuse some components so yeah I agree those sections I think need a bit of cleaning up and figuring out what exact information should be placed there um like the merge branch message taking that away but yeah I agree I think there's some simplification we can still do in that area yeah I'd be like if you end up testing this I would be interested in seeing if people say like if they if they want to scan I guess my column like does formatting the information in that way impacts that because I mean we're doing that in runner and there have been like two or two customers who have been like I don't I don't want to see it in this list view I'd rather see it in a table but the majority have been saying it's fine to see it in the way that it is um but the view I that we're using is very similar so I think the insights would carry over to the list well good to know and yeah I'm planning to run this through some solution validation as well when we have a more finalized design because there's such a big lift to do so hopefully we'll get some of the usability comments from that as well and then I have one more point there I'm like jumping in before we switch but it would be that when you do the solution validation I think try to include like more personas than you might not like try to push yourself to include more personas so we make this work for more people because I think it can have a bigger impact yeah because I think right now the dashboard sorry I'll come is not working for some of our personas so opening this up to a bunch of other ones is probably like the best fact well thanks again for all that I will pass it off to Gina now. Hey thanks I have two updates one of them is for pipeline insights um we're dealing with this problem of flaky tests we're going to if I gave a definition of these are not but the general one is that when you run tests they can sometimes fail but the failure isn't real like it wasn't actually detected it was because like the test is actually written incorrectly or maybe a test that that test relies on failed something like that and if it fails more often than it succeeds without actually detecting a failure it's considered flaky so we're trying to understand from users like their pain points right now their workarounds with how they're dealing with flaky tests and then definitely how they define them the key insight for us here is how they define them because we want to be able to when we define them for this MVC we want to make sure it matches their expectations so I included some of the insights that we've heard so far we've only met with three users so far but we have a few other participants coming up as well and then on the runner side we this is like one of our our bigger um what's a small feature but it's it's an important feature that we've added for runners it kind of has to do with the whole runner fleet monitoring slash q stuff I've been talking about for a while so it's it's difficult for users to be able to see if a runner is running a job at the moment and the reason why that's important is because if they were to update the runner for example um it would stop that runner from running any jobs so they don't want to impact any current running jobs or else the code just it doesn't go out so they want to know if if if that runner is actually running one um so we've added a badge to be able to see if it's running or if it's idle is the other word that we're using the tough part about this is that now we have two status badges we have one about if the runner is online and if the runner is like running a job so our next iteration would be combining those into a single status something like active where it's running a job and it's online um and then that will allow for less less load on the user any questions or anything I just want to say I love the idea of combining status badges into one thing that works because I've seen it quite a few times and I think it's in like the environments areas as well where there's like multiple status badges and you're not quite sure how they relate to each other so I think that's a great idea thanks it will definitely be a tough thing to do like because even with runner because everything's through the CLI too people can now get a list of all like online runners but all those statuses would have to change so it's going to be like a long a long process well I think that's it I don't think anybody has anything else so thanks for meeting today see everybody soon next week maybe",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 7.0,
      "text": " I can introduce the date also.",
      "tokens": [
        50364,
        286,
        393,
        5366,
        264,
        4002,
        611,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24018162814053623,
      "compression_ratio": 1.1726618705035972,
      "no_speech_prob": 0.048890817910432816
    },
    {
      "id": 1,
      "seek": 0,
      "start": 7.0,
      "end": 15.0,
      "text": " This is the CSED UX team meeting on November 16th of 2022.",
      "tokens": [
        50714,
        639,
        307,
        264,
        383,
        5879,
        35,
        40176,
        1469,
        3440,
        322,
        7674,
        3165,
        392,
        295,
        20229,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24018162814053623,
      "compression_ratio": 1.1726618705035972,
      "no_speech_prob": 0.048890817910432816
    },
    {
      "id": 2,
      "seek": 0,
      "start": 15.0,
      "end": 18.0,
      "text": " It's almost 2023, which is crazy.",
      "tokens": [
        51114,
        467,
        311,
        1920,
        44377,
        11,
        597,
        307,
        3219,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24018162814053623,
      "compression_ratio": 1.1726618705035972,
      "no_speech_prob": 0.048890817910432816
    },
    {
      "id": 3,
      "seek": 0,
      "start": 18.0,
      "end": 24.0,
      "text": " Hi, and I'll just I'll leave it to you.",
      "tokens": [
        51264,
        2421,
        11,
        293,
        286,
        603,
        445,
        286,
        603,
        1856,
        309,
        281,
        291,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24018162814053623,
      "compression_ratio": 1.1726618705035972,
      "no_speech_prob": 0.048890817910432816
    },
    {
      "id": 4,
      "seek": 2400,
      "start": 25.0,
      "end": 26.0,
      "text": " All right.",
      "tokens": [
        50414,
        1057,
        558,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 5,
      "seek": 2400,
      "start": 26.0,
      "end": 28.0,
      "text": " Thank you, Gina.",
      "tokens": [
        50464,
        1044,
        291,
        11,
        34711,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 6,
      "seek": 2400,
      "start": 28.0,
      "end": 29.0,
      "text": " I cannot see the agenda.",
      "tokens": [
        50564,
        286,
        2644,
        536,
        264,
        9829,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 7,
      "seek": 2400,
      "start": 29.0,
      "end": 30.0,
      "text": " My iPad is acting up.",
      "tokens": [
        50614,
        1222,
        12945,
        307,
        6577,
        493,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 8,
      "seek": 2400,
      "start": 30.0,
      "end": 35.0,
      "text": " But anyways, I think my first item.",
      "tokens": [
        50664,
        583,
        13448,
        11,
        286,
        519,
        452,
        700,
        3174,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 9,
      "seek": 2400,
      "start": 35.0,
      "end": 39.0,
      "text": " It's about severity labels.",
      "tokens": [
        50914,
        467,
        311,
        466,
        35179,
        16949,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 10,
      "seek": 2400,
      "start": 39.0,
      "end": 40.0,
      "text": " I'm not mistaken.",
      "tokens": [
        51114,
        286,
        478,
        406,
        21333,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 11,
      "seek": 2400,
      "start": 40.0,
      "end": 43.0,
      "text": " So just a heads up for product designers.",
      "tokens": [
        51164,
        407,
        445,
        257,
        8050,
        493,
        337,
        1674,
        16196,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 12,
      "seek": 2400,
      "start": 43.0,
      "end": 48.0,
      "text": " Please don't forget to add severity labels to your UX issues,",
      "tokens": [
        51314,
        2555,
        500,
        380,
        2870,
        281,
        909,
        35179,
        16949,
        281,
        428,
        40176,
        2663,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 13,
      "seek": 2400,
      "start": 48.0,
      "end": 50.0,
      "text": " especially the suspecting ones.",
      "tokens": [
        51564,
        2318,
        264,
        9091,
        278,
        2306,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 14,
      "seek": 2400,
      "start": 50.0,
      "end": 53.0,
      "text": " The boat will annoy you if you don't.",
      "tokens": [
        51664,
        440,
        6582,
        486,
        8759,
        291,
        498,
        291,
        500,
        380,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21215395833931716,
      "compression_ratio": 1.4798206278026906,
      "no_speech_prob": 0.0641360878944397
    },
    {
      "id": 15,
      "seek": 5300,
      "start": 53.0,
      "end": 57.0,
      "text": " So it's a good way of reminding us to label those issues",
      "tokens": [
        50364,
        407,
        309,
        311,
        257,
        665,
        636,
        295,
        27639,
        505,
        281,
        7645,
        729,
        2663,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25553610952276934,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.003305914578959346
    },
    {
      "id": 16,
      "seek": 5300,
      "start": 57.0,
      "end": 60.0,
      "text": " and accordingly so that we can have help with prioritization.",
      "tokens": [
        50564,
        293,
        19717,
        370,
        300,
        321,
        393,
        362,
        854,
        365,
        14846,
        2144,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25553610952276934,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.003305914578959346
    },
    {
      "id": 17,
      "seek": 5300,
      "start": 60.0,
      "end": 62.0,
      "text": " But also, I've seen some issues.",
      "tokens": [
        50714,
        583,
        611,
        11,
        286,
        600,
        1612,
        512,
        2663,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25553610952276934,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.003305914578959346
    },
    {
      "id": 18,
      "seek": 5300,
      "start": 62.0,
      "end": 69.0,
      "text": " You might see Valerie also doing some housekeeping on those on those issues",
      "tokens": [
        50814,
        509,
        1062,
        536,
        46656,
        611,
        884,
        512,
        48033,
        322,
        729,
        322,
        729,
        2663,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25553610952276934,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.003305914578959346
    },
    {
      "id": 19,
      "seek": 5300,
      "start": 69.0,
      "end": 71.0,
      "text": " and leaving comments, but there are some issues.",
      "tokens": [
        51164,
        293,
        5012,
        3053,
        11,
        457,
        456,
        366,
        512,
        2663,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25553610952276934,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.003305914578959346
    },
    {
      "id": 20,
      "seek": 5300,
      "start": 71.0,
      "end": 75.0,
      "text": " There are not label UX, but they do have your extra requirements.",
      "tokens": [
        51264,
        821,
        366,
        406,
        7645,
        40176,
        11,
        457,
        436,
        360,
        362,
        428,
        2857,
        7728,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25553610952276934,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.003305914578959346
    },
    {
      "id": 21,
      "seek": 5300,
      "start": 75.0,
      "end": 79.0,
      "text": " So I review one for verify today.",
      "tokens": [
        51464,
        407,
        286,
        3131,
        472,
        337,
        16888,
        965,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25553610952276934,
      "compression_ratio": 1.6206896551724137,
      "no_speech_prob": 0.003305914578959346
    },
    {
      "id": 22,
      "seek": 7900,
      "start": 79.0,
      "end": 82.0,
      "text": " And I, I just didn't know about the fact that it was a back in issue,",
      "tokens": [
        50364,
        400,
        286,
        11,
        286,
        445,
        994,
        380,
        458,
        466,
        264,
        1186,
        300,
        309,
        390,
        257,
        646,
        294,
        2734,
        11,
        50514
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 23,
      "seek": 7900,
      "start": 82.0,
      "end": 85.0,
      "text": " but it changed statings and it changed UI copy.",
      "tokens": [
        50514,
        457,
        309,
        3105,
        2219,
        1109,
        293,
        309,
        3105,
        15682,
        5055,
        13,
        50664
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 24,
      "seek": 7900,
      "start": 85.0,
      "end": 89.0,
      "text": " But it didn't have UX or a severity added.",
      "tokens": [
        50664,
        583,
        309,
        994,
        380,
        362,
        40176,
        420,
        257,
        35179,
        3869,
        13,
        50864
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 25,
      "seek": 7900,
      "start": 89.0,
      "end": 91.0,
      "text": " So just a reminder.",
      "tokens": [
        50864,
        407,
        445,
        257,
        13548,
        13,
        50964
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 26,
      "seek": 7900,
      "start": 91.0,
      "end": 93.0,
      "text": " For everyone to please.",
      "tokens": [
        50964,
        1171,
        1518,
        281,
        1767,
        13,
        51064
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 27,
      "seek": 7900,
      "start": 93.0,
      "end": 96.0,
      "text": " Make sure that the issues that you and your team are working on.",
      "tokens": [
        51064,
        4387,
        988,
        300,
        264,
        2663,
        300,
        291,
        293,
        428,
        1469,
        366,
        1364,
        322,
        13,
        51214
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 28,
      "seek": 7900,
      "start": 96.0,
      "end": 98.0,
      "text": " Have the correct labels applied.",
      "tokens": [
        51214,
        3560,
        264,
        3006,
        16949,
        6456,
        13,
        51314
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 29,
      "seek": 7900,
      "start": 98.0,
      "end": 99.0,
      "text": " That's one.",
      "tokens": [
        51314,
        663,
        311,
        472,
        13,
        51364
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 30,
      "seek": 7900,
      "start": 99.0,
      "end": 103.0,
      "text": " And then my other updates about hiring.",
      "tokens": [
        51364,
        400,
        550,
        452,
        661,
        9205,
        466,
        15335,
        13,
        51564
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 31,
      "seek": 7900,
      "start": 103.0,
      "end": 107.0,
      "text": " Have a new product designer joining the pipeline insights team.",
      "tokens": [
        51564,
        3560,
        257,
        777,
        1674,
        11795,
        5549,
        264,
        15517,
        14310,
        1469,
        13,
        51764
      ],
      "temperature": 0.6,
      "avg_logprob": -0.5030413660509833,
      "compression_ratio": 1.5833333333333333,
      "no_speech_prob": 0.016230694949626923
    },
    {
      "id": 32,
      "seek": 10700,
      "start": 107.0,
      "end": 108.08,
      "text": " in the coming months.",
      "tokens": [
        50364,
        294,
        264,
        1348,
        2493,
        13,
        50418
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 33,
      "seek": 10700,
      "start": 108.08,
      "end": 110.56,
      "text": " We don't have a start date yet,",
      "tokens": [
        50418,
        492,
        500,
        380,
        362,
        257,
        722,
        4002,
        1939,
        11,
        50542
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 34,
      "seek": 10700,
      "start": 110.56,
      "end": 113.64,
      "text": " but she will take over from five planning sites",
      "tokens": [
        50542,
        457,
        750,
        486,
        747,
        670,
        490,
        1732,
        5038,
        7533,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 35,
      "seek": 10700,
      "start": 113.64,
      "end": 116.48,
      "text": " so that Gina can transition full time to runner.",
      "tokens": [
        50696,
        370,
        300,
        34711,
        393,
        6034,
        1577,
        565,
        281,
        24376,
        13,
        50838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 36,
      "seek": 10700,
      "start": 116.48,
      "end": 118.12,
      "text": " So it's gonna happen.",
      "tokens": [
        50838,
        407,
        309,
        311,
        799,
        1051,
        13,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 37,
      "seek": 10700,
      "start": 119.16,
      "end": 122.08,
      "text": " Then we'll say no more about that the start date",
      "tokens": [
        50972,
        1396,
        321,
        603,
        584,
        572,
        544,
        466,
        300,
        264,
        722,
        4002,
        51118
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 38,
      "seek": 10700,
      "start": 122.08,
      "end": 125.0,
      "text": " and yeah, just to onboarding all that everybody know.",
      "tokens": [
        51118,
        293,
        1338,
        11,
        445,
        281,
        24033,
        278,
        439,
        300,
        2201,
        458,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 39,
      "seek": 10700,
      "start": 126.92,
      "end": 128.48,
      "text": " So that's that for me.",
      "tokens": [
        51360,
        407,
        300,
        311,
        300,
        337,
        385,
        13,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 40,
      "seek": 10700,
      "start": 128.48,
      "end": 130.04,
      "text": " Gina, you have a year off next.",
      "tokens": [
        51438,
        34711,
        11,
        291,
        362,
        257,
        1064,
        766,
        958,
        13,
        51516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 41,
      "seek": 10700,
      "start": 131.0,
      "end": 133.8,
      "text": " Yes, there's an issue that I linked here",
      "tokens": [
        51564,
        1079,
        11,
        456,
        311,
        364,
        2734,
        300,
        286,
        9408,
        510,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 42,
      "seek": 10700,
      "start": 133.8,
      "end": 135.8,
      "text": " that Amelia had brought up",
      "tokens": [
        51704,
        300,
        42814,
        632,
        3038,
        493,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3358098543607272,
      "compression_ratio": 1.5793650793650793,
      "no_speech_prob": 0.06348852068185806
    },
    {
      "id": 43,
      "seek": 13580,
      "start": 135.8,
      "end": 139.12,
      "text": " about discussing how to better collaborate with designers",
      "tokens": [
        50364,
        466,
        10850,
        577,
        281,
        1101,
        18338,
        365,
        16196,
        50530
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 44,
      "seek": 13580,
      "start": 139.12,
      "end": 142.24,
      "text": " but I think it also applies with research",
      "tokens": [
        50530,
        457,
        286,
        519,
        309,
        611,
        13165,
        365,
        2132,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 45,
      "seek": 13580,
      "start": 142.24,
      "end": 143.56,
      "text": " and even technical writing,",
      "tokens": [
        50686,
        293,
        754,
        6191,
        3579,
        11,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 46,
      "seek": 13580,
      "start": 143.56,
      "end": 145.12,
      "text": " cross stage or cross group.",
      "tokens": [
        50752,
        3278,
        3233,
        420,
        3278,
        1594,
        13,
        50830
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 47,
      "seek": 13580,
      "start": 146.16000000000003,
      "end": 147.44,
      "text": " I just mentioned it to this group.",
      "tokens": [
        50882,
        286,
        445,
        2835,
        309,
        281,
        341,
        1594,
        13,
        50946
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 48,
      "seek": 13580,
      "start": 147.44,
      "end": 150.0,
      "text": " I think a few of us have already jumped into it,",
      "tokens": [
        50946,
        286,
        519,
        257,
        1326,
        295,
        505,
        362,
        1217,
        13864,
        666,
        309,
        11,
        51074
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 49,
      "seek": 13580,
      "start": 150.0,
      "end": 152.24,
      "text": " but I think this group does a really great job",
      "tokens": [
        51074,
        457,
        286,
        519,
        341,
        1594,
        775,
        257,
        534,
        869,
        1691,
        51186
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 50,
      "seek": 13580,
      "start": 152.24,
      "end": 153.12,
      "text": " of collaborating.",
      "tokens": [
        51186,
        295,
        30188,
        13,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 51,
      "seek": 13580,
      "start": 153.12,
      "end": 156.56,
      "text": " So I was encouraging you to share your thoughts",
      "tokens": [
        51230,
        407,
        286,
        390,
        14580,
        291,
        281,
        2073,
        428,
        4598,
        51402
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 52,
      "seek": 13580,
      "start": 157.56,
      "end": 158.56,
      "text": " if you have time.",
      "tokens": [
        51452,
        498,
        291,
        362,
        565,
        13,
        51502
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16349650935122842,
      "compression_ratio": 1.6591928251121075,
      "no_speech_prob": 5.010037784813903e-05
    },
    {
      "id": 53,
      "seek": 16580,
      "start": 166.20000000000002,
      "end": 168.92000000000002,
      "text": " And I think we were gonna try to start from the bottom",
      "tokens": [
        50384,
        400,
        286,
        519,
        321,
        645,
        799,
        853,
        281,
        722,
        490,
        264,
        2767,
        50520
      ],
      "temperature": 0.6,
      "avg_logprob": -0.7666261336382698,
      "compression_ratio": 1.4518072289156627,
      "no_speech_prob": 0.001475350116379559
    },
    {
      "id": 54,
      "seek": 16580,
      "start": 168.92000000000002,
      "end": 172.0,
      "text": " of the agenda today, Erica, if you wanted to start.",
      "tokens": [
        50520,
        295,
        264,
        9829,
        965,
        11,
        37429,
        11,
        498,
        291,
        1415,
        281,
        722,
        13,
        50674
      ],
      "temperature": 0.6,
      "avg_logprob": -0.7666261336382698,
      "compression_ratio": 1.4518072289156627,
      "no_speech_prob": 0.001475350116379559
    },
    {
      "id": 55,
      "seek": 16580,
      "start": 176.68,
      "end": 179.68,
      "text": " Well, that's a great tie in because working backward from my list,",
      "tokens": [
        50908,
        1042,
        11,
        300,
        311,
        257,
        869,
        7582,
        294,
        570,
        1364,
        23897,
        490,
        452,
        1329,
        11,
        51058
      ],
      "temperature": 0.6,
      "avg_logprob": -0.7666261336382698,
      "compression_ratio": 1.4518072289156627,
      "no_speech_prob": 0.001475350116379559
    },
    {
      "id": 56,
      "seek": 16580,
      "start": 180.84,
      "end": 183.36,
      "text": " one of the things was that we have,",
      "tokens": [
        51116,
        472,
        295,
        264,
        721,
        390,
        300,
        321,
        362,
        11,
        51242
      ],
      "temperature": 0.6,
      "avg_logprob": -0.7666261336382698,
      "compression_ratio": 1.4518072289156627,
      "no_speech_prob": 0.001475350116379559
    },
    {
      "id": 57,
      "seek": 16580,
      "start": 185.08,
      "end": 187.84,
      "text": " I wanted to like celebrate the.",
      "tokens": [
        51328,
        286,
        1415,
        281,
        411,
        8098,
        264,
        13,
        51466
      ],
      "temperature": 0.6,
      "avg_logprob": -0.7666261336382698,
      "compression_ratio": 1.4518072289156627,
      "no_speech_prob": 0.001475350116379559
    },
    {
      "id": 58,
      "seek": 18784,
      "start": 187.84,
      "end": 197.12,
      "text": " list. One of the things was that we have, I wanted to like celebrate the my my updates today are",
      "tokens": [
        50364,
        1329,
        13,
        1485,
        295,
        264,
        721,
        390,
        300,
        321,
        362,
        11,
        286,
        1415,
        281,
        411,
        8098,
        264,
        452,
        452,
        9205,
        965,
        366,
        50828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2796686677371754,
      "compression_ratio": 1.5183246073298429,
      "no_speech_prob": 0.04099787771701813
    },
    {
      "id": 59,
      "seek": 18784,
      "start": 197.12,
      "end": 208.0,
      "text": " framed around welcome back Hannah. I wanted to know that Gina and Will actually got sick and",
      "tokens": [
        50828,
        30420,
        926,
        2928,
        646,
        21754,
        13,
        286,
        1415,
        281,
        458,
        300,
        34711,
        293,
        3099,
        767,
        658,
        4998,
        293,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2796686677371754,
      "compression_ratio": 1.5183246073298429,
      "no_speech_prob": 0.04099787771701813
    },
    {
      "id": 60,
      "seek": 18784,
      "start": 208.0,
      "end": 214.0,
      "text": " like tested such that I couldn't go to the conference. And so Gina like stepped into this leadership",
      "tokens": [
        51372,
        411,
        8246,
        1270,
        300,
        286,
        2809,
        380,
        352,
        281,
        264,
        7586,
        13,
        400,
        370,
        34711,
        411,
        15251,
        666,
        341,
        5848,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2796686677371754,
      "compression_ratio": 1.5183246073298429,
      "no_speech_prob": 0.04099787771701813
    },
    {
      "id": 61,
      "seek": 21400,
      "start": 214.0,
      "end": 220.64,
      "text": " position, will really delivered. And we have like four reports, I know amazing, I coupon,",
      "tokens": [
        50364,
        2535,
        11,
        486,
        534,
        10144,
        13,
        400,
        321,
        362,
        411,
        1451,
        7122,
        11,
        286,
        458,
        2243,
        11,
        286,
        8682,
        266,
        11,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22460147312709264,
      "compression_ratio": 1.6018099547511313,
      "no_speech_prob": 0.0014672722900286317
    },
    {
      "id": 62,
      "seek": 21400,
      "start": 221.36,
      "end": 227.92,
      "text": " four reports that we hammered out because of the data they collected. And then one more on the way",
      "tokens": [
        50732,
        1451,
        7122,
        300,
        321,
        13017,
        292,
        484,
        570,
        295,
        264,
        1412,
        436,
        11087,
        13,
        400,
        550,
        472,
        544,
        322,
        264,
        636,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22460147312709264,
      "compression_ratio": 1.6018099547511313,
      "no_speech_prob": 0.0014672722900286317
    },
    {
      "id": 63,
      "seek": 21400,
      "start": 227.92,
      "end": 235.28,
      "text": " which which ties into the issue that Gina just showed about cross stage collaboration. So we",
      "tokens": [
        51060,
        597,
        597,
        14039,
        666,
        264,
        2734,
        300,
        34711,
        445,
        4712,
        466,
        3278,
        3233,
        9363,
        13,
        407,
        321,
        51428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22460147312709264,
      "compression_ratio": 1.6018099547511313,
      "no_speech_prob": 0.0014672722900286317
    },
    {
      "id": 64,
      "seek": 21400,
      "start": 235.28,
      "end": 240.64,
      "text": " we set up like a game we gamified the interviews instead of running them",
      "tokens": [
        51428,
        321,
        992,
        493,
        411,
        257,
        1216,
        321,
        8019,
        2587,
        264,
        12318,
        2602,
        295,
        2614,
        552,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22460147312709264,
      "compression_ratio": 1.6018099547511313,
      "no_speech_prob": 0.0014672722900286317
    },
    {
      "id": 65,
      "seek": 24064,
      "start": 240.72,
      "end": 250.88,
      "text": " just like in a conversational way. And we were able to get great data. And I think we got actionable data.",
      "tokens": [
        50368,
        445,
        411,
        294,
        257,
        2615,
        1478,
        636,
        13,
        400,
        321,
        645,
        1075,
        281,
        483,
        869,
        1412,
        13,
        400,
        286,
        519,
        321,
        658,
        45098,
        1412,
        13,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15108799323057517,
      "compression_ratio": 1.5336787564766838,
      "no_speech_prob": 0.0016214377246797085
    },
    {
      "id": 66,
      "seek": 24064,
      "start": 251.51999999999998,
      "end": 257.03999999999996,
      "text": " So we're still working on that report and it's setting up a secret scan which we kind of all",
      "tokens": [
        50908,
        407,
        321,
        434,
        920,
        1364,
        322,
        300,
        2275,
        293,
        309,
        311,
        3287,
        493,
        257,
        4054,
        11049,
        597,
        321,
        733,
        295,
        439,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15108799323057517,
      "compression_ratio": 1.5336787564766838,
      "no_speech_prob": 0.0016214377246797085
    },
    {
      "id": 67,
      "seek": 24064,
      "start": 257.03999999999996,
      "end": 267.36,
      "text": " want to be working on anyway. So that was really good. Yay! And then I guess my last item too is",
      "tokens": [
        51184,
        528,
        281,
        312,
        1364,
        322,
        4033,
        13,
        407,
        300,
        390,
        534,
        665,
        13,
        13268,
        0,
        400,
        550,
        286,
        2041,
        452,
        1036,
        3174,
        886,
        307,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15108799323057517,
      "compression_ratio": 1.5336787564766838,
      "no_speech_prob": 0.0016214377246797085
    },
    {
      "id": 68,
      "seek": 26736,
      "start": 267.36,
      "end": 274.64,
      "text": " just asking if if you all would like to open up the H2 Verifying Package Common Screener for",
      "tokens": [
        50364,
        445,
        3365,
        498,
        498,
        291,
        439,
        576,
        411,
        281,
        1269,
        493,
        264,
        389,
        17,
        4281,
        5489,
        18466,
        609,
        18235,
        25823,
        260,
        337,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15580151478449503,
      "compression_ratio": 1.507936507936508,
      "no_speech_prob": 0.0003481496823951602
    },
    {
      "id": 69,
      "seek": 26736,
      "start": 274.64,
      "end": 280.64,
      "text": " solution validation studies. So I just wanted to check if it's worth like making that change with",
      "tokens": [
        50728,
        3827,
        24071,
        5313,
        13,
        407,
        286,
        445,
        1415,
        281,
        1520,
        498,
        309,
        311,
        3163,
        411,
        1455,
        300,
        1319,
        365,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15580151478449503,
      "compression_ratio": 1.507936507936508,
      "no_speech_prob": 0.0003481496823951602
    },
    {
      "id": 70,
      "seek": 26736,
      "start": 280.64,
      "end": 290.8,
      "text": " Caitlin. And I linked a PDF of the of what the questions are and is long. But we have like 500",
      "tokens": [
        51028,
        50131,
        13,
        400,
        286,
        9408,
        257,
        17752,
        295,
        264,
        295,
        437,
        264,
        1651,
        366,
        293,
        307,
        938,
        13,
        583,
        321,
        362,
        411,
        5923,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15580151478449503,
      "compression_ratio": 1.507936507936508,
      "no_speech_prob": 0.0003481496823951602
    },
    {
      "id": 71,
      "seek": 26736,
      "start": 290.8,
      "end": 296.72,
      "text": " participants in there and some of them have been used. But I think I'll give you time. You can",
      "tokens": [
        51536,
        10503,
        294,
        456,
        293,
        512,
        295,
        552,
        362,
        668,
        1143,
        13,
        583,
        286,
        519,
        286,
        603,
        976,
        291,
        565,
        13,
        509,
        393,
        51832
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15580151478449503,
      "compression_ratio": 1.507936507936508,
      "no_speech_prob": 0.0003481496823951602
    },
    {
      "id": 72,
      "seek": 29672,
      "start": 296.72,
      "end": 304.16,
      "text": " just mention me in the notes to give you time to look at it and just let me know like how many studies",
      "tokens": [
        50364,
        445,
        2152,
        385,
        294,
        264,
        5570,
        281,
        976,
        291,
        565,
        281,
        574,
        412,
        309,
        293,
        445,
        718,
        385,
        458,
        411,
        577,
        867,
        5313,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10846964518229167,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.00010239633411401883
    },
    {
      "id": 73,
      "seek": 29672,
      "start": 306.48,
      "end": 315.12,
      "text": " we might recruit for. And then my other findings are kind of just an overview of the Q4",
      "tokens": [
        50852,
        321,
        1062,
        15119,
        337,
        13,
        400,
        550,
        452,
        661,
        16483,
        366,
        733,
        295,
        445,
        364,
        12492,
        295,
        264,
        1249,
        19,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10846964518229167,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.00010239633411401883
    },
    {
      "id": 74,
      "seek": 29672,
      "start": 315.12,
      "end": 325.36,
      "text": " prioritization. So the big one is that we have a pre-work issue set up for Q3 to do some pre-work",
      "tokens": [
        51284,
        14846,
        2144,
        13,
        407,
        264,
        955,
        472,
        307,
        300,
        321,
        362,
        257,
        659,
        12,
        1902,
        2734,
        992,
        493,
        337,
        1249,
        18,
        281,
        360,
        512,
        659,
        12,
        1902,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10846964518229167,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.00010239633411401883
    },
    {
      "id": 75,
      "seek": 32536,
      "start": 325.36,
      "end": 333.84000000000003,
      "text": " related to a benchmark. Dare I say it for a package? I'm like a nervous. But anyway. So yeah. So we'll",
      "tokens": [
        50364,
        4077,
        281,
        257,
        18927,
        13,
        42320,
        286,
        584,
        309,
        337,
        257,
        7372,
        30,
        286,
        478,
        411,
        257,
        6296,
        13,
        583,
        4033,
        13,
        407,
        1338,
        13,
        407,
        321,
        603,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1926950974897905,
      "compression_ratio": 1.4365482233502538,
      "no_speech_prob": 0.00041195459198206663
    },
    {
      "id": 76,
      "seek": 32536,
      "start": 333.84000000000003,
      "end": 342.96000000000004,
      "text": " hopefully do a benchmark for a package in Q1. Fiscal Year 23 starting in 159 waiting for",
      "tokens": [
        50788,
        4696,
        360,
        257,
        18927,
        337,
        257,
        7372,
        294,
        1249,
        16,
        13,
        479,
        14616,
        10289,
        6673,
        2891,
        294,
        2119,
        24,
        3806,
        337,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1926950974897905,
      "compression_ratio": 1.4365482233502538,
      "no_speech_prob": 0.00041195459198206663
    },
    {
      "id": 77,
      "seek": 32536,
      "start": 343.84000000000003,
      "end": 351.68,
      "text": " design and PM resources to kind of come online. But before then I'm just doing work to like",
      "tokens": [
        51288,
        1715,
        293,
        12499,
        3593,
        281,
        733,
        295,
        808,
        2950,
        13,
        583,
        949,
        550,
        286,
        478,
        445,
        884,
        589,
        281,
        411,
        51680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1926950974897905,
      "compression_ratio": 1.4365482233502538,
      "no_speech_prob": 0.00041195459198206663
    },
    {
      "id": 78,
      "seek": 35168,
      "start": 351.76,
      "end": 359.36,
      "text": " kind of crosswalk the stages that have done this before to kind of like make sure what we do is on par.",
      "tokens": [
        50368,
        733,
        295,
        3278,
        12490,
        264,
        10232,
        300,
        362,
        1096,
        341,
        949,
        281,
        733,
        295,
        411,
        652,
        988,
        437,
        321,
        360,
        307,
        322,
        971,
        13,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13442301750183105,
      "compression_ratio": 1.5634517766497462,
      "no_speech_prob": 0.0004639894177671522
    },
    {
      "id": 79,
      "seek": 35168,
      "start": 361.36,
      "end": 369.92,
      "text": " And then we also kind of related to package resources. We put on hold this like cycle of an image study",
      "tokens": [
        50848,
        400,
        550,
        321,
        611,
        733,
        295,
        4077,
        281,
        7372,
        3593,
        13,
        492,
        829,
        322,
        1797,
        341,
        411,
        6586,
        295,
        364,
        3256,
        2979,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13442301750183105,
      "compression_ratio": 1.5634517766497462,
      "no_speech_prob": 0.0004639894177671522
    },
    {
      "id": 80,
      "seek": 35168,
      "start": 371.2,
      "end": 378.96000000000004,
      "text": " until the new PM joins. So that would be the study that we did kind of with secrets and CI templates",
      "tokens": [
        51340,
        1826,
        264,
        777,
        12499,
        24397,
        13,
        407,
        300,
        576,
        312,
        264,
        2979,
        300,
        321,
        630,
        733,
        295,
        365,
        14093,
        293,
        37777,
        21165,
        51728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13442301750183105,
      "compression_ratio": 1.5634517766497462,
      "no_speech_prob": 0.0004639894177671522
    },
    {
      "id": 81,
      "seek": 37896,
      "start": 378.96,
      "end": 384.79999999999995,
      "text": " where it's like how does it start? What happens next? What happens next? We would use that kind of",
      "tokens": [
        50364,
        689,
        309,
        311,
        411,
        577,
        775,
        309,
        722,
        30,
        708,
        2314,
        958,
        30,
        708,
        2314,
        958,
        30,
        492,
        576,
        764,
        300,
        733,
        295,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10950170818128084,
      "compression_ratio": 1.6651785714285714,
      "no_speech_prob": 0.0003328461607452482
    },
    {
      "id": 82,
      "seek": 37896,
      "start": 384.79999999999995,
      "end": 393.35999999999996,
      "text": " framework. And so that's on hold for the new PM. We think it's exciting for the new PM to work on.",
      "tokens": [
        50656,
        8388,
        13,
        400,
        370,
        300,
        311,
        322,
        1797,
        337,
        264,
        777,
        12499,
        13,
        492,
        519,
        309,
        311,
        4670,
        337,
        264,
        777,
        12499,
        281,
        589,
        322,
        13,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10950170818128084,
      "compression_ratio": 1.6651785714285714,
      "no_speech_prob": 0.0003328461607452482
    },
    {
      "id": 83,
      "seek": 37896,
      "start": 393.35999999999996,
      "end": 397.44,
      "text": " But I think the benchmarks would get priority and then it would go to that study.",
      "tokens": [
        51084,
        583,
        286,
        519,
        264,
        43751,
        576,
        483,
        9365,
        293,
        550,
        309,
        576,
        352,
        281,
        300,
        2979,
        13,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10950170818128084,
      "compression_ratio": 1.6651785714285714,
      "no_speech_prob": 0.0003328461607452482
    },
    {
      "id": 84,
      "seek": 37896,
      "start": 400.32,
      "end": 406.15999999999997,
      "text": " One more thing to mention about that is Gina has a really cool issue, a research issue around",
      "tokens": [
        51432,
        1485,
        544,
        551,
        281,
        2152,
        466,
        300,
        307,
        34711,
        575,
        257,
        534,
        1627,
        2734,
        11,
        257,
        2132,
        2734,
        926,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10950170818128084,
      "compression_ratio": 1.6651785714285714,
      "no_speech_prob": 0.0003328461607452482
    },
    {
      "id": 85,
      "seek": 40616,
      "start": 406.64000000000004,
      "end": 413.84000000000003,
      "text": " looking at the lifecycle of logs. And so part of me wants to try to fold that into this study. That's",
      "tokens": [
        50388,
        1237,
        412,
        264,
        45722,
        295,
        20820,
        13,
        400,
        370,
        644,
        295,
        385,
        2738,
        281,
        853,
        281,
        4860,
        300,
        666,
        341,
        2979,
        13,
        663,
        311,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1491884331954153,
      "compression_ratio": 1.5654008438818565,
      "no_speech_prob": 0.0006924132467247546
    },
    {
      "id": 86,
      "seek": 40616,
      "start": 413.84000000000003,
      "end": 421.28000000000003,
      "text": " no one holds. But I think we're getting feedback that we need to like scope that Gina's study down",
      "tokens": [
        50748,
        572,
        472,
        9190,
        13,
        583,
        286,
        519,
        321,
        434,
        1242,
        5824,
        300,
        321,
        643,
        281,
        411,
        11923,
        300,
        34711,
        311,
        2979,
        760,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1491884331954153,
      "compression_ratio": 1.5654008438818565,
      "no_speech_prob": 0.0006924132467247546
    },
    {
      "id": 87,
      "seek": 40616,
      "start": 421.28000000000003,
      "end": 426.24,
      "text": " a little bit. So but does note that I have like a plan because I think it's really smart.",
      "tokens": [
        51120,
        257,
        707,
        857,
        13,
        407,
        457,
        775,
        3637,
        300,
        286,
        362,
        411,
        257,
        1393,
        570,
        286,
        519,
        309,
        311,
        534,
        4069,
        13,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1491884331954153,
      "compression_ratio": 1.5654008438818565,
      "no_speech_prob": 0.0006924132467247546
    },
    {
      "id": 88,
      "seek": 40616,
      "start": 427.04,
      "end": 434.32000000000005,
      "text": " Like in foundational research terms. Sorry, I didn't wait for Hannah to say that",
      "tokens": [
        51408,
        1743,
        294,
        32195,
        2132,
        2115,
        13,
        4919,
        11,
        286,
        994,
        380,
        1699,
        337,
        21754,
        281,
        584,
        300,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1491884331954153,
      "compression_ratio": 1.5654008438818565,
      "no_speech_prob": 0.0006924132467247546
    },
    {
      "id": 89,
      "seek": 43432,
      "start": 434.4,
      "end": 436.48,
      "text": " thanks for the heads up on the benchmark.",
      "tokens": [
        50368,
        3231,
        337,
        264,
        8050,
        493,
        322,
        264,
        18927,
        13,
        50472
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35693466800382767,
      "compression_ratio": 1.5048543689320388,
      "no_speech_prob": 0.0022222595289349556
    },
    {
      "id": 90,
      "seek": 43432,
      "start": 440.32,
      "end": 449.44,
      "text": " Yes, sorry, my Google docs keeps, keeps crashing on me. I'm so I can not finish writing my question.",
      "tokens": [
        50664,
        1079,
        11,
        2597,
        11,
        452,
        3329,
        45623,
        5965,
        11,
        5965,
        26900,
        322,
        385,
        13,
        286,
        478,
        370,
        286,
        393,
        406,
        2413,
        3579,
        452,
        1168,
        13,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35693466800382767,
      "compression_ratio": 1.5048543689320388,
      "no_speech_prob": 0.0022222595289349556
    },
    {
      "id": 91,
      "seek": 43432,
      "start": 449.44,
      "end": 455.03999999999996,
      "text": " So yeah, about package, I have a question for you, Erica. I cannot open the issue now.",
      "tokens": [
        51120,
        407,
        1338,
        11,
        466,
        7372,
        11,
        286,
        362,
        257,
        1168,
        337,
        291,
        11,
        37429,
        13,
        286,
        2644,
        1269,
        264,
        2734,
        586,
        13,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35693466800382767,
      "compression_ratio": 1.5048543689320388,
      "no_speech_prob": 0.0022222595289349556
    },
    {
      "id": 92,
      "seek": 43432,
      "start": 456.4,
      "end": 461.76,
      "text": " On my iPad, but the pre-work issue is for the benchmark aid, right? For package.",
      "tokens": [
        51468,
        1282,
        452,
        12945,
        11,
        457,
        264,
        659,
        12,
        1902,
        2734,
        307,
        337,
        264,
        18927,
        9418,
        11,
        558,
        30,
        1171,
        7372,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.35693466800382767,
      "compression_ratio": 1.5048543689320388,
      "no_speech_prob": 0.0022222595289349556
    },
    {
      "id": 93,
      "seek": 46176,
      "start": 461.92,
      "end": 470.24,
      "text": " Yes, and correctly. Yes. And it's all things that I want to do. Like I'm comparing the",
      "tokens": [
        50372,
        1079,
        11,
        293,
        8944,
        13,
        1079,
        13,
        400,
        309,
        311,
        439,
        721,
        300,
        286,
        528,
        281,
        360,
        13,
        1743,
        286,
        478,
        15763,
        264,
        50788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2736527579171317,
      "compression_ratio": 1.4863387978142077,
      "no_speech_prob": 0.0004627950838766992
    },
    {
      "id": 94,
      "seek": 46176,
      "start": 470.24,
      "end": 478.15999999999997,
      "text": " screener questions because I think that and I worked on benchmarks in a lot of previous roles.",
      "tokens": [
        50788,
        2568,
        260,
        1651,
        570,
        286,
        519,
        300,
        293,
        286,
        2732,
        322,
        43751,
        294,
        257,
        688,
        295,
        3894,
        9604,
        13,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2736527579171317,
      "compression_ratio": 1.4863387978142077,
      "no_speech_prob": 0.0004627950838766992
    },
    {
      "id": 95,
      "seek": 46176,
      "start": 478.8,
      "end": 486.48,
      "text": " And one thing we want to see is how much we can compare across stages, which kind of means",
      "tokens": [
        51216,
        400,
        472,
        551,
        321,
        528,
        281,
        536,
        307,
        577,
        709,
        321,
        393,
        6794,
        2108,
        10232,
        11,
        597,
        733,
        295,
        1355,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2736527579171317,
      "compression_ratio": 1.4863387978142077,
      "no_speech_prob": 0.0004627950838766992
    },
    {
      "id": 96,
      "seek": 48648,
      "start": 487.12,
      "end": 492.32,
      "text": " looking at how comparable the samples are. And did we all use the same screener?",
      "tokens": [
        50396,
        1237,
        412,
        577,
        25323,
        264,
        10938,
        366,
        13,
        400,
        630,
        321,
        439,
        764,
        264,
        912,
        2568,
        260,
        30,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1682072129360465,
      "compression_ratio": 1.574766355140187,
      "no_speech_prob": 0.0005292341229505837
    },
    {
      "id": 97,
      "seek": 48648,
      "start": 493.36,
      "end": 499.76,
      "text": " And like what's the alignment? In part, I'm doing that so that I'm not making us be too rigorous",
      "tokens": [
        50708,
        400,
        411,
        437,
        311,
        264,
        18515,
        30,
        682,
        644,
        11,
        286,
        478,
        884,
        300,
        370,
        300,
        286,
        478,
        406,
        1455,
        505,
        312,
        886,
        29882,
        51028
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1682072129360465,
      "compression_ratio": 1.574766355140187,
      "no_speech_prob": 0.0005292341229505837
    },
    {
      "id": 98,
      "seek": 48648,
      "start": 499.76,
      "end": 506.0,
      "text": " with like finding a counterbalance sample. But like whatever we've done is an amazing iteration.",
      "tokens": [
        51028,
        365,
        411,
        5006,
        257,
        5682,
        29215,
        6889,
        13,
        583,
        411,
        2035,
        321,
        600,
        1096,
        307,
        364,
        2243,
        24784,
        13,
        51340
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1682072129360465,
      "compression_ratio": 1.574766355140187,
      "no_speech_prob": 0.0005292341229505837
    },
    {
      "id": 99,
      "seek": 48648,
      "start": 507.84000000000003,
      "end": 511.20000000000005,
      "text": " But we just want us to track it explicitly so we kind of know.",
      "tokens": [
        51432,
        583,
        321,
        445,
        528,
        505,
        281,
        2837,
        309,
        20803,
        370,
        321,
        733,
        295,
        458,
        13,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1682072129360465,
      "compression_ratio": 1.574766355140187,
      "no_speech_prob": 0.0005292341229505837
    },
    {
      "id": 100,
      "seek": 51120,
      "start": 511.84,
      "end": 516.72,
      "text": " So it's mainly me doing the pre-work of like what were the screeners?",
      "tokens": [
        50396,
        407,
        309,
        311,
        8704,
        385,
        884,
        264,
        659,
        12,
        1902,
        295,
        411,
        437,
        645,
        264,
        2568,
        433,
        30,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14150986551236705,
      "compression_ratio": 1.661710037174721,
      "no_speech_prob": 0.000563452485948801
    },
    {
      "id": 101,
      "seek": 51120,
      "start": 517.68,
      "end": 522.8,
      "text": " What's our screener looks like? I actually have our screener drafted. And so whenever Tim had time,",
      "tokens": [
        50688,
        708,
        311,
        527,
        2568,
        260,
        1542,
        411,
        30,
        286,
        767,
        362,
        527,
        2568,
        260,
        36288,
        13,
        400,
        370,
        5699,
        7172,
        632,
        565,
        11,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14150986551236705,
      "compression_ratio": 1.661710037174721,
      "no_speech_prob": 0.000563452485948801
    },
    {
      "id": 102,
      "seek": 51120,
      "start": 522.8,
      "end": 527.4399999999999,
      "text": " he can kind of come in. I think the idea would be we would treat it like a common screener",
      "tokens": [
        50944,
        415,
        393,
        733,
        295,
        808,
        294,
        13,
        286,
        519,
        264,
        1558,
        576,
        312,
        321,
        576,
        2387,
        309,
        411,
        257,
        2689,
        2568,
        260,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14150986551236705,
      "compression_ratio": 1.661710037174721,
      "no_speech_prob": 0.000563452485948801
    },
    {
      "id": 103,
      "seek": 51120,
      "start": 528.08,
      "end": 533.52,
      "text": " and then be in a position to run the next benchmark. Like we would have 500 participants,",
      "tokens": [
        51208,
        293,
        550,
        312,
        294,
        257,
        2535,
        281,
        1190,
        264,
        958,
        18927,
        13,
        1743,
        321,
        576,
        362,
        5923,
        10503,
        11,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14150986551236705,
      "compression_ratio": 1.661710037174721,
      "no_speech_prob": 0.000563452485948801
    },
    {
      "id": 104,
      "seek": 51120,
      "start": 533.52,
      "end": 538.96,
      "text": " so we could select from. If we kind of start rolling it out as soon as we're ready. And so we're",
      "tokens": [
        51480,
        370,
        321,
        727,
        3048,
        490,
        13,
        759,
        321,
        733,
        295,
        722,
        9439,
        309,
        484,
        382,
        2321,
        382,
        321,
        434,
        1919,
        13,
        400,
        370,
        321,
        434,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14150986551236705,
      "compression_ratio": 1.661710037174721,
      "no_speech_prob": 0.000563452485948801
    },
    {
      "id": 105,
      "seek": 53896,
      "start": 539.2,
      "end": 546.64,
      "text": " just waiting on Tim to have time. So it's like what were the screeners? How are the samples comparing?",
      "tokens": [
        50376,
        445,
        3806,
        322,
        7172,
        281,
        362,
        565,
        13,
        407,
        309,
        311,
        411,
        437,
        645,
        264,
        2568,
        433,
        30,
        1012,
        366,
        264,
        10938,
        15763,
        30,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15770976983227777,
      "compression_ratio": 1.58130081300813,
      "no_speech_prob": 9.551669063512236e-05
    },
    {
      "id": 106,
      "seek": 53896,
      "start": 547.6,
      "end": 552.8000000000001,
      "text": " And that will help us know. Like I think what I'm seeing so far is like we're mainly small",
      "tokens": [
        50796,
        400,
        300,
        486,
        854,
        505,
        458,
        13,
        1743,
        286,
        519,
        437,
        286,
        478,
        2577,
        370,
        1400,
        307,
        411,
        321,
        434,
        8704,
        1359,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15770976983227777,
      "compression_ratio": 1.58130081300813,
      "no_speech_prob": 9.551669063512236e-05
    },
    {
      "id": 107,
      "seek": 53896,
      "start": 552.8000000000001,
      "end": 558.88,
      "text": " medium business samples, which is fine to know, right? But it means we don't have to then stretch to",
      "tokens": [
        51056,
        6399,
        1606,
        10938,
        11,
        597,
        307,
        2489,
        281,
        458,
        11,
        558,
        30,
        583,
        309,
        1355,
        321,
        500,
        380,
        362,
        281,
        550,
        5985,
        281,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15770976983227777,
      "compression_ratio": 1.58130081300813,
      "no_speech_prob": 9.551669063512236e-05
    },
    {
      "id": 108,
      "seek": 53896,
      "start": 558.88,
      "end": 566.88,
      "text": " do an enterprise recruit. Kind of we want to be on par. And then I'll be looking at all of the",
      "tokens": [
        51360,
        360,
        364,
        14132,
        15119,
        13,
        9242,
        295,
        321,
        528,
        281,
        312,
        322,
        971,
        13,
        400,
        550,
        286,
        603,
        312,
        1237,
        412,
        439,
        295,
        264,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15770976983227777,
      "compression_ratio": 1.58130081300813,
      "no_speech_prob": 9.551669063512236e-05
    },
    {
      "id": 109,
      "seek": 56688,
      "start": 566.88,
      "end": 572.24,
      "text": " mechanisms that different researchers use to like get feedback. Like Will has this lovely",
      "tokens": [
        50364,
        15902,
        300,
        819,
        10309,
        764,
        281,
        411,
        483,
        5824,
        13,
        1743,
        3099,
        575,
        341,
        7496,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392618047780004,
      "compression_ratio": 1.5394190871369295,
      "no_speech_prob": 0.00039074831875041127
    },
    {
      "id": 110,
      "seek": 56688,
      "start": 573.04,
      "end": 580.0,
      "text": " URL approach that he used for jobs to be done like deciding on the tasks. And then working with Tim",
      "tokens": [
        50672,
        12905,
        3109,
        300,
        415,
        1143,
        337,
        4782,
        281,
        312,
        1096,
        411,
        17990,
        322,
        264,
        9608,
        13,
        400,
        550,
        1364,
        365,
        7172,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392618047780004,
      "compression_ratio": 1.5394190871369295,
      "no_speech_prob": 0.00039074831875041127
    },
    {
      "id": 111,
      "seek": 56688,
      "start": 580.0,
      "end": 586.24,
      "text": " to figure out like what the team has capacity for. I feel like we'll go more bare bones,",
      "tokens": [
        51020,
        281,
        2573,
        484,
        411,
        437,
        264,
        1469,
        575,
        6042,
        337,
        13,
        286,
        841,
        411,
        321,
        603,
        352,
        544,
        6949,
        10491,
        11,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392618047780004,
      "compression_ratio": 1.5394190871369295,
      "no_speech_prob": 0.00039074831875041127
    },
    {
      "id": 112,
      "seek": 56688,
      "start": 587.2,
      "end": 593.44,
      "text": " which is also okay. But so in a couple weeks when we get back from the Thanksgiving holiday,",
      "tokens": [
        51380,
        597,
        307,
        611,
        1392,
        13,
        583,
        370,
        294,
        257,
        1916,
        3259,
        562,
        321,
        483,
        646,
        490,
        264,
        21230,
        9960,
        11,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1392618047780004,
      "compression_ratio": 1.5394190871369295,
      "no_speech_prob": 0.00039074831875041127
    },
    {
      "id": 113,
      "seek": 59344,
      "start": 593.5200000000001,
      "end": 598.08,
      "text": " I'm going to meet with Tim to like give the updates and then see what his thoughts are",
      "tokens": [
        50368,
        286,
        478,
        516,
        281,
        1677,
        365,
        7172,
        281,
        411,
        976,
        264,
        9205,
        293,
        550,
        536,
        437,
        702,
        4598,
        366,
        50596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10520819182037025,
      "compression_ratio": 1.6157205240174672,
      "no_speech_prob": 0.000428427301812917
    },
    {
      "id": 114,
      "seek": 59344,
      "start": 599.12,
      "end": 606.6400000000001,
      "text": " related to the kind of the next steps. And my plan was just to use those little half hour meetings that",
      "tokens": [
        50648,
        4077,
        281,
        264,
        733,
        295,
        264,
        958,
        4439,
        13,
        400,
        452,
        1393,
        390,
        445,
        281,
        764,
        729,
        707,
        1922,
        1773,
        8410,
        300,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10520819182037025,
      "compression_ratio": 1.6157205240174672,
      "no_speech_prob": 0.000428427301812917
    },
    {
      "id": 115,
      "seek": 59344,
      "start": 606.6400000000001,
      "end": 613.6,
      "text": " I have set up with him. So they don't take too much time. And then the last thing that I'll look at",
      "tokens": [
        51024,
        286,
        362,
        992,
        493,
        365,
        796,
        13,
        407,
        436,
        500,
        380,
        747,
        886,
        709,
        565,
        13,
        400,
        550,
        264,
        1036,
        551,
        300,
        286,
        603,
        574,
        412,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10520819182037025,
      "compression_ratio": 1.6157205240174672,
      "no_speech_prob": 0.000428427301812917
    },
    {
      "id": 116,
      "seek": 59344,
      "start": 613.6,
      "end": 619.12,
      "text": " across those stage areas is just like the level at which the tasks were framed.",
      "tokens": [
        51372,
        2108,
        729,
        3233,
        3179,
        307,
        445,
        411,
        264,
        1496,
        412,
        597,
        264,
        9608,
        645,
        30420,
        13,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10520819182037025,
      "compression_ratio": 1.6157205240174672,
      "no_speech_prob": 0.000428427301812917
    },
    {
      "id": 117,
      "seek": 61912,
      "start": 619.76,
      "end": 629.28,
      "text": " Because that can impact performance too. So I think we'll also help like elevate the research program.",
      "tokens": [
        50396,
        1436,
        300,
        393,
        2712,
        3389,
        886,
        13,
        407,
        286,
        519,
        321,
        603,
        611,
        854,
        411,
        33054,
        264,
        2132,
        1461,
        13,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28516876220703125,
      "compression_ratio": 1.4492753623188406,
      "no_speech_prob": 0.000935806892812252
    },
    {
      "id": 118,
      "seek": 61912,
      "start": 630.48,
      "end": 638.24,
      "text": " With this work. Okay. I'm taking some notes here. Thank you. I think you're for the overview that",
      "tokens": [
        50932,
        2022,
        341,
        589,
        13,
        1033,
        13,
        286,
        478,
        1940,
        512,
        5570,
        510,
        13,
        1044,
        291,
        13,
        286,
        519,
        291,
        434,
        337,
        264,
        12492,
        300,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28516876220703125,
      "compression_ratio": 1.4492753623188406,
      "no_speech_prob": 0.000935806892812252
    },
    {
      "id": 119,
      "seek": 61912,
      "start": 638.64,
      "end": 643.84,
      "text": " that clarifies my next couple of questions. And then I just want to say please keep me in the loop.",
      "tokens": [
        51340,
        300,
        6093,
        11221,
        452,
        958,
        1916,
        295,
        1651,
        13,
        400,
        550,
        286,
        445,
        528,
        281,
        584,
        1767,
        1066,
        385,
        294,
        264,
        6367,
        13,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28516876220703125,
      "compression_ratio": 1.4492753623188406,
      "no_speech_prob": 0.000935806892812252
    },
    {
      "id": 120,
      "seek": 64384,
      "start": 643.84,
      "end": 652.24,
      "text": " Because if we know a bit ahead of what the UX I'll say like hands on design work for package",
      "tokens": [
        50364,
        1436,
        498,
        321,
        458,
        257,
        857,
        2286,
        295,
        437,
        264,
        40176,
        286,
        603,
        584,
        411,
        2377,
        322,
        1715,
        589,
        337,
        7372,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2351118007176359,
      "compression_ratio": 1.4371584699453552,
      "no_speech_prob": 0.004186772741377354
    },
    {
      "id": 121,
      "seek": 64384,
      "start": 652.24,
      "end": 658.48,
      "text": " is going to look like. I need to know to prepare the UX coverage because we won't have",
      "tokens": [
        50784,
        307,
        516,
        281,
        574,
        411,
        13,
        286,
        643,
        281,
        458,
        281,
        5940,
        264,
        40176,
        9645,
        570,
        321,
        1582,
        380,
        362,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2351118007176359,
      "compression_ratio": 1.4371584699453552,
      "no_speech_prob": 0.004186772741377354
    },
    {
      "id": 122,
      "seek": 64384,
      "start": 658.48,
      "end": 667.6,
      "text": " UX location for package until next year Q3 Q4. Okay. Yeah. We've made a decision to",
      "tokens": [
        51096,
        40176,
        4914,
        337,
        7372,
        1826,
        958,
        1064,
        1249,
        18,
        1249,
        19,
        13,
        1033,
        13,
        865,
        13,
        492,
        600,
        1027,
        257,
        3537,
        281,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2351118007176359,
      "compression_ratio": 1.4371584699453552,
      "no_speech_prob": 0.004186772741377354
    },
    {
      "id": 123,
      "seek": 66760,
      "start": 668.24,
      "end": 676.32,
      "text": " because team and Victor also Michelle they talk about the deliverable plans for package now. That's",
      "tokens": [
        50396,
        570,
        1469,
        293,
        15777,
        611,
        14933,
        436,
        751,
        466,
        264,
        4239,
        712,
        5482,
        337,
        7372,
        586,
        13,
        663,
        311,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2057250725043999,
      "compression_ratio": 1.719298245614035,
      "no_speech_prob": 0.011095304042100906
    },
    {
      "id": 124,
      "seek": 66760,
      "start": 676.32,
      "end": 683.6800000000001,
      "text": " for everybody to kind of be aware that they're hiring developers. They don't have for example",
      "tokens": [
        50800,
        337,
        2201,
        281,
        733,
        295,
        312,
        3650,
        300,
        436,
        434,
        15335,
        8849,
        13,
        814,
        500,
        380,
        362,
        337,
        1365,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2057250725043999,
      "compression_ratio": 1.719298245614035,
      "no_speech_prob": 0.011095304042100906
    },
    {
      "id": 125,
      "seek": 66760,
      "start": 683.6800000000001,
      "end": 690.16,
      "text": " front end allocation to build UI right now. So we are not going to be hiring a designer for package",
      "tokens": [
        51168,
        1868,
        917,
        27599,
        281,
        1322,
        15682,
        558,
        586,
        13,
        407,
        321,
        366,
        406,
        516,
        281,
        312,
        15335,
        257,
        11795,
        337,
        7372,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2057250725043999,
      "compression_ratio": 1.719298245614035,
      "no_speech_prob": 0.011095304042100906
    },
    {
      "id": 126,
      "seek": 66760,
      "start": 690.72,
      "end": 696.0,
      "text": " right now. We move the headcount to a different team and then we won't have a designer for package",
      "tokens": [
        51520,
        558,
        586,
        13,
        492,
        1286,
        264,
        1378,
        26050,
        281,
        257,
        819,
        1469,
        293,
        550,
        321,
        1582,
        380,
        362,
        257,
        11795,
        337,
        7372,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2057250725043999,
      "compression_ratio": 1.719298245614035,
      "no_speech_prob": 0.011095304042100906
    },
    {
      "id": 127,
      "seek": 69600,
      "start": 696.0,
      "end": 703.68,
      "text": " until next year right once development picks up. But if there is a the research is going on and we have",
      "tokens": [
        50364,
        1826,
        958,
        1064,
        558,
        1564,
        3250,
        16137,
        493,
        13,
        583,
        498,
        456,
        307,
        257,
        264,
        2132,
        307,
        516,
        322,
        293,
        321,
        362,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1878021074377972,
      "compression_ratio": 1.7268518518518519,
      "no_speech_prob": 0.0008272576960735023
    },
    {
      "id": 128,
      "seek": 69600,
      "start": 705.36,
      "end": 710.4,
      "text": " well the hiring for development also picks up and we know that we have a need for",
      "tokens": [
        50832,
        731,
        264,
        15335,
        337,
        3250,
        611,
        16137,
        493,
        293,
        321,
        458,
        300,
        321,
        362,
        257,
        643,
        337,
        51084
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1878021074377972,
      "compression_ratio": 1.7268518518518519,
      "no_speech_prob": 0.0008272576960735023
    },
    {
      "id": 129,
      "seek": 69600,
      "start": 710.96,
      "end": 715.68,
      "text": " package UX deliverables then yeah I'll need to know ahead of time so that we don't work on a",
      "tokens": [
        51112,
        7372,
        40176,
        4239,
        2965,
        550,
        1338,
        286,
        603,
        643,
        281,
        458,
        2286,
        295,
        565,
        370,
        300,
        321,
        500,
        380,
        589,
        322,
        257,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1878021074377972,
      "compression_ratio": 1.7268518518518519,
      "no_speech_prob": 0.0008272576960735023
    },
    {
      "id": 130,
      "seek": 69600,
      "start": 715.68,
      "end": 722.48,
      "text": " coverage or borrow plan or a hiring plan for the for the design backfill for Katie's backfill.",
      "tokens": [
        51348,
        9645,
        420,
        11172,
        1393,
        420,
        257,
        15335,
        1393,
        337,
        264,
        337,
        264,
        1715,
        646,
        31072,
        337,
        19602,
        311,
        646,
        31072,
        13,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1878021074377972,
      "compression_ratio": 1.7268518518518519,
      "no_speech_prob": 0.0008272576960735023
    },
    {
      "id": 131,
      "seek": 72248,
      "start": 723.44,
      "end": 728.48,
      "text": " But just so you're aware that yeah we're not playing any own deliverables for package because we",
      "tokens": [
        50412,
        583,
        445,
        370,
        291,
        434,
        3650,
        300,
        1338,
        321,
        434,
        406,
        2433,
        604,
        1065,
        4239,
        2965,
        337,
        7372,
        570,
        321,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22756261923878462,
      "compression_ratio": 1.6188524590163935,
      "no_speech_prob": 0.001332112355157733
    },
    {
      "id": 132,
      "seek": 72248,
      "start": 728.48,
      "end": 736.48,
      "text": " don't have anyone allocated there. And maybe we work backwards from that too. I don't know. I like",
      "tokens": [
        50664,
        500,
        380,
        362,
        2878,
        29772,
        456,
        13,
        400,
        1310,
        321,
        589,
        12204,
        490,
        300,
        886,
        13,
        286,
        500,
        380,
        458,
        13,
        286,
        411,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22756261923878462,
      "compression_ratio": 1.6188524590163935,
      "no_speech_prob": 0.001332112355157733
    },
    {
      "id": 133,
      "seek": 72248,
      "start": 736.48,
      "end": 743.52,
      "text": " really wanted to contribute to the okay R so I'm just kidding or we're trying. But I think I think it",
      "tokens": [
        51064,
        534,
        1415,
        281,
        10586,
        281,
        264,
        1392,
        497,
        370,
        286,
        478,
        445,
        9287,
        420,
        321,
        434,
        1382,
        13,
        583,
        286,
        519,
        286,
        519,
        309,
        51416
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22756261923878462,
      "compression_ratio": 1.6188524590163935,
      "no_speech_prob": 0.001332112355157733
    },
    {
      "id": 134,
      "seek": 72248,
      "start": 743.52,
      "end": 750.64,
      "text": " would be okay to get those findings and then have the designer as they on board like pick up with",
      "tokens": [
        51416,
        576,
        312,
        1392,
        281,
        483,
        729,
        16483,
        293,
        550,
        362,
        264,
        11795,
        382,
        436,
        322,
        3150,
        411,
        1888,
        493,
        365,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22756261923878462,
      "compression_ratio": 1.6188524590163935,
      "no_speech_prob": 0.001332112355157733
    },
    {
      "id": 135,
      "seek": 75064,
      "start": 750.64,
      "end": 757.68,
      "text": " them as long as we like set the expectations so everyone knows that that's our plan.",
      "tokens": [
        50364,
        552,
        382,
        938,
        382,
        321,
        411,
        992,
        264,
        9843,
        370,
        1518,
        3255,
        300,
        300,
        311,
        527,
        1393,
        13,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3494274809553817,
      "compression_ratio": 1.4598930481283423,
      "no_speech_prob": 0.0003741199616342783
    },
    {
      "id": 136,
      "seek": 75064,
      "start": 758.24,
      "end": 764.4,
      "text": " This seems okay but we'll let Tim guide us. But thank you for the update. Okay.",
      "tokens": [
        50744,
        639,
        2544,
        1392,
        457,
        321,
        603,
        718,
        7172,
        5934,
        505,
        13,
        583,
        1309,
        291,
        337,
        264,
        5623,
        13,
        1033,
        13,
        51052
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3494274809553817,
      "compression_ratio": 1.4598930481283423,
      "no_speech_prob": 0.0003741199616342783
    },
    {
      "id": 137,
      "seek": 75064,
      "start": 765.68,
      "end": 766.8,
      "text": " Keep me keep me the one.",
      "tokens": [
        51116,
        5527,
        385,
        1066,
        385,
        264,
        472,
        13,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3494274809553817,
      "compression_ratio": 1.4598930481283423,
      "no_speech_prob": 0.0003741199616342783
    },
    {
      "id": 138,
      "seek": 75064,
      "start": 771.68,
      "end": 779.4399999999999,
      "text": " Okay well. Sure. Just got a couple updates. I'm using the same prioritization issue",
      "tokens": [
        51416,
        1033,
        731,
        13,
        4894,
        13,
        1449,
        658,
        257,
        1916,
        9205,
        13,
        286,
        478,
        1228,
        264,
        912,
        14846,
        2144,
        2734,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3494274809553817,
      "compression_ratio": 1.4598930481283423,
      "no_speech_prob": 0.0003741199616342783
    },
    {
      "id": 139,
      "seek": 77944,
      "start": 780.24,
      "end": 790.8000000000001,
      "text": " in Q4 as I used in Q3. I'm kind of trialing just a longer term prioritization issue that goes",
      "tokens": [
        50404,
        294,
        1249,
        19,
        382,
        286,
        1143,
        294,
        1249,
        18,
        13,
        286,
        478,
        733,
        295,
        1376,
        4270,
        445,
        257,
        2854,
        1433,
        14846,
        2144,
        2734,
        300,
        1709,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10675599700526188,
      "compression_ratio": 1.5368421052631578,
      "no_speech_prob": 0.003538701217621565
    },
    {
      "id": 140,
      "seek": 77944,
      "start": 790.8000000000001,
      "end": 798.72,
      "text": " two quarters as opposed to one just to see how that process goes. I did add a comment in the issue",
      "tokens": [
        50932,
        732,
        20612,
        382,
        8851,
        281,
        472,
        445,
        281,
        536,
        577,
        300,
        1399,
        1709,
        13,
        286,
        630,
        909,
        257,
        2871,
        294,
        264,
        2734,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10675599700526188,
      "compression_ratio": 1.5368421052631578,
      "no_speech_prob": 0.003538701217621565
    },
    {
      "id": 141,
      "seek": 77944,
      "start": 800.5600000000001,
      "end": 806.96,
      "text": " with just some updates on like what projects we accomplished in Q3 so if you want to check that out",
      "tokens": [
        51420,
        365,
        445,
        512,
        9205,
        322,
        411,
        437,
        4455,
        321,
        15419,
        294,
        1249,
        18,
        370,
        498,
        291,
        528,
        281,
        1520,
        300,
        484,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10675599700526188,
      "compression_ratio": 1.5368421052631578,
      "no_speech_prob": 0.003538701217621565
    },
    {
      "id": 142,
      "seek": 80696,
      "start": 806.96,
      "end": 814.0,
      "text": " you're welcome to do so. And we're still collecting projects for Q4 but I've listed within that",
      "tokens": [
        50364,
        291,
        434,
        2928,
        281,
        360,
        370,
        13,
        400,
        321,
        434,
        920,
        12510,
        4455,
        337,
        1249,
        19,
        457,
        286,
        600,
        10052,
        1951,
        300,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09698810040111273,
      "compression_ratio": 1.4720812182741116,
      "no_speech_prob": 0.0005829829024150968
    },
    {
      "id": 143,
      "seek": 80696,
      "start": 814.0,
      "end": 823.84,
      "text": " comment what projects we're expecting to take on this quarter. Aside from that also met up with",
      "tokens": [
        50716,
        2871,
        437,
        4455,
        321,
        434,
        9650,
        281,
        747,
        322,
        341,
        6555,
        13,
        33726,
        490,
        300,
        611,
        1131,
        493,
        365,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09698810040111273,
      "compression_ratio": 1.4720812182741116,
      "no_speech_prob": 0.0005829829024150968
    },
    {
      "id": 144,
      "seek": 80696,
      "start": 823.84,
      "end": 833.52,
      "text": " Emily on Sunday which was awesome. We got to have dinner. It was nice to just meet another person.",
      "tokens": [
        51208,
        15034,
        322,
        7776,
        597,
        390,
        3476,
        13,
        492,
        658,
        281,
        362,
        6148,
        13,
        467,
        390,
        1481,
        281,
        445,
        1677,
        1071,
        954,
        13,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09698810040111273,
      "compression_ratio": 1.4720812182741116,
      "no_speech_prob": 0.0005829829024150968
    },
    {
      "id": 145,
      "seek": 83352,
      "start": 834.16,
      "end": 841.76,
      "text": " I've met like half the people on this call which I never thought when contribute got cancelled",
      "tokens": [
        50396,
        286,
        600,
        1131,
        411,
        1922,
        264,
        561,
        322,
        341,
        818,
        597,
        286,
        1128,
        1194,
        562,
        10586,
        658,
        25103,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16286028676958225,
      "compression_ratio": 1.4842105263157894,
      "no_speech_prob": 0.0012218120973557234
    },
    {
      "id": 146,
      "seek": 83352,
      "start": 841.76,
      "end": 849.84,
      "text": " for the year but yes just been great to slowly meet more and more team members as a bit a part of",
      "tokens": [
        50776,
        337,
        264,
        1064,
        457,
        2086,
        445,
        668,
        869,
        281,
        5692,
        1677,
        544,
        293,
        544,
        1469,
        2679,
        382,
        257,
        857,
        257,
        644,
        295,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16286028676958225,
      "compression_ratio": 1.4842105263157894,
      "no_speech_prob": 0.0012218120973557234
    },
    {
      "id": 147,
      "seek": 83352,
      "start": 849.84,
      "end": 859.12,
      "text": " the company. And my final update is that I've been reviewing scenarios kind of off and on",
      "tokens": [
        51180,
        264,
        2237,
        13,
        400,
        452,
        2572,
        5623,
        307,
        300,
        286,
        600,
        668,
        19576,
        15077,
        733,
        295,
        766,
        293,
        322,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16286028676958225,
      "compression_ratio": 1.4842105263157894,
      "no_speech_prob": 0.0012218120973557234
    },
    {
      "id": 148,
      "seek": 85912,
      "start": 859.2,
      "end": 865.44,
      "text": " for Emily's CMS study on environment management and she's been really putting a lot of effort into",
      "tokens": [
        50368,
        337,
        15034,
        311,
        33124,
        2979,
        322,
        2823,
        4592,
        293,
        750,
        311,
        668,
        534,
        3372,
        257,
        688,
        295,
        4630,
        666,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14967098236083984,
      "compression_ratio": 1.4611650485436893,
      "no_speech_prob": 0.001198456040583551
    },
    {
      "id": 149,
      "seek": 85912,
      "start": 865.44,
      "end": 878.08,
      "text": " that over the past couple weeks. Any questions for I turn it over to Emily? Okay Emily you could take it away.",
      "tokens": [
        50680,
        300,
        670,
        264,
        1791,
        1916,
        3259,
        13,
        2639,
        1651,
        337,
        286,
        1261,
        309,
        670,
        281,
        15034,
        30,
        1033,
        15034,
        291,
        727,
        747,
        309,
        1314,
        13,
        51312
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14967098236083984,
      "compression_ratio": 1.4611650485436893,
      "no_speech_prob": 0.001198456040583551
    },
    {
      "id": 150,
      "seek": 85912,
      "start": 878.08,
      "end": 884.72,
      "text": " Well I'll go a little out of order because I'll get to my critique one at the end but I was",
      "tokens": [
        51312,
        1042,
        286,
        603,
        352,
        257,
        707,
        484,
        295,
        1668,
        570,
        286,
        603,
        483,
        281,
        452,
        25673,
        472,
        412,
        264,
        917,
        457,
        286,
        390,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14967098236083984,
      "compression_ratio": 1.4611650485436893,
      "no_speech_prob": 0.001198456040583551
    },
    {
      "id": 151,
      "seek": 88472,
      "start": 884.72,
      "end": 891.2,
      "text": " mostly curious now that I'm kind of getting to the stage of conducting the CMS interviews with",
      "tokens": [
        50364,
        5240,
        6369,
        586,
        300,
        286,
        478,
        733,
        295,
        1242,
        281,
        264,
        3233,
        295,
        21749,
        264,
        33124,
        12318,
        365,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11644454335057458,
      "compression_ratio": 1.6085106382978724,
      "no_speech_prob": 0.0018627844983711839
    },
    {
      "id": 152,
      "seek": 88472,
      "start": 891.2,
      "end": 898.32,
      "text": " internal users just kind of some of the things you did to recruit people. I know we're using some",
      "tokens": [
        50688,
        6920,
        5022,
        445,
        733,
        295,
        512,
        295,
        264,
        721,
        291,
        630,
        281,
        15119,
        561,
        13,
        286,
        458,
        321,
        434,
        1228,
        512,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11644454335057458,
      "compression_ratio": 1.6085106382978724,
      "no_speech_prob": 0.0018627844983711839
    },
    {
      "id": 153,
      "seek": 88472,
      "start": 898.32,
      "end": 904.8000000000001,
      "text": " people from the delivery team who've already offered to volunteer but just any other options to",
      "tokens": [
        51044,
        561,
        490,
        264,
        8982,
        1469,
        567,
        600,
        1217,
        8059,
        281,
        13835,
        457,
        445,
        604,
        661,
        3956,
        281,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11644454335057458,
      "compression_ratio": 1.6085106382978724,
      "no_speech_prob": 0.0018627844983711839
    },
    {
      "id": 154,
      "seek": 88472,
      "start": 904.8000000000001,
      "end": 910.4,
      "text": " get people into the study I'm looking for so it's like Will and Gina both had to comments",
      "tokens": [
        51368,
        483,
        561,
        666,
        264,
        2979,
        286,
        478,
        1237,
        337,
        370,
        309,
        311,
        411,
        3099,
        293,
        34711,
        1293,
        632,
        281,
        3053,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11644454335057458,
      "compression_ratio": 1.6085106382978724,
      "no_speech_prob": 0.0018627844983711839
    },
    {
      "id": 155,
      "seek": 91040,
      "start": 910.4,
      "end": 918.8,
      "text": " around that? Sure so I haven't done this a ton. I did this probably the most like after I started",
      "tokens": [
        50364,
        926,
        300,
        30,
        4894,
        370,
        286,
        2378,
        380,
        1096,
        341,
        257,
        2952,
        13,
        286,
        630,
        341,
        1391,
        264,
        881,
        411,
        934,
        286,
        1409,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13995072682698567,
      "compression_ratio": 1.49746192893401,
      "no_speech_prob": 0.002531280042603612
    },
    {
      "id": 156,
      "seek": 91040,
      "start": 918.8,
      "end": 926.56,
      "text": " to get lab just because I wasn't sure how to get internal people to begin with and I've like posted",
      "tokens": [
        50784,
        281,
        483,
        2715,
        445,
        570,
        286,
        2067,
        380,
        988,
        577,
        281,
        483,
        6920,
        561,
        281,
        1841,
        365,
        293,
        286,
        600,
        411,
        9437,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13995072682698567,
      "compression_ratio": 1.49746192893401,
      "no_speech_prob": 0.002531280042603612
    },
    {
      "id": 157,
      "seek": 91040,
      "start": 926.56,
      "end": 933.68,
      "text": " on Slack channels just I try to keep like a very concise message of you know who I'm looking for,",
      "tokens": [
        51172,
        322,
        37211,
        9235,
        445,
        286,
        853,
        281,
        1066,
        411,
        257,
        588,
        44882,
        3636,
        295,
        291,
        458,
        567,
        286,
        478,
        1237,
        337,
        11,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13995072682698567,
      "compression_ratio": 1.49746192893401,
      "no_speech_prob": 0.002531280042603612
    },
    {
      "id": 158,
      "seek": 93368,
      "start": 934.4,
      "end": 943.68,
      "text": " what dates you know just any like kind of a summary of details about the study and just try to",
      "tokens": [
        50400,
        437,
        11691,
        291,
        458,
        445,
        604,
        411,
        733,
        295,
        257,
        12691,
        295,
        4365,
        466,
        264,
        2979,
        293,
        445,
        853,
        281,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10650852452153745,
      "compression_ratio": 1.5263157894736843,
      "no_speech_prob": 0.0010106184054166079
    },
    {
      "id": 159,
      "seek": 93368,
      "start": 943.68,
      "end": 951.12,
      "text": " post them on different channels. Sometimes I've like leaned on the PM to try to help direct me to",
      "tokens": [
        50864,
        2183,
        552,
        322,
        819,
        9235,
        13,
        4803,
        286,
        600,
        411,
        48874,
        322,
        264,
        12499,
        281,
        853,
        281,
        854,
        2047,
        385,
        281,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10650852452153745,
      "compression_ratio": 1.5263157894736843,
      "no_speech_prob": 0.0010106184054166079
    },
    {
      "id": 160,
      "seek": 93368,
      "start": 951.12,
      "end": 957.68,
      "text": " like the right channels to go to but since you're working a lot with the delivery team they might",
      "tokens": [
        51236,
        411,
        264,
        558,
        9235,
        281,
        352,
        281,
        457,
        1670,
        291,
        434,
        1364,
        257,
        688,
        365,
        264,
        8982,
        1469,
        436,
        1062,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10650852452153745,
      "compression_ratio": 1.5263157894736843,
      "no_speech_prob": 0.0010106184054166079
    },
    {
      "id": 161,
      "seek": 95768,
      "start": 958.3199999999999,
      "end": 964.4,
      "text": " you know help you know where to post or you could just talk to the participants that you have",
      "tokens": [
        50396,
        291,
        458,
        854,
        291,
        458,
        689,
        281,
        2183,
        420,
        291,
        727,
        445,
        751,
        281,
        264,
        10503,
        300,
        291,
        362,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12320571787217084,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.0006571091362275183
    },
    {
      "id": 162,
      "seek": 95768,
      "start": 964.4,
      "end": 969.1999999999999,
      "text": " signed up and say like hey you know now that you've gone through this study you know is there",
      "tokens": [
        50700,
        8175,
        493,
        293,
        584,
        411,
        4177,
        291,
        458,
        586,
        300,
        291,
        600,
        2780,
        807,
        341,
        2979,
        291,
        458,
        307,
        456,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12320571787217084,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.0006571091362275183
    },
    {
      "id": 163,
      "seek": 95768,
      "start": 969.1999999999999,
      "end": 980.8,
      "text": " someone else on your team that might be good for this? You mine was just plus wanting to what will",
      "tokens": [
        50940,
        1580,
        1646,
        322,
        428,
        1469,
        300,
        1062,
        312,
        665,
        337,
        341,
        30,
        509,
        3892,
        390,
        445,
        1804,
        7935,
        281,
        437,
        486,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12320571787217084,
      "compression_ratio": 1.625,
      "no_speech_prob": 0.0006571091362275183
    },
    {
      "id": 164,
      "seek": 98080,
      "start": 981.4399999999999,
      "end": 988.56,
      "text": " said I have posted in what's happening at GitLab before that has gotten traction and then I also found",
      "tokens": [
        50396,
        848,
        286,
        362,
        9437,
        294,
        437,
        311,
        2737,
        412,
        16939,
        37880,
        949,
        300,
        575,
        5768,
        23558,
        293,
        550,
        286,
        611,
        1352,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37751560741000706,
      "compression_ratio": 1.5151515151515151,
      "no_speech_prob": 0.001012215856462717
    },
    {
      "id": 165,
      "seek": 98080,
      "start": 988.56,
      "end": 994.88,
      "text": " that linking to the research issue helps kind of allow them allowing them to get contacts around",
      "tokens": [
        50752,
        300,
        25775,
        281,
        264,
        2132,
        2734,
        3665,
        733,
        295,
        2089,
        552,
        8293,
        552,
        281,
        483,
        15836,
        926,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37751560741000706,
      "compression_ratio": 1.5151515151515151,
      "no_speech_prob": 0.001012215856462717
    },
    {
      "id": 166,
      "seek": 98080,
      "start": 994.88,
      "end": 1003.4399999999999,
      "text": " with the researches about. Awesome sounds good. There's a hyanoilifta comment as well as a puzzling.",
      "tokens": [
        51068,
        365,
        264,
        2132,
        279,
        466,
        13,
        10391,
        3263,
        665,
        13,
        821,
        311,
        257,
        2477,
        3730,
        388,
        351,
        1328,
        2871,
        382,
        731,
        382,
        257,
        18741,
        1688,
        13,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.37751560741000706,
      "compression_ratio": 1.5151515151515151,
      "no_speech_prob": 0.001012215856462717
    },
    {
      "id": 167,
      "seek": 100344,
      "start": 1003.7600000000001,
      "end": 1011.6,
      "text": " Yeah I'm trying my my girl dogs are just not loading. I think I wrote down about",
      "tokens": [
        50380,
        865,
        286,
        478,
        1382,
        452,
        452,
        2013,
        7197,
        366,
        445,
        406,
        15114,
        13,
        286,
        519,
        286,
        4114,
        760,
        466,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24896085402544807,
      "compression_ratio": 1.5887445887445888,
      "no_speech_prob": 0.004693963564932346
    },
    {
      "id": 168,
      "seek": 100344,
      "start": 1011.6,
      "end": 1015.84,
      "text": " yeah looking of course in the handbook right we have a section with the internal customers for",
      "tokens": [
        50772,
        1338,
        1237,
        295,
        1164,
        294,
        264,
        1011,
        2939,
        558,
        321,
        362,
        257,
        3541,
        365,
        264,
        6920,
        4581,
        337,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24896085402544807,
      "compression_ratio": 1.5887445887445888,
      "no_speech_prob": 0.004693963564932346
    },
    {
      "id": 169,
      "seek": 100344,
      "start": 1015.84,
      "end": 1023.44,
      "text": " each stage group and then on which page is that? On the handbook product slash categories and if",
      "tokens": [
        50984,
        1184,
        3233,
        1594,
        293,
        550,
        322,
        597,
        3028,
        307,
        300,
        30,
        1282,
        264,
        1011,
        2939,
        1674,
        17330,
        10479,
        293,
        498,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24896085402544807,
      "compression_ratio": 1.5887445887445888,
      "no_speech_prob": 0.004693963564932346
    },
    {
      "id": 170,
      "seek": 100344,
      "start": 1023.44,
      "end": 1028.48,
      "text": " our release stage you know it's a delivery distribution team security so just echoing what the",
      "tokens": [
        51364,
        527,
        4374,
        3233,
        291,
        458,
        309,
        311,
        257,
        8982,
        7316,
        1469,
        3825,
        370,
        445,
        14300,
        278,
        437,
        264,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.24896085402544807,
      "compression_ratio": 1.5887445887445888,
      "no_speech_prob": 0.004693963564932346
    },
    {
      "id": 171,
      "seek": 102848,
      "start": 1029.04,
      "end": 1035.6,
      "text": " will and Gina say most of those groups they have their own Slack channel so can drop that same",
      "tokens": [
        50392,
        486,
        293,
        34711,
        584,
        881,
        295,
        729,
        3935,
        436,
        362,
        641,
        1065,
        37211,
        2269,
        370,
        393,
        3270,
        300,
        912,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22296372379165097,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.008598029613494873
    },
    {
      "id": 172,
      "seek": 102848,
      "start": 1035.6,
      "end": 1041.28,
      "text": " message in there then we need to reach out directly to people. I think for the release the",
      "tokens": [
        50720,
        3636,
        294,
        456,
        550,
        321,
        643,
        281,
        2524,
        484,
        3838,
        281,
        561,
        13,
        286,
        519,
        337,
        264,
        4374,
        264,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22296372379165097,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.008598029613494873
    },
    {
      "id": 173,
      "seek": 102848,
      "start": 1041.28,
      "end": 1047.1200000000001,
      "text": " delivery team they have super active so it's easy to find those connections through them and also",
      "tokens": [
        51004,
        8982,
        1469,
        436,
        362,
        1687,
        4967,
        370,
        309,
        311,
        1858,
        281,
        915,
        729,
        9271,
        807,
        552,
        293,
        611,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22296372379165097,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.008598029613494873
    },
    {
      "id": 174,
      "seek": 102848,
      "start": 1047.1200000000001,
      "end": 1052.16,
      "text": " ask like who is someone that is working or has used xyz feature functionality in the",
      "tokens": [
        51296,
        1029,
        411,
        567,
        307,
        1580,
        300,
        307,
        1364,
        420,
        575,
        1143,
        2031,
        37433,
        4111,
        14980,
        294,
        264,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22296372379165097,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.008598029613494873
    },
    {
      "id": 175,
      "seek": 105216,
      "start": 1052.16,
      "end": 1057.68,
      "text": " if you know contact with them but in Gina and will they already gave the best tips so just echoing",
      "tokens": [
        50364,
        498,
        291,
        458,
        3385,
        365,
        552,
        457,
        294,
        34711,
        293,
        486,
        436,
        1217,
        2729,
        264,
        1151,
        6082,
        370,
        445,
        14300,
        278,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841173261125511,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.000453142449259758
    },
    {
      "id": 176,
      "seek": 105216,
      "start": 1057.68,
      "end": 1066.48,
      "text": " what they say. Cool the second update I wanted to give is we adjusted the deployments navigation",
      "tokens": [
        50640,
        437,
        436,
        584,
        13,
        8561,
        264,
        1150,
        5623,
        286,
        1415,
        281,
        976,
        307,
        321,
        19871,
        264,
        7274,
        1117,
        17346,
        51080
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841173261125511,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.000453142449259758
    },
    {
      "id": 177,
      "seek": 105216,
      "start": 1066.48,
      "end": 1071.92,
      "text": " so now when you click on the high level deployments you land on the environments page not feature flags",
      "tokens": [
        51080,
        370,
        586,
        562,
        291,
        2052,
        322,
        264,
        1090,
        1496,
        7274,
        1117,
        291,
        2117,
        322,
        264,
        12388,
        3028,
        406,
        4111,
        23265,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841173261125511,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.000453142449259758
    },
    {
      "id": 178,
      "seek": 105216,
      "start": 1071.92,
      "end": 1077.2,
      "text": " because there's a lot of data showing that people would land on feature flags and navigate away",
      "tokens": [
        51352,
        570,
        456,
        311,
        257,
        688,
        295,
        1412,
        4099,
        300,
        561,
        576,
        2117,
        322,
        4111,
        23265,
        293,
        12350,
        1314,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841173261125511,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.000453142449259758
    },
    {
      "id": 179,
      "seek": 105216,
      "start": 1077.2,
      "end": 1082.0800000000002,
      "text": " as well there was comments about this in our like benchmarking study so that is now",
      "tokens": [
        51616,
        382,
        731,
        456,
        390,
        3053,
        466,
        341,
        294,
        527,
        411,
        18927,
        278,
        2979,
        370,
        300,
        307,
        586,
        51860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1841173261125511,
      "compression_ratio": 1.7292418772563176,
      "no_speech_prob": 0.000453142449259758
    },
    {
      "id": 180,
      "seek": 108208,
      "start": 1082.08,
      "end": 1088.1599999999999,
      "text": " in production which is really great and then will I know as you had a comment on that as well.",
      "tokens": [
        50364,
        294,
        4265,
        597,
        307,
        534,
        869,
        293,
        550,
        486,
        286,
        458,
        382,
        291,
        632,
        257,
        2871,
        322,
        300,
        382,
        731,
        13,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11592328813340928,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.000662651436869055
    },
    {
      "id": 181,
      "seek": 108208,
      "start": 1089.4399999999998,
      "end": 1096.0,
      "text": " Yes you talked about we did see this a lot in the benchmarking study and I would just constantly",
      "tokens": [
        50732,
        1079,
        291,
        2825,
        466,
        321,
        630,
        536,
        341,
        257,
        688,
        294,
        264,
        18927,
        278,
        2979,
        293,
        286,
        576,
        445,
        6460,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11592328813340928,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.000662651436869055
    },
    {
      "id": 182,
      "seek": 108208,
      "start": 1096.0,
      "end": 1101.6799999999998,
      "text": " see participants like click on the link and know that they weren't going to go to the right place",
      "tokens": [
        51060,
        536,
        10503,
        411,
        2052,
        322,
        264,
        2113,
        293,
        458,
        300,
        436,
        4999,
        380,
        516,
        281,
        352,
        281,
        264,
        558,
        1081,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11592328813340928,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.000662651436869055
    },
    {
      "id": 183,
      "seek": 108208,
      "start": 1101.6799999999998,
      "end": 1106.8799999999999,
      "text": " and then they would just like get frustrated and then have to you know use that extra click to",
      "tokens": [
        51344,
        293,
        550,
        436,
        576,
        445,
        411,
        483,
        15751,
        293,
        550,
        362,
        281,
        291,
        458,
        764,
        300,
        2857,
        2052,
        281,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11592328813340928,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.000662651436869055
    },
    {
      "id": 184,
      "seek": 110688,
      "start": 1106.88,
      "end": 1110.72,
      "text": " go to the right page so I know that's going to be a big time change.",
      "tokens": [
        50364,
        352,
        281,
        264,
        558,
        3028,
        370,
        286,
        458,
        300,
        311,
        516,
        281,
        312,
        257,
        955,
        565,
        1319,
        13,
        50556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17337645253827494,
      "compression_ratio": 1.646788990825688,
      "no_speech_prob": 0.0013437499292194843
    },
    {
      "id": 185,
      "seek": 110688,
      "start": 1113.7600000000002,
      "end": 1121.7600000000002,
      "text": " Awesome and to do a time to do a little kind of design review I think we still have like 20 minutes",
      "tokens": [
        50708,
        10391,
        293,
        281,
        360,
        257,
        565,
        281,
        360,
        257,
        707,
        733,
        295,
        1715,
        3131,
        286,
        519,
        321,
        920,
        362,
        411,
        945,
        2077,
        51108
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17337645253827494,
      "compression_ratio": 1.646788990825688,
      "no_speech_prob": 0.0013437499292194843
    },
    {
      "id": 186,
      "seek": 110688,
      "start": 1121.7600000000002,
      "end": 1126.72,
      "text": " so I try I will try not to take up all the time but just wanted to make sure I wasn't taking up",
      "tokens": [
        51108,
        370,
        286,
        853,
        286,
        486,
        853,
        406,
        281,
        747,
        493,
        439,
        264,
        565,
        457,
        445,
        1415,
        281,
        652,
        988,
        286,
        2067,
        380,
        1940,
        493,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17337645253827494,
      "compression_ratio": 1.646788990825688,
      "no_speech_prob": 0.0013437499292194843
    },
    {
      "id": 187,
      "seek": 110688,
      "start": 1126.72,
      "end": 1133.2800000000002,
      "text": " too much time so the background of this this has been a long standing issue that's opened that",
      "tokens": [
        51356,
        886,
        709,
        565,
        370,
        264,
        3678,
        295,
        341,
        341,
        575,
        668,
        257,
        938,
        4877,
        2734,
        300,
        311,
        5625,
        300,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17337645253827494,
      "compression_ratio": 1.646788990825688,
      "no_speech_prob": 0.0013437499292194843
    },
    {
      "id": 188,
      "seek": 113328,
      "start": 1133.28,
      "end": 1140.0,
      "text": " basically we want to design a page that for MVC starts out to host production environments across",
      "tokens": [
        50364,
        1936,
        321,
        528,
        281,
        1715,
        257,
        3028,
        300,
        337,
        17663,
        34,
        3719,
        484,
        281,
        3975,
        4265,
        12388,
        2108,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07534783536737616,
      "compression_ratio": 1.7092511013215859,
      "no_speech_prob": 0.0001994166086660698
    },
    {
      "id": 189,
      "seek": 113328,
      "start": 1140.0,
      "end": 1146.32,
      "text": " a group we've seen a lot of research showing that users are having a lot of problems tracking",
      "tokens": [
        50700,
        257,
        1594,
        321,
        600,
        1612,
        257,
        688,
        295,
        2132,
        4099,
        300,
        5022,
        366,
        1419,
        257,
        688,
        295,
        2740,
        11603,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07534783536737616,
      "compression_ratio": 1.7092511013215859,
      "no_speech_prob": 0.0001994166086660698
    },
    {
      "id": 190,
      "seek": 113328,
      "start": 1146.32,
      "end": 1152.32,
      "text": " environments at the group level and they're having to go to each project bubble page kind of track",
      "tokens": [
        51016,
        12388,
        412,
        264,
        1594,
        1496,
        293,
        436,
        434,
        1419,
        281,
        352,
        281,
        1184,
        1716,
        12212,
        3028,
        733,
        295,
        2837,
        51316
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07534783536737616,
      "compression_ratio": 1.7092511013215859,
      "no_speech_prob": 0.0001994166086660698
    },
    {
      "id": 191,
      "seek": 113328,
      "start": 1152.32,
      "end": 1158.16,
      "text": " statuses on there so kind of crafting up a page here that people would be able to see like a high",
      "tokens": [
        51316,
        6558,
        279,
        322,
        456,
        370,
        733,
        295,
        29048,
        493,
        257,
        3028,
        510,
        300,
        561,
        576,
        312,
        1075,
        281,
        536,
        411,
        257,
        1090,
        51608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07534783536737616,
      "compression_ratio": 1.7092511013215859,
      "no_speech_prob": 0.0001994166086660698
    },
    {
      "id": 192,
      "seek": 115816,
      "start": 1158.16,
      "end": 1165.76,
      "text": " level summary and then be able to click in and take action if needed. So I hi I think you for",
      "tokens": [
        50364,
        1496,
        12691,
        293,
        550,
        312,
        1075,
        281,
        2052,
        294,
        293,
        747,
        3069,
        498,
        2978,
        13,
        407,
        286,
        4879,
        286,
        519,
        291,
        337,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1337415411117229,
      "compression_ratio": 1.6594827586206897,
      "no_speech_prob": 0.0010121349478140473
    },
    {
      "id": 193,
      "seek": 115816,
      "start": 1165.76,
      "end": 1169.76,
      "text": " telling me to kind of just step back and start from scratch because that really got me started",
      "tokens": [
        50744,
        3585,
        385,
        281,
        733,
        295,
        445,
        1823,
        646,
        293,
        722,
        490,
        8459,
        570,
        300,
        534,
        658,
        385,
        1409,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1337415411117229,
      "compression_ratio": 1.6594827586206897,
      "no_speech_prob": 0.0010121349478140473
    },
    {
      "id": 194,
      "seek": 115816,
      "start": 1170.48,
      "end": 1177.92,
      "text": " quite well but I'll go ahead and share my screen if I can figure out what screen I have to share",
      "tokens": [
        50980,
        1596,
        731,
        457,
        286,
        603,
        352,
        2286,
        293,
        2073,
        452,
        2568,
        498,
        286,
        393,
        2573,
        484,
        437,
        2568,
        286,
        362,
        281,
        2073,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1337415411117229,
      "compression_ratio": 1.6594827586206897,
      "no_speech_prob": 0.0010121349478140473
    },
    {
      "id": 195,
      "seek": 115816,
      "start": 1178.64,
      "end": 1185.2,
      "text": " this one. Well so how I started this is I really took a step back and went through the research and",
      "tokens": [
        51388,
        341,
        472,
        13,
        1042,
        370,
        577,
        286,
        1409,
        341,
        307,
        286,
        534,
        1890,
        257,
        1823,
        646,
        293,
        1437,
        807,
        264,
        2132,
        293,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1337415411117229,
      "compression_ratio": 1.6594827586206897,
      "no_speech_prob": 0.0010121349478140473
    },
    {
      "id": 196,
      "seek": 118520,
      "start": 1186.0800000000002,
      "end": 1190.8,
      "text": " this page is interesting because it's not a typical flow users wouldn't be going here to complete",
      "tokens": [
        50408,
        341,
        3028,
        307,
        1880,
        570,
        309,
        311,
        406,
        257,
        7476,
        3095,
        5022,
        2759,
        380,
        312,
        516,
        510,
        281,
        3566,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08317894684640985,
      "compression_ratio": 1.8076923076923077,
      "no_speech_prob": 0.0003527214576024562
    },
    {
      "id": 197,
      "seek": 118520,
      "start": 1191.3600000000001,
      "end": 1196.24,
      "text": " like a typical flow but I did want to get onto paper kind of like some of the tasks that",
      "tokens": [
        50672,
        411,
        257,
        7476,
        3095,
        457,
        286,
        630,
        528,
        281,
        483,
        3911,
        3035,
        733,
        295,
        411,
        512,
        295,
        264,
        9608,
        300,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08317894684640985,
      "compression_ratio": 1.8076923076923077,
      "no_speech_prob": 0.0003527214576024562
    },
    {
      "id": 198,
      "seek": 118520,
      "start": 1196.8,
      "end": 1200.72,
      "text": " the research showed that they were looking for. I don't know if I should go into this if this",
      "tokens": [
        50944,
        264,
        2132,
        4712,
        300,
        436,
        645,
        1237,
        337,
        13,
        286,
        500,
        380,
        458,
        498,
        286,
        820,
        352,
        666,
        341,
        498,
        341,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08317894684640985,
      "compression_ratio": 1.8076923076923077,
      "no_speech_prob": 0.0003527214576024562
    },
    {
      "id": 199,
      "seek": 118520,
      "start": 1200.72,
      "end": 1206.4,
      "text": " is going to be public but you can kind of take a look at kind of some of this and then just",
      "tokens": [
        51140,
        307,
        516,
        281,
        312,
        1908,
        457,
        291,
        393,
        733,
        295,
        747,
        257,
        574,
        412,
        733,
        295,
        512,
        295,
        341,
        293,
        550,
        445,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08317894684640985,
      "compression_ratio": 1.8076923076923077,
      "no_speech_prob": 0.0003527214576024562
    },
    {
      "id": 200,
      "seek": 118520,
      "start": 1206.4,
      "end": 1212.72,
      "text": " taking a step back and really figuring out so this is like a high level view what do users really",
      "tokens": [
        51424,
        1940,
        257,
        1823,
        646,
        293,
        534,
        15213,
        484,
        370,
        341,
        307,
        411,
        257,
        1090,
        1496,
        1910,
        437,
        360,
        5022,
        534,
        51740
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08317894684640985,
      "compression_ratio": 1.8076923076923077,
      "no_speech_prob": 0.0003527214576024562
    },
    {
      "id": 201,
      "seek": 121272,
      "start": 1212.72,
      "end": 1218.48,
      "text": " want to understand and starting from like the information architecture point of view here not even",
      "tokens": [
        50364,
        528,
        281,
        1223,
        293,
        2891,
        490,
        411,
        264,
        1589,
        9482,
        935,
        295,
        1910,
        510,
        406,
        754,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1437966909753271,
      "compression_ratio": 1.6768558951965065,
      "no_speech_prob": 0.000359811499947682
    },
    {
      "id": 202,
      "seek": 121272,
      "start": 1218.48,
      "end": 1224.88,
      "text": " designing something just trying to figure out from a high level what we should be showing on this",
      "tokens": [
        50652,
        14685,
        746,
        445,
        1382,
        281,
        2573,
        484,
        490,
        257,
        1090,
        1496,
        437,
        321,
        820,
        312,
        4099,
        322,
        341,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1437966909753271,
      "compression_ratio": 1.6768558951965065,
      "no_speech_prob": 0.000359811499947682
    },
    {
      "id": 203,
      "seek": 121272,
      "start": 1224.88,
      "end": 1232.16,
      "text": " page. So with some like a team feedback I've done some like St. Cals with the engineers on this",
      "tokens": [
        50972,
        3028,
        13,
        407,
        365,
        512,
        411,
        257,
        1469,
        5824,
        286,
        600,
        1096,
        512,
        411,
        745,
        13,
        383,
        1124,
        365,
        264,
        11955,
        322,
        341,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1437966909753271,
      "compression_ratio": 1.6768558951965065,
      "no_speech_prob": 0.000359811499947682
    },
    {
      "id": 204,
      "seek": 121272,
      "start": 1232.16,
      "end": 1238.64,
      "text": " I kind of landed on something like this where we would show kind of production environments",
      "tokens": [
        51336,
        286,
        733,
        295,
        15336,
        322,
        746,
        411,
        341,
        689,
        321,
        576,
        855,
        733,
        295,
        4265,
        12388,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1437966909753271,
      "compression_ratio": 1.6768558951965065,
      "no_speech_prob": 0.000359811499947682
    },
    {
      "id": 205,
      "seek": 123864,
      "start": 1238.72,
      "end": 1244.48,
      "text": " a top-level summary of like your environment health across the group so like how many environments",
      "tokens": [
        50368,
        257,
        1192,
        12,
        12418,
        12691,
        295,
        411,
        428,
        2823,
        1585,
        2108,
        264,
        1594,
        370,
        411,
        577,
        867,
        12388,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0824111591685902,
      "compression_ratio": 2.00418410041841,
      "no_speech_prob": 0.0025986835826188326
    },
    {
      "id": 206,
      "seek": 123864,
      "start": 1244.48,
      "end": 1250.24,
      "text": " are healthy are you having problems with any of them. So a little TBD on what to show in this area",
      "tokens": [
        50656,
        366,
        4627,
        366,
        291,
        1419,
        2740,
        365,
        604,
        295,
        552,
        13,
        407,
        257,
        707,
        29711,
        35,
        322,
        437,
        281,
        855,
        294,
        341,
        1859,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0824111591685902,
      "compression_ratio": 2.00418410041841,
      "no_speech_prob": 0.0025986835826188326
    },
    {
      "id": 207,
      "seek": 123864,
      "start": 1250.24,
      "end": 1254.8000000000002,
      "text": " but really having that high level summary and then being able to dig down if you need",
      "tokens": [
        50944,
        457,
        534,
        1419,
        300,
        1090,
        1496,
        12691,
        293,
        550,
        885,
        1075,
        281,
        2528,
        760,
        498,
        291,
        643,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0824111591685902,
      "compression_ratio": 2.00418410041841,
      "no_speech_prob": 0.0025986835826188326
    },
    {
      "id": 208,
      "seek": 123864,
      "start": 1255.6000000000001,
      "end": 1260.5600000000002,
      "text": " and then when you go into the environment showing an environment level summary of that production",
      "tokens": [
        51212,
        293,
        550,
        562,
        291,
        352,
        666,
        264,
        2823,
        4099,
        364,
        2823,
        1496,
        12691,
        295,
        300,
        4265,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0824111591685902,
      "compression_ratio": 2.00418410041841,
      "no_speech_prob": 0.0025986835826188326
    },
    {
      "id": 209,
      "seek": 123864,
      "start": 1260.5600000000002,
      "end": 1266.5600000000002,
      "text": " environment with like environment health project the deployment the most recent deployment health",
      "tokens": [
        51460,
        2823,
        365,
        411,
        2823,
        1585,
        1716,
        264,
        19317,
        264,
        881,
        5162,
        19317,
        1585,
        51760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0824111591685902,
      "compression_ratio": 2.00418410041841,
      "no_speech_prob": 0.0025986835826188326
    },
    {
      "id": 210,
      "seek": 126656,
      "start": 1266.6399999999999,
      "end": 1271.6,
      "text": " and then some actions you can take as well as showing that most recent deployment so you have",
      "tokens": [
        50368,
        293,
        550,
        512,
        5909,
        291,
        393,
        747,
        382,
        731,
        382,
        4099,
        300,
        881,
        5162,
        19317,
        370,
        291,
        362,
        50616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0714168297617059,
      "compression_ratio": 1.7302158273381294,
      "no_speech_prob": 0.00018869756604544818
    },
    {
      "id": 211,
      "seek": 126656,
      "start": 1271.6,
      "end": 1278.6399999999999,
      "text": " like context of what is going into that environment currently. I've cut it down quite a bit from some",
      "tokens": [
        50616,
        411,
        4319,
        295,
        437,
        307,
        516,
        666,
        300,
        2823,
        4362,
        13,
        286,
        600,
        1723,
        309,
        760,
        1596,
        257,
        857,
        490,
        512,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0714168297617059,
      "compression_ratio": 1.7302158273381294,
      "no_speech_prob": 0.00018869756604544818
    },
    {
      "id": 212,
      "seek": 126656,
      "start": 1278.6399999999999,
      "end": 1284.72,
      "text": " of the original proposals because this page we really want to show them what is going on and not",
      "tokens": [
        50968,
        295,
        264,
        3380,
        20198,
        570,
        341,
        3028,
        321,
        534,
        528,
        281,
        855,
        552,
        437,
        307,
        516,
        322,
        293,
        406,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0714168297617059,
      "compression_ratio": 1.7302158273381294,
      "no_speech_prob": 0.00018869756604544818
    },
    {
      "id": 213,
      "seek": 126656,
      "start": 1284.72,
      "end": 1289.28,
      "text": " bog them down by a bunch of different information that they could kind of dig into and find.",
      "tokens": [
        51272,
        26132,
        552,
        760,
        538,
        257,
        3840,
        295,
        819,
        1589,
        300,
        436,
        727,
        733,
        295,
        2528,
        666,
        293,
        915,
        13,
        51500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0714168297617059,
      "compression_ratio": 1.7302158273381294,
      "no_speech_prob": 0.00018869756604544818
    },
    {
      "id": 214,
      "seek": 126656,
      "start": 1290.6399999999999,
      "end": 1296.32,
      "text": " So I've kind of moved it into this again as you can see this is like a really big TBD I want to",
      "tokens": [
        51568,
        407,
        286,
        600,
        733,
        295,
        4259,
        309,
        666,
        341,
        797,
        382,
        291,
        393,
        536,
        341,
        307,
        411,
        257,
        534,
        955,
        29711,
        35,
        286,
        528,
        281,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0714168297617059,
      "compression_ratio": 1.7302158273381294,
      "no_speech_prob": 0.00018869756604544818
    },
    {
      "id": 215,
      "seek": 129632,
      "start": 1296.32,
      "end": 1302.0,
      "text": " create a nice summary at the top but kind of showing this into like group name environment at the",
      "tokens": [
        50364,
        1884,
        257,
        1481,
        12691,
        412,
        264,
        1192,
        457,
        733,
        295,
        4099,
        341,
        666,
        411,
        1594,
        1315,
        2823,
        412,
        264,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08698194622993469,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0001213705400004983
    },
    {
      "id": 216,
      "seek": 129632,
      "start": 1302.0,
      "end": 1307.84,
      "text": " production tier kind of like is the most recent deployment successful is there anything action you",
      "tokens": [
        50648,
        4265,
        12362,
        733,
        295,
        411,
        307,
        264,
        881,
        5162,
        19317,
        4406,
        307,
        456,
        1340,
        3069,
        291,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08698194622993469,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0001213705400004983
    },
    {
      "id": 217,
      "seek": 129632,
      "start": 1307.84,
      "end": 1313.28,
      "text": " have to take and then kind of showing details about the most recent deployment underneath it",
      "tokens": [
        50940,
        362,
        281,
        747,
        293,
        550,
        733,
        295,
        4099,
        4365,
        466,
        264,
        881,
        5162,
        19317,
        7223,
        309,
        51212
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08698194622993469,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0001213705400004983
    },
    {
      "id": 218,
      "seek": 129632,
      "start": 1314.08,
      "end": 1321.12,
      "text": " with options to like view and project and kind of debug problems going that way but by condensing",
      "tokens": [
        51252,
        365,
        3956,
        281,
        411,
        1910,
        293,
        1716,
        293,
        733,
        295,
        24083,
        2740,
        516,
        300,
        636,
        457,
        538,
        2224,
        22481,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08698194622993469,
      "compression_ratio": 1.8428571428571427,
      "no_speech_prob": 0.0001213705400004983
    },
    {
      "id": 219,
      "seek": 132112,
      "start": 1321.36,
      "end": 1327.04,
      "text": " this information down reducing the amount of like pagination you need so being able to show things all",
      "tokens": [
        50376,
        341,
        1589,
        760,
        12245,
        264,
        2372,
        295,
        411,
        11812,
        2486,
        291,
        643,
        370,
        885,
        1075,
        281,
        855,
        721,
        439,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1117241106535259,
      "compression_ratio": 1.837962962962963,
      "no_speech_prob": 0.000300724757835269
    },
    {
      "id": 220,
      "seek": 132112,
      "start": 1327.04,
      "end": 1333.6,
      "text": " on one page and being able to show just the information you need to kind of take the action that",
      "tokens": [
        50660,
        322,
        472,
        3028,
        293,
        885,
        1075,
        281,
        855,
        445,
        264,
        1589,
        291,
        643,
        281,
        733,
        295,
        747,
        264,
        3069,
        300,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1117241106535259,
      "compression_ratio": 1.837962962962963,
      "no_speech_prob": 0.000300724757835269
    },
    {
      "id": 221,
      "seek": 132112,
      "start": 1333.6,
      "end": 1340.0,
      "text": " you need to take so open to suggestions on this but that's kind of like how I've started this it's",
      "tokens": [
        50988,
        291,
        643,
        281,
        747,
        370,
        1269,
        281,
        13396,
        322,
        341,
        457,
        300,
        311,
        733,
        295,
        411,
        577,
        286,
        600,
        1409,
        341,
        309,
        311,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1117241106535259,
      "compression_ratio": 1.837962962962963,
      "no_speech_prob": 0.000300724757835269
    },
    {
      "id": 222,
      "seek": 132112,
      "start": 1340.0,
      "end": 1347.04,
      "text": " still fairly rough so there's like I do want to run this by some users as well but but I would get",
      "tokens": [
        51308,
        920,
        6457,
        5903,
        370,
        456,
        311,
        411,
        286,
        360,
        528,
        281,
        1190,
        341,
        538,
        512,
        5022,
        382,
        731,
        457,
        457,
        286,
        576,
        483,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1117241106535259,
      "compression_ratio": 1.837962962962963,
      "no_speech_prob": 0.000300724757835269
    },
    {
      "id": 223,
      "seek": 134704,
      "start": 1347.84,
      "end": 1352.8,
      "text": " first feedback look even though this is kind of like a rough low fidelity right now.",
      "tokens": [
        50404,
        700,
        5824,
        574,
        754,
        1673,
        341,
        307,
        733,
        295,
        411,
        257,
        5903,
        2295,
        46404,
        558,
        586,
        13,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12364355723063152,
      "compression_ratio": 1.7168949771689497,
      "no_speech_prob": 0.00015642975631635636
    },
    {
      "id": 224,
      "seek": 134704,
      "start": 1358.1599999999999,
      "end": 1364.1599999999999,
      "text": " I had one comment just saying that I thought it looks great I didn't even see this the one that you're",
      "tokens": [
        50920,
        286,
        632,
        472,
        2871,
        445,
        1566,
        300,
        286,
        1194,
        309,
        1542,
        869,
        286,
        994,
        380,
        754,
        536,
        341,
        264,
        472,
        300,
        291,
        434,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12364355723063152,
      "compression_ratio": 1.7168949771689497,
      "no_speech_prob": 0.00015642975631635636
    },
    {
      "id": 225,
      "seek": 134704,
      "start": 1364.1599999999999,
      "end": 1372.0,
      "text": " showing right now I only saw the IA stuff so I think it I think it looks like with the all the",
      "tokens": [
        51220,
        4099,
        558,
        586,
        286,
        787,
        1866,
        264,
        286,
        32,
        1507,
        370,
        286,
        519,
        309,
        286,
        519,
        309,
        1542,
        411,
        365,
        264,
        439,
        264,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12364355723063152,
      "compression_ratio": 1.7168949771689497,
      "no_speech_prob": 0.00015642975631635636
    },
    {
      "id": 226,
      "seek": 134704,
      "start": 1372.0,
      "end": 1376.08,
      "text": " information that you have to deal with which there is a lot like you did a really good job of",
      "tokens": [
        51612,
        1589,
        300,
        291,
        362,
        281,
        2028,
        365,
        597,
        456,
        307,
        257,
        688,
        411,
        291,
        630,
        257,
        534,
        665,
        1691,
        295,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12364355723063152,
      "compression_ratio": 1.7168949771689497,
      "no_speech_prob": 0.00015642975631635636
    },
    {
      "id": 227,
      "seek": 137608,
      "start": 1376.08,
      "end": 1383.76,
      "text": " summarizing that and making it clear. I also the thing that came to mind for the summary view",
      "tokens": [
        50364,
        14611,
        3319,
        300,
        293,
        1455,
        309,
        1850,
        13,
        286,
        611,
        264,
        551,
        300,
        1361,
        281,
        1575,
        337,
        264,
        12691,
        1910,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11734308666653104,
      "compression_ratio": 1.7616822429906542,
      "no_speech_prob": 0.00010674417717382312
    },
    {
      "id": 228,
      "seek": 137608,
      "start": 1383.76,
      "end": 1390.6399999999999,
      "text": " up top I think that this single set component is always good for that type of stuff",
      "tokens": [
        50748,
        493,
        1192,
        286,
        519,
        300,
        341,
        2167,
        992,
        6542,
        307,
        1009,
        665,
        337,
        300,
        2010,
        295,
        1507,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11734308666653104,
      "compression_ratio": 1.7616822429906542,
      "no_speech_prob": 0.00010674417717382312
    },
    {
      "id": 229,
      "seek": 137608,
      "start": 1392.0,
      "end": 1398.3999999999999,
      "text": " so if you you could consider using something like that for up there I've seen other pages do that",
      "tokens": [
        51160,
        370,
        498,
        291,
        291,
        727,
        1949,
        1228,
        746,
        411,
        300,
        337,
        493,
        456,
        286,
        600,
        1612,
        661,
        7183,
        360,
        300,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11734308666653104,
      "compression_ratio": 1.7616822429906542,
      "no_speech_prob": 0.00010674417717382312
    },
    {
      "id": 230,
      "seek": 137608,
      "start": 1398.3999999999999,
      "end": 1404.8799999999999,
      "text": " as well and what runner does that and then there's a like a dev ops report type of thing that kind of",
      "tokens": [
        51480,
        382,
        731,
        293,
        437,
        24376,
        775,
        300,
        293,
        550,
        456,
        311,
        257,
        411,
        257,
        1905,
        44663,
        2275,
        2010,
        295,
        551,
        300,
        733,
        295,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11734308666653104,
      "compression_ratio": 1.7616822429906542,
      "no_speech_prob": 0.00010674417717382312
    },
    {
      "id": 231,
      "seek": 140488,
      "start": 1404.88,
      "end": 1412.0800000000002,
      "text": " does it. And that's called the like single stat component. Yeah I'll link it to you from pajamas.",
      "tokens": [
        50364,
        775,
        309,
        13,
        400,
        300,
        311,
        1219,
        264,
        411,
        2167,
        2219,
        6542,
        13,
        865,
        286,
        603,
        2113,
        309,
        281,
        291,
        490,
        43625,
        13,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18801258831489376,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.00018239540804643184
    },
    {
      "id": 232,
      "seek": 140488,
      "start": 1412.72,
      "end": 1419.68,
      "text": " Awesome it's pretty flexible too which is great. Then my only other comment was",
      "tokens": [
        50756,
        10391,
        309,
        311,
        1238,
        11358,
        886,
        597,
        307,
        869,
        13,
        1396,
        452,
        787,
        661,
        2871,
        390,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18801258831489376,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.00018239540804643184
    },
    {
      "id": 233,
      "seek": 140488,
      "start": 1422.16,
      "end": 1427.5200000000002,
      "text": " for like this would be adding a new navigation item for for groups and",
      "tokens": [
        51228,
        337,
        411,
        341,
        576,
        312,
        5127,
        257,
        777,
        17346,
        3174,
        337,
        337,
        3935,
        293,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18801258831489376,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.00018239540804643184
    },
    {
      "id": 234,
      "seek": 140488,
      "start": 1428.64,
      "end": 1434.4,
      "text": " we had to do a similar thing for runner so I would consider talking to the foundation steam just",
      "tokens": [
        51552,
        321,
        632,
        281,
        360,
        257,
        2531,
        551,
        337,
        24376,
        370,
        286,
        576,
        1949,
        1417,
        281,
        264,
        7030,
        11952,
        445,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18801258831489376,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.00018239540804643184
    },
    {
      "id": 235,
      "seek": 143440,
      "start": 1434.4,
      "end": 1441.0400000000002,
      "text": " to make sure like I think you have to get approval from them now I can link the handbook page but",
      "tokens": [
        50364,
        281,
        652,
        988,
        411,
        286,
        519,
        291,
        362,
        281,
        483,
        13317,
        490,
        552,
        586,
        286,
        393,
        2113,
        264,
        1011,
        2939,
        3028,
        457,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08845491723699885,
      "compression_ratio": 1.6752136752136753,
      "no_speech_prob": 0.0002942973223980516
    },
    {
      "id": 236,
      "seek": 143440,
      "start": 1441.0400000000002,
      "end": 1446.72,
      "text": " I also know because they have all their navigation efforts going on it may change so something to be",
      "tokens": [
        50696,
        286,
        611,
        458,
        570,
        436,
        362,
        439,
        641,
        17346,
        6484,
        516,
        322,
        309,
        815,
        1319,
        370,
        746,
        281,
        312,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08845491723699885,
      "compression_ratio": 1.6752136752136753,
      "no_speech_prob": 0.0002942973223980516
    },
    {
      "id": 237,
      "seek": 143440,
      "start": 1446.72,
      "end": 1452.48,
      "text": " aware of. Yeah I know when we were trying to do billing on the growth team we were running into",
      "tokens": [
        50980,
        3650,
        295,
        13,
        865,
        286,
        458,
        562,
        321,
        645,
        1382,
        281,
        360,
        35618,
        322,
        264,
        4599,
        1469,
        321,
        645,
        2614,
        666,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08845491723699885,
      "compression_ratio": 1.6752136752136753,
      "no_speech_prob": 0.0002942973223980516
    },
    {
      "id": 238,
      "seek": 143440,
      "start": 1452.48,
      "end": 1459.2,
      "text": " a similar thing there was like a process in adding something to the nav so I will definitely kind",
      "tokens": [
        51268,
        257,
        2531,
        551,
        456,
        390,
        411,
        257,
        1399,
        294,
        5127,
        746,
        281,
        264,
        5947,
        370,
        286,
        486,
        2138,
        733,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08845491723699885,
      "compression_ratio": 1.6752136752136753,
      "no_speech_prob": 0.0002942973223980516
    },
    {
      "id": 239,
      "seek": 145920,
      "start": 1459.2,
      "end": 1463.44,
      "text": " of communicate to this idea with them and see how to go from there. Okay yeah.",
      "tokens": [
        50364,
        295,
        7890,
        281,
        341,
        1558,
        365,
        552,
        293,
        536,
        577,
        281,
        352,
        490,
        456,
        13,
        1033,
        1338,
        13,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18798913528670125,
      "compression_ratio": 1.5433526011560694,
      "no_speech_prob": 0.0003583408542908728
    },
    {
      "id": 240,
      "seek": 145920,
      "start": 1469.76,
      "end": 1476.56,
      "text": " Erica I think you had the next comment. Yes thanks for sharing this I love that you're sharing",
      "tokens": [
        50892,
        37429,
        286,
        519,
        291,
        632,
        264,
        958,
        2871,
        13,
        1079,
        3231,
        337,
        5414,
        341,
        286,
        959,
        300,
        291,
        434,
        5414,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18798913528670125,
      "compression_ratio": 1.5433526011560694,
      "no_speech_prob": 0.0003583408542908728
    },
    {
      "id": 241,
      "seek": 145920,
      "start": 1476.56,
      "end": 1483.6000000000001,
      "text": " that's in this in this meeting. So one thing that we're we've learned about the workflow with",
      "tokens": [
        51232,
        300,
        311,
        294,
        341,
        294,
        341,
        3440,
        13,
        407,
        472,
        551,
        300,
        321,
        434,
        321,
        600,
        3264,
        466,
        264,
        20993,
        365,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18798913528670125,
      "compression_ratio": 1.5433526011560694,
      "no_speech_prob": 0.0003583408542908728
    },
    {
      "id": 242,
      "seek": 148360,
      "start": 1483.6,
      "end": 1490.8,
      "text": " CI CD variables and the subset of those are secrets is that one of the reasons people want to use",
      "tokens": [
        50364,
        37777,
        6743,
        9102,
        293,
        264,
        25993,
        295,
        729,
        366,
        14093,
        307,
        300,
        472,
        295,
        264,
        4112,
        561,
        528,
        281,
        764,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10536651611328125,
      "compression_ratio": 1.7534883720930232,
      "no_speech_prob": 0.0009595141164027154
    },
    {
      "id": 243,
      "seek": 148360,
      "start": 1490.8,
      "end": 1496.6399999999999,
      "text": " the unprotected values is because they tend to use the wrong ones per environment because it's",
      "tokens": [
        50724,
        264,
        517,
        33629,
        39963,
        4190,
        307,
        570,
        436,
        3928,
        281,
        764,
        264,
        2085,
        2306,
        680,
        2823,
        570,
        309,
        311,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10536651611328125,
      "compression_ratio": 1.7534883720930232,
      "no_speech_prob": 0.0009595141164027154
    },
    {
      "id": 244,
      "seek": 148360,
      "start": 1496.6399999999999,
      "end": 1502.8,
      "text": " confusing. So yeah like a subset of that finding is that they use different secrets values",
      "tokens": [
        51016,
        13181,
        13,
        407,
        1338,
        411,
        257,
        25993,
        295,
        300,
        5006,
        307,
        300,
        436,
        764,
        819,
        14093,
        4190,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10536651611328125,
      "compression_ratio": 1.7534883720930232,
      "no_speech_prob": 0.0009595141164027154
    },
    {
      "id": 245,
      "seek": 148360,
      "start": 1504.1599999999999,
      "end": 1510.56,
      "text": " for the different environments. So I think you could add clarity here if there's like a light",
      "tokens": [
        51392,
        337,
        264,
        819,
        12388,
        13,
        407,
        286,
        519,
        291,
        727,
        909,
        16992,
        510,
        498,
        456,
        311,
        411,
        257,
        1442,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10536651611328125,
      "compression_ratio": 1.7534883720930232,
      "no_speech_prob": 0.0009595141164027154
    },
    {
      "id": 246,
      "seek": 151056,
      "start": 1510.56,
      "end": 1516.72,
      "text": " touch way to even like allow people to dig into the different variables that are being used in",
      "tokens": [
        50364,
        2557,
        636,
        281,
        754,
        411,
        2089,
        561,
        281,
        2528,
        666,
        264,
        819,
        9102,
        300,
        366,
        885,
        1143,
        294,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09781909657415942,
      "compression_ratio": 1.7992565055762082,
      "no_speech_prob": 0.0003686839481815696
    },
    {
      "id": 247,
      "seek": 151056,
      "start": 1516.72,
      "end": 1523.04,
      "text": " different environments. I do I think that would help them and it feels like if we're going to do an",
      "tokens": [
        50672,
        819,
        12388,
        13,
        286,
        360,
        286,
        519,
        300,
        576,
        854,
        552,
        293,
        309,
        3417,
        411,
        498,
        321,
        434,
        516,
        281,
        360,
        364,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09781909657415942,
      "compression_ratio": 1.7992565055762082,
      "no_speech_prob": 0.0003686839481815696
    },
    {
      "id": 248,
      "seek": 151056,
      "start": 1523.04,
      "end": 1530.48,
      "text": " overview like that that that would be something to highlight or think about. I can definitely",
      "tokens": [
        50988,
        12492,
        411,
        300,
        300,
        300,
        576,
        312,
        746,
        281,
        5078,
        420,
        519,
        466,
        13,
        286,
        393,
        2138,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09781909657415942,
      "compression_ratio": 1.7992565055762082,
      "no_speech_prob": 0.0003686839481815696
    },
    {
      "id": 249,
      "seek": 151056,
      "start": 1530.48,
      "end": 1535.12,
      "text": " think into that I'm still in the process of trying to figure out what is the best information to",
      "tokens": [
        51360,
        519,
        666,
        300,
        286,
        478,
        920,
        294,
        264,
        1399,
        295,
        1382,
        281,
        2573,
        484,
        437,
        307,
        264,
        1151,
        1589,
        281,
        51592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09781909657415942,
      "compression_ratio": 1.7992565055762082,
      "no_speech_prob": 0.0003686839481815696
    },
    {
      "id": 250,
      "seek": 151056,
      "start": 1535.12,
      "end": 1540.08,
      "text": " show here what should be still cut out because some of this deployment information is just kind of",
      "tokens": [
        51592,
        855,
        510,
        437,
        820,
        312,
        920,
        1723,
        484,
        570,
        512,
        295,
        341,
        19317,
        1589,
        307,
        445,
        733,
        295,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09781909657415942,
      "compression_ratio": 1.7992565055762082,
      "no_speech_prob": 0.0003686839481815696
    },
    {
      "id": 251,
      "seek": 154008,
      "start": 1540.08,
      "end": 1546.24,
      "text": " copied over from the environment index page. So definitely want to do a bit more exploration on like",
      "tokens": [
        50364,
        25365,
        670,
        490,
        264,
        2823,
        8186,
        3028,
        13,
        407,
        2138,
        528,
        281,
        360,
        257,
        857,
        544,
        16197,
        322,
        411,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12335731365062573,
      "compression_ratio": 1.6325581395348838,
      "no_speech_prob": 8.706204971531406e-05
    },
    {
      "id": 252,
      "seek": 154008,
      "start": 1546.24,
      "end": 1550.96,
      "text": " is this the right amount of information and if there's additional information like you said the",
      "tokens": [
        50672,
        307,
        341,
        264,
        558,
        2372,
        295,
        1589,
        293,
        498,
        456,
        311,
        4497,
        1589,
        411,
        291,
        848,
        264,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12335731365062573,
      "compression_ratio": 1.6325581395348838,
      "no_speech_prob": 8.706204971531406e-05
    },
    {
      "id": 253,
      "seek": 154008,
      "start": 1550.96,
      "end": 1556.0,
      "text": " kind of secrets how do you show that here. So thanks for bringing that to my attention.",
      "tokens": [
        50908,
        733,
        295,
        14093,
        577,
        360,
        291,
        855,
        300,
        510,
        13,
        407,
        3231,
        337,
        5062,
        300,
        281,
        452,
        3202,
        13,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12335731365062573,
      "compression_ratio": 1.6325581395348838,
      "no_speech_prob": 8.706204971531406e-05
    },
    {
      "id": 254,
      "seek": 154008,
      "start": 1559.84,
      "end": 1564.8,
      "text": " Well thank you all for the feedback by the way I see Will is next.",
      "tokens": [
        51352,
        1042,
        1309,
        291,
        439,
        337,
        264,
        5824,
        538,
        264,
        636,
        286,
        536,
        3099,
        307,
        958,
        13,
        51600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12335731365062573,
      "compression_ratio": 1.6325581395348838,
      "no_speech_prob": 8.706204971531406e-05
    },
    {
      "id": 255,
      "seek": 156480,
      "start": 1564.8,
      "end": 1574.8,
      "text": " Yeah I think for the summary view some of the things that could be helpful is just being able to",
      "tokens": [
        50364,
        865,
        286,
        519,
        337,
        264,
        12691,
        1910,
        512,
        295,
        264,
        721,
        300,
        727,
        312,
        4961,
        307,
        445,
        885,
        1075,
        281,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09450470851017878,
      "compression_ratio": 1.653179190751445,
      "no_speech_prob": 0.002737295115366578
    },
    {
      "id": 256,
      "seek": 156480,
      "start": 1574.8,
      "end": 1582.3999999999999,
      "text": " identify not just like how many environments are in a successful status but also if there's ones",
      "tokens": [
        50864,
        5876,
        406,
        445,
        411,
        577,
        867,
        12388,
        366,
        294,
        257,
        4406,
        6558,
        457,
        611,
        498,
        456,
        311,
        2306,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09450470851017878,
      "compression_ratio": 1.653179190751445,
      "no_speech_prob": 0.002737295115366578
    },
    {
      "id": 257,
      "seek": 156480,
      "start": 1582.3999999999999,
      "end": 1588.8799999999999,
      "text": " that are like pending or if there are ones that are like failing or having some sort of like",
      "tokens": [
        51244,
        300,
        366,
        411,
        32110,
        420,
        498,
        456,
        366,
        2306,
        300,
        366,
        411,
        18223,
        420,
        1419,
        512,
        1333,
        295,
        411,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09450470851017878,
      "compression_ratio": 1.653179190751445,
      "no_speech_prob": 0.002737295115366578
    },
    {
      "id": 258,
      "seek": 158888,
      "start": 1588.96,
      "end": 1595.92,
      "text": " difficulties just so that people can like easily like click into those and be taken to those somehow",
      "tokens": [
        50368,
        14399,
        445,
        370,
        300,
        561,
        393,
        411,
        3612,
        411,
        2052,
        666,
        729,
        293,
        312,
        2726,
        281,
        729,
        6063,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1558186262845993,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.00042513609514571726
    },
    {
      "id": 259,
      "seek": 158888,
      "start": 1597.92,
      "end": 1606.5600000000002,
      "text": " and then also I like how in your design you're not like using that care at Sasha",
      "tokens": [
        50816,
        293,
        550,
        611,
        286,
        411,
        577,
        294,
        428,
        1715,
        291,
        434,
        406,
        411,
        1228,
        300,
        1127,
        412,
        29276,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1558186262845993,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.00042513609514571726
    },
    {
      "id": 260,
      "seek": 158888,
      "start": 1606.5600000000002,
      "end": 1614.0800000000002,
      "text": " Cordian style menu that that we currently have just because it's nice to be able to just see",
      "tokens": [
        51248,
        40267,
        952,
        3758,
        6510,
        300,
        300,
        321,
        4362,
        362,
        445,
        570,
        309,
        311,
        1481,
        281,
        312,
        1075,
        281,
        445,
        536,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1558186262845993,
      "compression_ratio": 1.5930232558139534,
      "no_speech_prob": 0.00042513609514571726
    },
    {
      "id": 261,
      "seek": 161408,
      "start": 1615.04,
      "end": 1622.48,
      "text": " some of the specific data that users were having to like really stumble around to try to find.",
      "tokens": [
        50412,
        512,
        295,
        264,
        2685,
        1412,
        300,
        5022,
        645,
        1419,
        281,
        411,
        534,
        41302,
        926,
        281,
        853,
        281,
        915,
        13,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1114478728350471,
      "compression_ratio": 1.6415929203539823,
      "no_speech_prob": 0.0010796349961310625
    },
    {
      "id": 262,
      "seek": 161408,
      "start": 1624.96,
      "end": 1629.76,
      "text": " Awesome yeah thank you that was kind of I know a lot of our research has shown those",
      "tokens": [
        50908,
        10391,
        1338,
        1309,
        291,
        300,
        390,
        733,
        295,
        286,
        458,
        257,
        688,
        295,
        527,
        2132,
        575,
        4898,
        729,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1114478728350471,
      "compression_ratio": 1.6415929203539823,
      "no_speech_prob": 0.0010796349961310625
    },
    {
      "id": 263,
      "seek": 161408,
      "start": 1629.76,
      "end": 1634.0,
      "text": " collapsible sections when you're trying to find a high level view of everything was just not",
      "tokens": [
        51148,
        16567,
        964,
        10863,
        562,
        291,
        434,
        1382,
        281,
        915,
        257,
        1090,
        1496,
        1910,
        295,
        1203,
        390,
        445,
        406,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1114478728350471,
      "compression_ratio": 1.6415929203539823,
      "no_speech_prob": 0.0010796349961310625
    },
    {
      "id": 264,
      "seek": 161408,
      "start": 1634.0,
      "end": 1639.12,
      "text": " working out right so I was trying my best not to even collapse any information and just if there's",
      "tokens": [
        51360,
        1364,
        484,
        558,
        370,
        286,
        390,
        1382,
        452,
        1151,
        406,
        281,
        754,
        15584,
        604,
        1589,
        293,
        445,
        498,
        456,
        311,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1114478728350471,
      "compression_ratio": 1.6415929203539823,
      "no_speech_prob": 0.0010796349961310625
    },
    {
      "id": 265,
      "seek": 163912,
      "start": 1639.12,
      "end": 1645.4399999999998,
      "text": " information you that needs to be hidden maybe it's not the right place to put it on this page so",
      "tokens": [
        50364,
        1589,
        291,
        300,
        2203,
        281,
        312,
        7633,
        1310,
        309,
        311,
        406,
        264,
        558,
        1081,
        281,
        829,
        309,
        322,
        341,
        3028,
        370,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30388692709115833,
      "compression_ratio": 1.6047619047619048,
      "no_speech_prob": 0.0006322042318060994
    },
    {
      "id": 266,
      "seek": 163912,
      "start": 1646.0,
      "end": 1653.6,
      "text": " appreciate and you're welcome. Then hi and I think you have the last comments.",
      "tokens": [
        50708,
        4449,
        293,
        291,
        434,
        2928,
        13,
        1396,
        4879,
        293,
        286,
        519,
        291,
        362,
        264,
        1036,
        3053,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30388692709115833,
      "compression_ratio": 1.6047619047619048,
      "no_speech_prob": 0.0006322042318060994
    },
    {
      "id": 267,
      "seek": 163912,
      "start": 1654.6399999999999,
      "end": 1661.04,
      "text": " Yeah so just post one on what we'll say about showing information without using that",
      "tokens": [
        51140,
        865,
        370,
        445,
        2183,
        472,
        322,
        437,
        321,
        603,
        584,
        466,
        4099,
        1589,
        1553,
        1228,
        300,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30388692709115833,
      "compression_ratio": 1.6047619047619048,
      "no_speech_prob": 0.0006322042318060994
    },
    {
      "id": 268,
      "seek": 163912,
      "start": 1662.0,
      "end": 1666.2399999999998,
      "text": " awful pattern of what you're expanding collapsing it just hides all the info",
      "tokens": [
        51508,
        11232,
        5102,
        295,
        437,
        291,
        434,
        14702,
        45339,
        309,
        445,
        35953,
        439,
        264,
        13614,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.30388692709115833,
      "compression_ratio": 1.6047619047619048,
      "no_speech_prob": 0.0006322042318060994
    },
    {
      "id": 269,
      "seek": 166624,
      "start": 1666.88,
      "end": 1672.56,
      "text": " that it's essential in this page pretty much in both in this case the group but also the",
      "tokens": [
        50396,
        300,
        309,
        311,
        7115,
        294,
        341,
        3028,
        1238,
        709,
        294,
        1293,
        294,
        341,
        1389,
        264,
        1594,
        457,
        611,
        264,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28748496537356033,
      "compression_ratio": 1.736842105263158,
      "no_speech_prob": 0.002761838026344776
    },
    {
      "id": 270,
      "seek": 166624,
      "start": 1672.56,
      "end": 1677.52,
      "text": " the project level environments view and also plus one on the summary block I think this sort of",
      "tokens": [
        50680,
        264,
        1716,
        1496,
        12388,
        1910,
        293,
        611,
        1804,
        472,
        322,
        264,
        12691,
        3461,
        286,
        519,
        341,
        1333,
        295,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28748496537356033,
      "compression_ratio": 1.736842105263158,
      "no_speech_prob": 0.002761838026344776
    },
    {
      "id": 271,
      "seek": 166624,
      "start": 1677.52,
      "end": 1682.0,
      "text": " give users that add what understanding of how their environments are doing across the board",
      "tokens": [
        50928,
        976,
        5022,
        300,
        909,
        437,
        3701,
        295,
        577,
        641,
        12388,
        366,
        884,
        2108,
        264,
        3150,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28748496537356033,
      "compression_ratio": 1.736842105263158,
      "no_speech_prob": 0.002761838026344776
    },
    {
      "id": 272,
      "seek": 166624,
      "start": 1682.0,
      "end": 1688.64,
      "text": " and that's important of course not only for the developers but you know the managers the",
      "tokens": [
        51152,
        293,
        300,
        311,
        1021,
        295,
        1164,
        406,
        787,
        337,
        264,
        8849,
        457,
        291,
        458,
        264,
        14084,
        264,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28748496537356033,
      "compression_ratio": 1.736842105263158,
      "no_speech_prob": 0.002761838026344776
    },
    {
      "id": 273,
      "seek": 166624,
      "start": 1688.64,
      "end": 1693.68,
      "text": " the director of buyer percent anyways anyone really that is interested in how the application is",
      "tokens": [
        51484,
        264,
        5391,
        295,
        24645,
        3043,
        13448,
        2878,
        534,
        300,
        307,
        3102,
        294,
        577,
        264,
        3861,
        307,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28748496537356033,
      "compression_ratio": 1.736842105263158,
      "no_speech_prob": 0.002761838026344776
    },
    {
      "id": 274,
      "seek": 169368,
      "start": 1693.76,
      "end": 1700.0,
      "text": " doing at the higher level so I think that's that's going to be a great addition addition",
      "tokens": [
        50368,
        884,
        412,
        264,
        2946,
        1496,
        370,
        286,
        519,
        300,
        311,
        300,
        311,
        516,
        281,
        312,
        257,
        869,
        4500,
        4500,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2104292388009553,
      "compression_ratio": 1.8185483870967742,
      "no_speech_prob": 0.0005910802283324301
    },
    {
      "id": 275,
      "seek": 169368,
      "start": 1701.6000000000001,
      "end": 1705.68,
      "text": " and I have a couple of follow-up questions Emily and I'm sure if you have the time but you know",
      "tokens": [
        50760,
        293,
        286,
        362,
        257,
        1916,
        295,
        1524,
        12,
        1010,
        1651,
        15034,
        293,
        286,
        478,
        988,
        498,
        291,
        362,
        264,
        565,
        457,
        291,
        458,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2104292388009553,
      "compression_ratio": 1.8185483870967742,
      "no_speech_prob": 0.0005910802283324301
    },
    {
      "id": 276,
      "seek": 169368,
      "start": 1705.68,
      "end": 1709.28,
      "text": " I think those those are just the things I was thinking of while looking at the prototypes",
      "tokens": [
        50964,
        286,
        519,
        729,
        729,
        366,
        445,
        264,
        721,
        286,
        390,
        1953,
        295,
        1339,
        1237,
        412,
        264,
        42197,
        51144
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2104292388009553,
      "compression_ratio": 1.8185483870967742,
      "no_speech_prob": 0.0005910802283324301
    },
    {
      "id": 277,
      "seek": 169368,
      "start": 1710.72,
      "end": 1717.04,
      "text": " what type of environments will be displayed on this overview just like the protected environments",
      "tokens": [
        51216,
        437,
        2010,
        295,
        12388,
        486,
        312,
        16372,
        322,
        341,
        12492,
        445,
        411,
        264,
        10594,
        12388,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2104292388009553,
      "compression_ratio": 1.8185483870967742,
      "no_speech_prob": 0.0005910802283324301
    },
    {
      "id": 278,
      "seek": 169368,
      "start": 1717.04,
      "end": 1721.52,
      "text": " production only and also I was wondering how would users set up this overview.",
      "tokens": [
        51532,
        4265,
        787,
        293,
        611,
        286,
        390,
        6359,
        577,
        576,
        5022,
        992,
        493,
        341,
        12492,
        13,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2104292388009553,
      "compression_ratio": 1.8185483870967742,
      "no_speech_prob": 0.0005910802283324301
    },
    {
      "id": 279,
      "seek": 172152,
      "start": 1722.48,
      "end": 1727.52,
      "text": " Has the team considered if this would be something that would be just pre-populated you know coming",
      "tokens": [
        50412,
        8646,
        264,
        1469,
        4888,
        498,
        341,
        576,
        312,
        746,
        300,
        576,
        312,
        445,
        659,
        12,
        13872,
        6987,
        291,
        458,
        1348,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1931478500366211,
      "compression_ratio": 1.6150627615062763,
      "no_speech_prob": 0.0007138099754229188
    },
    {
      "id": 280,
      "seek": 172152,
      "start": 1727.52,
      "end": 1734.8799999999999,
      "text": " from all the projects that have the have the environments that meet a specific criteria or",
      "tokens": [
        50664,
        490,
        439,
        264,
        4455,
        300,
        362,
        264,
        362,
        264,
        12388,
        300,
        1677,
        257,
        2685,
        11101,
        420,
        51032
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1931478500366211,
      "compression_ratio": 1.6150627615062763,
      "no_speech_prob": 0.0007138099754229188
    },
    {
      "id": 281,
      "seek": 172152,
      "start": 1734.8799999999999,
      "end": 1741.04,
      "text": " we users be able to let's say manage and customize that view based on what's important for them to",
      "tokens": [
        51032,
        321,
        5022,
        312,
        1075,
        281,
        718,
        311,
        584,
        3067,
        293,
        19734,
        300,
        1910,
        2361,
        322,
        437,
        311,
        1021,
        337,
        552,
        281,
        51340
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1931478500366211,
      "compression_ratio": 1.6150627615062763,
      "no_speech_prob": 0.0007138099754229188
    },
    {
      "id": 282,
      "seek": 172152,
      "start": 1741.04,
      "end": 1747.44,
      "text": " see you know for each project. Yeah so this is a good question for MVC we've really landed on we",
      "tokens": [
        51340,
        536,
        291,
        458,
        337,
        1184,
        1716,
        13,
        865,
        370,
        341,
        307,
        257,
        665,
        1168,
        337,
        17663,
        34,
        321,
        600,
        534,
        15336,
        322,
        321,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1931478500366211,
      "compression_ratio": 1.6150627615062763,
      "no_speech_prob": 0.0007138099754229188
    },
    {
      "id": 283,
      "seek": 174744,
      "start": 1747.44,
      "end": 1754.16,
      "text": " want to show just production tier environments and then figuring out later we'll need to scale",
      "tokens": [
        50364,
        528,
        281,
        855,
        445,
        4265,
        12362,
        12388,
        293,
        550,
        15213,
        484,
        1780,
        321,
        603,
        643,
        281,
        4373,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06831084500561964,
      "compression_ratio": 1.8937007874015748,
      "no_speech_prob": 0.00012211332796141505
    },
    {
      "id": 284,
      "seek": 174744,
      "start": 1754.16,
      "end": 1760.0800000000002,
      "text": " this up to show the different tiers but kind of pre-populate this based on like tier of environments",
      "tokens": [
        50700,
        341,
        493,
        281,
        855,
        264,
        819,
        40563,
        457,
        733,
        295,
        659,
        12,
        13872,
        5256,
        341,
        2361,
        322,
        411,
        12362,
        295,
        12388,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06831084500561964,
      "compression_ratio": 1.8937007874015748,
      "no_speech_prob": 0.00012211332796141505
    },
    {
      "id": 285,
      "seek": 174744,
      "start": 1760.64,
      "end": 1764.96,
      "text": " this is actually where the empty state comes in I don't think I'm the one that designed the",
      "tokens": [
        51024,
        341,
        307,
        767,
        689,
        264,
        6707,
        1785,
        1487,
        294,
        286,
        500,
        380,
        519,
        286,
        478,
        264,
        472,
        300,
        4761,
        264,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06831084500561964,
      "compression_ratio": 1.8937007874015748,
      "no_speech_prob": 0.00012211332796141505
    },
    {
      "id": 286,
      "seek": 174744,
      "start": 1764.96,
      "end": 1770.0800000000002,
      "text": " empty state I kind of grabbed it from one of the others but if you don't aren't using environment",
      "tokens": [
        51240,
        6707,
        1785,
        286,
        733,
        295,
        18607,
        309,
        490,
        472,
        295,
        264,
        2357,
        457,
        498,
        291,
        500,
        380,
        3212,
        380,
        1228,
        2823,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06831084500561964,
      "compression_ratio": 1.8937007874015748,
      "no_speech_prob": 0.00012211332796141505
    },
    {
      "id": 287,
      "seek": 174744,
      "start": 1770.0800000000002,
      "end": 1775.92,
      "text": " tiers using this empty state to kind of encourage users to kind of set that up so that they can",
      "tokens": [
        51496,
        40563,
        1228,
        341,
        6707,
        1785,
        281,
        733,
        295,
        5373,
        5022,
        281,
        733,
        295,
        992,
        300,
        493,
        370,
        300,
        436,
        393,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06831084500561964,
      "compression_ratio": 1.8937007874015748,
      "no_speech_prob": 0.00012211332796141505
    },
    {
      "id": 288,
      "seek": 177592,
      "start": 1776.0,
      "end": 1782.24,
      "text": " pre-populate this page but also use this feature which we don't have any area now where we're really",
      "tokens": [
        50368,
        659,
        12,
        13872,
        5256,
        341,
        3028,
        457,
        611,
        764,
        341,
        4111,
        597,
        321,
        500,
        380,
        362,
        604,
        1859,
        586,
        689,
        321,
        434,
        534,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06834424775222252,
      "compression_ratio": 1.6883116883116882,
      "no_speech_prob": 0.00011700854520313442
    },
    {
      "id": 289,
      "seek": 177592,
      "start": 1782.24,
      "end": 1787.6000000000001,
      "text": " encouraging them to do so so having the empty state is both a bonus of setting up this but also",
      "tokens": [
        50680,
        14580,
        552,
        281,
        360,
        370,
        370,
        1419,
        264,
        6707,
        1785,
        307,
        1293,
        257,
        10882,
        295,
        3287,
        493,
        341,
        457,
        611,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06834424775222252,
      "compression_ratio": 1.6883116883116882,
      "no_speech_prob": 0.00011700854520313442
    },
    {
      "id": 290,
      "seek": 177592,
      "start": 1787.6000000000001,
      "end": 1794.16,
      "text": " encouraging people to use environment tiers so hopefully that answers your question for MVC we",
      "tokens": [
        50948,
        14580,
        561,
        281,
        764,
        2823,
        40563,
        370,
        4696,
        300,
        6338,
        428,
        1168,
        337,
        17663,
        34,
        321,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06834424775222252,
      "compression_ratio": 1.6883116883116882,
      "no_speech_prob": 0.00011700854520313442
    },
    {
      "id": 291,
      "seek": 177592,
      "start": 1794.16,
      "end": 1799.68,
      "text": " are just going to stick with production tier environments and to set it up would be enabling tiers",
      "tokens": [
        51276,
        366,
        445,
        516,
        281,
        2897,
        365,
        4265,
        12362,
        12388,
        293,
        281,
        992,
        309,
        493,
        576,
        312,
        23148,
        40563,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06834424775222252,
      "compression_ratio": 1.6883116883116882,
      "no_speech_prob": 0.00011700854520313442
    },
    {
      "id": 292,
      "seek": 179968,
      "start": 1799.76,
      "end": 1803.3600000000001,
      "text": " in your environments to show them pre-populated on this page.",
      "tokens": [
        50368,
        294,
        428,
        12388,
        281,
        855,
        552,
        659,
        12,
        13872,
        6987,
        322,
        341,
        3028,
        13,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1500008076797297,
      "compression_ratio": 1.5898617511520738,
      "no_speech_prob": 0.00013998488429933786
    },
    {
      "id": 293,
      "seek": 179968,
      "start": 1804.8,
      "end": 1811.3600000000001,
      "text": " Yeah thanks that answers my question I think following up to that and thinking about too",
      "tokens": [
        50620,
        865,
        3231,
        300,
        6338,
        452,
        1168,
        286,
        519,
        3480,
        493,
        281,
        300,
        293,
        1953,
        466,
        886,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1500008076797297,
      "compression_ratio": 1.5898617511520738,
      "no_speech_prob": 0.00013998488429933786
    },
    {
      "id": 294,
      "seek": 179968,
      "start": 1812.0800000000002,
      "end": 1820.3200000000002,
      "text": " is that when you have the chance look at how the MVC plus would look like because for example if",
      "tokens": [
        50984,
        307,
        300,
        562,
        291,
        362,
        264,
        2931,
        574,
        412,
        577,
        264,
        17663,
        34,
        1804,
        576,
        574,
        411,
        570,
        337,
        1365,
        498,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1500008076797297,
      "compression_ratio": 1.5898617511520738,
      "no_speech_prob": 0.00013998488429933786
    },
    {
      "id": 295,
      "seek": 179968,
      "start": 1820.3200000000002,
      "end": 1827.52,
      "text": " I'm not mistaken you can have multiple environments under the same tier right so if you set it up",
      "tokens": [
        51396,
        286,
        478,
        406,
        21333,
        291,
        393,
        362,
        3866,
        12388,
        833,
        264,
        912,
        12362,
        558,
        370,
        498,
        291,
        992,
        309,
        493,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1500008076797297,
      "compression_ratio": 1.5898617511520738,
      "no_speech_prob": 0.00013998488429933786
    },
    {
      "id": 296,
      "seek": 182752,
      "start": 1827.6,
      "end": 1832.48,
      "text": " in the CI file you can have I don't know different production environments,",
      "tokens": [
        50368,
        294,
        264,
        37777,
        3991,
        291,
        393,
        362,
        286,
        500,
        380,
        458,
        819,
        4265,
        12388,
        11,
        50612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16411958956250958,
      "compression_ratio": 1.8414634146341464,
      "no_speech_prob": 0.0005038999952375889
    },
    {
      "id": 297,
      "seek": 182752,
      "start": 1833.2,
      "end": 1838.0,
      "text": " label production but put a different name right so how would that look like in the UI how would",
      "tokens": [
        50648,
        7645,
        4265,
        457,
        829,
        257,
        819,
        1315,
        558,
        370,
        577,
        576,
        300,
        574,
        411,
        294,
        264,
        15682,
        577,
        576,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16411958956250958,
      "compression_ratio": 1.8414634146341464,
      "no_speech_prob": 0.0005038999952375889
    },
    {
      "id": 298,
      "seek": 182752,
      "start": 1838.0,
      "end": 1842.8,
      "text": " users customize so I think it would be a good step for you there to see how this page would grow",
      "tokens": [
        50888,
        5022,
        19734,
        370,
        286,
        519,
        309,
        576,
        312,
        257,
        665,
        1823,
        337,
        291,
        456,
        281,
        536,
        577,
        341,
        3028,
        576,
        1852,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16411958956250958,
      "compression_ratio": 1.8414634146341464,
      "no_speech_prob": 0.0005038999952375889
    },
    {
      "id": 299,
      "seek": 182752,
      "start": 1842.8,
      "end": 1846.16,
      "text": " uh because we're not the challenges that we had with the current environments pages that",
      "tokens": [
        51128,
        2232,
        570,
        321,
        434,
        406,
        264,
        4759,
        300,
        321,
        632,
        365,
        264,
        2190,
        12388,
        7183,
        300,
        51296
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16411958956250958,
      "compression_ratio": 1.8414634146341464,
      "no_speech_prob": 0.0005038999952375889
    },
    {
      "id": 300,
      "seek": 182752,
      "start": 1846.8799999999999,
      "end": 1852.8799999999999,
      "text": " while designing and also coding it we were not thinking of how that page would scale so I think",
      "tokens": [
        51332,
        1339,
        14685,
        293,
        611,
        17720,
        309,
        321,
        645,
        406,
        1953,
        295,
        577,
        300,
        3028,
        576,
        4373,
        370,
        286,
        519,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16411958956250958,
      "compression_ratio": 1.8414634146341464,
      "no_speech_prob": 0.0005038999952375889
    },
    {
      "id": 301,
      "seek": 185288,
      "start": 1852.88,
      "end": 1859.3600000000001,
      "text": " you have the the ability here to predict some of the edgegates but also to avoid you know",
      "tokens": [
        50364,
        291,
        362,
        264,
        264,
        3485,
        510,
        281,
        6069,
        512,
        295,
        264,
        4691,
        70,
        1024,
        457,
        611,
        281,
        5042,
        291,
        458,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16014923872771086,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 0.0008336072787642479
    },
    {
      "id": 302,
      "seek": 185288,
      "start": 1859.3600000000001,
      "end": 1863.5200000000002,
      "text": " I'm happy and happy bets in the UI in the overall UX.",
      "tokens": [
        50688,
        286,
        478,
        2055,
        293,
        2055,
        39922,
        294,
        264,
        15682,
        294,
        264,
        4787,
        40176,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16014923872771086,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 0.0008336072787642479
    },
    {
      "id": 303,
      "seek": 185288,
      "start": 1864.72,
      "end": 1869.2800000000002,
      "text": " Yeah for sure yeah that's something and where I'm early enough into the designs here now that I",
      "tokens": [
        50956,
        865,
        337,
        988,
        1338,
        300,
        311,
        746,
        293,
        689,
        286,
        478,
        2440,
        1547,
        666,
        264,
        11347,
        510,
        586,
        300,
        286,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16014923872771086,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 0.0008336072787642479
    },
    {
      "id": 304,
      "seek": 185288,
      "start": 1869.2800000000002,
      "end": 1873.6000000000001,
      "text": " have to kind of build out what does like unhealthy environments look like what happens when you have",
      "tokens": [
        51184,
        362,
        281,
        733,
        295,
        1322,
        484,
        437,
        775,
        411,
        29147,
        12388,
        574,
        411,
        437,
        2314,
        562,
        291,
        362,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16014923872771086,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 0.0008336072787642479
    },
    {
      "id": 305,
      "seek": 185288,
      "start": 1873.6000000000001,
      "end": 1878.24,
      "text": " like a lot on this page so I think we still have quite a bit of time to kind of build out all these",
      "tokens": [
        51400,
        411,
        257,
        688,
        322,
        341,
        3028,
        370,
        286,
        519,
        321,
        920,
        362,
        1596,
        257,
        857,
        295,
        565,
        281,
        733,
        295,
        1322,
        484,
        439,
        613,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16014923872771086,
      "compression_ratio": 1.746031746031746,
      "no_speech_prob": 0.0008336072787642479
    },
    {
      "id": 306,
      "seek": 187824,
      "start": 1878.24,
      "end": 1883.44,
      "text": " educations and then once we start showing more than just the production tier how do you set that",
      "tokens": [
        50364,
        2400,
        763,
        293,
        550,
        1564,
        321,
        722,
        4099,
        544,
        813,
        445,
        264,
        4265,
        12362,
        577,
        360,
        291,
        992,
        300,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14921588282431325,
      "compression_ratio": 1.6625,
      "no_speech_prob": 0.00019039917970076203
    },
    {
      "id": 307,
      "seek": 187824,
      "start": 1883.44,
      "end": 1888.8,
      "text": " up what does that view look like and everything like that so I think there's lots of work to be done",
      "tokens": [
        50624,
        493,
        437,
        775,
        300,
        1910,
        574,
        411,
        293,
        1203,
        411,
        300,
        370,
        286,
        519,
        456,
        311,
        3195,
        295,
        589,
        281,
        312,
        1096,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14921588282431325,
      "compression_ratio": 1.6625,
      "no_speech_prob": 0.00019039917970076203
    },
    {
      "id": 308,
      "seek": 187824,
      "start": 1888.8,
      "end": 1898.08,
      "text": " on this page but it'll be good work to finally get out to users. Yeah awesome and then my next point",
      "tokens": [
        50892,
        322,
        341,
        3028,
        457,
        309,
        603,
        312,
        665,
        589,
        281,
        2721,
        483,
        484,
        281,
        5022,
        13,
        865,
        3476,
        293,
        550,
        452,
        958,
        935,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14921588282431325,
      "compression_ratio": 1.6625,
      "no_speech_prob": 0.00019039917970076203
    },
    {
      "id": 309,
      "seek": 187824,
      "start": 1898.08,
      "end": 1904.88,
      "text": " is about that it seems like if you move forward with this approach right up for left environments we",
      "tokens": [
        51356,
        307,
        466,
        300,
        309,
        2544,
        411,
        498,
        291,
        1286,
        2128,
        365,
        341,
        3109,
        558,
        493,
        337,
        1411,
        12388,
        321,
        51696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14921588282431325,
      "compression_ratio": 1.6625,
      "no_speech_prob": 0.00019039917970076203
    },
    {
      "id": 310,
      "seek": 190488,
      "start": 1905.0400000000002,
      "end": 1911.92,
      "text": " could potentially deprecate the environment's dashboard view. What are the team discussions about it",
      "tokens": [
        50372,
        727,
        7263,
        1367,
        13867,
        473,
        264,
        2823,
        311,
        18342,
        1910,
        13,
        708,
        366,
        264,
        1469,
        11088,
        466,
        309,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1366807692641512,
      "compression_ratio": 1.7374100719424461,
      "no_speech_prob": 0.0003366136224940419
    },
    {
      "id": 311,
      "seek": 190488,
      "start": 1911.92,
      "end": 1917.68,
      "text": " if there's any discussion going on around deprecating or replacing the page if they were off this",
      "tokens": [
        50716,
        498,
        456,
        311,
        604,
        5017,
        516,
        322,
        926,
        1367,
        13867,
        990,
        420,
        19139,
        264,
        3028,
        498,
        436,
        645,
        766,
        341,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1366807692641512,
      "compression_ratio": 1.7374100719424461,
      "no_speech_prob": 0.0003366136224940419
    },
    {
      "id": 312,
      "seek": 190488,
      "start": 1917.68,
      "end": 1922.96,
      "text": " group view? Yeah so there hasn't been any like official conversations going on but I have",
      "tokens": [
        51004,
        1594,
        1910,
        30,
        865,
        370,
        456,
        6132,
        380,
        668,
        604,
        411,
        4783,
        7315,
        516,
        322,
        457,
        286,
        362,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1366807692641512,
      "compression_ratio": 1.7374100719424461,
      "no_speech_prob": 0.0003366136224940419
    },
    {
      "id": 313,
      "seek": 190488,
      "start": 1922.96,
      "end": 1929.2,
      "text": " chatted with like Andrew on the team of the reasons of moving away from it and just the performance",
      "tokens": [
        51268,
        417,
        32509,
        365,
        411,
        10110,
        322,
        264,
        1469,
        295,
        264,
        4112,
        295,
        2684,
        1314,
        490,
        309,
        293,
        445,
        264,
        3389,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1366807692641512,
      "compression_ratio": 1.7374100719424461,
      "no_speech_prob": 0.0003366136224940419
    },
    {
      "id": 314,
      "seek": 190488,
      "start": 1929.2,
      "end": 1934.64,
      "text": " issues on that page were so hard to sort out that that's kind of where this idea has come from",
      "tokens": [
        51580,
        2663,
        322,
        300,
        3028,
        645,
        370,
        1152,
        281,
        1333,
        484,
        300,
        300,
        311,
        733,
        295,
        689,
        341,
        1558,
        575,
        808,
        490,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1366807692641512,
      "compression_ratio": 1.7374100719424461,
      "no_speech_prob": 0.0003366136224940419
    },
    {
      "id": 315,
      "seek": 193464,
      "start": 1934.72,
      "end": 1940.0,
      "text": " and kind of like why we might be moving forward with this and some of the performance issues",
      "tokens": [
        50368,
        293,
        733,
        295,
        411,
        983,
        321,
        1062,
        312,
        2684,
        2128,
        365,
        341,
        293,
        512,
        295,
        264,
        3389,
        2663,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08841507933860601,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 7.920680218376219e-05
    },
    {
      "id": 316,
      "seek": 193464,
      "start": 1940.0,
      "end": 1946.3200000000002,
      "text": " are really hard to kind of solve for but I think we need like some written out kind of conversation",
      "tokens": [
        50632,
        366,
        534,
        1152,
        281,
        733,
        295,
        5039,
        337,
        457,
        286,
        519,
        321,
        643,
        411,
        512,
        3720,
        484,
        733,
        295,
        3761,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08841507933860601,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 7.920680218376219e-05
    },
    {
      "id": 317,
      "seek": 193464,
      "start": 1946.3200000000002,
      "end": 1951.76,
      "text": " with the PMs and everyone on that team to figure out is this a like a replacement can they work",
      "tokens": [
        50948,
        365,
        264,
        12499,
        82,
        293,
        1518,
        322,
        300,
        1469,
        281,
        2573,
        484,
        307,
        341,
        257,
        411,
        257,
        14419,
        393,
        436,
        589,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08841507933860601,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 7.920680218376219e-05
    },
    {
      "id": 318,
      "seek": 193464,
      "start": 1951.76,
      "end": 1958.96,
      "text": " together what are the main pros of this pros of the environment dashboard and really sort that",
      "tokens": [
        51220,
        1214,
        437,
        366,
        264,
        2135,
        6267,
        295,
        341,
        6267,
        295,
        264,
        2823,
        18342,
        293,
        534,
        1333,
        300,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08841507933860601,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 7.920680218376219e-05
    },
    {
      "id": 319,
      "seek": 195896,
      "start": 1958.96,
      "end": 1970.88,
      "text": " plan out as well. Awesome yeah I think that that would be you know a good I'm going to put that",
      "tokens": [
        50364,
        1393,
        484,
        382,
        731,
        13,
        10391,
        1338,
        286,
        519,
        300,
        300,
        576,
        312,
        291,
        458,
        257,
        665,
        286,
        478,
        516,
        281,
        829,
        300,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18883411586284637,
      "compression_ratio": 1.4942528735632183,
      "no_speech_prob": 0.001203935593366623
    },
    {
      "id": 320,
      "seek": 195896,
      "start": 1972.08,
      "end": 1978.8,
      "text": " justification right for deprecating or moving away from that environment dashboard view.",
      "tokens": [
        51020,
        31591,
        558,
        337,
        1367,
        13867,
        990,
        420,
        2684,
        1314,
        490,
        300,
        2823,
        18342,
        1910,
        13,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18883411586284637,
      "compression_ratio": 1.4942528735632183,
      "no_speech_prob": 0.001203935593366623
    },
    {
      "id": 321,
      "seek": 195896,
      "start": 1979.44,
      "end": 1984.8,
      "text": " There's no traffic there as far as I know and to your point there's so many",
      "tokens": [
        51388,
        821,
        311,
        572,
        6419,
        456,
        382,
        1400,
        382,
        286,
        458,
        293,
        281,
        428,
        935,
        456,
        311,
        370,
        867,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18883411586284637,
      "compression_ratio": 1.4942528735632183,
      "no_speech_prob": 0.001203935593366623
    },
    {
      "id": 322,
      "seek": 198480,
      "start": 1985.76,
      "end": 1998.3999999999999,
      "text": " restrictions in terms of the performance of that page that you know I would say if you can it",
      "tokens": [
        50412,
        14191,
        294,
        2115,
        295,
        264,
        3389,
        295,
        300,
        3028,
        300,
        291,
        458,
        286,
        576,
        584,
        498,
        291,
        393,
        309,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810670156327505,
      "compression_ratio": 1.6388888888888888,
      "no_speech_prob": 0.0012392484350129962
    },
    {
      "id": 323,
      "seek": 198480,
      "start": 1998.3999999999999,
      "end": 2003.04,
      "text": " also when you have the decisions and conversations with the team putting the proposal to right that how",
      "tokens": [
        51044,
        611,
        562,
        291,
        362,
        264,
        5327,
        293,
        7315,
        365,
        264,
        1469,
        3372,
        264,
        11494,
        281,
        558,
        300,
        577,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810670156327505,
      "compression_ratio": 1.6388888888888888,
      "no_speech_prob": 0.0012392484350129962
    },
    {
      "id": 324,
      "seek": 198480,
      "start": 2003.04,
      "end": 2009.12,
      "text": " this page will work potentially solve the jobs we don't solve the problems that the environment's",
      "tokens": [
        51276,
        341,
        3028,
        486,
        589,
        7263,
        5039,
        264,
        4782,
        321,
        500,
        380,
        5039,
        264,
        2740,
        300,
        264,
        2823,
        311,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2810670156327505,
      "compression_ratio": 1.6388888888888888,
      "no_speech_prob": 0.0012392484350129962
    },
    {
      "id": 325,
      "seek": 200912,
      "start": 2009.6,
      "end": 2021.12,
      "text": " dashboard view does not solve right. Thank you and then no sorry go ahead. No I just",
      "tokens": [
        50388,
        18342,
        1910,
        775,
        406,
        5039,
        558,
        13,
        1044,
        291,
        293,
        550,
        572,
        2597,
        352,
        2286,
        13,
        883,
        286,
        445,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23305816650390626,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0007684141164645553
    },
    {
      "id": 326,
      "seek": 200912,
      "start": 2021.12,
      "end": 2026.1599999999999,
      "text": " say thank you that's like something I definitely have to think on so we'll get that written up.",
      "tokens": [
        50964,
        584,
        1309,
        291,
        300,
        311,
        411,
        746,
        286,
        2138,
        362,
        281,
        519,
        322,
        370,
        321,
        603,
        483,
        300,
        3720,
        493,
        13,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23305816650390626,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0007684141164645553
    },
    {
      "id": 327,
      "seek": 200912,
      "start": 2027.6799999999998,
      "end": 2034.1599999999999,
      "text": " Awesome and then my last thing back is just about the UI and then if I let me zoom in here yeah",
      "tokens": [
        51292,
        10391,
        293,
        550,
        452,
        1036,
        551,
        646,
        307,
        445,
        466,
        264,
        15682,
        293,
        550,
        498,
        286,
        718,
        385,
        8863,
        294,
        510,
        1338,
        51616
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23305816650390626,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0007684141164645553
    },
    {
      "id": 328,
      "seek": 203416,
      "start": 2034.88,
      "end": 2044.16,
      "text": " um when I did the validation for the environment's uh uh page right um I learned that uh that information",
      "tokens": [
        50400,
        1105,
        562,
        286,
        630,
        264,
        24071,
        337,
        264,
        2823,
        311,
        2232,
        2232,
        3028,
        558,
        1105,
        286,
        3264,
        300,
        2232,
        300,
        1589,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1736972445533389,
      "compression_ratio": 1.8151658767772512,
      "no_speech_prob": 0.001707347109913826
    },
    {
      "id": 329,
      "seek": 203416,
      "start": 2044.16,
      "end": 2050.64,
      "text": " about the commit message it's irrelevant to users or it's usually irrelevant when that commit",
      "tokens": [
        50864,
        466,
        264,
        5599,
        3636,
        309,
        311,
        28682,
        281,
        5022,
        420,
        309,
        311,
        2673,
        28682,
        562,
        300,
        5599,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1736972445533389,
      "compression_ratio": 1.8151658767772512,
      "no_speech_prob": 0.001707347109913826
    },
    {
      "id": 330,
      "seek": 203416,
      "start": 2050.64,
      "end": 2056.4,
      "text": " is merging or branch or anything into master because it often shows that same you know the",
      "tokens": [
        51188,
        307,
        44559,
        420,
        9819,
        420,
        1340,
        666,
        4505,
        570,
        309,
        2049,
        3110,
        300,
        912,
        291,
        458,
        264,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1736972445533389,
      "compression_ratio": 1.8151658767772512,
      "no_speech_prob": 0.001707347109913826
    },
    {
      "id": 331,
      "seek": 203416,
      "start": 2056.4,
      "end": 2062.56,
      "text": " folk message merge branch and then branch name and that's not readable and that's not a very",
      "tokens": [
        51476,
        15748,
        3636,
        22183,
        9819,
        293,
        550,
        9819,
        1315,
        293,
        300,
        311,
        406,
        49857,
        293,
        300,
        311,
        406,
        257,
        588,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1736972445533389,
      "compression_ratio": 1.8151658767772512,
      "no_speech_prob": 0.001707347109913826
    },
    {
      "id": 332,
      "seek": 206256,
      "start": 2062.56,
      "end": 2072.32,
      "text": " informative to users um so my feedback here would be like check in the um the insights I don't",
      "tokens": [
        50364,
        27759,
        281,
        5022,
        1105,
        370,
        452,
        5824,
        510,
        576,
        312,
        411,
        1520,
        294,
        264,
        1105,
        264,
        14310,
        286,
        500,
        380,
        50852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12399039871391208,
      "compression_ratio": 1.7660550458715596,
      "no_speech_prob": 0.0003764088323805481
    },
    {
      "id": 333,
      "seek": 206256,
      "start": 2072.32,
      "end": 2077.12,
      "text": " remember correctly now what what's the most relevant information that that we should be displaying",
      "tokens": [
        50852,
        1604,
        8944,
        586,
        437,
        437,
        311,
        264,
        881,
        7340,
        1589,
        300,
        300,
        321,
        820,
        312,
        36834,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12399039871391208,
      "compression_ratio": 1.7660550458715596,
      "no_speech_prob": 0.0003764088323805481
    },
    {
      "id": 334,
      "seek": 206256,
      "start": 2077.12,
      "end": 2085.12,
      "text": " here to users and see how you know and if it could be um if it could replace the merge branch",
      "tokens": [
        51092,
        510,
        281,
        5022,
        293,
        536,
        577,
        291,
        458,
        293,
        498,
        309,
        727,
        312,
        1105,
        498,
        309,
        727,
        7406,
        264,
        22183,
        9819,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12399039871391208,
      "compression_ratio": 1.7660550458715596,
      "no_speech_prob": 0.0003764088323805481
    },
    {
      "id": 335,
      "seek": 206256,
      "start": 2085.12,
      "end": 2090.24,
      "text": " message um because that's what we have today in the environment's page it's just the same message",
      "tokens": [
        51492,
        3636,
        1105,
        570,
        300,
        311,
        437,
        321,
        362,
        965,
        294,
        264,
        2823,
        311,
        3028,
        309,
        311,
        445,
        264,
        912,
        3636,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12399039871391208,
      "compression_ratio": 1.7660550458715596,
      "no_speech_prob": 0.0003764088323805481
    },
    {
      "id": 336,
      "seek": 209024,
      "start": 2090.3199999999997,
      "end": 2097.12,
      "text": " everywhere with the link um and there's already so much I think you can use that space um in",
      "tokens": [
        50368,
        5315,
        365,
        264,
        2113,
        1105,
        293,
        456,
        311,
        1217,
        370,
        709,
        286,
        519,
        291,
        393,
        764,
        300,
        1901,
        1105,
        294,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14194204496300739,
      "compression_ratio": 1.7366071428571428,
      "no_speech_prob": 0.001133690238930285
    },
    {
      "id": 337,
      "seek": 209024,
      "start": 2097.12,
      "end": 2105.52,
      "text": " uh in a in a more a different way rather than just showing this message yeah I agree I think there's",
      "tokens": [
        50708,
        2232,
        294,
        257,
        294,
        257,
        544,
        257,
        819,
        636,
        2831,
        813,
        445,
        4099,
        341,
        3636,
        1338,
        286,
        3986,
        286,
        519,
        456,
        311,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14194204496300739,
      "compression_ratio": 1.7366071428571428,
      "no_speech_prob": 0.001133690238930285
    },
    {
      "id": 338,
      "seek": 209024,
      "start": 2105.52,
      "end": 2112.0,
      "text": " stuff we can especially that if we can save real estate on anything in this page and take out uh",
      "tokens": [
        51128,
        1507,
        321,
        393,
        2318,
        300,
        498,
        321,
        393,
        3155,
        957,
        9749,
        322,
        1340,
        294,
        341,
        3028,
        293,
        747,
        484,
        2232,
        51452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14194204496300739,
      "compression_ratio": 1.7366071428571428,
      "no_speech_prob": 0.001133690238930285
    },
    {
      "id": 339,
      "seek": 209024,
      "start": 2112.0,
      "end": 2116.72,
      "text": " things that they don't need at this viewpoint um something I'm working towards right now so that's",
      "tokens": [
        51452,
        721,
        300,
        436,
        500,
        380,
        643,
        412,
        341,
        35248,
        1105,
        746,
        286,
        478,
        1364,
        3030,
        558,
        586,
        370,
        300,
        311,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14194204496300739,
      "compression_ratio": 1.7366071428571428,
      "no_speech_prob": 0.001133690238930285
    },
    {
      "id": 340,
      "seek": 211672,
      "start": 2116.72,
      "end": 2124.7999999999997,
      "text": " great to know that's something we can potentially take out of this awesome well thanks everyone",
      "tokens": [
        50364,
        869,
        281,
        458,
        300,
        311,
        746,
        321,
        393,
        7263,
        747,
        484,
        295,
        341,
        3476,
        731,
        3231,
        1518,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10707031294356945,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.00018614900182001293
    },
    {
      "id": 341,
      "seek": 211672,
      "start": 2124.7999999999997,
      "end": 2129.9199999999996,
      "text": " for your feedback I want to give Gina enough time for her points as well but I appreciate uh",
      "tokens": [
        50768,
        337,
        428,
        5824,
        286,
        528,
        281,
        976,
        34711,
        1547,
        565,
        337,
        720,
        2793,
        382,
        731,
        457,
        286,
        4449,
        2232,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10707031294356945,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.00018614900182001293
    },
    {
      "id": 342,
      "seek": 211672,
      "start": 2129.9199999999996,
      "end": 2137.2,
      "text": " kind of taking the time to let me walk through that so thanks Emily I have one other question",
      "tokens": [
        51024,
        733,
        295,
        1940,
        264,
        565,
        281,
        718,
        385,
        1792,
        807,
        300,
        370,
        3231,
        15034,
        286,
        362,
        472,
        661,
        1168,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10707031294356945,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.00018614900182001293
    },
    {
      "id": 343,
      "seek": 211672,
      "start": 2137.2,
      "end": 2145.68,
      "text": " for you I noticed that the the way that you were like for each row there was kind of like many",
      "tokens": [
        51388,
        337,
        291,
        286,
        5694,
        300,
        264,
        264,
        636,
        300,
        291,
        645,
        411,
        337,
        1184,
        5386,
        456,
        390,
        733,
        295,
        411,
        867,
        51812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10707031294356945,
      "compression_ratio": 1.7058823529411764,
      "no_speech_prob": 0.00018614900182001293
    },
    {
      "id": 344,
      "seek": 214568,
      "start": 2145.68,
      "end": 2152.56,
      "text": " columns of metadata in there like the job like all that's up have you heard I got any feedback",
      "tokens": [
        50364,
        13766,
        295,
        26603,
        294,
        456,
        411,
        264,
        1691,
        411,
        439,
        300,
        311,
        493,
        362,
        291,
        2198,
        286,
        658,
        604,
        5824,
        50708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09961339329065902,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.00026045399135909975
    },
    {
      "id": 345,
      "seek": 214568,
      "start": 2152.56,
      "end": 2162.08,
      "text": " around how that impacts like scanability I guess across different deployments yeah because it is",
      "tokens": [
        50708,
        926,
        577,
        300,
        11606,
        411,
        11049,
        2310,
        286,
        2041,
        2108,
        819,
        7274,
        1117,
        1338,
        570,
        309,
        307,
        51184
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09961339329065902,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.00026045399135909975
    },
    {
      "id": 346,
      "seek": 214568,
      "start": 2162.08,
      "end": 2168.24,
      "text": " a lot of information so as like a side note I've kind of added these in here to this I'm still",
      "tokens": [
        51184,
        257,
        688,
        295,
        1589,
        370,
        382,
        411,
        257,
        1252,
        3637,
        286,
        600,
        733,
        295,
        3869,
        613,
        294,
        510,
        281,
        341,
        286,
        478,
        920,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09961339329065902,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.00026045399135909975
    },
    {
      "id": 347,
      "seek": 214568,
      "start": 2168.24,
      "end": 2173.04,
      "text": " considering it like a low fidelity I've just added in what we have on the environment index page",
      "tokens": [
        51492,
        8079,
        309,
        411,
        257,
        2295,
        46404,
        286,
        600,
        445,
        3869,
        294,
        437,
        321,
        362,
        322,
        264,
        2823,
        8186,
        3028,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09961339329065902,
      "compression_ratio": 1.6508620689655173,
      "no_speech_prob": 0.00026045399135909975
    },
    {
      "id": 348,
      "seek": 217304,
      "start": 2173.12,
      "end": 2177.7599999999998,
      "text": " and I'm planning in like the next version of this to kind of go through see what information",
      "tokens": [
        50368,
        293,
        286,
        478,
        5038,
        294,
        411,
        264,
        958,
        3037,
        295,
        341,
        281,
        733,
        295,
        352,
        807,
        536,
        437,
        1589,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07074211245385285,
      "compression_ratio": 1.8202247191011236,
      "no_speech_prob": 0.0004101807717233896
    },
    {
      "id": 349,
      "seek": 217304,
      "start": 2177.7599999999998,
      "end": 2184.16,
      "text": " we can remove from there see what information is like the most important um based on conversation",
      "tokens": [
        50600,
        321,
        393,
        4159,
        490,
        456,
        536,
        437,
        1589,
        307,
        411,
        264,
        881,
        1021,
        1105,
        2361,
        322,
        3761,
        50920
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07074211245385285,
      "compression_ratio": 1.8202247191011236,
      "no_speech_prob": 0.0004101807717233896
    },
    {
      "id": 350,
      "seek": 217304,
      "start": 2184.16,
      "end": 2189.6,
      "text": " with the engineers to kind of for MVC start with what we have and kind of take away from that if",
      "tokens": [
        50920,
        365,
        264,
        11955,
        281,
        733,
        295,
        337,
        17663,
        34,
        722,
        365,
        437,
        321,
        362,
        293,
        733,
        295,
        747,
        1314,
        490,
        300,
        498,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07074211245385285,
      "compression_ratio": 1.8202247191011236,
      "no_speech_prob": 0.0004101807717233896
    },
    {
      "id": 351,
      "seek": 217304,
      "start": 2189.6,
      "end": 2195.12,
      "text": " possible just so we can reuse some components so yeah I agree those sections I think need a bit of",
      "tokens": [
        51192,
        1944,
        445,
        370,
        321,
        393,
        26225,
        512,
        6677,
        370,
        1338,
        286,
        3986,
        729,
        10863,
        286,
        519,
        643,
        257,
        857,
        295,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07074211245385285,
      "compression_ratio": 1.8202247191011236,
      "no_speech_prob": 0.0004101807717233896
    },
    {
      "id": 352,
      "seek": 217304,
      "start": 2195.12,
      "end": 2201.84,
      "text": " cleaning up and figuring out what exact information should be placed there um like the merge branch",
      "tokens": [
        51468,
        8924,
        493,
        293,
        15213,
        484,
        437,
        1900,
        1589,
        820,
        312,
        7074,
        456,
        1105,
        411,
        264,
        22183,
        9819,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07074211245385285,
      "compression_ratio": 1.8202247191011236,
      "no_speech_prob": 0.0004101807717233896
    },
    {
      "id": 353,
      "seek": 220184,
      "start": 2202.32,
      "end": 2208.2400000000002,
      "text": " message taking that away but yeah I agree I think there's some simplification we can still do in that area",
      "tokens": [
        50388,
        3636,
        1940,
        300,
        1314,
        457,
        1338,
        286,
        3986,
        286,
        519,
        456,
        311,
        512,
        6883,
        3774,
        321,
        393,
        920,
        360,
        294,
        300,
        1859,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10844014638877776,
      "compression_ratio": 1.7339901477832513,
      "no_speech_prob": 0.0002636494464240968
    },
    {
      "id": 354,
      "seek": 220184,
      "start": 2209.84,
      "end": 2216.32,
      "text": " yeah I'd be like if you end up testing this I would be interested in seeing if people say",
      "tokens": [
        50764,
        1338,
        286,
        1116,
        312,
        411,
        498,
        291,
        917,
        493,
        4997,
        341,
        286,
        576,
        312,
        3102,
        294,
        2577,
        498,
        561,
        584,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10844014638877776,
      "compression_ratio": 1.7339901477832513,
      "no_speech_prob": 0.0002636494464240968
    },
    {
      "id": 355,
      "seek": 220184,
      "start": 2217.28,
      "end": 2222.1600000000003,
      "text": " like if they if they want to scan I guess my column like does",
      "tokens": [
        51136,
        411,
        498,
        436,
        498,
        436,
        528,
        281,
        11049,
        286,
        2041,
        452,
        7738,
        411,
        775,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10844014638877776,
      "compression_ratio": 1.7339901477832513,
      "no_speech_prob": 0.0002636494464240968
    },
    {
      "id": 356,
      "seek": 220184,
      "start": 2223.36,
      "end": 2228.7200000000003,
      "text": " formatting the information in that way impacts that because I mean we're doing that in runner",
      "tokens": [
        51440,
        39366,
        264,
        1589,
        294,
        300,
        636,
        11606,
        300,
        570,
        286,
        914,
        321,
        434,
        884,
        300,
        294,
        24376,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10844014638877776,
      "compression_ratio": 1.7339901477832513,
      "no_speech_prob": 0.0002636494464240968
    },
    {
      "id": 357,
      "seek": 222872,
      "start": 2228.72,
      "end": 2234.64,
      "text": " and there have been like two or two customers who have been like I don't I don't want to see it in",
      "tokens": [
        50364,
        293,
        456,
        362,
        668,
        411,
        732,
        420,
        732,
        4581,
        567,
        362,
        668,
        411,
        286,
        500,
        380,
        286,
        500,
        380,
        528,
        281,
        536,
        309,
        294,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09461944103240967,
      "compression_ratio": 1.8352490421455938,
      "no_speech_prob": 0.00034897320438176394
    },
    {
      "id": 358,
      "seek": 222872,
      "start": 2234.64,
      "end": 2239.7599999999998,
      "text": " this list view I'd rather see it in a table but the majority have been saying it's fine to see it",
      "tokens": [
        50660,
        341,
        1329,
        1910,
        286,
        1116,
        2831,
        536,
        309,
        294,
        257,
        3199,
        457,
        264,
        6286,
        362,
        668,
        1566,
        309,
        311,
        2489,
        281,
        536,
        309,
        50916
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09461944103240967,
      "compression_ratio": 1.8352490421455938,
      "no_speech_prob": 0.00034897320438176394
    },
    {
      "id": 359,
      "seek": 222872,
      "start": 2239.7599999999998,
      "end": 2247.4399999999996,
      "text": " in the way that it is um but the view I that we're using is very similar so I think the insights",
      "tokens": [
        50916,
        294,
        264,
        636,
        300,
        309,
        307,
        1105,
        457,
        264,
        1910,
        286,
        300,
        321,
        434,
        1228,
        307,
        588,
        2531,
        370,
        286,
        519,
        264,
        14310,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09461944103240967,
      "compression_ratio": 1.8352490421455938,
      "no_speech_prob": 0.00034897320438176394
    },
    {
      "id": 360,
      "seek": 222872,
      "start": 2247.4399999999996,
      "end": 2252.0,
      "text": " would carry over to the list well good to know and yeah I'm planning to run this through some",
      "tokens": [
        51300,
        576,
        3985,
        670,
        281,
        264,
        1329,
        731,
        665,
        281,
        458,
        293,
        1338,
        286,
        478,
        5038,
        281,
        1190,
        341,
        807,
        512,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09461944103240967,
      "compression_ratio": 1.8352490421455938,
      "no_speech_prob": 0.00034897320438176394
    },
    {
      "id": 361,
      "seek": 222872,
      "start": 2252.0,
      "end": 2256.56,
      "text": " solution validation as well when we have a more finalized design because there's such a big",
      "tokens": [
        51528,
        3827,
        24071,
        382,
        731,
        562,
        321,
        362,
        257,
        544,
        2572,
        1602,
        1715,
        570,
        456,
        311,
        1270,
        257,
        955,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09461944103240967,
      "compression_ratio": 1.8352490421455938,
      "no_speech_prob": 0.00034897320438176394
    },
    {
      "id": 362,
      "seek": 225656,
      "start": 2257.12,
      "end": 2261.7599999999998,
      "text": " lift to do so hopefully we'll get some of the usability comments from that as well",
      "tokens": [
        50392,
        5533,
        281,
        360,
        370,
        4696,
        321,
        603,
        483,
        512,
        295,
        264,
        46878,
        3053,
        490,
        300,
        382,
        731,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09909750401288614,
      "compression_ratio": 1.731818181818182,
      "no_speech_prob": 0.0005308293038979173
    },
    {
      "id": 363,
      "seek": 225656,
      "start": 2262.88,
      "end": 2268.96,
      "text": " and then I have one more point there I'm like jumping in before we switch but it would be that when",
      "tokens": [
        50680,
        293,
        550,
        286,
        362,
        472,
        544,
        935,
        456,
        286,
        478,
        411,
        11233,
        294,
        949,
        321,
        3679,
        457,
        309,
        576,
        312,
        300,
        562,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09909750401288614,
      "compression_ratio": 1.731818181818182,
      "no_speech_prob": 0.0005308293038979173
    },
    {
      "id": 364,
      "seek": 225656,
      "start": 2268.96,
      "end": 2276.48,
      "text": " you do the solution validation I think try to include like more personas than you might not like try",
      "tokens": [
        50984,
        291,
        360,
        264,
        3827,
        24071,
        286,
        519,
        853,
        281,
        4090,
        411,
        544,
        12019,
        813,
        291,
        1062,
        406,
        411,
        853,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09909750401288614,
      "compression_ratio": 1.731818181818182,
      "no_speech_prob": 0.0005308293038979173
    },
    {
      "id": 365,
      "seek": 225656,
      "start": 2276.48,
      "end": 2283.04,
      "text": " to push yourself to include more personas so we make this work for more people because I think it",
      "tokens": [
        51360,
        281,
        2944,
        1803,
        281,
        4090,
        544,
        12019,
        370,
        321,
        652,
        341,
        589,
        337,
        544,
        561,
        570,
        286,
        519,
        309,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09909750401288614,
      "compression_ratio": 1.731818181818182,
      "no_speech_prob": 0.0005308293038979173
    },
    {
      "id": 366,
      "seek": 228304,
      "start": 2283.04,
      "end": 2288.96,
      "text": " can have a bigger impact yeah because I think right now the dashboard sorry I'll come",
      "tokens": [
        50364,
        393,
        362,
        257,
        3801,
        2712,
        1338,
        570,
        286,
        519,
        558,
        586,
        264,
        18342,
        2597,
        286,
        603,
        808,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893210018382353,
      "compression_ratio": 1.579646017699115,
      "no_speech_prob": 0.00013518684136215597
    },
    {
      "id": 367,
      "seek": 228304,
      "start": 2289.92,
      "end": 2295.36,
      "text": " is not working for some of our personas so opening this up to a bunch of other ones is probably",
      "tokens": [
        50708,
        307,
        406,
        1364,
        337,
        512,
        295,
        527,
        12019,
        370,
        5193,
        341,
        493,
        281,
        257,
        3840,
        295,
        661,
        2306,
        307,
        1391,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893210018382353,
      "compression_ratio": 1.579646017699115,
      "no_speech_prob": 0.00013518684136215597
    },
    {
      "id": 368,
      "seek": 228304,
      "start": 2295.36,
      "end": 2303.2799999999997,
      "text": " like the best fact well thanks again for all that I will pass it off to Gina now.",
      "tokens": [
        50980,
        411,
        264,
        1151,
        1186,
        731,
        3231,
        797,
        337,
        439,
        300,
        286,
        486,
        1320,
        309,
        766,
        281,
        34711,
        586,
        13,
        51376
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893210018382353,
      "compression_ratio": 1.579646017699115,
      "no_speech_prob": 0.00013518684136215597
    },
    {
      "id": 369,
      "seek": 228304,
      "start": 2304.4,
      "end": 2312.56,
      "text": " Hey thanks I have two updates one of them is for pipeline insights um we're dealing with this",
      "tokens": [
        51432,
        1911,
        3231,
        286,
        362,
        732,
        9205,
        472,
        295,
        552,
        307,
        337,
        15517,
        14310,
        1105,
        321,
        434,
        6260,
        365,
        341,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1893210018382353,
      "compression_ratio": 1.579646017699115,
      "no_speech_prob": 0.00013518684136215597
    },
    {
      "id": 370,
      "seek": 231256,
      "start": 2312.56,
      "end": 2319.2,
      "text": " problem of flaky tests we're going to if I gave a definition of these are not but the general one",
      "tokens": [
        50364,
        1154,
        295,
        932,
        15681,
        6921,
        321,
        434,
        516,
        281,
        498,
        286,
        2729,
        257,
        7123,
        295,
        613,
        366,
        406,
        457,
        264,
        2674,
        472,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08259326014025457,
      "compression_ratio": 1.7366071428571428,
      "no_speech_prob": 0.00024150637909770012
    },
    {
      "id": 371,
      "seek": 231256,
      "start": 2319.2,
      "end": 2327.04,
      "text": " is that when you run tests they can sometimes fail but the failure isn't real like it wasn't actually",
      "tokens": [
        50696,
        307,
        300,
        562,
        291,
        1190,
        6921,
        436,
        393,
        2171,
        3061,
        457,
        264,
        7763,
        1943,
        380,
        957,
        411,
        309,
        2067,
        380,
        767,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08259326014025457,
      "compression_ratio": 1.7366071428571428,
      "no_speech_prob": 0.00024150637909770012
    },
    {
      "id": 372,
      "seek": 231256,
      "start": 2327.04,
      "end": 2332.96,
      "text": " detected it was because like the test is actually written incorrectly or maybe a test that that",
      "tokens": [
        51088,
        21896,
        309,
        390,
        570,
        411,
        264,
        1500,
        307,
        767,
        3720,
        42892,
        420,
        1310,
        257,
        1500,
        300,
        300,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08259326014025457,
      "compression_ratio": 1.7366071428571428,
      "no_speech_prob": 0.00024150637909770012
    },
    {
      "id": 373,
      "seek": 231256,
      "start": 2332.96,
      "end": 2339.7599999999998,
      "text": " test relies on failed something like that and if it fails more often than it succeeds without",
      "tokens": [
        51384,
        1500,
        30910,
        322,
        7612,
        746,
        411,
        300,
        293,
        498,
        309,
        18199,
        544,
        2049,
        813,
        309,
        49263,
        1553,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08259326014025457,
      "compression_ratio": 1.7366071428571428,
      "no_speech_prob": 0.00024150637909770012
    },
    {
      "id": 374,
      "seek": 233976,
      "start": 2339.76,
      "end": 2345.6800000000003,
      "text": " actually detecting a failure it's considered flaky so we're trying to understand from users",
      "tokens": [
        50364,
        767,
        40237,
        257,
        7763,
        309,
        311,
        4888,
        932,
        15681,
        370,
        321,
        434,
        1382,
        281,
        1223,
        490,
        5022,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08543578603050926,
      "compression_ratio": 1.7772727272727273,
      "no_speech_prob": 8.038392843445763e-05
    },
    {
      "id": 375,
      "seek": 233976,
      "start": 2346.7200000000003,
      "end": 2352.96,
      "text": " like their pain points right now their workarounds with how they're dealing with flaky tests and then",
      "tokens": [
        50712,
        411,
        641,
        1822,
        2793,
        558,
        586,
        641,
        589,
        289,
        4432,
        365,
        577,
        436,
        434,
        6260,
        365,
        932,
        15681,
        6921,
        293,
        550,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08543578603050926,
      "compression_ratio": 1.7772727272727273,
      "no_speech_prob": 8.038392843445763e-05
    },
    {
      "id": 376,
      "seek": 233976,
      "start": 2352.96,
      "end": 2359.6000000000004,
      "text": " definitely how they define them the key insight for us here is how they define them because we",
      "tokens": [
        51024,
        2138,
        577,
        436,
        6964,
        552,
        264,
        2141,
        11269,
        337,
        505,
        510,
        307,
        577,
        436,
        6964,
        552,
        570,
        321,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08543578603050926,
      "compression_ratio": 1.7772727272727273,
      "no_speech_prob": 8.038392843445763e-05
    },
    {
      "id": 377,
      "seek": 233976,
      "start": 2359.6000000000004,
      "end": 2365.92,
      "text": " want to be able to when we define them for this MVC we want to make sure it matches their expectations",
      "tokens": [
        51356,
        528,
        281,
        312,
        1075,
        281,
        562,
        321,
        6964,
        552,
        337,
        341,
        17663,
        34,
        321,
        528,
        281,
        652,
        988,
        309,
        10676,
        641,
        9843,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08543578603050926,
      "compression_ratio": 1.7772727272727273,
      "no_speech_prob": 8.038392843445763e-05
    },
    {
      "id": 378,
      "seek": 236592,
      "start": 2366.88,
      "end": 2372.2400000000002,
      "text": " so I included some of the insights that we've heard so far we've only met with three users so far",
      "tokens": [
        50412,
        370,
        286,
        5556,
        512,
        295,
        264,
        14310,
        300,
        321,
        600,
        2198,
        370,
        1400,
        321,
        600,
        787,
        1131,
        365,
        1045,
        5022,
        370,
        1400,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10863946613512541,
      "compression_ratio": 1.72,
      "no_speech_prob": 0.0008077833335846663
    },
    {
      "id": 379,
      "seek": 236592,
      "start": 2372.2400000000002,
      "end": 2381.2000000000003,
      "text": " but we have a few other participants coming up as well and then on the runner side we this is like",
      "tokens": [
        50680,
        457,
        321,
        362,
        257,
        1326,
        661,
        10503,
        1348,
        493,
        382,
        731,
        293,
        550,
        322,
        264,
        24376,
        1252,
        321,
        341,
        307,
        411,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10863946613512541,
      "compression_ratio": 1.72,
      "no_speech_prob": 0.0008077833335846663
    },
    {
      "id": 380,
      "seek": 236592,
      "start": 2381.2000000000003,
      "end": 2387.36,
      "text": " one of our our bigger um what's a small feature but it's it's an important feature that we've added",
      "tokens": [
        51128,
        472,
        295,
        527,
        527,
        3801,
        1105,
        437,
        311,
        257,
        1359,
        4111,
        457,
        309,
        311,
        309,
        311,
        364,
        1021,
        4111,
        300,
        321,
        600,
        3869,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10863946613512541,
      "compression_ratio": 1.72,
      "no_speech_prob": 0.0008077833335846663
    },
    {
      "id": 381,
      "seek": 236592,
      "start": 2387.36,
      "end": 2395.84,
      "text": " for runners it kind of has to do with the whole runner fleet monitoring slash q stuff I've",
      "tokens": [
        51436,
        337,
        33892,
        309,
        733,
        295,
        575,
        281,
        360,
        365,
        264,
        1379,
        24376,
        19396,
        11028,
        17330,
        9505,
        1507,
        286,
        600,
        51860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10863946613512541,
      "compression_ratio": 1.72,
      "no_speech_prob": 0.0008077833335846663
    },
    {
      "id": 382,
      "seek": 239584,
      "start": 2395.84,
      "end": 2402.2400000000002,
      "text": " been talking about for a while so it's it's difficult for users to be able to see if a runner is",
      "tokens": [
        50364,
        668,
        1417,
        466,
        337,
        257,
        1339,
        370,
        309,
        311,
        309,
        311,
        2252,
        337,
        5022,
        281,
        312,
        1075,
        281,
        536,
        498,
        257,
        24376,
        307,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07010205248568921,
      "compression_ratio": 1.8037383177570094,
      "no_speech_prob": 8.931692718761042e-05
    },
    {
      "id": 383,
      "seek": 239584,
      "start": 2402.2400000000002,
      "end": 2408.6400000000003,
      "text": " running a job at the moment and the reason why that's important is because if they were to update",
      "tokens": [
        50684,
        2614,
        257,
        1691,
        412,
        264,
        1623,
        293,
        264,
        1778,
        983,
        300,
        311,
        1021,
        307,
        570,
        498,
        436,
        645,
        281,
        5623,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07010205248568921,
      "compression_ratio": 1.8037383177570094,
      "no_speech_prob": 8.931692718761042e-05
    },
    {
      "id": 384,
      "seek": 239584,
      "start": 2408.6400000000003,
      "end": 2414.1600000000003,
      "text": " the runner for example um it would stop that runner from running any jobs so they don't want to",
      "tokens": [
        51004,
        264,
        24376,
        337,
        1365,
        1105,
        309,
        576,
        1590,
        300,
        24376,
        490,
        2614,
        604,
        4782,
        370,
        436,
        500,
        380,
        528,
        281,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07010205248568921,
      "compression_ratio": 1.8037383177570094,
      "no_speech_prob": 8.931692718761042e-05
    },
    {
      "id": 385,
      "seek": 239584,
      "start": 2414.1600000000003,
      "end": 2421.84,
      "text": " impact any current running jobs or else the code just it doesn't go out so they want to know if",
      "tokens": [
        51280,
        2712,
        604,
        2190,
        2614,
        4782,
        420,
        1646,
        264,
        3089,
        445,
        309,
        1177,
        380,
        352,
        484,
        370,
        436,
        528,
        281,
        458,
        498,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07010205248568921,
      "compression_ratio": 1.8037383177570094,
      "no_speech_prob": 8.931692718761042e-05
    },
    {
      "id": 386,
      "seek": 242184,
      "start": 2422.1600000000003,
      "end": 2428.48,
      "text": " if if that runner is actually running one um so we've added a badge to be able to",
      "tokens": [
        50380,
        498,
        498,
        300,
        24376,
        307,
        767,
        2614,
        472,
        1105,
        370,
        321,
        600,
        3869,
        257,
        25797,
        281,
        312,
        1075,
        281,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10035437477959527,
      "compression_ratio": 1.83,
      "no_speech_prob": 0.0002853150654118508
    },
    {
      "id": 387,
      "seek": 242184,
      "start": 2429.6800000000003,
      "end": 2435.52,
      "text": " see if it's running or if it's idle is the other word that we're using the tough part about this is",
      "tokens": [
        50756,
        536,
        498,
        309,
        311,
        2614,
        420,
        498,
        309,
        311,
        30650,
        307,
        264,
        661,
        1349,
        300,
        321,
        434,
        1228,
        264,
        4930,
        644,
        466,
        341,
        307,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10035437477959527,
      "compression_ratio": 1.83,
      "no_speech_prob": 0.0002853150654118508
    },
    {
      "id": 388,
      "seek": 242184,
      "start": 2435.52,
      "end": 2443.28,
      "text": " that now we have two status badges we have one about if the runner is online and if the runner is",
      "tokens": [
        51048,
        300,
        586,
        321,
        362,
        732,
        6558,
        43894,
        321,
        362,
        472,
        466,
        498,
        264,
        24376,
        307,
        2950,
        293,
        498,
        264,
        24376,
        307,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10035437477959527,
      "compression_ratio": 1.83,
      "no_speech_prob": 0.0002853150654118508
    },
    {
      "id": 389,
      "seek": 242184,
      "start": 2443.28,
      "end": 2448.4,
      "text": " like running a job so our next iteration would be combining those into a single status",
      "tokens": [
        51436,
        411,
        2614,
        257,
        1691,
        370,
        527,
        958,
        24784,
        576,
        312,
        21928,
        729,
        666,
        257,
        2167,
        6558,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10035437477959527,
      "compression_ratio": 1.83,
      "no_speech_prob": 0.0002853150654118508
    },
    {
      "id": 390,
      "seek": 244840,
      "start": 2449.12,
      "end": 2454.88,
      "text": " something like active where it's running a job and it's online um and then that will allow for",
      "tokens": [
        50400,
        746,
        411,
        4967,
        689,
        309,
        311,
        2614,
        257,
        1691,
        293,
        309,
        311,
        2950,
        1105,
        293,
        550,
        300,
        486,
        2089,
        337,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2683878697847065,
      "compression_ratio": 1.3738317757009346,
      "no_speech_prob": 0.0016720484709367156
    },
    {
      "id": 391,
      "seek": 244840,
      "start": 2454.88,
      "end": 2457.12,
      "text": " less less load on the user",
      "tokens": [
        50688,
        1570,
        1570,
        3677,
        322,
        264,
        4195,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2683878697847065,
      "compression_ratio": 1.3738317757009346,
      "no_speech_prob": 0.0016720484709367156
    },
    {
      "id": 392,
      "seek": 244840,
      "start": 2463.92,
      "end": 2473.92,
      "text": " any questions or anything",
      "tokens": [
        51140,
        604,
        1651,
        420,
        1340,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2683878697847065,
      "compression_ratio": 1.3738317757009346,
      "no_speech_prob": 0.0016720484709367156
    },
    {
      "id": 393,
      "seek": 247392,
      "start": 2474.56,
      "end": 2481.92,
      "text": " I just want to say I love the idea of combining status badges into one thing that works because",
      "tokens": [
        50396,
        286,
        445,
        528,
        281,
        584,
        286,
        959,
        264,
        1558,
        295,
        21928,
        6558,
        43894,
        666,
        472,
        551,
        300,
        1985,
        570,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10160424974229601,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 0.0013897160533815622
    },
    {
      "id": 394,
      "seek": 247392,
      "start": 2481.92,
      "end": 2487.12,
      "text": " I've seen it quite a few times and I think it's in like the environments areas as well where there's",
      "tokens": [
        50764,
        286,
        600,
        1612,
        309,
        1596,
        257,
        1326,
        1413,
        293,
        286,
        519,
        309,
        311,
        294,
        411,
        264,
        12388,
        3179,
        382,
        731,
        689,
        456,
        311,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10160424974229601,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 0.0013897160533815622
    },
    {
      "id": 395,
      "seek": 247392,
      "start": 2487.12,
      "end": 2491.52,
      "text": " like multiple status badges and you're not quite sure how they relate to each other so I think",
      "tokens": [
        51024,
        411,
        3866,
        6558,
        43894,
        293,
        291,
        434,
        406,
        1596,
        988,
        577,
        436,
        10961,
        281,
        1184,
        661,
        370,
        286,
        519,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10160424974229601,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 0.0013897160533815622
    },
    {
      "id": 396,
      "seek": 247392,
      "start": 2491.52,
      "end": 2501.04,
      "text": " that's a great idea thanks it will definitely be a tough thing to do like because even with",
      "tokens": [
        51244,
        300,
        311,
        257,
        869,
        1558,
        3231,
        309,
        486,
        2138,
        312,
        257,
        4930,
        551,
        281,
        360,
        411,
        570,
        754,
        365,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10160424974229601,
      "compression_ratio": 1.7174887892376682,
      "no_speech_prob": 0.0013897160533815622
    },
    {
      "id": 397,
      "seek": 250104,
      "start": 2501.04,
      "end": 2507.12,
      "text": " runner because everything's through the CLI too people can now get a list of all like online runners",
      "tokens": [
        50364,
        24376,
        570,
        1203,
        311,
        807,
        264,
        12855,
        40,
        886,
        561,
        393,
        586,
        483,
        257,
        1329,
        295,
        439,
        411,
        2950,
        33892,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11852860450744629,
      "compression_ratio": 1.4148148148148147,
      "no_speech_prob": 5.4931253544054925e-05
    },
    {
      "id": 398,
      "seek": 250104,
      "start": 2507.12,
      "end": 2512.56,
      "text": " but all those statuses would have to change so it's going to be like a long a long process",
      "tokens": [
        50668,
        457,
        439,
        729,
        6558,
        279,
        576,
        362,
        281,
        1319,
        370,
        309,
        311,
        516,
        281,
        312,
        411,
        257,
        938,
        257,
        938,
        1399,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11852860450744629,
      "compression_ratio": 1.4148148148148147,
      "no_speech_prob": 5.4931253544054925e-05
    },
    {
      "id": 399,
      "seek": 253104,
      "start": 2531.12,
      "end": 2545.2,
      "text": " well I think that's it I don't think anybody has anything else so thanks for meeting today",
      "tokens": [
        50368,
        731,
        286,
        519,
        300,
        311,
        309,
        286,
        500,
        380,
        519,
        4472,
        575,
        1340,
        1646,
        370,
        3231,
        337,
        3440,
        965,
        51072
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36985238393147785,
      "compression_ratio": 1.3157894736842106,
      "no_speech_prob": 0.015130911953747272
    },
    {
      "id": 400,
      "seek": 253104,
      "start": 2548.48,
      "end": 2550.64,
      "text": " see everybody soon next week maybe",
      "tokens": [
        51236,
        536,
        2201,
        2321,
        958,
        1243,
        1310,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.36985238393147785,
      "compression_ratio": 1.3157894736842106,
      "no_speech_prob": 0.015130911953747272
    }
  ]
}