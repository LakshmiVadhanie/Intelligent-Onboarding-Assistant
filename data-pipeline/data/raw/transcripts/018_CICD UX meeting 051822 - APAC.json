{
  "title": "CI/CD UX meeting 05/18/22 - APAC",
  "video_id": "JwZFWmmUuGs",
  "url": "https://www.youtube.com/watch?v=JwZFWmmUuGs",
  "transcript": " All right, welcome everyone to this the 18th of May and we are meeting for CI CD UX meeting the APAC edition. Getting started the agenda we have a kind of a full agenda today and a lot of items under general and manager announcements. I'll start with that. The first one is to review the OCR's progress and just like mark the progress in the issue and also make a note if anything is blocked or at risk and everyone should get in touch with their I mean speak with their PMs and schedule things into work for a design during Q2 from the issue that's marked there and I have updated something that was a question for me by Hianna and I had a conversation with James yesterday and even though the list looks pretty long for weapon execution and the issue we figured that designs are provided for most of them so maybe we just have to work on the design first to explore issues this quarter and that seems manageable to us. And then there are some changes which have been made to video policy go through this and like drop any comments if there are I see Nadia has put a comment there Nadia do you want to talk about it. Yeah, I was just wondering if this goes for the country where you're physically currently present or your official country of residence. I would assume it's your official country of residence but it's just not very clear. So yeah, I just wanted to clarify because for someone like me that makes a big difference usually I take Polish holidays off but I'm also happy to take Indonesian holidays off and that's not so hard. Yeah, and this was also a little I mean so in India especially like this not especially real estate where I'm located but we generally have a lot of occasions when the public schools and government offices are closed. So I think that would be I would be gone a lot of time so I need to check on that. The next one is if you are being picked by PM or a team outside of a stage group it's an FIA that you and they need you to support with design work work first with Hianna together in the history approvals and then the process would be followed as steps when it comes to borrowing a designer to have a designer temporarily assessed somewhere and there's also a template that has been linked here. Moving on to the other agenda items. So the first one is here by Gina. Gina is talking about the validation study that she would be working on and also the roadmap that she would be working on with her new PM Chaslin. So there's some updates about that. Please take a look at that and drop any comments if you have thoughts around it and the next one is Katie. Katie, do you? So this week I'm mostly focused on doing some dissolution validation for the NBC of the container registry cleanup policies just a bit of background information. This feature actually already exists in production but there's been a lot of customer feedback for the past two years about certain features that are missing from it. There's quite a lot of technical constraints with the container registry and any implementation. So we have a very kind of minimal like NBC and part of the questions that we're trying to answer with the solution validation is this two minimal like is it still worthwhile to make these changes. So I have just on my fifth session before this so I've got one more and then I'll be doing analysis this week and I'll let everyone know how it goes. And my second item that I'm focusing on I'm trying to upskill myself in kind of data related like making design decisions based off of data. I also saw that there's recently been a handbook page added about this and I've been working with Matthew Peterson who works on the growth team to answer some of these questions and he's setting some stuff up for me and my hope is eventually I can use what he's set up to kind of write my own queries going forward. So yeah I'll let everyone know how that's going. Beatka did you want to voice your questions? Yeah so I looked through this before the meeting and it looks pretty great and very thorough. I'm just wondering like how did you get started on this from where did this effort start and how you identify that you could take part in months of activity? I created the sheet almost like as soon as I joined GitLab just having I had some questions about design decisions I wanted to make and data that would maybe support those questions and the problem was our engineers in the package team are so busy that they don't have time to support with this at the moment and so I started talking to the growth team. I actually engaged with Matthew because I was writing a secret query myself and it was broken and he helped me fix it and then we just got to talking that like maybe he could provide some mentorship and help about this. That's great because I have been looking forward to set something up for the Papua Newsytutian team and I definitely haven't tried to write the queries myself and I've been looking forward to our engineers having some bandwidth to assist me with that. So it's inspiring that you've gotten started already and maybe we can take inspiration from you and some help from you to set things for ourselves. Yeah I would want to maybe eventually make this a UX showcase. What I need to understand is there are basically tables of data and the data has names and then there's SQL and you put the two things together. So maybe eventually Matthew and I can write a tutorial or guidelines of you know if you wanted to approach this yourself how would you do it but we're still very early days so yeah we'll see if that's possible. Next is Nadia. Yeah so I wanted to share some solution validation results around variables. If you want to check out the research issue it's linked right there at the beginning. So the core insights were that the current processing mechanism for variables was not clear to our users at all. So currently if you use a dollar sign in your variable it's interpreted as the start of a new variable which is essentially something you would do only if you want to create a variable inside a variable. Otherwise usually when you create a password for example it might contain dollar sign especially if it's machines generated for security purposes and it's surprised to the users that by default it will be expanded. Usually they kind of learn it the wrong way you know the pipeline just doesn't work the credential doesn't work because it's misinterpreted. Then passwords were expected to be masked for security purposes and evaluated as a raw string so without variable expansion or creating a variable reference with the dollar sign and also we found out too many options for creating a variable in the UI. We have this form with several different options where you can protect variable mask variable and now we want to add another option to process it to the raw string. It's starting to become overwhelming so in the future we want to look into adding some predefined variable configurations based on the variable type for example instead of having to look at the form and evaluate all of the different options they're available to you and how to put them together to get desired result. We might consider suggesting that hey if you want to create a password click here and then the appropriate configuration is selected by default so I think it will require some additional research but it really answered some questions for us and we're moving forward with an MVC proposal more confidently knowing that this is actually something that our users really need and in the future we want to actually make raw processing the default way of processing variables. Yeah so this making like masking the variables made default for certain requirements it came up in one of the discussions that we were having I think as a part of ops think back long back about six seven months back when we were talking about secrets that we provide many options but our default like how we treat these variables and secrets by default it's not like even though we have a lot of capability we're not using them right. So this will be very helpful I've been I've been only been able to look at this first one here and not all yet but the first one looks very useful like it would be adding a lot of value for users. Yeah there's some other problems there with masking by default which is kind of blocker is some of the characters cannot be masked and it makes zero sense logically but that's just limitation that we have and we have to work around it for example I think if you have a percentage if we're doing because your password can definitely have a percentage sign and then you have to edit your password because of that so yeah hopefully we can go around it eventually. So my goal now is to advocate for fixing those problems first so we can actually provide the desired experience because we've been going in circles a little bit like I keep suggesting that and I keep hearing that we have the sanitation but the room must be away just need to find it. Yeah. Okay so anything else? What is it? I don't know. The three research. Did I break or do I? Okay my internet is unstable. I think we're both dead. Okay and the last thing I want to share is about the health drawers. So I've been working with Suzanne from the technical writing team. She's staff technical writer and with Jeremy on the guidelines for health drawers in GitLab and we've been collaborating closely on the guidelines specifically for the content like how can we implement markdown documentation content in drawers and we're suggesting two ways. First you can fool in documentation directly from the docs if it's still readable in the drawer there might be instances like that depending on how the content is formatted in the docs basically or you can also have custom content if the documentation content for some reason doesn't work and then you will still have to follow the documentation guidelines around how you structure that content and technical writing will have to be involved for sure there helping out with the copy but yeah the guidelines are still a work in progress it's the OR is still being refined there's a bunch of threats there and questions so if you have the time feel free to jump in especially if you think there might be a need for a health drawer in your stage group because we need to account for all kinds of different use cases and we had some interest from several different stage groups but I think the requirements might really vary depending on what kind of task you want to support and what kind of content you want to show so we want to make sure we account for those. That's all from me. We think I'll take it away. All right so I just have like very small updates. I have I'm still busy in fact I just did the last interview the ninth interview for the foundational research for PIPEN execution and it's going very well and I would be sharing the results on Friday mostly for this and I have added the dovetail link which has about six interviews uploaded until now so I would update this further and share with the team and with the findings of course. The next thing is James and I have worked on the priority for design issues for this quarter so if you just go to this epic you would be able to see a reprioritized list so that's what that's how I would be going about working on these design issues in the same sequence as you see in trying to feel like the one on the top is the highest importance to us and I mean Nadia if you see the top issue it's something that we have discussed about but there are some updates about it I think James would have put an update there that basically it's not what we thought it is it's different it's just an experiment and yeah that's it nothing more from my side let's see what's there in the UX research thread so we have a new page our UXR training resources has a new page on using quantitative data to find insights you can go ahead check there and then will and Erica have posted a link to their prioritization issues and that's it anything else before we wrap up okay we all get some time back in that case I will good day ahead all of you bye you",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 9.72,
      "text": " All right, welcome everyone to this the 18th of May and we are meeting for CI CD UX meeting",
      "tokens": [
        50364,
        1057,
        558,
        11,
        2928,
        1518,
        281,
        341,
        264,
        2443,
        392,
        295,
        1891,
        293,
        321,
        366,
        3440,
        337,
        37777,
        6743,
        40176,
        3440,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3919675615098741,
      "compression_ratio": 1.51528384279476,
      "no_speech_prob": 0.1044977456331253
    },
    {
      "id": 1,
      "seek": 0,
      "start": 9.72,
      "end": 12.780000000000001,
      "text": " the APAC edition.",
      "tokens": [
        50850,
        264,
        5372,
        4378,
        11377,
        13,
        51003
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3919675615098741,
      "compression_ratio": 1.51528384279476,
      "no_speech_prob": 0.1044977456331253
    },
    {
      "id": 2,
      "seek": 0,
      "start": 12.780000000000001,
      "end": 19.56,
      "text": " Getting started the agenda we have a kind of a full agenda today and a lot of items under",
      "tokens": [
        51003,
        13674,
        1409,
        264,
        9829,
        321,
        362,
        257,
        733,
        295,
        257,
        1577,
        9829,
        965,
        293,
        257,
        688,
        295,
        4754,
        833,
        51342
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3919675615098741,
      "compression_ratio": 1.51528384279476,
      "no_speech_prob": 0.1044977456331253
    },
    {
      "id": 3,
      "seek": 0,
      "start": 19.56,
      "end": 21.16,
      "text": " general and manager announcements.",
      "tokens": [
        51342,
        2674,
        293,
        6598,
        23785,
        13,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3919675615098741,
      "compression_ratio": 1.51528384279476,
      "no_speech_prob": 0.1044977456331253
    },
    {
      "id": 4,
      "seek": 0,
      "start": 21.16,
      "end": 22.8,
      "text": " I'll start with that.",
      "tokens": [
        51422,
        286,
        603,
        722,
        365,
        300,
        13,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3919675615098741,
      "compression_ratio": 1.51528384279476,
      "no_speech_prob": 0.1044977456331253
    },
    {
      "id": 5,
      "seek": 0,
      "start": 22.8,
      "end": 29.560000000000002,
      "text": " The first one is to review the OCR's progress and just like mark the progress in the issue",
      "tokens": [
        51504,
        440,
        700,
        472,
        307,
        281,
        3131,
        264,
        422,
        18547,
        311,
        4205,
        293,
        445,
        411,
        1491,
        264,
        4205,
        294,
        264,
        2734,
        51842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3919675615098741,
      "compression_ratio": 1.51528384279476,
      "no_speech_prob": 0.1044977456331253
    },
    {
      "id": 6,
      "seek": 2956,
      "start": 29.56,
      "end": 36.8,
      "text": " and also make a note if anything is blocked or at risk and everyone should get in touch",
      "tokens": [
        50364,
        293,
        611,
        652,
        257,
        3637,
        498,
        1340,
        307,
        15470,
        420,
        412,
        3148,
        293,
        1518,
        820,
        483,
        294,
        2557,
        50726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26427854974585846,
      "compression_ratio": 1.5954545454545455,
      "no_speech_prob": 0.00872145127505064
    },
    {
      "id": 7,
      "seek": 2956,
      "start": 36.8,
      "end": 41.519999999999996,
      "text": " with their I mean speak with their PMs and schedule things into work for a design during",
      "tokens": [
        50726,
        365,
        641,
        286,
        914,
        1710,
        365,
        641,
        12499,
        82,
        293,
        7567,
        721,
        666,
        589,
        337,
        257,
        1715,
        1830,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26427854974585846,
      "compression_ratio": 1.5954545454545455,
      "no_speech_prob": 0.00872145127505064
    },
    {
      "id": 8,
      "seek": 2956,
      "start": 41.519999999999996,
      "end": 50.08,
      "text": " Q2 from the issue that's marked there and I have updated something that was a question",
      "tokens": [
        50962,
        1249,
        17,
        490,
        264,
        2734,
        300,
        311,
        12658,
        456,
        293,
        286,
        362,
        10588,
        746,
        300,
        390,
        257,
        1168,
        51390
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26427854974585846,
      "compression_ratio": 1.5954545454545455,
      "no_speech_prob": 0.00872145127505064
    },
    {
      "id": 9,
      "seek": 2956,
      "start": 50.08,
      "end": 56.68,
      "text": " for me by Hianna and I had a conversation with James yesterday and even though the list",
      "tokens": [
        51390,
        337,
        385,
        538,
        389,
        952,
        629,
        293,
        286,
        632,
        257,
        3761,
        365,
        5678,
        5186,
        293,
        754,
        1673,
        264,
        1329,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26427854974585846,
      "compression_ratio": 1.5954545454545455,
      "no_speech_prob": 0.00872145127505064
    },
    {
      "id": 10,
      "seek": 5668,
      "start": 56.68,
      "end": 61.48,
      "text": " looks pretty long for weapon execution and the issue we figured that designs are provided",
      "tokens": [
        50364,
        1542,
        1238,
        938,
        337,
        7463,
        15058,
        293,
        264,
        2734,
        321,
        8932,
        300,
        11347,
        366,
        5649,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31167783640851876,
      "compression_ratio": 1.6951219512195121,
      "no_speech_prob": 0.015369521453976631
    },
    {
      "id": 11,
      "seek": 5668,
      "start": 61.48,
      "end": 66.84,
      "text": " for most of them so maybe we just have to work on the design first to explore issues this",
      "tokens": [
        50604,
        337,
        881,
        295,
        552,
        370,
        1310,
        321,
        445,
        362,
        281,
        589,
        322,
        264,
        1715,
        700,
        281,
        6839,
        2663,
        341,
        50872
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31167783640851876,
      "compression_ratio": 1.6951219512195121,
      "no_speech_prob": 0.015369521453976631
    },
    {
      "id": 12,
      "seek": 5668,
      "start": 66.84,
      "end": 71.36,
      "text": " quarter and that seems manageable to us.",
      "tokens": [
        50872,
        6555,
        293,
        300,
        2544,
        38798,
        281,
        505,
        13,
        51098
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31167783640851876,
      "compression_ratio": 1.6951219512195121,
      "no_speech_prob": 0.015369521453976631
    },
    {
      "id": 13,
      "seek": 5668,
      "start": 71.36,
      "end": 77.4,
      "text": " And then there are some changes which have been made to video policy go through this and",
      "tokens": [
        51098,
        400,
        550,
        456,
        366,
        512,
        2962,
        597,
        362,
        668,
        1027,
        281,
        960,
        3897,
        352,
        807,
        341,
        293,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31167783640851876,
      "compression_ratio": 1.6951219512195121,
      "no_speech_prob": 0.015369521453976631
    },
    {
      "id": 14,
      "seek": 5668,
      "start": 77.4,
      "end": 83.6,
      "text": " like drop any comments if there are I see Nadia has put a comment there Nadia do you want",
      "tokens": [
        51400,
        411,
        3270,
        604,
        3053,
        498,
        456,
        366,
        286,
        536,
        23269,
        654,
        575,
        829,
        257,
        2871,
        456,
        23269,
        654,
        360,
        291,
        528,
        51710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31167783640851876,
      "compression_ratio": 1.6951219512195121,
      "no_speech_prob": 0.015369521453976631
    },
    {
      "id": 15,
      "seek": 5668,
      "start": 83.6,
      "end": 84.84,
      "text": " to talk about it.",
      "tokens": [
        51710,
        281,
        751,
        466,
        309,
        13,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31167783640851876,
      "compression_ratio": 1.6951219512195121,
      "no_speech_prob": 0.015369521453976631
    },
    {
      "id": 16,
      "seek": 8484,
      "start": 85.84,
      "end": 93.44,
      "text": " Yeah, I was just wondering if this goes for the country where you're physically currently",
      "tokens": [
        50414,
        865,
        11,
        286,
        390,
        445,
        6359,
        498,
        341,
        1709,
        337,
        264,
        1941,
        689,
        291,
        434,
        9762,
        4362,
        50794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21836094374067327,
      "compression_ratio": 1.7112068965517242,
      "no_speech_prob": 0.03518921136856079
    },
    {
      "id": 17,
      "seek": 8484,
      "start": 93.44,
      "end": 97.12,
      "text": " present or your official country of residence.",
      "tokens": [
        50794,
        1974,
        420,
        428,
        4783,
        1941,
        295,
        19607,
        13,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21836094374067327,
      "compression_ratio": 1.7112068965517242,
      "no_speech_prob": 0.03518921136856079
    },
    {
      "id": 18,
      "seek": 8484,
      "start": 97.12,
      "end": 101.80000000000001,
      "text": " I would assume it's your official country of residence but it's just not very clear.",
      "tokens": [
        50978,
        286,
        576,
        6552,
        309,
        311,
        428,
        4783,
        1941,
        295,
        19607,
        457,
        309,
        311,
        445,
        406,
        588,
        1850,
        13,
        51212
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21836094374067327,
      "compression_ratio": 1.7112068965517242,
      "no_speech_prob": 0.03518921136856079
    },
    {
      "id": 19,
      "seek": 8484,
      "start": 101.80000000000001,
      "end": 107.4,
      "text": " So yeah, I just wanted to clarify because for someone like me that makes a big difference",
      "tokens": [
        51212,
        407,
        1338,
        11,
        286,
        445,
        1415,
        281,
        17594,
        570,
        337,
        1580,
        411,
        385,
        300,
        1669,
        257,
        955,
        2649,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21836094374067327,
      "compression_ratio": 1.7112068965517242,
      "no_speech_prob": 0.03518921136856079
    },
    {
      "id": 20,
      "seek": 8484,
      "start": 107.4,
      "end": 112.48,
      "text": " usually I take Polish holidays off but I'm also happy to take Indonesian holidays off",
      "tokens": [
        51492,
        2673,
        286,
        747,
        18504,
        15734,
        766,
        457,
        286,
        478,
        611,
        2055,
        281,
        747,
        39772,
        15734,
        766,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21836094374067327,
      "compression_ratio": 1.7112068965517242,
      "no_speech_prob": 0.03518921136856079
    },
    {
      "id": 21,
      "seek": 11248,
      "start": 112.48,
      "end": 115.48,
      "text": " and that's not so hard.",
      "tokens": [
        50364,
        293,
        300,
        311,
        406,
        370,
        1152,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27174908281808874,
      "compression_ratio": 1.62,
      "no_speech_prob": 0.05328536406159401
    },
    {
      "id": 22,
      "seek": 11248,
      "start": 115.48,
      "end": 124.04,
      "text": " Yeah, and this was also a little I mean so in India especially like this not especially",
      "tokens": [
        50514,
        865,
        11,
        293,
        341,
        390,
        611,
        257,
        707,
        286,
        914,
        370,
        294,
        5282,
        2318,
        411,
        341,
        406,
        2318,
        50942
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27174908281808874,
      "compression_ratio": 1.62,
      "no_speech_prob": 0.05328536406159401
    },
    {
      "id": 23,
      "seek": 11248,
      "start": 124.04,
      "end": 129.72,
      "text": " real estate where I'm located but we generally have a lot of occasions when the public schools",
      "tokens": [
        50942,
        957,
        9749,
        689,
        286,
        478,
        6870,
        457,
        321,
        5101,
        362,
        257,
        688,
        295,
        20641,
        562,
        264,
        1908,
        4656,
        51226
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27174908281808874,
      "compression_ratio": 1.62,
      "no_speech_prob": 0.05328536406159401
    },
    {
      "id": 24,
      "seek": 11248,
      "start": 129.72,
      "end": 132.08,
      "text": " and government offices are closed.",
      "tokens": [
        51226,
        293,
        2463,
        14434,
        366,
        5395,
        13,
        51344
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27174908281808874,
      "compression_ratio": 1.62,
      "no_speech_prob": 0.05328536406159401
    },
    {
      "id": 25,
      "seek": 11248,
      "start": 132.08,
      "end": 141.68,
      "text": " So I think that would be I would be gone a lot of time so I need to check on that.",
      "tokens": [
        51344,
        407,
        286,
        519,
        300,
        576,
        312,
        286,
        576,
        312,
        2780,
        257,
        688,
        295,
        565,
        370,
        286,
        643,
        281,
        1520,
        322,
        300,
        13,
        51824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27174908281808874,
      "compression_ratio": 1.62,
      "no_speech_prob": 0.05328536406159401
    },
    {
      "id": 26,
      "seek": 14168,
      "start": 142.4,
      "end": 148.32,
      "text": " The next one is if you are being picked by PM or a team outside of a stage group it's",
      "tokens": [
        50400,
        440,
        958,
        472,
        307,
        498,
        291,
        366,
        885,
        6183,
        538,
        12499,
        420,
        257,
        1469,
        2380,
        295,
        257,
        3233,
        1594,
        309,
        311,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31546345162898937,
      "compression_ratio": 1.625514403292181,
      "no_speech_prob": 0.03818386420607567
    },
    {
      "id": 27,
      "seek": 14168,
      "start": 148.32,
      "end": 155.52,
      "text": " an FIA that you and they need you to support with design work work first with Hianna together",
      "tokens": [
        50696,
        364,
        479,
        6914,
        300,
        291,
        293,
        436,
        643,
        291,
        281,
        1406,
        365,
        1715,
        589,
        589,
        700,
        365,
        389,
        952,
        629,
        1214,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31546345162898937,
      "compression_ratio": 1.625514403292181,
      "no_speech_prob": 0.03818386420607567
    },
    {
      "id": 28,
      "seek": 14168,
      "start": 155.52,
      "end": 161.96,
      "text": " in the history approvals and then the process would be followed as steps when it comes to",
      "tokens": [
        51056,
        294,
        264,
        2503,
        2075,
        19778,
        293,
        550,
        264,
        1399,
        576,
        312,
        6263,
        382,
        4439,
        562,
        309,
        1487,
        281,
        51378
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31546345162898937,
      "compression_ratio": 1.625514403292181,
      "no_speech_prob": 0.03818386420607567
    },
    {
      "id": 29,
      "seek": 14168,
      "start": 161.96,
      "end": 166.88,
      "text": " borrowing a designer to have a designer temporarily assessed somewhere and there's also a template",
      "tokens": [
        51378,
        35024,
        257,
        11795,
        281,
        362,
        257,
        11795,
        23750,
        36051,
        4079,
        293,
        456,
        311,
        611,
        257,
        12379,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31546345162898937,
      "compression_ratio": 1.625514403292181,
      "no_speech_prob": 0.03818386420607567
    },
    {
      "id": 30,
      "seek": 14168,
      "start": 166.88,
      "end": 170.8,
      "text": " that has been linked here.",
      "tokens": [
        51624,
        300,
        575,
        668,
        9408,
        510,
        13,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.31546345162898937,
      "compression_ratio": 1.625514403292181,
      "no_speech_prob": 0.03818386420607567
    },
    {
      "id": 31,
      "seek": 17080,
      "start": 170.8,
      "end": 174.88000000000002,
      "text": " Moving on to the other agenda items.",
      "tokens": [
        50364,
        14242,
        322,
        281,
        264,
        661,
        9829,
        4754,
        13,
        50568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3483666438682407,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.01118834875524044
    },
    {
      "id": 32,
      "seek": 17080,
      "start": 174.88000000000002,
      "end": 176.8,
      "text": " So the first one is here by Gina.",
      "tokens": [
        50568,
        407,
        264,
        700,
        472,
        307,
        510,
        538,
        34711,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3483666438682407,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.01118834875524044
    },
    {
      "id": 33,
      "seek": 17080,
      "start": 176.8,
      "end": 183.08,
      "text": " Gina is talking about the validation study that she would be working on and also the",
      "tokens": [
        50664,
        34711,
        307,
        1417,
        466,
        264,
        24071,
        2979,
        300,
        750,
        576,
        312,
        1364,
        322,
        293,
        611,
        264,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3483666438682407,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.01118834875524044
    },
    {
      "id": 34,
      "seek": 17080,
      "start": 183.08,
      "end": 188.0,
      "text": " roadmap that she would be working on with her new PM Chaslin.",
      "tokens": [
        50978,
        35738,
        300,
        750,
        576,
        312,
        1364,
        322,
        365,
        720,
        777,
        12499,
        761,
        296,
        5045,
        13,
        51224
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3483666438682407,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.01118834875524044
    },
    {
      "id": 35,
      "seek": 17080,
      "start": 188.0,
      "end": 189.88000000000002,
      "text": " So there's some updates about that.",
      "tokens": [
        51224,
        407,
        456,
        311,
        512,
        9205,
        466,
        300,
        13,
        51318
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3483666438682407,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.01118834875524044
    },
    {
      "id": 36,
      "seek": 17080,
      "start": 189.88000000000002,
      "end": 195.96,
      "text": " Please take a look at that and drop any comments if you have thoughts around it and the next",
      "tokens": [
        51318,
        2555,
        747,
        257,
        574,
        412,
        300,
        293,
        3270,
        604,
        3053,
        498,
        291,
        362,
        4598,
        926,
        309,
        293,
        264,
        958,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3483666438682407,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.01118834875524044
    },
    {
      "id": 37,
      "seek": 17080,
      "start": 195.96,
      "end": 197.12,
      "text": " one is Katie.",
      "tokens": [
        51622,
        472,
        307,
        19602,
        13,
        51680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3483666438682407,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.01118834875524044
    },
    {
      "id": 38,
      "seek": 17080,
      "start": 197.12,
      "end": 199.12,
      "text": " Katie, do you?",
      "tokens": [
        51680,
        19602,
        11,
        360,
        291,
        30,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3483666438682407,
      "compression_ratio": 1.6816143497757847,
      "no_speech_prob": 0.01118834875524044
    },
    {
      "id": 39,
      "seek": 19912,
      "start": 200.08,
      "end": 207.04,
      "text": " So this week I'm mostly focused on doing some dissolution validation for the NBC of the",
      "tokens": [
        50412,
        407,
        341,
        1243,
        286,
        478,
        5240,
        5178,
        322,
        884,
        512,
        7802,
        3386,
        24071,
        337,
        264,
        31504,
        295,
        264,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21693830380494566,
      "compression_ratio": 1.66015625,
      "no_speech_prob": 0.013274213299155235
    },
    {
      "id": 40,
      "seek": 19912,
      "start": 207.04,
      "end": 210.56,
      "text": " container registry cleanup policies just a bit of background information.",
      "tokens": [
        50760,
        10129,
        36468,
        40991,
        7657,
        445,
        257,
        857,
        295,
        3678,
        1589,
        13,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21693830380494566,
      "compression_ratio": 1.66015625,
      "no_speech_prob": 0.013274213299155235
    },
    {
      "id": 41,
      "seek": 19912,
      "start": 210.56,
      "end": 215.6,
      "text": " This feature actually already exists in production but there's been a lot of customer feedback",
      "tokens": [
        50936,
        639,
        4111,
        767,
        1217,
        8198,
        294,
        4265,
        457,
        456,
        311,
        668,
        257,
        688,
        295,
        5474,
        5824,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21693830380494566,
      "compression_ratio": 1.66015625,
      "no_speech_prob": 0.013274213299155235
    },
    {
      "id": 42,
      "seek": 19912,
      "start": 215.6,
      "end": 219.52,
      "text": " for the past two years about certain features that are missing from it.",
      "tokens": [
        51188,
        337,
        264,
        1791,
        732,
        924,
        466,
        1629,
        4122,
        300,
        366,
        5361,
        490,
        309,
        13,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21693830380494566,
      "compression_ratio": 1.66015625,
      "no_speech_prob": 0.013274213299155235
    },
    {
      "id": 43,
      "seek": 19912,
      "start": 220.24,
      "end": 225.28,
      "text": " There's quite a lot of technical constraints with the container registry and any implementation.",
      "tokens": [
        51420,
        821,
        311,
        1596,
        257,
        688,
        295,
        6191,
        18491,
        365,
        264,
        10129,
        36468,
        293,
        604,
        11420,
        13,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21693830380494566,
      "compression_ratio": 1.66015625,
      "no_speech_prob": 0.013274213299155235
    },
    {
      "id": 44,
      "seek": 22528,
      "start": 226.24,
      "end": 234.88,
      "text": " So we have a very kind of minimal like NBC and part of the questions that we're trying",
      "tokens": [
        50412,
        407,
        321,
        362,
        257,
        588,
        733,
        295,
        13206,
        411,
        31504,
        293,
        644,
        295,
        264,
        1651,
        300,
        321,
        434,
        1382,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23025541527326718,
      "compression_ratio": 1.5944700460829493,
      "no_speech_prob": 0.018482979387044907
    },
    {
      "id": 45,
      "seek": 22528,
      "start": 234.88,
      "end": 242.08,
      "text": " to answer with the solution validation is this two minimal like is it still worthwhile to make",
      "tokens": [
        50844,
        281,
        1867,
        365,
        264,
        3827,
        24071,
        307,
        341,
        732,
        13206,
        411,
        307,
        309,
        920,
        28159,
        281,
        652,
        51204
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23025541527326718,
      "compression_ratio": 1.5944700460829493,
      "no_speech_prob": 0.018482979387044907
    },
    {
      "id": 46,
      "seek": 22528,
      "start": 242.08,
      "end": 243.08,
      "text": " these changes.",
      "tokens": [
        51204,
        613,
        2962,
        13,
        51254
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23025541527326718,
      "compression_ratio": 1.5944700460829493,
      "no_speech_prob": 0.018482979387044907
    },
    {
      "id": 47,
      "seek": 22528,
      "start": 243.08,
      "end": 248.96,
      "text": " So I have just on my fifth session before this so I've got one more and then I'll be doing",
      "tokens": [
        51254,
        407,
        286,
        362,
        445,
        322,
        452,
        9266,
        5481,
        949,
        341,
        370,
        286,
        600,
        658,
        472,
        544,
        293,
        550,
        286,
        603,
        312,
        884,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23025541527326718,
      "compression_ratio": 1.5944700460829493,
      "no_speech_prob": 0.018482979387044907
    },
    {
      "id": 48,
      "seek": 22528,
      "start": 248.96,
      "end": 252.08,
      "text": " analysis this week and I'll let everyone know how it goes.",
      "tokens": [
        51548,
        5215,
        341,
        1243,
        293,
        286,
        603,
        718,
        1518,
        458,
        577,
        309,
        1709,
        13,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23025541527326718,
      "compression_ratio": 1.5944700460829493,
      "no_speech_prob": 0.018482979387044907
    },
    {
      "id": 49,
      "seek": 25208,
      "start": 253.04000000000002,
      "end": 260.8,
      "text": " And my second item that I'm focusing on I'm trying to upskill myself in kind of data related",
      "tokens": [
        50412,
        400,
        452,
        1150,
        3174,
        300,
        286,
        478,
        8416,
        322,
        286,
        478,
        1382,
        281,
        493,
        5161,
        373,
        2059,
        294,
        733,
        295,
        1412,
        4077,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15306470301244166,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.11897526681423187
    },
    {
      "id": 50,
      "seek": 25208,
      "start": 262.48,
      "end": 265.6,
      "text": " like making design decisions based off of data.",
      "tokens": [
        50884,
        411,
        1455,
        1715,
        5327,
        2361,
        766,
        295,
        1412,
        13,
        51040
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15306470301244166,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.11897526681423187
    },
    {
      "id": 51,
      "seek": 25208,
      "start": 265.6,
      "end": 272.72,
      "text": " I also saw that there's recently been a handbook page added about this and I've been working",
      "tokens": [
        51040,
        286,
        611,
        1866,
        300,
        456,
        311,
        3938,
        668,
        257,
        1011,
        2939,
        3028,
        3869,
        466,
        341,
        293,
        286,
        600,
        668,
        1364,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15306470301244166,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.11897526681423187
    },
    {
      "id": 52,
      "seek": 25208,
      "start": 272.72,
      "end": 277.76,
      "text": " with Matthew Peterson who works on the growth team to answer some of these questions and",
      "tokens": [
        51396,
        365,
        12434,
        36943,
        567,
        1985,
        322,
        264,
        4599,
        1469,
        281,
        1867,
        512,
        295,
        613,
        1651,
        293,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15306470301244166,
      "compression_ratio": 1.5333333333333334,
      "no_speech_prob": 0.11897526681423187
    },
    {
      "id": 53,
      "seek": 27776,
      "start": 278.32,
      "end": 283.44,
      "text": " he's setting some stuff up for me and my hope is eventually I can use what he's set up to kind",
      "tokens": [
        50392,
        415,
        311,
        3287,
        512,
        1507,
        493,
        337,
        385,
        293,
        452,
        1454,
        307,
        4728,
        286,
        393,
        764,
        437,
        415,
        311,
        992,
        493,
        281,
        733,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211303523942536,
      "compression_ratio": 1.6031746031746033,
      "no_speech_prob": 0.022305643185973167
    },
    {
      "id": 54,
      "seek": 27776,
      "start": 283.44,
      "end": 285.52,
      "text": " of write my own queries going forward.",
      "tokens": [
        50648,
        295,
        2464,
        452,
        1065,
        24109,
        516,
        2128,
        13,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211303523942536,
      "compression_ratio": 1.6031746031746033,
      "no_speech_prob": 0.022305643185973167
    },
    {
      "id": 55,
      "seek": 27776,
      "start": 286.8,
      "end": 289.92,
      "text": " So yeah I'll let everyone know how that's going.",
      "tokens": [
        50816,
        407,
        1338,
        286,
        603,
        718,
        1518,
        458,
        577,
        300,
        311,
        516,
        13,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211303523942536,
      "compression_ratio": 1.6031746031746033,
      "no_speech_prob": 0.022305643185973167
    },
    {
      "id": 56,
      "seek": 27776,
      "start": 290.64,
      "end": 292.32,
      "text": " Beatka did you want to voice your questions?",
      "tokens": [
        51008,
        16031,
        2330,
        630,
        291,
        528,
        281,
        3177,
        428,
        1651,
        30,
        51092
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211303523942536,
      "compression_ratio": 1.6031746031746033,
      "no_speech_prob": 0.022305643185973167
    },
    {
      "id": 57,
      "seek": 27776,
      "start": 292.8,
      "end": 297.68,
      "text": " Yeah so I looked through this before the meeting and it looks pretty great and very",
      "tokens": [
        51116,
        865,
        370,
        286,
        2956,
        807,
        341,
        949,
        264,
        3440,
        293,
        309,
        1542,
        1238,
        869,
        293,
        588,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211303523942536,
      "compression_ratio": 1.6031746031746033,
      "no_speech_prob": 0.022305643185973167
    },
    {
      "id": 58,
      "seek": 27776,
      "start": 297.68,
      "end": 303.84,
      "text": " thorough. I'm just wondering like how did you get started on this from where did this effort",
      "tokens": [
        51360,
        12934,
        13,
        286,
        478,
        445,
        6359,
        411,
        577,
        630,
        291,
        483,
        1409,
        322,
        341,
        490,
        689,
        630,
        341,
        4630,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2211303523942536,
      "compression_ratio": 1.6031746031746033,
      "no_speech_prob": 0.022305643185973167
    },
    {
      "id": 59,
      "seek": 30384,
      "start": 303.84,
      "end": 308.64,
      "text": " start and how you identify that you could take part in months of activity?",
      "tokens": [
        50364,
        722,
        293,
        577,
        291,
        5876,
        300,
        291,
        727,
        747,
        644,
        294,
        2493,
        295,
        5191,
        30,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15528795046684069,
      "compression_ratio": 1.5890410958904109,
      "no_speech_prob": 0.0008736430900171399
    },
    {
      "id": 60,
      "seek": 30384,
      "start": 311.76,
      "end": 319.35999999999996,
      "text": " I created the sheet almost like as soon as I joined GitLab just having I had some questions about",
      "tokens": [
        50760,
        286,
        2942,
        264,
        8193,
        1920,
        411,
        382,
        2321,
        382,
        286,
        6869,
        16939,
        37880,
        445,
        1419,
        286,
        632,
        512,
        1651,
        466,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15528795046684069,
      "compression_ratio": 1.5890410958904109,
      "no_speech_prob": 0.0008736430900171399
    },
    {
      "id": 61,
      "seek": 30384,
      "start": 319.35999999999996,
      "end": 322.71999999999997,
      "text": " design decisions I wanted to make and data that would maybe support those questions",
      "tokens": [
        51140,
        1715,
        5327,
        286,
        1415,
        281,
        652,
        293,
        1412,
        300,
        576,
        1310,
        1406,
        729,
        1651,
        51308
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15528795046684069,
      "compression_ratio": 1.5890410958904109,
      "no_speech_prob": 0.0008736430900171399
    },
    {
      "id": 62,
      "seek": 30384,
      "start": 323.28,
      "end": 330.0,
      "text": " and the problem was our engineers in the package team are so busy that they don't have time",
      "tokens": [
        51336,
        293,
        264,
        1154,
        390,
        527,
        11955,
        294,
        264,
        7372,
        1469,
        366,
        370,
        5856,
        300,
        436,
        500,
        380,
        362,
        565,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15528795046684069,
      "compression_ratio": 1.5890410958904109,
      "no_speech_prob": 0.0008736430900171399
    },
    {
      "id": 63,
      "seek": 33000,
      "start": 330.0,
      "end": 337.44,
      "text": " to support with this at the moment and so I started talking to the growth team.",
      "tokens": [
        50364,
        281,
        1406,
        365,
        341,
        412,
        264,
        1623,
        293,
        370,
        286,
        1409,
        1417,
        281,
        264,
        4599,
        1469,
        13,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17905018838603845,
      "compression_ratio": 1.6118143459915613,
      "no_speech_prob": 0.004314083140343428
    },
    {
      "id": 64,
      "seek": 33000,
      "start": 338.08,
      "end": 342.96,
      "text": " I actually engaged with Matthew because I was writing a secret query myself and it was broken",
      "tokens": [
        50768,
        286,
        767,
        8237,
        365,
        12434,
        570,
        286,
        390,
        3579,
        257,
        4054,
        14581,
        2059,
        293,
        309,
        390,
        5463,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17905018838603845,
      "compression_ratio": 1.6118143459915613,
      "no_speech_prob": 0.004314083140343428
    },
    {
      "id": 65,
      "seek": 33000,
      "start": 343.28,
      "end": 348.4,
      "text": " and he helped me fix it and then we just got to talking that like maybe he could provide some",
      "tokens": [
        51028,
        293,
        415,
        4254,
        385,
        3191,
        309,
        293,
        550,
        321,
        445,
        658,
        281,
        1417,
        300,
        411,
        1310,
        415,
        727,
        2893,
        512,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17905018838603845,
      "compression_ratio": 1.6118143459915613,
      "no_speech_prob": 0.004314083140343428
    },
    {
      "id": 66,
      "seek": 33000,
      "start": 348.4,
      "end": 350.56,
      "text": " mentorship and help about this.",
      "tokens": [
        51284,
        40422,
        293,
        854,
        466,
        341,
        13,
        51392
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17905018838603845,
      "compression_ratio": 1.6118143459915613,
      "no_speech_prob": 0.004314083140343428
    },
    {
      "id": 67,
      "seek": 33000,
      "start": 351.52,
      "end": 356.8,
      "text": " That's great because I have been looking forward to set something up for the Papua",
      "tokens": [
        51440,
        663,
        311,
        869,
        570,
        286,
        362,
        668,
        1237,
        2128,
        281,
        992,
        746,
        493,
        337,
        264,
        15919,
        4398,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17905018838603845,
      "compression_ratio": 1.6118143459915613,
      "no_speech_prob": 0.004314083140343428
    },
    {
      "id": 68,
      "seek": 35680,
      "start": 356.8,
      "end": 362.72,
      "text": " Newsytutian team and I definitely haven't tried to write the queries myself and I've been",
      "tokens": [
        50364,
        7987,
        4328,
        325,
        952,
        1469,
        293,
        286,
        2138,
        2378,
        380,
        3031,
        281,
        2464,
        264,
        24109,
        2059,
        293,
        286,
        600,
        668,
        50660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17639381327527634,
      "compression_ratio": 1.6254980079681276,
      "no_speech_prob": 0.013833398930728436
    },
    {
      "id": 69,
      "seek": 35680,
      "start": 362.72,
      "end": 367.28000000000003,
      "text": " looking forward to our engineers having some bandwidth to assist me with that.",
      "tokens": [
        50660,
        1237,
        2128,
        281,
        527,
        11955,
        1419,
        512,
        23647,
        281,
        4255,
        385,
        365,
        300,
        13,
        50888
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17639381327527634,
      "compression_ratio": 1.6254980079681276,
      "no_speech_prob": 0.013833398930728436
    },
    {
      "id": 70,
      "seek": 35680,
      "start": 368.0,
      "end": 374.8,
      "text": " So it's inspiring that you've gotten started already and maybe we can take inspiration from you",
      "tokens": [
        50924,
        407,
        309,
        311,
        15883,
        300,
        291,
        600,
        5768,
        1409,
        1217,
        293,
        1310,
        321,
        393,
        747,
        10249,
        490,
        291,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17639381327527634,
      "compression_ratio": 1.6254980079681276,
      "no_speech_prob": 0.013833398930728436
    },
    {
      "id": 71,
      "seek": 35680,
      "start": 374.8,
      "end": 377.28000000000003,
      "text": " and some help from you to set things for ourselves.",
      "tokens": [
        51264,
        293,
        512,
        854,
        490,
        291,
        281,
        992,
        721,
        337,
        4175,
        13,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17639381327527634,
      "compression_ratio": 1.6254980079681276,
      "no_speech_prob": 0.013833398930728436
    },
    {
      "id": 72,
      "seek": 35680,
      "start": 378.48,
      "end": 383.76,
      "text": " Yeah I would want to maybe eventually make this a UX showcase. What I need to understand is",
      "tokens": [
        51448,
        865,
        286,
        576,
        528,
        281,
        1310,
        4728,
        652,
        341,
        257,
        40176,
        20388,
        13,
        708,
        286,
        643,
        281,
        1223,
        307,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17639381327527634,
      "compression_ratio": 1.6254980079681276,
      "no_speech_prob": 0.013833398930728436
    },
    {
      "id": 73,
      "seek": 38376,
      "start": 384.0,
      "end": 390.56,
      "text": " there are basically tables of data and the data has names and then there's SQL and you put the",
      "tokens": [
        50376,
        456,
        366,
        1936,
        8020,
        295,
        1412,
        293,
        264,
        1412,
        575,
        5288,
        293,
        550,
        456,
        311,
        19200,
        293,
        291,
        829,
        264,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1824672405536358,
      "compression_ratio": 1.5053191489361701,
      "no_speech_prob": 0.0024155343417078257
    },
    {
      "id": 74,
      "seek": 38376,
      "start": 390.56,
      "end": 399.2,
      "text": " two things together. So maybe eventually Matthew and I can write a tutorial or guidelines of",
      "tokens": [
        50704,
        732,
        721,
        1214,
        13,
        407,
        1310,
        4728,
        12434,
        293,
        286,
        393,
        2464,
        257,
        7073,
        420,
        12470,
        295,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1824672405536358,
      "compression_ratio": 1.5053191489361701,
      "no_speech_prob": 0.0024155343417078257
    },
    {
      "id": 75,
      "seek": 38376,
      "start": 399.2,
      "end": 403.44,
      "text": " you know if you wanted to approach this yourself how would you do it but we're still very early",
      "tokens": [
        51136,
        291,
        458,
        498,
        291,
        1415,
        281,
        3109,
        341,
        1803,
        577,
        576,
        291,
        360,
        309,
        457,
        321,
        434,
        920,
        588,
        2440,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1824672405536358,
      "compression_ratio": 1.5053191489361701,
      "no_speech_prob": 0.0024155343417078257
    },
    {
      "id": 76,
      "seek": 40344,
      "start": 403.52,
      "end": 405.44,
      "text": " days so yeah we'll see if that's possible.",
      "tokens": [
        50368,
        1708,
        370,
        1338,
        321,
        603,
        536,
        498,
        300,
        311,
        1944,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15751005473889804,
      "compression_ratio": 1.4285714285714286,
      "no_speech_prob": 0.005591432563960552
    },
    {
      "id": 77,
      "seek": 40344,
      "start": 409.2,
      "end": 410.48,
      "text": " Next is Nadia.",
      "tokens": [
        50652,
        3087,
        307,
        23269,
        654,
        13,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15751005473889804,
      "compression_ratio": 1.4285714285714286,
      "no_speech_prob": 0.005591432563960552
    },
    {
      "id": 78,
      "seek": 40344,
      "start": 414.96,
      "end": 419.36,
      "text": " Yeah so I wanted to share some solution validation results around variables.",
      "tokens": [
        50940,
        865,
        370,
        286,
        1415,
        281,
        2073,
        512,
        3827,
        24071,
        3542,
        926,
        9102,
        13,
        51160
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15751005473889804,
      "compression_ratio": 1.4285714285714286,
      "no_speech_prob": 0.005591432563960552
    },
    {
      "id": 79,
      "seek": 40344,
      "start": 421.2,
      "end": 425.84,
      "text": " If you want to check out the research issue it's linked right there at the beginning.",
      "tokens": [
        51252,
        759,
        291,
        528,
        281,
        1520,
        484,
        264,
        2132,
        2734,
        309,
        311,
        9408,
        558,
        456,
        412,
        264,
        2863,
        13,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15751005473889804,
      "compression_ratio": 1.4285714285714286,
      "no_speech_prob": 0.005591432563960552
    },
    {
      "id": 80,
      "seek": 42584,
      "start": 426.4,
      "end": 434.23999999999995,
      "text": " So the core insights were that the current processing mechanism for variables was not",
      "tokens": [
        50392,
        407,
        264,
        4965,
        14310,
        645,
        300,
        264,
        2190,
        9007,
        7513,
        337,
        9102,
        390,
        406,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11734512544447376,
      "compression_ratio": 1.622093023255814,
      "no_speech_prob": 0.00234837899915874
    },
    {
      "id": 81,
      "seek": 42584,
      "start": 434.23999999999995,
      "end": 443.28,
      "text": " clear to our users at all. So currently if you use a dollar sign in your variable it's interpreted",
      "tokens": [
        50784,
        1850,
        281,
        527,
        5022,
        412,
        439,
        13,
        407,
        4362,
        498,
        291,
        764,
        257,
        7241,
        1465,
        294,
        428,
        7006,
        309,
        311,
        26749,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11734512544447376,
      "compression_ratio": 1.622093023255814,
      "no_speech_prob": 0.00234837899915874
    },
    {
      "id": 82,
      "seek": 42584,
      "start": 443.28,
      "end": 451.44,
      "text": " as the start of a new variable which is essentially something you would do only if you want to",
      "tokens": [
        51236,
        382,
        264,
        722,
        295,
        257,
        777,
        7006,
        597,
        307,
        4476,
        746,
        291,
        576,
        360,
        787,
        498,
        291,
        528,
        281,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11734512544447376,
      "compression_ratio": 1.622093023255814,
      "no_speech_prob": 0.00234837899915874
    },
    {
      "id": 83,
      "seek": 45144,
      "start": 452.4,
      "end": 459.84,
      "text": " create a variable inside a variable. Otherwise usually when you create a password for example it",
      "tokens": [
        50412,
        1884,
        257,
        7006,
        1854,
        257,
        7006,
        13,
        10328,
        2673,
        562,
        291,
        1884,
        257,
        11524,
        337,
        1365,
        309,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14700701236724853,
      "compression_ratio": 1.6347826086956523,
      "no_speech_prob": 0.0010268808109685779
    },
    {
      "id": 84,
      "seek": 45144,
      "start": 459.84,
      "end": 466.16,
      "text": " might contain dollar sign especially if it's machines generated for security purposes and it's",
      "tokens": [
        50784,
        1062,
        5304,
        7241,
        1465,
        2318,
        498,
        309,
        311,
        8379,
        10833,
        337,
        3825,
        9932,
        293,
        309,
        311,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14700701236724853,
      "compression_ratio": 1.6347826086956523,
      "no_speech_prob": 0.0010268808109685779
    },
    {
      "id": 85,
      "seek": 45144,
      "start": 466.16,
      "end": 470.96,
      "text": " surprised to the users that by default it will be expanded. Usually they kind of learn it",
      "tokens": [
        51100,
        6100,
        281,
        264,
        5022,
        300,
        538,
        7576,
        309,
        486,
        312,
        14342,
        13,
        11419,
        436,
        733,
        295,
        1466,
        309,
        51340
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14700701236724853,
      "compression_ratio": 1.6347826086956523,
      "no_speech_prob": 0.0010268808109685779
    },
    {
      "id": 86,
      "seek": 45144,
      "start": 471.6,
      "end": 476.08,
      "text": " the wrong way you know the pipeline just doesn't work the credential doesn't work because it's",
      "tokens": [
        51372,
        264,
        2085,
        636,
        291,
        458,
        264,
        15517,
        445,
        1177,
        380,
        589,
        264,
        22034,
        1177,
        380,
        589,
        570,
        309,
        311,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14700701236724853,
      "compression_ratio": 1.6347826086956523,
      "no_speech_prob": 0.0010268808109685779
    },
    {
      "id": 87,
      "seek": 47608,
      "start": 476.08,
      "end": 484.71999999999997,
      "text": " misinterpreted. Then passwords were expected to be masked for security purposes and",
      "tokens": [
        50364,
        3346,
        41935,
        292,
        13,
        1396,
        33149,
        645,
        5176,
        281,
        312,
        45249,
        337,
        3825,
        9932,
        293,
        50796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13373978073532516,
      "compression_ratio": 1.7190476190476192,
      "no_speech_prob": 0.0002261355402879417
    },
    {
      "id": 88,
      "seek": 47608,
      "start": 485.44,
      "end": 492.96,
      "text": " evaluated as a raw string so without variable expansion or creating a variable reference with",
      "tokens": [
        50832,
        25509,
        382,
        257,
        8936,
        6798,
        370,
        1553,
        7006,
        11260,
        420,
        4084,
        257,
        7006,
        6408,
        365,
        51208
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13373978073532516,
      "compression_ratio": 1.7190476190476192,
      "no_speech_prob": 0.0002261355402879417
    },
    {
      "id": 89,
      "seek": 47608,
      "start": 492.96,
      "end": 497.76,
      "text": " the dollar sign and also we found out too many options for creating a variable in the UI.",
      "tokens": [
        51208,
        264,
        7241,
        1465,
        293,
        611,
        321,
        1352,
        484,
        886,
        867,
        3956,
        337,
        4084,
        257,
        7006,
        294,
        264,
        15682,
        13,
        51448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13373978073532516,
      "compression_ratio": 1.7190476190476192,
      "no_speech_prob": 0.0002261355402879417
    },
    {
      "id": 90,
      "seek": 47608,
      "start": 498.64,
      "end": 503.2,
      "text": " We have this form with several different options where you can protect variable mask variable",
      "tokens": [
        51492,
        492,
        362,
        341,
        1254,
        365,
        2940,
        819,
        3956,
        689,
        291,
        393,
        2371,
        7006,
        6094,
        7006,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13373978073532516,
      "compression_ratio": 1.7190476190476192,
      "no_speech_prob": 0.0002261355402879417
    },
    {
      "id": 91,
      "seek": 50320,
      "start": 503.2,
      "end": 509.28,
      "text": " and now we want to add another option to process it to the raw string. It's starting to become",
      "tokens": [
        50364,
        293,
        586,
        321,
        528,
        281,
        909,
        1071,
        3614,
        281,
        1399,
        309,
        281,
        264,
        8936,
        6798,
        13,
        467,
        311,
        2891,
        281,
        1813,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09988291123334099,
      "compression_ratio": 1.7168141592920354,
      "no_speech_prob": 0.0005001579411327839
    },
    {
      "id": 92,
      "seek": 50320,
      "start": 509.28,
      "end": 515.36,
      "text": " overwhelming so in the future we want to look into adding some predefined variable configurations",
      "tokens": [
        50668,
        13373,
        370,
        294,
        264,
        2027,
        321,
        528,
        281,
        574,
        666,
        5127,
        512,
        659,
        37716,
        7006,
        31493,
        50972
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09988291123334099,
      "compression_ratio": 1.7168141592920354,
      "no_speech_prob": 0.0005001579411327839
    },
    {
      "id": 93,
      "seek": 50320,
      "start": 515.36,
      "end": 520.96,
      "text": " based on the variable type for example instead of having to look at the form and evaluate all of",
      "tokens": [
        50972,
        2361,
        322,
        264,
        7006,
        2010,
        337,
        1365,
        2602,
        295,
        1419,
        281,
        574,
        412,
        264,
        1254,
        293,
        13059,
        439,
        295,
        51252
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09988291123334099,
      "compression_ratio": 1.7168141592920354,
      "no_speech_prob": 0.0005001579411327839
    },
    {
      "id": 94,
      "seek": 50320,
      "start": 520.96,
      "end": 525.6,
      "text": " the different options they're available to you and how to put them together to get desired result.",
      "tokens": [
        51252,
        264,
        819,
        3956,
        436,
        434,
        2435,
        281,
        291,
        293,
        577,
        281,
        829,
        552,
        1214,
        281,
        483,
        14721,
        1874,
        13,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09988291123334099,
      "compression_ratio": 1.7168141592920354,
      "no_speech_prob": 0.0005001579411327839
    },
    {
      "id": 95,
      "seek": 52560,
      "start": 526.24,
      "end": 533.9200000000001,
      "text": " We might consider suggesting that hey if you want to create a password click here and then",
      "tokens": [
        50396,
        492,
        1062,
        1949,
        18094,
        300,
        4177,
        498,
        291,
        528,
        281,
        1884,
        257,
        11524,
        2052,
        510,
        293,
        550,
        50780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10680237208327202,
      "compression_ratio": 1.5938864628820961,
      "no_speech_prob": 0.003584046848118305
    },
    {
      "id": 96,
      "seek": 52560,
      "start": 533.9200000000001,
      "end": 539.6800000000001,
      "text": " the appropriate configuration is selected by default so I think it will require some additional",
      "tokens": [
        50780,
        264,
        6854,
        11694,
        307,
        8209,
        538,
        7576,
        370,
        286,
        519,
        309,
        486,
        3651,
        512,
        4497,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10680237208327202,
      "compression_ratio": 1.5938864628820961,
      "no_speech_prob": 0.003584046848118305
    },
    {
      "id": 97,
      "seek": 52560,
      "start": 539.6800000000001,
      "end": 547.12,
      "text": " research but it really answered some questions for us and we're moving forward with an MVC",
      "tokens": [
        51068,
        2132,
        457,
        309,
        534,
        10103,
        512,
        1651,
        337,
        505,
        293,
        321,
        434,
        2684,
        2128,
        365,
        364,
        17663,
        34,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10680237208327202,
      "compression_ratio": 1.5938864628820961,
      "no_speech_prob": 0.003584046848118305
    },
    {
      "id": 98,
      "seek": 52560,
      "start": 547.12,
      "end": 554.24,
      "text": " proposal more confidently knowing that this is actually something that our users really",
      "tokens": [
        51440,
        11494,
        544,
        41956,
        5276,
        300,
        341,
        307,
        767,
        746,
        300,
        527,
        5022,
        534,
        51796
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10680237208327202,
      "compression_ratio": 1.5938864628820961,
      "no_speech_prob": 0.003584046848118305
    },
    {
      "id": 99,
      "seek": 55424,
      "start": 554.24,
      "end": 562.64,
      "text": " need and in the future we want to actually make raw processing the default way of processing variables.",
      "tokens": [
        50364,
        643,
        293,
        294,
        264,
        2027,
        321,
        528,
        281,
        767,
        652,
        8936,
        9007,
        264,
        7576,
        636,
        295,
        9007,
        9102,
        13,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1948694884777069,
      "compression_ratio": 1.6229508196721312,
      "no_speech_prob": 0.002742087934166193
    },
    {
      "id": 100,
      "seek": 55424,
      "start": 563.6,
      "end": 571.6,
      "text": " Yeah so this making like masking the variables made default for certain requirements it came up in",
      "tokens": [
        50832,
        865,
        370,
        341,
        1455,
        411,
        31226,
        264,
        9102,
        1027,
        7576,
        337,
        1629,
        7728,
        309,
        1361,
        493,
        294,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1948694884777069,
      "compression_ratio": 1.6229508196721312,
      "no_speech_prob": 0.002742087934166193
    },
    {
      "id": 101,
      "seek": 55424,
      "start": 571.6,
      "end": 577.6800000000001,
      "text": " one of the discussions that we were having I think as a part of ops think back long back about",
      "tokens": [
        51232,
        472,
        295,
        264,
        11088,
        300,
        321,
        645,
        1419,
        286,
        519,
        382,
        257,
        644,
        295,
        44663,
        519,
        646,
        938,
        646,
        466,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1948694884777069,
      "compression_ratio": 1.6229508196721312,
      "no_speech_prob": 0.002742087934166193
    },
    {
      "id": 102,
      "seek": 57768,
      "start": 577.68,
      "end": 585.3599999999999,
      "text": " six seven months back when we were talking about secrets that we provide many options but our default",
      "tokens": [
        50364,
        2309,
        3407,
        2493,
        646,
        562,
        321,
        645,
        1417,
        466,
        14093,
        300,
        321,
        2893,
        867,
        3956,
        457,
        527,
        7576,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16245905090780818,
      "compression_ratio": 1.5392670157068062,
      "no_speech_prob": 0.00206778128631413
    },
    {
      "id": 103,
      "seek": 57768,
      "start": 587.04,
      "end": 594.88,
      "text": " like how we treat these variables and secrets by default it's not like even though we have a lot",
      "tokens": [
        50832,
        411,
        577,
        321,
        2387,
        613,
        9102,
        293,
        14093,
        538,
        7576,
        309,
        311,
        406,
        411,
        754,
        1673,
        321,
        362,
        257,
        688,
        51224
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16245905090780818,
      "compression_ratio": 1.5392670157068062,
      "no_speech_prob": 0.00206778128631413
    },
    {
      "id": 104,
      "seek": 57768,
      "start": 594.88,
      "end": 602.4799999999999,
      "text": " of capability we're not using them right. So this will be very helpful I've been I've been only",
      "tokens": [
        51224,
        295,
        13759,
        321,
        434,
        406,
        1228,
        552,
        558,
        13,
        407,
        341,
        486,
        312,
        588,
        4961,
        286,
        600,
        668,
        286,
        600,
        668,
        787,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16245905090780818,
      "compression_ratio": 1.5392670157068062,
      "no_speech_prob": 0.00206778128631413
    },
    {
      "id": 105,
      "seek": 60248,
      "start": 602.5600000000001,
      "end": 609.6800000000001,
      "text": " been able to look at this first one here and not all yet but the first one looks very useful like",
      "tokens": [
        50368,
        668,
        1075,
        281,
        574,
        412,
        341,
        700,
        472,
        510,
        293,
        406,
        439,
        1939,
        457,
        264,
        700,
        472,
        1542,
        588,
        4420,
        411,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0831362936231825,
      "compression_ratio": 1.6695278969957081,
      "no_speech_prob": 0.0021603303030133247
    },
    {
      "id": 106,
      "seek": 60248,
      "start": 609.6800000000001,
      "end": 617.6800000000001,
      "text": " it would be adding a lot of value for users. Yeah there's some other problems there with masking",
      "tokens": [
        50724,
        309,
        576,
        312,
        5127,
        257,
        688,
        295,
        2158,
        337,
        5022,
        13,
        865,
        456,
        311,
        512,
        661,
        2740,
        456,
        365,
        31226,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0831362936231825,
      "compression_ratio": 1.6695278969957081,
      "no_speech_prob": 0.0021603303030133247
    },
    {
      "id": 107,
      "seek": 60248,
      "start": 617.6800000000001,
      "end": 625.6,
      "text": " by default which is kind of blocker is some of the characters cannot be masked and it makes zero",
      "tokens": [
        51124,
        538,
        7576,
        597,
        307,
        733,
        295,
        3461,
        260,
        307,
        512,
        295,
        264,
        4342,
        2644,
        312,
        45249,
        293,
        309,
        1669,
        4018,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0831362936231825,
      "compression_ratio": 1.6695278969957081,
      "no_speech_prob": 0.0021603303030133247
    },
    {
      "id": 108,
      "seek": 60248,
      "start": 625.6,
      "end": 632.4,
      "text": " sense logically but that's just limitation that we have and we have to work around it for example",
      "tokens": [
        51520,
        2020,
        38887,
        457,
        300,
        311,
        445,
        27432,
        300,
        321,
        362,
        293,
        321,
        362,
        281,
        589,
        926,
        309,
        337,
        1365,
        51860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0831362936231825,
      "compression_ratio": 1.6695278969957081,
      "no_speech_prob": 0.0021603303030133247
    },
    {
      "id": 109,
      "seek": 63240,
      "start": 632.4,
      "end": 641.52,
      "text": " I think if you have a percentage if we're doing because your password can definitely have a",
      "tokens": [
        50364,
        286,
        519,
        498,
        291,
        362,
        257,
        9668,
        498,
        321,
        434,
        884,
        570,
        428,
        11524,
        393,
        2138,
        362,
        257,
        50820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13376187142871676,
      "compression_ratio": 1.7155555555555555,
      "no_speech_prob": 0.0003667291603051126
    },
    {
      "id": 110,
      "seek": 63240,
      "start": 641.52,
      "end": 649.04,
      "text": " percentage sign and then you have to edit your password because of that so yeah hopefully we can",
      "tokens": [
        50820,
        9668,
        1465,
        293,
        550,
        291,
        362,
        281,
        8129,
        428,
        11524,
        570,
        295,
        300,
        370,
        1338,
        4696,
        321,
        393,
        51196
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13376187142871676,
      "compression_ratio": 1.7155555555555555,
      "no_speech_prob": 0.0003667291603051126
    },
    {
      "id": 111,
      "seek": 63240,
      "start": 649.04,
      "end": 655.76,
      "text": " go around it eventually. So my goal now is to advocate for fixing those problems first so we can",
      "tokens": [
        51196,
        352,
        926,
        309,
        4728,
        13,
        407,
        452,
        3387,
        586,
        307,
        281,
        14608,
        337,
        19442,
        729,
        2740,
        700,
        370,
        321,
        393,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13376187142871676,
      "compression_ratio": 1.7155555555555555,
      "no_speech_prob": 0.0003667291603051126
    },
    {
      "id": 112,
      "seek": 63240,
      "start": 655.76,
      "end": 660.4,
      "text": " actually provide the desired experience because we've been going in circles a little bit like I keep",
      "tokens": [
        51532,
        767,
        2893,
        264,
        14721,
        1752,
        570,
        321,
        600,
        668,
        516,
        294,
        13040,
        257,
        707,
        857,
        411,
        286,
        1066,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13376187142871676,
      "compression_ratio": 1.7155555555555555,
      "no_speech_prob": 0.0003667291603051126
    },
    {
      "id": 113,
      "seek": 66040,
      "start": 660.4,
      "end": 667.12,
      "text": " suggesting that and I keep hearing that we have the sanitation but the room must be away",
      "tokens": [
        50364,
        18094,
        300,
        293,
        286,
        1066,
        4763,
        300,
        321,
        362,
        264,
        50146,
        457,
        264,
        1808,
        1633,
        312,
        1314,
        50700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5648941713220933,
      "compression_ratio": 1.330935251798561,
      "no_speech_prob": 0.0019945271778851748
    },
    {
      "id": 114,
      "seek": 66040,
      "start": 669.4399999999999,
      "end": 678.24,
      "text": " just need to find it. Yeah. Okay so anything else?",
      "tokens": [
        50816,
        445,
        643,
        281,
        915,
        309,
        13,
        865,
        13,
        1033,
        370,
        1340,
        1646,
        30,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5648941713220933,
      "compression_ratio": 1.330935251798561,
      "no_speech_prob": 0.0019945271778851748
    },
    {
      "id": 115,
      "seek": 66040,
      "start": 679.76,
      "end": 681.28,
      "text": " What is it? I don't know. The three research.",
      "tokens": [
        51332,
        708,
        307,
        309,
        30,
        286,
        500,
        380,
        458,
        13,
        440,
        1045,
        2132,
        13,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5648941713220933,
      "compression_ratio": 1.330935251798561,
      "no_speech_prob": 0.0019945271778851748
    },
    {
      "id": 116,
      "seek": 68128,
      "start": 681.68,
      "end": 692.72,
      "text": " Did I break or do I? Okay my internet is unstable. I think we're both dead.",
      "tokens": [
        50384,
        2589,
        286,
        1821,
        420,
        360,
        286,
        30,
        1033,
        452,
        4705,
        307,
        23742,
        13,
        286,
        519,
        321,
        434,
        1293,
        3116,
        13,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3536415389089873,
      "compression_ratio": 1.4858757062146892,
      "no_speech_prob": 0.009277768433094025
    },
    {
      "id": 117,
      "seek": 68128,
      "start": 697.28,
      "end": 703.1999999999999,
      "text": " Okay and the last thing I want to share is about the health drawers. So I've been working with",
      "tokens": [
        51164,
        1033,
        293,
        264,
        1036,
        551,
        286,
        528,
        281,
        2073,
        307,
        466,
        264,
        1585,
        38302,
        13,
        407,
        286,
        600,
        668,
        1364,
        365,
        51460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3536415389089873,
      "compression_ratio": 1.4858757062146892,
      "no_speech_prob": 0.009277768433094025
    },
    {
      "id": 118,
      "seek": 68128,
      "start": 704.0,
      "end": 709.76,
      "text": " Suzanne from the technical writing team. She's staff technical writer and with Jeremy on the",
      "tokens": [
        51500,
        48901,
        490,
        264,
        6191,
        3579,
        1469,
        13,
        1240,
        311,
        3525,
        6191,
        9936,
        293,
        365,
        17809,
        322,
        264,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3536415389089873,
      "compression_ratio": 1.4858757062146892,
      "no_speech_prob": 0.009277768433094025
    },
    {
      "id": 119,
      "seek": 70976,
      "start": 709.76,
      "end": 716.24,
      "text": " guidelines for health drawers in GitLab and we've been collaborating closely on the guidelines",
      "tokens": [
        50364,
        12470,
        337,
        1585,
        38302,
        294,
        16939,
        37880,
        293,
        321,
        600,
        668,
        30188,
        8185,
        322,
        264,
        12470,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16755016226517527,
      "compression_ratio": 1.6622222222222223,
      "no_speech_prob": 0.000905923661775887
    },
    {
      "id": 120,
      "seek": 70976,
      "start": 716.24,
      "end": 724.48,
      "text": " specifically for the content like how can we implement markdown documentation content in",
      "tokens": [
        50688,
        4682,
        337,
        264,
        2701,
        411,
        577,
        393,
        321,
        4445,
        1491,
        5093,
        14333,
        2701,
        294,
        51100
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16755016226517527,
      "compression_ratio": 1.6622222222222223,
      "no_speech_prob": 0.000905923661775887
    },
    {
      "id": 121,
      "seek": 70976,
      "start": 724.48,
      "end": 732.0,
      "text": " drawers and we're suggesting two ways. First you can fool in documentation directly from the docs",
      "tokens": [
        51100,
        38302,
        293,
        321,
        434,
        18094,
        732,
        2098,
        13,
        2386,
        291,
        393,
        7979,
        294,
        14333,
        3838,
        490,
        264,
        45623,
        51476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16755016226517527,
      "compression_ratio": 1.6622222222222223,
      "no_speech_prob": 0.000905923661775887
    },
    {
      "id": 122,
      "seek": 70976,
      "start": 733.12,
      "end": 739.2,
      "text": " if it's still readable in the drawer there might be instances like that depending on how the",
      "tokens": [
        51532,
        498,
        309,
        311,
        920,
        49857,
        294,
        264,
        24039,
        456,
        1062,
        312,
        14519,
        411,
        300,
        5413,
        322,
        577,
        264,
        51836
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16755016226517527,
      "compression_ratio": 1.6622222222222223,
      "no_speech_prob": 0.000905923661775887
    },
    {
      "id": 123,
      "seek": 73920,
      "start": 739.2,
      "end": 747.2800000000001,
      "text": " content is formatted in the docs basically or you can also have custom content if the",
      "tokens": [
        50364,
        2701,
        307,
        1254,
        32509,
        294,
        264,
        45623,
        1936,
        420,
        291,
        393,
        611,
        362,
        2375,
        2701,
        498,
        264,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14716669456245973,
      "compression_ratio": 1.8525896414342629,
      "no_speech_prob": 0.0002255118452012539
    },
    {
      "id": 124,
      "seek": 73920,
      "start": 747.2800000000001,
      "end": 751.84,
      "text": " documentation content for some reason doesn't work and then you will still have to follow the",
      "tokens": [
        50768,
        14333,
        2701,
        337,
        512,
        1778,
        1177,
        380,
        589,
        293,
        550,
        291,
        486,
        920,
        362,
        281,
        1524,
        264,
        50996
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14716669456245973,
      "compression_ratio": 1.8525896414342629,
      "no_speech_prob": 0.0002255118452012539
    },
    {
      "id": 125,
      "seek": 73920,
      "start": 751.84,
      "end": 757.36,
      "text": " documentation guidelines around how you structure that content and technical writing will have to",
      "tokens": [
        50996,
        14333,
        12470,
        926,
        577,
        291,
        3877,
        300,
        2701,
        293,
        6191,
        3579,
        486,
        362,
        281,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14716669456245973,
      "compression_ratio": 1.8525896414342629,
      "no_speech_prob": 0.0002255118452012539
    },
    {
      "id": 126,
      "seek": 73920,
      "start": 757.36,
      "end": 763.0400000000001,
      "text": " be involved for sure there helping out with the copy but yeah the guidelines are still a work in",
      "tokens": [
        51272,
        312,
        3288,
        337,
        988,
        456,
        4315,
        484,
        365,
        264,
        5055,
        457,
        1338,
        264,
        12470,
        366,
        920,
        257,
        589,
        294,
        51556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14716669456245973,
      "compression_ratio": 1.8525896414342629,
      "no_speech_prob": 0.0002255118452012539
    },
    {
      "id": 127,
      "seek": 73920,
      "start": 763.0400000000001,
      "end": 768.96,
      "text": " progress it's the OR is still being refined there's a bunch of threats there and questions",
      "tokens": [
        51556,
        4205,
        309,
        311,
        264,
        19654,
        307,
        920,
        885,
        26201,
        456,
        311,
        257,
        3840,
        295,
        14909,
        456,
        293,
        1651,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14716669456245973,
      "compression_ratio": 1.8525896414342629,
      "no_speech_prob": 0.0002255118452012539
    },
    {
      "id": 128,
      "seek": 76896,
      "start": 768.96,
      "end": 774.72,
      "text": " so if you have the time feel free to jump in especially if you think there might be a need for",
      "tokens": [
        50364,
        370,
        498,
        291,
        362,
        264,
        565,
        841,
        1737,
        281,
        3012,
        294,
        2318,
        498,
        291,
        519,
        456,
        1062,
        312,
        257,
        643,
        337,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07312525898577218,
      "compression_ratio": 1.7339449541284404,
      "no_speech_prob": 0.0002075247175525874
    },
    {
      "id": 129,
      "seek": 76896,
      "start": 774.72,
      "end": 779.6800000000001,
      "text": " a health drawer in your stage group because we need to account for all kinds of different",
      "tokens": [
        50652,
        257,
        1585,
        24039,
        294,
        428,
        3233,
        1594,
        570,
        321,
        643,
        281,
        2696,
        337,
        439,
        3685,
        295,
        819,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07312525898577218,
      "compression_ratio": 1.7339449541284404,
      "no_speech_prob": 0.0002075247175525874
    },
    {
      "id": 130,
      "seek": 76896,
      "start": 779.6800000000001,
      "end": 789.0400000000001,
      "text": " use cases and we had some interest from several different stage groups but I think the requirements",
      "tokens": [
        50900,
        764,
        3331,
        293,
        321,
        632,
        512,
        1179,
        490,
        2940,
        819,
        3233,
        3935,
        457,
        286,
        519,
        264,
        7728,
        51368
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07312525898577218,
      "compression_ratio": 1.7339449541284404,
      "no_speech_prob": 0.0002075247175525874
    },
    {
      "id": 131,
      "seek": 76896,
      "start": 789.0400000000001,
      "end": 793.2,
      "text": " might really vary depending on what kind of task you want to support and what kind of content",
      "tokens": [
        51368,
        1062,
        534,
        10559,
        5413,
        322,
        437,
        733,
        295,
        5633,
        291,
        528,
        281,
        1406,
        293,
        437,
        733,
        295,
        2701,
        51576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07312525898577218,
      "compression_ratio": 1.7339449541284404,
      "no_speech_prob": 0.0002075247175525874
    },
    {
      "id": 132,
      "seek": 79320,
      "start": 793.2,
      "end": 796.5600000000001,
      "text": " you want to show so we want to make sure we account for those.",
      "tokens": [
        50364,
        291,
        528,
        281,
        855,
        370,
        321,
        528,
        281,
        652,
        988,
        321,
        2696,
        337,
        729,
        13,
        50532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27688134800304065,
      "compression_ratio": 1.5475113122171946,
      "no_speech_prob": 0.004858713131397963
    },
    {
      "id": 133,
      "seek": 79320,
      "start": 805.12,
      "end": 812.0,
      "text": " That's all from me. We think I'll take it away. All right so I just have like very small updates.",
      "tokens": [
        50960,
        663,
        311,
        439,
        490,
        385,
        13,
        492,
        519,
        286,
        603,
        747,
        309,
        1314,
        13,
        1057,
        558,
        370,
        286,
        445,
        362,
        411,
        588,
        1359,
        9205,
        13,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27688134800304065,
      "compression_ratio": 1.5475113122171946,
      "no_speech_prob": 0.004858713131397963
    },
    {
      "id": 134,
      "seek": 79320,
      "start": 812.0,
      "end": 816.88,
      "text": " I have I'm still busy in fact I just did the last interview the ninth interview for the",
      "tokens": [
        51304,
        286,
        362,
        286,
        478,
        920,
        5856,
        294,
        1186,
        286,
        445,
        630,
        264,
        1036,
        4049,
        264,
        28207,
        4049,
        337,
        264,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27688134800304065,
      "compression_ratio": 1.5475113122171946,
      "no_speech_prob": 0.004858713131397963
    },
    {
      "id": 135,
      "seek": 79320,
      "start": 816.88,
      "end": 822.32,
      "text": " foundational research for PIPEN execution and it's going very well and I would be sharing the",
      "tokens": [
        51548,
        32195,
        2132,
        337,
        430,
        9139,
        2195,
        15058,
        293,
        309,
        311,
        516,
        588,
        731,
        293,
        286,
        576,
        312,
        5414,
        264,
        51820
      ],
      "temperature": 0.0,
      "avg_logprob": -0.27688134800304065,
      "compression_ratio": 1.5475113122171946,
      "no_speech_prob": 0.004858713131397963
    },
    {
      "id": 136,
      "seek": 82232,
      "start": 822.32,
      "end": 830.72,
      "text": " results on Friday mostly for this and I have added the dovetail link which has about six interviews",
      "tokens": [
        50364,
        3542,
        322,
        6984,
        5240,
        337,
        341,
        293,
        286,
        362,
        3869,
        264,
        360,
        9771,
        864,
        2113,
        597,
        575,
        466,
        2309,
        12318,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11404545627423186,
      "compression_ratio": 1.5654450261780104,
      "no_speech_prob": 0.002277063438668847
    },
    {
      "id": 137,
      "seek": 82232,
      "start": 830.72,
      "end": 839.6800000000001,
      "text": " uploaded until now so I would update this further and share with the team and with the findings of",
      "tokens": [
        50784,
        17135,
        1826,
        586,
        370,
        286,
        576,
        5623,
        341,
        3052,
        293,
        2073,
        365,
        264,
        1469,
        293,
        365,
        264,
        16483,
        295,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11404545627423186,
      "compression_ratio": 1.5654450261780104,
      "no_speech_prob": 0.002277063438668847
    },
    {
      "id": 138,
      "seek": 82232,
      "start": 839.6800000000001,
      "end": 848.8800000000001,
      "text": " course. The next thing is James and I have worked on the priority for design issues for this quarter",
      "tokens": [
        51232,
        1164,
        13,
        440,
        958,
        551,
        307,
        5678,
        293,
        286,
        362,
        2732,
        322,
        264,
        9365,
        337,
        1715,
        2663,
        337,
        341,
        6555,
        51692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11404545627423186,
      "compression_ratio": 1.5654450261780104,
      "no_speech_prob": 0.002277063438668847
    },
    {
      "id": 139,
      "seek": 84888,
      "start": 848.96,
      "end": 855.92,
      "text": " so if you just go to this epic you would be able to see a reprioritized list so that's what that's",
      "tokens": [
        50368,
        370,
        498,
        291,
        445,
        352,
        281,
        341,
        13581,
        291,
        576,
        312,
        1075,
        281,
        536,
        257,
        1085,
        470,
        50017,
        1602,
        1329,
        370,
        300,
        311,
        437,
        300,
        311,
        50716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10261833424470862,
      "compression_ratio": 1.7268722466960353,
      "no_speech_prob": 0.008140486665070057
    },
    {
      "id": 140,
      "seek": 84888,
      "start": 855.92,
      "end": 860.8,
      "text": " how I would be going about working on these design issues in the same sequence as you see in",
      "tokens": [
        50716,
        577,
        286,
        576,
        312,
        516,
        466,
        1364,
        322,
        613,
        1715,
        2663,
        294,
        264,
        912,
        8310,
        382,
        291,
        536,
        294,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10261833424470862,
      "compression_ratio": 1.7268722466960353,
      "no_speech_prob": 0.008140486665070057
    },
    {
      "id": 141,
      "seek": 84888,
      "start": 860.8,
      "end": 868.64,
      "text": " trying to feel like the one on the top is the highest importance to us and I mean Nadia if you see",
      "tokens": [
        50960,
        1382,
        281,
        841,
        411,
        264,
        472,
        322,
        264,
        1192,
        307,
        264,
        6343,
        7379,
        281,
        505,
        293,
        286,
        914,
        23269,
        654,
        498,
        291,
        536,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10261833424470862,
      "compression_ratio": 1.7268722466960353,
      "no_speech_prob": 0.008140486665070057
    },
    {
      "id": 142,
      "seek": 84888,
      "start": 868.64,
      "end": 874.08,
      "text": " the top issue it's something that we have discussed about but there are some updates about it I think",
      "tokens": [
        51352,
        264,
        1192,
        2734,
        309,
        311,
        746,
        300,
        321,
        362,
        7152,
        466,
        457,
        456,
        366,
        512,
        9205,
        466,
        309,
        286,
        519,
        51624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10261833424470862,
      "compression_ratio": 1.7268722466960353,
      "no_speech_prob": 0.008140486665070057
    },
    {
      "id": 143,
      "seek": 87408,
      "start": 874.08,
      "end": 880.5600000000001,
      "text": " James would have put an update there that basically it's not what we thought it is it's different",
      "tokens": [
        50364,
        5678,
        576,
        362,
        829,
        364,
        5623,
        456,
        300,
        1936,
        309,
        311,
        406,
        437,
        321,
        1194,
        309,
        307,
        309,
        311,
        819,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07062567144200421,
      "compression_ratio": 1.5852272727272727,
      "no_speech_prob": 0.0023655155673623085
    },
    {
      "id": 144,
      "seek": 87408,
      "start": 880.5600000000001,
      "end": 889.84,
      "text": " it's just an experiment and yeah that's it nothing more from my side let's see what's there in the",
      "tokens": [
        50688,
        309,
        311,
        445,
        364,
        5120,
        293,
        1338,
        300,
        311,
        309,
        1825,
        544,
        490,
        452,
        1252,
        718,
        311,
        536,
        437,
        311,
        456,
        294,
        264,
        51152
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07062567144200421,
      "compression_ratio": 1.5852272727272727,
      "no_speech_prob": 0.0023655155673623085
    },
    {
      "id": 145,
      "seek": 87408,
      "start": 889.84,
      "end": 900.0,
      "text": " UX research thread so we have a new page our UXR training resources has a new page",
      "tokens": [
        51152,
        40176,
        2132,
        7207,
        370,
        321,
        362,
        257,
        777,
        3028,
        527,
        40176,
        49,
        3097,
        3593,
        575,
        257,
        777,
        3028,
        51660
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07062567144200421,
      "compression_ratio": 1.5852272727272727,
      "no_speech_prob": 0.0023655155673623085
    },
    {
      "id": 146,
      "seek": 90000,
      "start": 900.08,
      "end": 906.64,
      "text": " on using quantitative data to find insights you can go ahead check there and then will and Erica",
      "tokens": [
        50368,
        322,
        1228,
        27778,
        1412,
        281,
        915,
        14310,
        291,
        393,
        352,
        2286,
        1520,
        456,
        293,
        550,
        486,
        293,
        37429,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18792539834976196,
      "compression_ratio": 1.5251396648044693,
      "no_speech_prob": 0.0032048651482909918
    },
    {
      "id": 147,
      "seek": 90000,
      "start": 906.64,
      "end": 915.44,
      "text": " have posted a link to their prioritization issues and that's it anything else before we wrap up",
      "tokens": [
        50696,
        362,
        9437,
        257,
        2113,
        281,
        641,
        14846,
        2144,
        2663,
        293,
        300,
        311,
        309,
        1340,
        1646,
        949,
        321,
        7019,
        493,
        51136
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18792539834976196,
      "compression_ratio": 1.5251396648044693,
      "no_speech_prob": 0.0032048651482909918
    },
    {
      "id": 148,
      "seek": 90000,
      "start": 919.36,
      "end": 926.24,
      "text": " okay we all get some time back in that case I will good day ahead all of you bye",
      "tokens": [
        51332,
        1392,
        321,
        439,
        483,
        512,
        565,
        646,
        294,
        300,
        1389,
        286,
        486,
        665,
        786,
        2286,
        439,
        295,
        291,
        6543,
        51676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18792539834976196,
      "compression_ratio": 1.5251396648044693,
      "no_speech_prob": 0.0032048651482909918
    },
    {
      "id": 149,
      "seek": 92624,
      "start": 926.24,
      "end": 938.72,
      "text": " you",
      "tokens": [
        50364,
        291,
        50988
      ],
      "temperature": 1.0,
      "avg_logprob": -2.1745517253875732,
      "compression_ratio": 0.2727272727272727,
      "no_speech_prob": 0.19448263943195343
    }
  ]
}