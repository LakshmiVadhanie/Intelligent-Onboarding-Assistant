{
  "title": "CI/CD UX Meeting Part II - 2023-09-13",
  "video_id": "kGHyK_SkZB0",
  "url": "https://www.youtube.com/watch?v=kGHyK_SkZB0",
  "transcript": " Maybe you can. Yeah. But I don't know where this is getting recorded to a cloud on my computer. Anyway. Yeah, so I was saying that Sanjum, I learned a lot from the process that you were following and all the learnings that came from that and so like we thought that it's going to be good to kick it, kick it off as soon as possible. I'm not waiting for everything to develop first and then think about where to place it. Yeah, yeah. This is the right way to go. Thanks for sharing. So my item on there is free of big and rather radical change from the CSED private catalog. So we discussed this a lot and this came up and inspired me a lot while I did the journey map exercise. And I didn't feel this right to having this private CSED catalog scope for namespace because we have interviewed several self manage and customer. It could be really multiple namespaces. I'm not going to disclose the exact number, but you could be a lot. Of course, it depends on the organization size. And now, dove announced this change and this will impact a bit of our product roadmap or the timeline, the design wise that impact is not that big. But I think this is the right way to go. So I was fully supportive about this change. And yeah, you can see that now we simply find the structure. So we will have one organization catalog and one open source catalog that is kind of similar to the marketplace. And I have personal updates. So you can read through it. I might need to reschedule some of our coffee chat or one of one if I need to from next week until the end of September. I wanted to hear with you all. So hi, I am. Yeah. Emotions are not working. Yeah. It's mostly common control shift that works for me to show the model or the emojis. I'm not sure if it's the lock. Not ship sorry space. Okay, so. So my Ana is not here. So we can just go through this asynchronously. Maybe we can move to a resource then. Yes. So I am just analyzing all the sessions from how do we use AI to help users optimize their runner and CI builds. And it's pretty cool. We use like a decision tree process from this book on AI that I'm reading and basically the idea is if you can put the decisions into like clear if then statements, then you have support that you can automate this workflow a bit. So we didn't know if it would be like I think about this, but that's related to this and then this is really, but actually it's like pretty straightforward. Anyway, so I won't go into the results, but I'm working on the report. And that'll come out. I think I'll share it with the UXR team soon and then it will come out next week. But there's really good information in there about. And just the details that people need to make decisions. And kind of the outcomes for optimizing pipelines. And the process is very trial and error. And set it and forget it. That's the main thing. So I think that's like one of our CI learnings just like the biggest thing I've learned at GitLab. And I think that's the thing that they don't think of these things in their minds either like they specialize in it, they execute and then they go away. But I think that there's also findings related to how to like support teamwork. So I think you'll like their report. And then next week or as soon as I kind of like get my mind into that report, then I'll start working on this how users are using GitLab and the cloud. And we'll do what I ask you. Yeah, could you just elaborate a little bit more on the effort. Yeah, so I'm actually very proud of us as a product company that we're like ready to move into this space. So we're looking at kind of the connection points between GitLab and the cloud. I'm like where the work flow links are, kind of the tools that users are using. And that'll inform in part of some integrations that we're building. Like June with GCP, but then also like long term what works well in terms of the integrating. And that's actually where I think we can bring in some questions about resources and whether or not they should live at the project or the group level. Like how teams access like secrets for example, like where do those get stored and GitLab. And is it like higher up organization? Because I'm thinking a lot about this new change that's coming related to organizations with some new notes because that's like the new play with the catalog, which I think is really smart. And which is to put it up there. But then I'm wondering like what else could we move up there? Like maybe the secrets because they're at their organized at this company level. But that's what we can look into. Talking about that Erica, I like, can you like later go and chime into the issue that I've created for navigation and like share your views there. And then I think that's what we're going to do is, yeah, we don't want, even though I have mentioned about like taking it out of CICD. If there's any any research that points that we should have it maybe as a part of the mind navigation or at a higher level navigation. We should be aware of that and that would help us inform the methodologies that we would like select for research. And that's actually that detailed because that's actually like really tactical. Most of the research so far has been like, what is this secrets? So, but I'll look, I'll look up with the lens on there, but I think I won't have much. But I think from this study, we might get something. Okay. And by the way, I've also picked this up based on your recommendation. I think that's something to do. You can read that chapter. Sorry. No, it's okay. I just have another like follow up question. Are you only looking at GitLab sass user, so I was trying to read through your issue. And I mentioned that because one of the teams that I work with and enablements currently the application performance group is changing their name. To cloud connector. Okay. And they're focusing on. Self managed users, essentially giving them access to like AI features and things that would be available through GitLab sass, but at the self managed level. So that might be a good team to connect with. You know, in terms of this research. Okay. Thank you. I think we landed on the sass. Users. Yeah, but either way, I think they would at least be interested. So that's so helpful. Well, thank you. I'm embarrassed that I can't quickly find that image too, but it's okay. I'm on the other project. Yeah. So if you want to ping their entire group, I can list the channel there. And then the feedback and also list the PM as well. Okay. Cool. I just put thank you. Thank you. We'll go team. And then I have this is no. I have to find it in the, but I'm watching the sessions again and again. So it's coming. But there's just lovely quote about how we made a change and. The details people could see about the type lines completing. And this woman was like, I love it. And I think she was like, I'm going to have to do a lot of things. And then I'm going to have to do a lot of things. And then I'm going to use it the other day to show my executives that I need more funding. For my pipelines because I could show like kind of the times and how if we reorganize things, this would impact the times. And then she used that to find more of our product. So that's like the best. You can put this in your portfolio, Bica. And then I'm going to put it in your portfolio. Oh, no. I mean, I don't know. But when she was telling me was that the new way that she can look at the metrics. Allow her to make this argument. I need to pull up the. I'll pull up the quote. Okay. It was pre on. Nice. I think it's a good thing. I think it's a good thing. The other updates before I go or. No, days were taking. So I don't necessarily have anything. Connected to delivery or dedicated this week. I guess just a. Announce what I'm working on outside of that. So I included the research issue. And I've been constantly like adding and refining research questions there. And then I'm doing a workshop on breaking changes. Some adding people from different departments at the moment. And can be doing that soon. It's going to be kind of a mix of async and synchronous. Workshop parts. I was looking for Jocelyn and the list because I mean given how much she has been struggling with breaking changes and I see her there. Yeah, that was somebody who came up pretty quickly in conversations with the PM that I'm working with Sam. He was like Jocelyn definitely let's include her. But if you have any other suggestions on who might be a good person to include. Let me know. So that's all the updates that I have this week. Okay, so with this we are at the end of the agenda. Anything that someone wants to bring up. If not, then the is it. It's in the meeting here. Hi everyone. Have a good one.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 2.0,
      "text": " Maybe you can. Yeah.",
      "tokens": [
        50364,
        2704,
        291,
        393,
        13,
        865,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26064206935741285,
      "compression_ratio": 1.6091954022988506,
      "no_speech_prob": 0.1030849814414978
    },
    {
      "id": 1,
      "seek": 0,
      "start": 4.0,
      "end": 8.0,
      "text": " But I don't know where this is getting recorded to a cloud on my computer. Anyway.",
      "tokens": [
        50564,
        583,
        286,
        500,
        380,
        458,
        689,
        341,
        307,
        1242,
        8287,
        281,
        257,
        4588,
        322,
        452,
        3820,
        13,
        5684,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26064206935741285,
      "compression_ratio": 1.6091954022988506,
      "no_speech_prob": 0.1030849814414978
    },
    {
      "id": 2,
      "seek": 0,
      "start": 8.0,
      "end": 21.0,
      "text": " Yeah, so I was saying that Sanjum, I learned a lot from the process that you were following and all the learnings that came from that and so like we thought that it's going to be good to kick it, kick it off as soon as possible.",
      "tokens": [
        50764,
        865,
        11,
        370,
        286,
        390,
        1566,
        300,
        5271,
        73,
        449,
        11,
        286,
        3264,
        257,
        688,
        490,
        264,
        1399,
        300,
        291,
        645,
        3480,
        293,
        439,
        264,
        2539,
        82,
        300,
        1361,
        490,
        300,
        293,
        370,
        411,
        321,
        1194,
        300,
        309,
        311,
        516,
        281,
        312,
        665,
        281,
        4437,
        309,
        11,
        4437,
        309,
        766,
        382,
        2321,
        382,
        1944,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26064206935741285,
      "compression_ratio": 1.6091954022988506,
      "no_speech_prob": 0.1030849814414978
    },
    {
      "id": 3,
      "seek": 0,
      "start": 21.0,
      "end": 25.0,
      "text": " I'm not waiting for everything to develop first and then think about where to place it.",
      "tokens": [
        51414,
        286,
        478,
        406,
        3806,
        337,
        1203,
        281,
        1499,
        700,
        293,
        550,
        519,
        466,
        689,
        281,
        1081,
        309,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26064206935741285,
      "compression_ratio": 1.6091954022988506,
      "no_speech_prob": 0.1030849814414978
    },
    {
      "id": 4,
      "seek": 2500,
      "start": 26.0,
      "end": 27.0,
      "text": " Yeah, yeah.",
      "tokens": [
        50414,
        865,
        11,
        1338,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25645206996372766,
      "compression_ratio": 1.4463276836158192,
      "no_speech_prob": 0.08218982815742493
    },
    {
      "id": 5,
      "seek": 2500,
      "start": 27.0,
      "end": 30.0,
      "text": " This is the right way to go. Thanks for sharing.",
      "tokens": [
        50464,
        639,
        307,
        264,
        558,
        636,
        281,
        352,
        13,
        2561,
        337,
        5414,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25645206996372766,
      "compression_ratio": 1.4463276836158192,
      "no_speech_prob": 0.08218982815742493
    },
    {
      "id": 6,
      "seek": 2500,
      "start": 30.0,
      "end": 40.0,
      "text": " So my item on there is free of big and rather radical change from the CSED private catalog.",
      "tokens": [
        50614,
        407,
        452,
        3174,
        322,
        456,
        307,
        1737,
        295,
        955,
        293,
        2831,
        12001,
        1319,
        490,
        264,
        383,
        5879,
        35,
        4551,
        19746,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25645206996372766,
      "compression_ratio": 1.4463276836158192,
      "no_speech_prob": 0.08218982815742493
    },
    {
      "id": 7,
      "seek": 2500,
      "start": 40.0,
      "end": 49.0,
      "text": " So we discussed this a lot and this came up and inspired me a lot while I did the journey map exercise.",
      "tokens": [
        51114,
        407,
        321,
        7152,
        341,
        257,
        688,
        293,
        341,
        1361,
        493,
        293,
        7547,
        385,
        257,
        688,
        1339,
        286,
        630,
        264,
        4671,
        4471,
        5380,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.25645206996372766,
      "compression_ratio": 1.4463276836158192,
      "no_speech_prob": 0.08218982815742493
    },
    {
      "id": 8,
      "seek": 4900,
      "start": 49.0,
      "end": 62.0,
      "text": " And I didn't feel this right to having this private CSED catalog scope for namespace because we have interviewed several self manage and customer.",
      "tokens": [
        50364,
        400,
        286,
        994,
        380,
        841,
        341,
        558,
        281,
        1419,
        341,
        4551,
        383,
        5879,
        35,
        19746,
        11923,
        337,
        5288,
        17940,
        570,
        321,
        362,
        19770,
        2940,
        2698,
        3067,
        293,
        5474,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2455754358260358,
      "compression_ratio": 1.4350282485875707,
      "no_speech_prob": 0.028773875907063484
    },
    {
      "id": 9,
      "seek": 4900,
      "start": 62.0,
      "end": 71.0,
      "text": " It could be really multiple namespaces. I'm not going to disclose the exact number, but you could be a lot.",
      "tokens": [
        51014,
        467,
        727,
        312,
        534,
        3866,
        5288,
        79,
        2116,
        13,
        286,
        478,
        406,
        516,
        281,
        36146,
        264,
        1900,
        1230,
        11,
        457,
        291,
        727,
        312,
        257,
        688,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2455754358260358,
      "compression_ratio": 1.4350282485875707,
      "no_speech_prob": 0.028773875907063484
    },
    {
      "id": 10,
      "seek": 7100,
      "start": 71.0,
      "end": 74.0,
      "text": " Of course, it depends on the organization size.",
      "tokens": [
        50364,
        2720,
        1164,
        11,
        309,
        5946,
        322,
        264,
        4475,
        2744,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3267122705777486,
      "compression_ratio": 1.4130434782608696,
      "no_speech_prob": 0.26621124148368835
    },
    {
      "id": 11,
      "seek": 7100,
      "start": 74.0,
      "end": 88.0,
      "text": " And now, dove announced this change and this will impact a bit of our product roadmap or the timeline, the design wise that impact is not that big.",
      "tokens": [
        50514,
        400,
        586,
        11,
        360,
        303,
        7548,
        341,
        1319,
        293,
        341,
        486,
        2712,
        257,
        857,
        295,
        527,
        1674,
        35738,
        420,
        264,
        12933,
        11,
        264,
        1715,
        10829,
        300,
        2712,
        307,
        406,
        300,
        955,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3267122705777486,
      "compression_ratio": 1.4130434782608696,
      "no_speech_prob": 0.26621124148368835
    },
    {
      "id": 12,
      "seek": 8800,
      "start": 88.0,
      "end": 94.0,
      "text": " But I think this is the right way to go. So I was fully supportive about this change.",
      "tokens": [
        50364,
        583,
        286,
        519,
        341,
        307,
        264,
        558,
        636,
        281,
        352,
        13,
        407,
        286,
        390,
        4498,
        14435,
        466,
        341,
        1319,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14827600072641842,
      "compression_ratio": 1.463276836158192,
      "no_speech_prob": 0.09428823739290237
    },
    {
      "id": 13,
      "seek": 8800,
      "start": 94.0,
      "end": 108.0,
      "text": " And yeah, you can see that now we simply find the structure. So we will have one organization catalog and one open source catalog that is kind of similar to the marketplace.",
      "tokens": [
        50664,
        400,
        1338,
        11,
        291,
        393,
        536,
        300,
        586,
        321,
        2935,
        915,
        264,
        3877,
        13,
        407,
        321,
        486,
        362,
        472,
        4475,
        19746,
        293,
        472,
        1269,
        4009,
        19746,
        300,
        307,
        733,
        295,
        2531,
        281,
        264,
        19455,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14827600072641842,
      "compression_ratio": 1.463276836158192,
      "no_speech_prob": 0.09428823739290237
    },
    {
      "id": 14,
      "seek": 10800,
      "start": 108.0,
      "end": 123.0,
      "text": " And I have personal updates. So you can read through it. I might need to reschedule some of our coffee chat or one of one if I need to from next week until the end of September.",
      "tokens": [
        50364,
        400,
        286,
        362,
        2973,
        9205,
        13,
        407,
        291,
        393,
        1401,
        807,
        309,
        13,
        286,
        1062,
        643,
        281,
        725,
        19318,
        2271,
        512,
        295,
        527,
        4982,
        5081,
        420,
        472,
        295,
        472,
        498,
        286,
        643,
        281,
        490,
        958,
        1243,
        1826,
        264,
        917,
        295,
        7216,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2999341103338426,
      "compression_ratio": 1.4258064516129032,
      "no_speech_prob": 0.04771513491868973
    },
    {
      "id": 15,
      "seek": 10800,
      "start": 123.0,
      "end": 131.0,
      "text": " I wanted to hear with you all. So hi, I am.",
      "tokens": [
        51114,
        286,
        1415,
        281,
        1568,
        365,
        291,
        439,
        13,
        407,
        4879,
        11,
        286,
        669,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2999341103338426,
      "compression_ratio": 1.4258064516129032,
      "no_speech_prob": 0.04771513491868973
    },
    {
      "id": 16,
      "seek": 13100,
      "start": 131.0,
      "end": 139.0,
      "text": " Yeah.",
      "tokens": [
        50364,
        865,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28984534740448,
      "compression_ratio": 1.198019801980198,
      "no_speech_prob": 0.03153980150818825
    },
    {
      "id": 17,
      "seek": 13100,
      "start": 139.0,
      "end": 142.0,
      "text": " Emotions are not working.",
      "tokens": [
        50764,
        3968,
        310,
        626,
        366,
        406,
        1364,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28984534740448,
      "compression_ratio": 1.198019801980198,
      "no_speech_prob": 0.03153980150818825
    },
    {
      "id": 18,
      "seek": 13100,
      "start": 142.0,
      "end": 147.0,
      "text": " Yeah.",
      "tokens": [
        50914,
        865,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28984534740448,
      "compression_ratio": 1.198019801980198,
      "no_speech_prob": 0.03153980150818825
    },
    {
      "id": 19,
      "seek": 13100,
      "start": 147.0,
      "end": 156.0,
      "text": " It's mostly common control shift that works for me to show the model or the emojis.",
      "tokens": [
        51164,
        467,
        311,
        5240,
        2689,
        1969,
        5513,
        300,
        1985,
        337,
        385,
        281,
        855,
        264,
        2316,
        420,
        264,
        19611,
        40371,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.28984534740448,
      "compression_ratio": 1.198019801980198,
      "no_speech_prob": 0.03153980150818825
    },
    {
      "id": 20,
      "seek": 15600,
      "start": 156.0,
      "end": 160.0,
      "text": " I'm not sure if it's the lock.",
      "tokens": [
        50364,
        286,
        478,
        406,
        988,
        498,
        309,
        311,
        264,
        4017,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.9574411886709707,
      "compression_ratio": 0.9393939393939394,
      "no_speech_prob": 0.06015755236148834
    },
    {
      "id": 21,
      "seek": 15600,
      "start": 160.0,
      "end": 167.0,
      "text": " Not ship sorry space.",
      "tokens": [
        50564,
        1726,
        5374,
        2597,
        1901,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.9574411886709707,
      "compression_ratio": 0.9393939393939394,
      "no_speech_prob": 0.06015755236148834
    },
    {
      "id": 22,
      "seek": 15600,
      "start": 167.0,
      "end": 168.0,
      "text": " Okay, so.",
      "tokens": [
        50914,
        1033,
        11,
        370,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.9574411886709707,
      "compression_ratio": 0.9393939393939394,
      "no_speech_prob": 0.06015755236148834
    },
    {
      "id": 23,
      "seek": 16800,
      "start": 168.0,
      "end": 175.0,
      "text": " So my Ana is not here. So we can just go through this asynchronously.",
      "tokens": [
        50364,
        407,
        452,
        21202,
        307,
        406,
        510,
        13,
        407,
        321,
        393,
        445,
        352,
        807,
        341,
        42642,
        5098,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2508350531260172,
      "compression_ratio": 1.3975155279503106,
      "no_speech_prob": 0.01245605107396841
    },
    {
      "id": 24,
      "seek": 16800,
      "start": 175.0,
      "end": 183.0,
      "text": " Maybe we can move to a resource then.",
      "tokens": [
        50714,
        2704,
        321,
        393,
        1286,
        281,
        257,
        7684,
        550,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2508350531260172,
      "compression_ratio": 1.3975155279503106,
      "no_speech_prob": 0.01245605107396841
    },
    {
      "id": 25,
      "seek": 16800,
      "start": 183.0,
      "end": 195.0,
      "text": " Yes. So I am just analyzing all the sessions from how do we use AI to help users optimize their runner and CI builds.",
      "tokens": [
        51114,
        1079,
        13,
        407,
        286,
        669,
        445,
        23663,
        439,
        264,
        11081,
        490,
        577,
        360,
        321,
        764,
        7318,
        281,
        854,
        5022,
        19719,
        641,
        24376,
        293,
        37777,
        15182,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2508350531260172,
      "compression_ratio": 1.3975155279503106,
      "no_speech_prob": 0.01245605107396841
    },
    {
      "id": 26,
      "seek": 19500,
      "start": 195.0,
      "end": 213.0,
      "text": " And it's pretty cool. We use like a decision tree process from this book on AI that I'm reading and basically the idea is if you can put the decisions into like clear if then statements, then you have support that you can automate this workflow a bit.",
      "tokens": [
        50364,
        400,
        309,
        311,
        1238,
        1627,
        13,
        492,
        764,
        411,
        257,
        3537,
        4230,
        1399,
        490,
        341,
        1446,
        322,
        7318,
        300,
        286,
        478,
        3760,
        293,
        1936,
        264,
        1558,
        307,
        498,
        291,
        393,
        829,
        264,
        5327,
        666,
        411,
        1850,
        498,
        550,
        12363,
        11,
        550,
        291,
        362,
        1406,
        300,
        291,
        393,
        31605,
        341,
        20993,
        257,
        857,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17849960661771005,
      "compression_ratio": 1.494047619047619,
      "no_speech_prob": 0.00599918607622385
    },
    {
      "id": 27,
      "seek": 21300,
      "start": 213.0,
      "end": 220.0,
      "text": " So we didn't know if it would be like I think about this, but that's related to this and then this is really, but actually it's like pretty straightforward.",
      "tokens": [
        50364,
        407,
        321,
        994,
        380,
        458,
        498,
        309,
        576,
        312,
        411,
        286,
        519,
        466,
        341,
        11,
        457,
        300,
        311,
        4077,
        281,
        341,
        293,
        550,
        341,
        307,
        534,
        11,
        457,
        767,
        309,
        311,
        411,
        1238,
        15325,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13893991413682993,
      "compression_ratio": 1.6798245614035088,
      "no_speech_prob": 0.022139770910143852
    },
    {
      "id": 28,
      "seek": 21300,
      "start": 220.0,
      "end": 225.0,
      "text": " Anyway, so I won't go into the results, but I'm working on the report.",
      "tokens": [
        50714,
        5684,
        11,
        370,
        286,
        1582,
        380,
        352,
        666,
        264,
        3542,
        11,
        457,
        286,
        478,
        1364,
        322,
        264,
        2275,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13893991413682993,
      "compression_ratio": 1.6798245614035088,
      "no_speech_prob": 0.022139770910143852
    },
    {
      "id": 29,
      "seek": 21300,
      "start": 225.0,
      "end": 231.0,
      "text": " And that'll come out. I think I'll share it with the UXR team soon and then it will come out next week.",
      "tokens": [
        50964,
        400,
        300,
        603,
        808,
        484,
        13,
        286,
        519,
        286,
        603,
        2073,
        309,
        365,
        264,
        40176,
        49,
        1469,
        2321,
        293,
        550,
        309,
        486,
        808,
        484,
        958,
        1243,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13893991413682993,
      "compression_ratio": 1.6798245614035088,
      "no_speech_prob": 0.022139770910143852
    },
    {
      "id": 30,
      "seek": 21300,
      "start": 231.0,
      "end": 235.0,
      "text": " But there's really good information in there about.",
      "tokens": [
        51264,
        583,
        456,
        311,
        534,
        665,
        1589,
        294,
        456,
        466,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13893991413682993,
      "compression_ratio": 1.6798245614035088,
      "no_speech_prob": 0.022139770910143852
    },
    {
      "id": 31,
      "seek": 23500,
      "start": 235.0,
      "end": 240.0,
      "text": " And just the details that people need to make decisions.",
      "tokens": [
        50364,
        400,
        445,
        264,
        4365,
        300,
        561,
        643,
        281,
        652,
        5327,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1382444088275616,
      "compression_ratio": 1.5179487179487179,
      "no_speech_prob": 0.020179852843284607
    },
    {
      "id": 32,
      "seek": 23500,
      "start": 240.0,
      "end": 244.0,
      "text": " And kind of the outcomes for optimizing pipelines.",
      "tokens": [
        50614,
        400,
        733,
        295,
        264,
        10070,
        337,
        40425,
        40168,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1382444088275616,
      "compression_ratio": 1.5179487179487179,
      "no_speech_prob": 0.020179852843284607
    },
    {
      "id": 33,
      "seek": 23500,
      "start": 244.0,
      "end": 249.0,
      "text": " And the process is very trial and error.",
      "tokens": [
        50814,
        400,
        264,
        1399,
        307,
        588,
        7308,
        293,
        6713,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1382444088275616,
      "compression_ratio": 1.5179487179487179,
      "no_speech_prob": 0.020179852843284607
    },
    {
      "id": 34,
      "seek": 23500,
      "start": 249.0,
      "end": 252.0,
      "text": " And set it and forget it. That's the main thing.",
      "tokens": [
        51064,
        400,
        992,
        309,
        293,
        2870,
        309,
        13,
        663,
        311,
        264,
        2135,
        551,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1382444088275616,
      "compression_ratio": 1.5179487179487179,
      "no_speech_prob": 0.020179852843284607
    },
    {
      "id": 35,
      "seek": 23500,
      "start": 252.0,
      "end": 260.0,
      "text": " So I think that's like one of our CI learnings just like the biggest thing I've learned at GitLab.",
      "tokens": [
        51214,
        407,
        286,
        519,
        300,
        311,
        411,
        472,
        295,
        527,
        37777,
        2539,
        82,
        445,
        411,
        264,
        3880,
        551,
        286,
        600,
        3264,
        412,
        16939,
        37880,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1382444088275616,
      "compression_ratio": 1.5179487179487179,
      "no_speech_prob": 0.020179852843284607
    },
    {
      "id": 36,
      "seek": 26000,
      "start": 260.0,
      "end": 268.0,
      "text": " And I think that's the thing that they don't think of these things in their minds either like they specialize in it, they execute and then they go away.",
      "tokens": [
        50364,
        400,
        286,
        519,
        300,
        311,
        264,
        551,
        300,
        436,
        500,
        380,
        519,
        295,
        613,
        721,
        294,
        641,
        9634,
        2139,
        411,
        436,
        37938,
        294,
        309,
        11,
        436,
        14483,
        293,
        550,
        436,
        352,
        1314,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21966116244976336,
      "compression_ratio": 1.7396694214876034,
      "no_speech_prob": 0.0038979563396424055
    },
    {
      "id": 37,
      "seek": 26000,
      "start": 268.0,
      "end": 273.0,
      "text": " But I think that there's also findings related to how to like support teamwork.",
      "tokens": [
        50764,
        583,
        286,
        519,
        300,
        456,
        311,
        611,
        16483,
        4077,
        281,
        577,
        281,
        411,
        1406,
        30015,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21966116244976336,
      "compression_ratio": 1.7396694214876034,
      "no_speech_prob": 0.0038979563396424055
    },
    {
      "id": 38,
      "seek": 26000,
      "start": 273.0,
      "end": 276.0,
      "text": " So I think you'll like their report.",
      "tokens": [
        51014,
        407,
        286,
        519,
        291,
        603,
        411,
        641,
        2275,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21966116244976336,
      "compression_ratio": 1.7396694214876034,
      "no_speech_prob": 0.0038979563396424055
    },
    {
      "id": 39,
      "seek": 26000,
      "start": 276.0,
      "end": 289.0,
      "text": " And then next week or as soon as I kind of like get my mind into that report, then I'll start working on this how users are using GitLab and the cloud.",
      "tokens": [
        51164,
        400,
        550,
        958,
        1243,
        420,
        382,
        2321,
        382,
        286,
        733,
        295,
        411,
        483,
        452,
        1575,
        666,
        300,
        2275,
        11,
        550,
        286,
        603,
        722,
        1364,
        322,
        341,
        577,
        5022,
        366,
        1228,
        16939,
        37880,
        293,
        264,
        4588,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21966116244976336,
      "compression_ratio": 1.7396694214876034,
      "no_speech_prob": 0.0038979563396424055
    },
    {
      "id": 40,
      "seek": 28900,
      "start": 289.0,
      "end": 295.0,
      "text": " And we'll do what I ask you.",
      "tokens": [
        50364,
        400,
        321,
        603,
        360,
        437,
        286,
        1029,
        291,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2200629711151123,
      "compression_ratio": 1.3445945945945945,
      "no_speech_prob": 0.0010333133395761251
    },
    {
      "id": 41,
      "seek": 28900,
      "start": 295.0,
      "end": 300.0,
      "text": " Yeah, could you just elaborate a little bit more on the effort.",
      "tokens": [
        50664,
        865,
        11,
        727,
        291,
        445,
        20945,
        257,
        707,
        857,
        544,
        322,
        264,
        4630,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2200629711151123,
      "compression_ratio": 1.3445945945945945,
      "no_speech_prob": 0.0010333133395761251
    },
    {
      "id": 42,
      "seek": 28900,
      "start": 300.0,
      "end": 309.0,
      "text": " Yeah, so I'm actually very proud of us as a product company that we're like ready to move into this space.",
      "tokens": [
        50914,
        865,
        11,
        370,
        286,
        478,
        767,
        588,
        4570,
        295,
        505,
        382,
        257,
        1674,
        2237,
        300,
        321,
        434,
        411,
        1919,
        281,
        1286,
        666,
        341,
        1901,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2200629711151123,
      "compression_ratio": 1.3445945945945945,
      "no_speech_prob": 0.0010333133395761251
    },
    {
      "id": 43,
      "seek": 30900,
      "start": 309.0,
      "end": 315.0,
      "text": " So we're looking at kind of the connection points between GitLab and the cloud.",
      "tokens": [
        50364,
        407,
        321,
        434,
        1237,
        412,
        733,
        295,
        264,
        4984,
        2793,
        1296,
        16939,
        37880,
        293,
        264,
        4588,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18414936996087794,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0012195430463179946
    },
    {
      "id": 44,
      "seek": 30900,
      "start": 315.0,
      "end": 321.0,
      "text": " I'm like where the work flow links are, kind of the tools that users are using.",
      "tokens": [
        50664,
        286,
        478,
        411,
        689,
        264,
        589,
        3095,
        6123,
        366,
        11,
        733,
        295,
        264,
        3873,
        300,
        5022,
        366,
        1228,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18414936996087794,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0012195430463179946
    },
    {
      "id": 45,
      "seek": 30900,
      "start": 321.0,
      "end": 327.0,
      "text": " And that'll inform in part of some integrations that we're building.",
      "tokens": [
        50964,
        400,
        300,
        603,
        1356,
        294,
        644,
        295,
        512,
        3572,
        763,
        300,
        321,
        434,
        2390,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18414936996087794,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0012195430463179946
    },
    {
      "id": 46,
      "seek": 30900,
      "start": 327.0,
      "end": 334.0,
      "text": " Like June with GCP, but then also like long term what works well in terms of the integrating.",
      "tokens": [
        51264,
        1743,
        6928,
        365,
        29435,
        47,
        11,
        457,
        550,
        611,
        411,
        938,
        1433,
        437,
        1985,
        731,
        294,
        2115,
        295,
        264,
        26889,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18414936996087794,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0012195430463179946
    },
    {
      "id": 47,
      "seek": 33400,
      "start": 335.0,
      "end": 349.0,
      "text": " And that's actually where I think we can bring in some questions about resources and whether or not they should live at the project or the group level.",
      "tokens": [
        50414,
        400,
        300,
        311,
        767,
        689,
        286,
        519,
        321,
        393,
        1565,
        294,
        512,
        1651,
        466,
        3593,
        293,
        1968,
        420,
        406,
        436,
        820,
        1621,
        412,
        264,
        1716,
        420,
        264,
        1594,
        1496,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20826216610995205,
      "compression_ratio": 1.4404761904761905,
      "no_speech_prob": 0.002257403451949358
    },
    {
      "id": 48,
      "seek": 33400,
      "start": 349.0,
      "end": 360.0,
      "text": " Like how teams access like secrets for example, like where do those get stored and GitLab.",
      "tokens": [
        51114,
        1743,
        577,
        5491,
        2105,
        411,
        14093,
        337,
        1365,
        11,
        411,
        689,
        360,
        729,
        483,
        12187,
        293,
        16939,
        37880,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20826216610995205,
      "compression_ratio": 1.4404761904761905,
      "no_speech_prob": 0.002257403451949358
    },
    {
      "id": 49,
      "seek": 36000,
      "start": 360.0,
      "end": 368.0,
      "text": " And is it like higher up organization?",
      "tokens": [
        50364,
        400,
        307,
        309,
        411,
        2946,
        493,
        4475,
        30,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22497714482820952,
      "compression_ratio": 1.509933774834437,
      "no_speech_prob": 0.009965372271835804
    },
    {
      "id": 50,
      "seek": 36000,
      "start": 368.0,
      "end": 383.0,
      "text": " Because I'm thinking a lot about this new change that's coming related to organizations with some new notes because that's like the new play with the catalog, which I think is really smart.",
      "tokens": [
        50764,
        1436,
        286,
        478,
        1953,
        257,
        688,
        466,
        341,
        777,
        1319,
        300,
        311,
        1348,
        4077,
        281,
        6150,
        365,
        512,
        777,
        5570,
        570,
        300,
        311,
        411,
        264,
        777,
        862,
        365,
        264,
        19746,
        11,
        597,
        286,
        519,
        307,
        534,
        4069,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22497714482820952,
      "compression_ratio": 1.509933774834437,
      "no_speech_prob": 0.009965372271835804
    },
    {
      "id": 51,
      "seek": 38300,
      "start": 383.0,
      "end": 393.0,
      "text": " And which is to put it up there. But then I'm wondering like what else could we move up there? Like maybe the secrets because they're at their organized at this company level.",
      "tokens": [
        50364,
        400,
        597,
        307,
        281,
        829,
        309,
        493,
        456,
        13,
        583,
        550,
        286,
        478,
        6359,
        411,
        437,
        1646,
        727,
        321,
        1286,
        493,
        456,
        30,
        1743,
        1310,
        264,
        14093,
        570,
        436,
        434,
        412,
        641,
        9983,
        412,
        341,
        2237,
        1496,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18954875857331033,
      "compression_ratio": 1.5892857142857142,
      "no_speech_prob": 0.20402875542640686
    },
    {
      "id": 52,
      "seek": 38300,
      "start": 393.0,
      "end": 398.0,
      "text": " But that's what we can look into.",
      "tokens": [
        50864,
        583,
        300,
        311,
        437,
        321,
        393,
        574,
        666,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18954875857331033,
      "compression_ratio": 1.5892857142857142,
      "no_speech_prob": 0.20402875542640686
    },
    {
      "id": 53,
      "seek": 38300,
      "start": 398.0,
      "end": 410.0,
      "text": " Talking about that Erica, I like, can you like later go and chime into the issue that I've created for navigation and like share your views there.",
      "tokens": [
        51114,
        22445,
        466,
        300,
        37429,
        11,
        286,
        411,
        11,
        393,
        291,
        411,
        1780,
        352,
        293,
        40921,
        666,
        264,
        2734,
        300,
        286,
        600,
        2942,
        337,
        17346,
        293,
        411,
        2073,
        428,
        6809,
        456,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18954875857331033,
      "compression_ratio": 1.5892857142857142,
      "no_speech_prob": 0.20402875542640686
    },
    {
      "id": 54,
      "seek": 41000,
      "start": 410.0,
      "end": 420.0,
      "text": " And then I think that's what we're going to do is, yeah, we don't want, even though I have mentioned about like taking it out of CICD.",
      "tokens": [
        50364,
        400,
        550,
        286,
        519,
        300,
        311,
        437,
        321,
        434,
        516,
        281,
        360,
        307,
        11,
        1338,
        11,
        321,
        500,
        380,
        528,
        11,
        754,
        1673,
        286,
        362,
        2835,
        466,
        411,
        1940,
        309,
        484,
        295,
        383,
        2532,
        35,
        13,
        50864
      ],
      "temperature": 0.2,
      "avg_logprob": -0.373753517552426,
      "compression_ratio": 1.6695652173913043,
      "no_speech_prob": 0.24903805553913116
    },
    {
      "id": 55,
      "seek": 41000,
      "start": 420.0,
      "end": 429.0,
      "text": " If there's any any research that points that we should have it maybe as a part of the mind navigation or at a higher level navigation.",
      "tokens": [
        50864,
        759,
        456,
        311,
        604,
        604,
        2132,
        300,
        2793,
        300,
        321,
        820,
        362,
        309,
        1310,
        382,
        257,
        644,
        295,
        264,
        1575,
        17346,
        420,
        412,
        257,
        2946,
        1496,
        17346,
        13,
        51314
      ],
      "temperature": 0.2,
      "avg_logprob": -0.373753517552426,
      "compression_ratio": 1.6695652173913043,
      "no_speech_prob": 0.24903805553913116
    },
    {
      "id": 56,
      "seek": 41000,
      "start": 429.0,
      "end": 436.0,
      "text": " We should be aware of that and that would help us inform the methodologies that we would like select for research.",
      "tokens": [
        51314,
        492,
        820,
        312,
        3650,
        295,
        300,
        293,
        300,
        576,
        854,
        505,
        1356,
        264,
        3170,
        6204,
        300,
        321,
        576,
        411,
        3048,
        337,
        2132,
        13,
        51664
      ],
      "temperature": 0.2,
      "avg_logprob": -0.373753517552426,
      "compression_ratio": 1.6695652173913043,
      "no_speech_prob": 0.24903805553913116
    },
    {
      "id": 57,
      "seek": 43600,
      "start": 436.0,
      "end": 439.0,
      "text": " And that's actually that detailed because that's actually like really tactical.",
      "tokens": [
        50364,
        400,
        300,
        311,
        767,
        300,
        9942,
        570,
        300,
        311,
        767,
        411,
        534,
        26323,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2784346570872297,
      "compression_ratio": 1.5973451327433628,
      "no_speech_prob": 0.3551393747329712
    },
    {
      "id": 58,
      "seek": 43600,
      "start": 439.0,
      "end": 444.0,
      "text": " Most of the research so far has been like, what is this secrets?",
      "tokens": [
        50514,
        4534,
        295,
        264,
        2132,
        370,
        1400,
        575,
        668,
        411,
        11,
        437,
        307,
        341,
        14093,
        30,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2784346570872297,
      "compression_ratio": 1.5973451327433628,
      "no_speech_prob": 0.3551393747329712
    },
    {
      "id": 59,
      "seek": 43600,
      "start": 444.0,
      "end": 450.0,
      "text": " So, but I'll look, I'll look up with the lens on there, but I think I won't have much.",
      "tokens": [
        50764,
        407,
        11,
        457,
        286,
        603,
        574,
        11,
        286,
        603,
        574,
        493,
        365,
        264,
        6765,
        322,
        456,
        11,
        457,
        286,
        519,
        286,
        1582,
        380,
        362,
        709,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2784346570872297,
      "compression_ratio": 1.5973451327433628,
      "no_speech_prob": 0.3551393747329712
    },
    {
      "id": 60,
      "seek": 43600,
      "start": 450.0,
      "end": 454.0,
      "text": " But I think from this study, we might get something.",
      "tokens": [
        51064,
        583,
        286,
        519,
        490,
        341,
        2979,
        11,
        321,
        1062,
        483,
        746,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2784346570872297,
      "compression_ratio": 1.5973451327433628,
      "no_speech_prob": 0.3551393747329712
    },
    {
      "id": 61,
      "seek": 43600,
      "start": 454.0,
      "end": 456.0,
      "text": " Okay.",
      "tokens": [
        51264,
        1033,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2784346570872297,
      "compression_ratio": 1.5973451327433628,
      "no_speech_prob": 0.3551393747329712
    },
    {
      "id": 62,
      "seek": 43600,
      "start": 456.0,
      "end": 462.0,
      "text": " And by the way, I've also picked this up based on your recommendation.",
      "tokens": [
        51364,
        400,
        538,
        264,
        636,
        11,
        286,
        600,
        611,
        6183,
        341,
        493,
        2361,
        322,
        428,
        11879,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2784346570872297,
      "compression_ratio": 1.5973451327433628,
      "no_speech_prob": 0.3551393747329712
    },
    {
      "id": 63,
      "seek": 46200,
      "start": 462.0,
      "end": 468.0,
      "text": " I think that's something to do.",
      "tokens": [
        50364,
        286,
        519,
        300,
        311,
        746,
        281,
        360,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32016210353120844,
      "compression_ratio": 1.523404255319149,
      "no_speech_prob": 0.02115604840219021
    },
    {
      "id": 64,
      "seek": 46200,
      "start": 468.0,
      "end": 470.0,
      "text": " You can read that chapter.",
      "tokens": [
        50664,
        509,
        393,
        1401,
        300,
        7187,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32016210353120844,
      "compression_ratio": 1.523404255319149,
      "no_speech_prob": 0.02115604840219021
    },
    {
      "id": 65,
      "seek": 46200,
      "start": 470.0,
      "end": 471.0,
      "text": " Sorry.",
      "tokens": [
        50764,
        4919,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32016210353120844,
      "compression_ratio": 1.523404255319149,
      "no_speech_prob": 0.02115604840219021
    },
    {
      "id": 66,
      "seek": 46200,
      "start": 471.0,
      "end": 472.0,
      "text": " No, it's okay.",
      "tokens": [
        50814,
        883,
        11,
        309,
        311,
        1392,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32016210353120844,
      "compression_ratio": 1.523404255319149,
      "no_speech_prob": 0.02115604840219021
    },
    {
      "id": 67,
      "seek": 46200,
      "start": 472.0,
      "end": 475.0,
      "text": " I just have another like follow up question.",
      "tokens": [
        50864,
        286,
        445,
        362,
        1071,
        411,
        1524,
        493,
        1168,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32016210353120844,
      "compression_ratio": 1.523404255319149,
      "no_speech_prob": 0.02115604840219021
    },
    {
      "id": 68,
      "seek": 46200,
      "start": 475.0,
      "end": 483.0,
      "text": " Are you only looking at GitLab sass user, so I was trying to read through your issue.",
      "tokens": [
        51014,
        2014,
        291,
        787,
        1237,
        412,
        16939,
        37880,
        262,
        640,
        4195,
        11,
        370,
        286,
        390,
        1382,
        281,
        1401,
        807,
        428,
        2734,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32016210353120844,
      "compression_ratio": 1.523404255319149,
      "no_speech_prob": 0.02115604840219021
    },
    {
      "id": 69,
      "seek": 46200,
      "start": 483.0,
      "end": 491.0,
      "text": " And I mentioned that because one of the teams that I work with and enablements currently the application performance group is changing their name.",
      "tokens": [
        51414,
        400,
        286,
        2835,
        300,
        570,
        472,
        295,
        264,
        5491,
        300,
        286,
        589,
        365,
        293,
        9528,
        1117,
        4362,
        264,
        3861,
        3389,
        1594,
        307,
        4473,
        641,
        1315,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.32016210353120844,
      "compression_ratio": 1.523404255319149,
      "no_speech_prob": 0.02115604840219021
    },
    {
      "id": 70,
      "seek": 49100,
      "start": 491.0,
      "end": 494.0,
      "text": " To cloud connector.",
      "tokens": [
        50364,
        1407,
        4588,
        19127,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18262695956539798,
      "compression_ratio": 1.4405940594059405,
      "no_speech_prob": 0.0009806293528527021
    },
    {
      "id": 71,
      "seek": 49100,
      "start": 494.0,
      "end": 496.0,
      "text": " Okay.",
      "tokens": [
        50514,
        1033,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18262695956539798,
      "compression_ratio": 1.4405940594059405,
      "no_speech_prob": 0.0009806293528527021
    },
    {
      "id": 72,
      "seek": 49100,
      "start": 496.0,
      "end": 499.0,
      "text": " And they're focusing on.",
      "tokens": [
        50614,
        400,
        436,
        434,
        8416,
        322,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18262695956539798,
      "compression_ratio": 1.4405940594059405,
      "no_speech_prob": 0.0009806293528527021
    },
    {
      "id": 73,
      "seek": 49100,
      "start": 499.0,
      "end": 511.0,
      "text": " Self managed users, essentially giving them access to like AI features and things that would be available through GitLab sass, but at the self managed level.",
      "tokens": [
        50764,
        16348,
        6453,
        5022,
        11,
        4476,
        2902,
        552,
        2105,
        281,
        411,
        7318,
        4122,
        293,
        721,
        300,
        576,
        312,
        2435,
        807,
        16939,
        37880,
        262,
        640,
        11,
        457,
        412,
        264,
        2698,
        6453,
        1496,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18262695956539798,
      "compression_ratio": 1.4405940594059405,
      "no_speech_prob": 0.0009806293528527021
    },
    {
      "id": 74,
      "seek": 49100,
      "start": 511.0,
      "end": 516.0,
      "text": " So that might be a good team to connect with.",
      "tokens": [
        51364,
        407,
        300,
        1062,
        312,
        257,
        665,
        1469,
        281,
        1745,
        365,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18262695956539798,
      "compression_ratio": 1.4405940594059405,
      "no_speech_prob": 0.0009806293528527021
    },
    {
      "id": 75,
      "seek": 49100,
      "start": 516.0,
      "end": 519.0,
      "text": " You know, in terms of this research.",
      "tokens": [
        51614,
        509,
        458,
        11,
        294,
        2115,
        295,
        341,
        2132,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18262695956539798,
      "compression_ratio": 1.4405940594059405,
      "no_speech_prob": 0.0009806293528527021
    },
    {
      "id": 76,
      "seek": 51900,
      "start": 519.0,
      "end": 520.0,
      "text": " Okay.",
      "tokens": [
        50364,
        1033,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 77,
      "seek": 51900,
      "start": 520.0,
      "end": 522.0,
      "text": " Thank you.",
      "tokens": [
        50414,
        1044,
        291,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 78,
      "seek": 51900,
      "start": 522.0,
      "end": 525.0,
      "text": " I think we landed on the sass.",
      "tokens": [
        50514,
        286,
        519,
        321,
        15336,
        322,
        264,
        262,
        640,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 79,
      "seek": 51900,
      "start": 525.0,
      "end": 528.0,
      "text": " Users.",
      "tokens": [
        50664,
        47092,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 80,
      "seek": 51900,
      "start": 528.0,
      "end": 532.0,
      "text": " Yeah, but either way, I think they would at least be interested.",
      "tokens": [
        50814,
        865,
        11,
        457,
        2139,
        636,
        11,
        286,
        519,
        436,
        576,
        412,
        1935,
        312,
        3102,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 81,
      "seek": 51900,
      "start": 532.0,
      "end": 533.0,
      "text": " So that's so helpful.",
      "tokens": [
        51014,
        407,
        300,
        311,
        370,
        4961,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 82,
      "seek": 51900,
      "start": 533.0,
      "end": 534.0,
      "text": " Well, thank you.",
      "tokens": [
        51064,
        1042,
        11,
        1309,
        291,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 83,
      "seek": 51900,
      "start": 534.0,
      "end": 537.0,
      "text": " I'm embarrassed that I can't quickly find that image too, but it's okay.",
      "tokens": [
        51114,
        286,
        478,
        16843,
        300,
        286,
        393,
        380,
        2661,
        915,
        300,
        3256,
        886,
        11,
        457,
        309,
        311,
        1392,
        13,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 84,
      "seek": 51900,
      "start": 537.0,
      "end": 539.0,
      "text": " I'm on the other project.",
      "tokens": [
        51264,
        286,
        478,
        322,
        264,
        661,
        1716,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 85,
      "seek": 51900,
      "start": 539.0,
      "end": 540.0,
      "text": " Yeah.",
      "tokens": [
        51364,
        865,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 86,
      "seek": 51900,
      "start": 540.0,
      "end": 545.0,
      "text": " So if you want to ping their entire group, I can list the channel there.",
      "tokens": [
        51414,
        407,
        498,
        291,
        528,
        281,
        26151,
        641,
        2302,
        1594,
        11,
        286,
        393,
        1329,
        264,
        2269,
        456,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 87,
      "seek": 51900,
      "start": 545.0,
      "end": 548.0,
      "text": " And then the feedback and also list the PM as well.",
      "tokens": [
        51664,
        400,
        550,
        264,
        5824,
        293,
        611,
        1329,
        264,
        12499,
        382,
        731,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20841107829924552,
      "compression_ratio": 1.5967078189300412,
      "no_speech_prob": 0.011019180528819561
    },
    {
      "id": 88,
      "seek": 54800,
      "start": 548.0,
      "end": 549.0,
      "text": " Okay.",
      "tokens": [
        50364,
        1033,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 89,
      "seek": 54800,
      "start": 549.0,
      "end": 550.0,
      "text": " Cool.",
      "tokens": [
        50414,
        8561,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 90,
      "seek": 54800,
      "start": 550.0,
      "end": 552.0,
      "text": " I just put thank you.",
      "tokens": [
        50464,
        286,
        445,
        829,
        1309,
        291,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 91,
      "seek": 54800,
      "start": 552.0,
      "end": 553.0,
      "text": " Thank you.",
      "tokens": [
        50564,
        1044,
        291,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 92,
      "seek": 54800,
      "start": 553.0,
      "end": 554.0,
      "text": " We'll go team.",
      "tokens": [
        50614,
        492,
        603,
        352,
        1469,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 93,
      "seek": 54800,
      "start": 554.0,
      "end": 557.0,
      "text": " And then I have this is no.",
      "tokens": [
        50664,
        400,
        550,
        286,
        362,
        341,
        307,
        572,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 94,
      "seek": 54800,
      "start": 557.0,
      "end": 561.0,
      "text": " I have to find it in the, but I'm watching the sessions again and again.",
      "tokens": [
        50814,
        286,
        362,
        281,
        915,
        309,
        294,
        264,
        11,
        457,
        286,
        478,
        1976,
        264,
        11081,
        797,
        293,
        797,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 95,
      "seek": 54800,
      "start": 561.0,
      "end": 562.0,
      "text": " So it's coming.",
      "tokens": [
        51014,
        407,
        309,
        311,
        1348,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 96,
      "seek": 54800,
      "start": 562.0,
      "end": 567.0,
      "text": " But there's just lovely quote about how we made a change and.",
      "tokens": [
        51064,
        583,
        456,
        311,
        445,
        7496,
        6513,
        466,
        577,
        321,
        1027,
        257,
        1319,
        293,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 97,
      "seek": 54800,
      "start": 567.0,
      "end": 571.0,
      "text": " The details people could see about the type lines completing.",
      "tokens": [
        51314,
        440,
        4365,
        561,
        727,
        536,
        466,
        264,
        2010,
        3876,
        19472,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 98,
      "seek": 54800,
      "start": 571.0,
      "end": 574.0,
      "text": " And this woman was like, I love it.",
      "tokens": [
        51514,
        400,
        341,
        3059,
        390,
        411,
        11,
        286,
        959,
        309,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21183019214206272,
      "compression_ratio": 1.5483870967741935,
      "no_speech_prob": 0.003348349826410413
    },
    {
      "id": 99,
      "seek": 57400,
      "start": 574.0,
      "end": 577.0,
      "text": " And I think she was like, I'm going to have to do a lot of things.",
      "tokens": [
        50364,
        400,
        286,
        519,
        750,
        390,
        411,
        11,
        286,
        478,
        516,
        281,
        362,
        281,
        360,
        257,
        688,
        295,
        721,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5549787081204928,
      "compression_ratio": 1.8630705394190872,
      "no_speech_prob": 0.01611333340406418
    },
    {
      "id": 100,
      "seek": 57400,
      "start": 577.0,
      "end": 580.0,
      "text": " And then I'm going to have to do a lot of things.",
      "tokens": [
        50514,
        400,
        550,
        286,
        478,
        516,
        281,
        362,
        281,
        360,
        257,
        688,
        295,
        721,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5549787081204928,
      "compression_ratio": 1.8630705394190872,
      "no_speech_prob": 0.01611333340406418
    },
    {
      "id": 101,
      "seek": 57400,
      "start": 580.0,
      "end": 584.0,
      "text": " And then I'm going to use it the other day to show my executives that I need more",
      "tokens": [
        50664,
        400,
        550,
        286,
        478,
        516,
        281,
        764,
        309,
        264,
        661,
        786,
        281,
        855,
        452,
        28485,
        300,
        286,
        643,
        544,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5549787081204928,
      "compression_ratio": 1.8630705394190872,
      "no_speech_prob": 0.01611333340406418
    },
    {
      "id": 102,
      "seek": 57400,
      "start": 584.0,
      "end": 585.0,
      "text": " funding.",
      "tokens": [
        50864,
        6137,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5549787081204928,
      "compression_ratio": 1.8630705394190872,
      "no_speech_prob": 0.01611333340406418
    },
    {
      "id": 103,
      "seek": 57400,
      "start": 585.0,
      "end": 590.0,
      "text": " For my pipelines because I could show like kind of the times and how if we",
      "tokens": [
        50914,
        1171,
        452,
        40168,
        570,
        286,
        727,
        855,
        411,
        733,
        295,
        264,
        1413,
        293,
        577,
        498,
        321,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5549787081204928,
      "compression_ratio": 1.8630705394190872,
      "no_speech_prob": 0.01611333340406418
    },
    {
      "id": 104,
      "seek": 57400,
      "start": 590.0,
      "end": 593.0,
      "text": " reorganize things, this would impact the times.",
      "tokens": [
        51164,
        41203,
        1125,
        721,
        11,
        341,
        576,
        2712,
        264,
        1413,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5549787081204928,
      "compression_ratio": 1.8630705394190872,
      "no_speech_prob": 0.01611333340406418
    },
    {
      "id": 105,
      "seek": 57400,
      "start": 593.0,
      "end": 597.0,
      "text": " And then she used that to find more of our product.",
      "tokens": [
        51314,
        400,
        550,
        750,
        1143,
        300,
        281,
        915,
        544,
        295,
        527,
        1674,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5549787081204928,
      "compression_ratio": 1.8630705394190872,
      "no_speech_prob": 0.01611333340406418
    },
    {
      "id": 106,
      "seek": 57400,
      "start": 597.0,
      "end": 599.0,
      "text": " So that's like the best.",
      "tokens": [
        51514,
        407,
        300,
        311,
        411,
        264,
        1151,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5549787081204928,
      "compression_ratio": 1.8630705394190872,
      "no_speech_prob": 0.01611333340406418
    },
    {
      "id": 107,
      "seek": 57400,
      "start": 599.0,
      "end": 602.0,
      "text": " You can put this in your portfolio, Bica.",
      "tokens": [
        51614,
        509,
        393,
        829,
        341,
        294,
        428,
        12583,
        11,
        363,
        2262,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.5549787081204928,
      "compression_ratio": 1.8630705394190872,
      "no_speech_prob": 0.01611333340406418
    },
    {
      "id": 108,
      "seek": 60200,
      "start": 602.0,
      "end": 605.0,
      "text": " And then I'm going to put it in your portfolio.",
      "tokens": [
        50364,
        400,
        550,
        286,
        478,
        516,
        281,
        829,
        309,
        294,
        428,
        12583,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 109,
      "seek": 60200,
      "start": 605.0,
      "end": 606.0,
      "text": " Oh, no.",
      "tokens": [
        50514,
        876,
        11,
        572,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 110,
      "seek": 60200,
      "start": 606.0,
      "end": 608.0,
      "text": " I mean, I don't know.",
      "tokens": [
        50564,
        286,
        914,
        11,
        286,
        500,
        380,
        458,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 111,
      "seek": 60200,
      "start": 608.0,
      "end": 612.0,
      "text": " But when she was telling me was that the new way that she can look at the metrics.",
      "tokens": [
        50664,
        583,
        562,
        750,
        390,
        3585,
        385,
        390,
        300,
        264,
        777,
        636,
        300,
        750,
        393,
        574,
        412,
        264,
        16367,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 112,
      "seek": 60200,
      "start": 612.0,
      "end": 614.0,
      "text": " Allow her to make this argument.",
      "tokens": [
        50864,
        32225,
        720,
        281,
        652,
        341,
        6770,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 113,
      "seek": 60200,
      "start": 614.0,
      "end": 616.0,
      "text": " I need to pull up the.",
      "tokens": [
        50964,
        286,
        643,
        281,
        2235,
        493,
        264,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 114,
      "seek": 60200,
      "start": 616.0,
      "end": 617.0,
      "text": " I'll pull up the quote.",
      "tokens": [
        51064,
        286,
        603,
        2235,
        493,
        264,
        6513,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 115,
      "seek": 60200,
      "start": 617.0,
      "end": 618.0,
      "text": " Okay.",
      "tokens": [
        51114,
        1033,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 116,
      "seek": 60200,
      "start": 618.0,
      "end": 619.0,
      "text": " It was pre on.",
      "tokens": [
        51164,
        467,
        390,
        659,
        322,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 117,
      "seek": 60200,
      "start": 619.0,
      "end": 626.0,
      "text": " Nice.",
      "tokens": [
        51214,
        5490,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3950443870142887,
      "compression_ratio": 1.5,
      "no_speech_prob": 0.0020883549004793167
    },
    {
      "id": 118,
      "seek": 62600,
      "start": 626.0,
      "end": 636.0,
      "text": " I think it's a good thing.",
      "tokens": [
        50364,
        286,
        519,
        309,
        311,
        257,
        665,
        551,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49838181483892746,
      "compression_ratio": 1.5088757396449703,
      "no_speech_prob": 0.02261660434305668
    },
    {
      "id": 119,
      "seek": 62600,
      "start": 636.0,
      "end": 638.0,
      "text": " I think it's a good thing.",
      "tokens": [
        50864,
        286,
        519,
        309,
        311,
        257,
        665,
        551,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49838181483892746,
      "compression_ratio": 1.5088757396449703,
      "no_speech_prob": 0.02261660434305668
    },
    {
      "id": 120,
      "seek": 62600,
      "start": 638.0,
      "end": 641.0,
      "text": " The other updates before I go or.",
      "tokens": [
        50964,
        440,
        661,
        9205,
        949,
        286,
        352,
        420,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49838181483892746,
      "compression_ratio": 1.5088757396449703,
      "no_speech_prob": 0.02261660434305668
    },
    {
      "id": 121,
      "seek": 62600,
      "start": 641.0,
      "end": 643.0,
      "text": " No, days were taking.",
      "tokens": [
        51114,
        883,
        11,
        1708,
        645,
        1940,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49838181483892746,
      "compression_ratio": 1.5088757396449703,
      "no_speech_prob": 0.02261660434305668
    },
    {
      "id": 122,
      "seek": 62600,
      "start": 643.0,
      "end": 646.0,
      "text": " So I don't necessarily have anything.",
      "tokens": [
        51214,
        407,
        286,
        500,
        380,
        4725,
        362,
        1340,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49838181483892746,
      "compression_ratio": 1.5088757396449703,
      "no_speech_prob": 0.02261660434305668
    },
    {
      "id": 123,
      "seek": 62600,
      "start": 646.0,
      "end": 650.0,
      "text": " Connected to delivery or dedicated this week.",
      "tokens": [
        51364,
        11653,
        292,
        281,
        8982,
        420,
        8374,
        341,
        1243,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49838181483892746,
      "compression_ratio": 1.5088757396449703,
      "no_speech_prob": 0.02261660434305668
    },
    {
      "id": 124,
      "seek": 62600,
      "start": 650.0,
      "end": 652.0,
      "text": " I guess just a.",
      "tokens": [
        51564,
        286,
        2041,
        445,
        257,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49838181483892746,
      "compression_ratio": 1.5088757396449703,
      "no_speech_prob": 0.02261660434305668
    },
    {
      "id": 125,
      "seek": 62600,
      "start": 652.0,
      "end": 655.0,
      "text": " Announce what I'm working on outside of that.",
      "tokens": [
        51664,
        8860,
        7826,
        437,
        286,
        478,
        1364,
        322,
        2380,
        295,
        300,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.49838181483892746,
      "compression_ratio": 1.5088757396449703,
      "no_speech_prob": 0.02261660434305668
    },
    {
      "id": 126,
      "seek": 65500,
      "start": 655.0,
      "end": 658.0,
      "text": " So I included the research issue.",
      "tokens": [
        50364,
        407,
        286,
        5556,
        264,
        2132,
        2734,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17551844953054405,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0023258544970303774
    },
    {
      "id": 127,
      "seek": 65500,
      "start": 658.0,
      "end": 663.0,
      "text": " And I've been constantly like adding and refining research questions there.",
      "tokens": [
        50514,
        400,
        286,
        600,
        668,
        6460,
        411,
        5127,
        293,
        1895,
        1760,
        2132,
        1651,
        456,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17551844953054405,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0023258544970303774
    },
    {
      "id": 128,
      "seek": 65500,
      "start": 663.0,
      "end": 667.0,
      "text": " And then I'm doing a workshop on breaking changes.",
      "tokens": [
        50764,
        400,
        550,
        286,
        478,
        884,
        257,
        13541,
        322,
        7697,
        2962,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17551844953054405,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0023258544970303774
    },
    {
      "id": 129,
      "seek": 65500,
      "start": 667.0,
      "end": 672.0,
      "text": " Some adding people from different departments at the moment.",
      "tokens": [
        50964,
        2188,
        5127,
        561,
        490,
        819,
        15326,
        412,
        264,
        1623,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17551844953054405,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0023258544970303774
    },
    {
      "id": 130,
      "seek": 65500,
      "start": 672.0,
      "end": 674.0,
      "text": " And can be doing that soon.",
      "tokens": [
        51214,
        400,
        393,
        312,
        884,
        300,
        2321,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17551844953054405,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0023258544970303774
    },
    {
      "id": 131,
      "seek": 65500,
      "start": 674.0,
      "end": 679.0,
      "text": " It's going to be kind of a mix of async and synchronous.",
      "tokens": [
        51314,
        467,
        311,
        516,
        281,
        312,
        733,
        295,
        257,
        2890,
        295,
        382,
        34015,
        293,
        44743,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17551844953054405,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0023258544970303774
    },
    {
      "id": 132,
      "seek": 65500,
      "start": 679.0,
      "end": 682.0,
      "text": " Workshop parts.",
      "tokens": [
        51564,
        48366,
        3166,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17551844953054405,
      "compression_ratio": 1.6019900497512438,
      "no_speech_prob": 0.0023258544970303774
    },
    {
      "id": 133,
      "seek": 68200,
      "start": 682.0,
      "end": 690.0,
      "text": " I was looking for Jocelyn and the list because I mean given how much she has been struggling with breaking changes and I see her there.",
      "tokens": [
        50364,
        286,
        390,
        1237,
        337,
        508,
        905,
        49449,
        293,
        264,
        1329,
        570,
        286,
        914,
        2212,
        577,
        709,
        750,
        575,
        668,
        9314,
        365,
        7697,
        2962,
        293,
        286,
        536,
        720,
        456,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15543872117996216,
      "compression_ratio": 1.5524193548387097,
      "no_speech_prob": 0.00833945069462061
    },
    {
      "id": 134,
      "seek": 68200,
      "start": 690.0,
      "end": 697.0,
      "text": " Yeah, that was somebody who came up pretty quickly in conversations with the PM that I'm working with Sam.",
      "tokens": [
        50764,
        865,
        11,
        300,
        390,
        2618,
        567,
        1361,
        493,
        1238,
        2661,
        294,
        7315,
        365,
        264,
        12499,
        300,
        286,
        478,
        1364,
        365,
        4832,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15543872117996216,
      "compression_ratio": 1.5524193548387097,
      "no_speech_prob": 0.00833945069462061
    },
    {
      "id": 135,
      "seek": 68200,
      "start": 697.0,
      "end": 702.0,
      "text": " He was like Jocelyn definitely let's include her.",
      "tokens": [
        51114,
        634,
        390,
        411,
        508,
        905,
        49449,
        2138,
        718,
        311,
        4090,
        720,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15543872117996216,
      "compression_ratio": 1.5524193548387097,
      "no_speech_prob": 0.00833945069462061
    },
    {
      "id": 136,
      "seek": 68200,
      "start": 702.0,
      "end": 708.0,
      "text": " But if you have any other suggestions on who might be a good person to include.",
      "tokens": [
        51364,
        583,
        498,
        291,
        362,
        604,
        661,
        13396,
        322,
        567,
        1062,
        312,
        257,
        665,
        954,
        281,
        4090,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15543872117996216,
      "compression_ratio": 1.5524193548387097,
      "no_speech_prob": 0.00833945069462061
    },
    {
      "id": 137,
      "seek": 68200,
      "start": 708.0,
      "end": 710.0,
      "text": " Let me know.",
      "tokens": [
        51664,
        961,
        385,
        458,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15543872117996216,
      "compression_ratio": 1.5524193548387097,
      "no_speech_prob": 0.00833945069462061
    },
    {
      "id": 138,
      "seek": 71000,
      "start": 710.0,
      "end": 733.0,
      "text": " So that's all the updates that I have this week.",
      "tokens": [
        50364,
        407,
        300,
        311,
        439,
        264,
        9205,
        300,
        286,
        362,
        341,
        1243,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.34301626682281494,
      "compression_ratio": 0.96,
      "no_speech_prob": 0.007158899679780006
    },
    {
      "id": 139,
      "seek": 73300,
      "start": 733.0,
      "end": 736.0,
      "text": " Okay, so with this we are at the end of the agenda.",
      "tokens": [
        50364,
        1033,
        11,
        370,
        365,
        341,
        321,
        366,
        412,
        264,
        917,
        295,
        264,
        9829,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23210816723959787,
      "compression_ratio": 1.34375,
      "no_speech_prob": 0.5300352573394775
    },
    {
      "id": 140,
      "seek": 73300,
      "start": 736.0,
      "end": 739.0,
      "text": " Anything that someone wants to bring up.",
      "tokens": [
        50514,
        11998,
        300,
        1580,
        2738,
        281,
        1565,
        493,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23210816723959787,
      "compression_ratio": 1.34375,
      "no_speech_prob": 0.5300352573394775
    },
    {
      "id": 141,
      "seek": 73300,
      "start": 739.0,
      "end": 742.0,
      "text": " If not, then the is it.",
      "tokens": [
        50664,
        759,
        406,
        11,
        550,
        264,
        307,
        309,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23210816723959787,
      "compression_ratio": 1.34375,
      "no_speech_prob": 0.5300352573394775
    },
    {
      "id": 142,
      "seek": 73300,
      "start": 742.0,
      "end": 746.0,
      "text": " It's in the meeting here.",
      "tokens": [
        50814,
        467,
        311,
        294,
        264,
        3440,
        510,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23210816723959787,
      "compression_ratio": 1.34375,
      "no_speech_prob": 0.5300352573394775
    },
    {
      "id": 143,
      "seek": 73300,
      "start": 746.0,
      "end": 750.0,
      "text": " Hi everyone. Have a good one.",
      "tokens": [
        51014,
        2421,
        1518,
        13,
        3560,
        257,
        665,
        472,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23210816723959787,
      "compression_ratio": 1.34375,
      "no_speech_prob": 0.5300352573394775
    }
  ]
}