{
  "content": "End-to-end Pipeline Monitoring\nOverview of our E2E monitoring tools and practices\nEnd-to-end (E2E) test pipelines\nThe test pipelines run on a scheduled basis, and their results are posted to Slack. The following are the end-to-end test pipelines that are monitored every day.\nEnvironment\nLinks\nTests type\nFrequency\nSlack channel\nLatest test report\nProduction\nPipelines\n\nDefinition\nSmoke\nafter each deployment to Canary\n#e2e-run-production\nProduction Sanity\nCanary\nPipelines\n\nDefinition\n\nChatops\nSmoke\nafter each deployment to Canary\nand\nafter a feature flag in production has been updated to\ntrue\nor\n100%\n#e2e-run-production\nCanary Sanity\nStaging\nPipelines\n\nDefinition\nSmoke\nafter each deployment to Staging-Canary\n#e2e-run-staging\nStaging Sanity\n-\nPipelines\n\nDefinition\nSmoke\nafter the execution of post-deploy migrations in Staging\n#e2e-run-staging\nStaging Sanity\nStaging Canary\nPipelines\n\nDefinition\nSmoke\nafter each deployment to Staging-Canary\n#e2e-run-staging\nStaging-Canary Sanity\n-\nPipelines\n\nDefinition\n\nChatops\nFull\nafter each deployment to Staging-Canary\nand\nafter a feature flag in Staging has been updated to\ntrue\nor\n100%\n#e2e-run-staging\nStaging-Canary Full\nCustomersDot Staging\nPipelines\n\nDefinition\nFull\nafter each deployment to CustomersDot Staging\n#e2e-run-staging\n#s_fulfillment_status\nCustomersDot Staging\nCustomersDot Production\nPipelines\n\nDefinition\nSmoke\nafter each deployment to CustomersDot Production\n#e2e-run-production\n#s_fulfillment_status\nN/A\nPreprod\nPipelines\n\nDefinition\nSmoke\nEvery month for a few days before release, at 03:00 UTC\nand after\ndeployment to preprod\nduring Security and Patch releases\n#e2e-run-preprod\nPreprod\nRelease\nPipelines\n\nDefinition\nSmoke\nEvery month after the final release\nand after\ndeployment to Release\nduring Security and Patch releases\n#e2e-run-release\nRelease\nGitLab\nmaster\ne2e:test-on-omnibus-ee\nPipelines\n\nDefinition\nFull\nscheduled pipeline every 2 hours\n#e2e-run-master\nMaster EE\nGitLab\nmaster\ne2e:test-on-omnibus-ce\nPipelines\n\nDefinition\nFull\nDaily at 4:00am UTC\n#e2e-run-master\nMaster CE\nGitLab\nmaster\ne2e:test-on-gdk\nPipelines\n\nDefinition\nFull\nscheduled pipeline every 2 hours\n#e2e-run-master\nMaster GDK\nGitLab\nmaster\ne2e:test-on-cng\nPipelines\n\nDefinition\nSmoke\nscheduled pipeline every 2 hours\n#e2e-run-master\nMaster CNG\nGitLab\nmaster\nNightly\nPipelines\n\nDefinition\nFull\nDaily at 4:00am UTC\n#e2e-run-master\nMaster Nightly\nNOTE:\nFor information on how to investigate failing end-to-end tests and pipelines, check out\nDebugging Failing Tests and Test Pipelines\nVisual Pipeline Environment Map\nThis diagram provides a visual representation of how our end-to-end test pipelines map to various environments in our infrastructure. It illustrates the flow of tests across Merge Requests, Development, Staging, Preprod, and Production environments, showing when tests are triggered (on commit, after deploy, after configuration changes, etc.) and what type of tests run in each environment (smoke, full, etc.).\nThe color coding indicates test types and environment categories, making it easier to understand our comprehensive testing strategy across the entire deployment pipeline. This visualization is particularly valuable for infrastructure planning. The original\nLucidChart diagram\nalso includes a Cells version so we can visualize what it will look like.\nTest metrics\nFor visibility on the test health, we have test execution results exported to:\nan\nInfluxDb\ninstance and use\nGrafana\ndashboards to visualize the results\na\nGoogle Cloud Storage (GCS)\ninstance which is then accessible through\nSnowflake\nTest reports\nAllure report\nAnother tool we have to present the test results is through the\nAllure\ntest reports. Tests that run on pipelines generate Allure reports. The\nQA\nframework uses the\nAllure RSpec\ngem to generate source files for the\nAllure\ntest report. An additional job in the pipeline:\nFetches these source files from all test jobs.\nGenerates and uploads the report to the\nS3\nbucket\ngitlab-qa-allure-report\nlocated in\nAWS\ngroup project\neng-quality-ops-ci-cd-shared-infra\n.\nEach type of scheduled pipeline generates a static link for the latest test report according to its stage:\nEnvironment\nDescription\nLink\nmaster\n(\ngdk\n)\nE2E test execution against\ngitlab-development-kit\nenvironment packaged in a\nDocker\ncontainer.\nAllure test report\nmaster\n(\ntest-on-omnibus\n)\nE2E test execution against various configurations of\nomnibus\nimages.\nAllure test report\nnightly\nE2E test execution against various configurations of\nomnibus\nnightly images.\nAllure test report\nstaging-full\nE2E test execution against\nhttps://staging.gitlab.com\nenvironment.\nAllure test report\nstaging-sanity\nE2E test execution against various configurations of\nomnibus\nnightly images.\nAllure test report\nstaging-ref-full\nE2E test execution against\nhttps://staging-ref.gitlab.com\nenvironment.\nAllure test report\nstaging-ref-sanity\nE2E test execution against\nhttps://staging-ref.gitlab.com\nenvironment.\nAllure test report\npreprod\nE2E test execution against\nhttps://pre.gitlab.com\nenvironment.\nAllure test report\nproduction-full\nE2E test execution against\nhttps://gitlab.com\nenvironment.\nAllure test report\nproduction-sanity\nE2E test execution against\nhttps://gitlab.com\nenvironment.\nAllure test report\nThese reports are also included in the pipeline status alerts on Slack.\nTest session issue\nFor each end-to-end pipeline that runs in the various environments we automatically test, we create a\ntest session issue\nthat contains the test session information. Test session issues group test results by DevOps stages, and link to\ntest cases\n, and\ntest failure issues\n.\nExample of a test session issue:\nhttps://gitlab.com/gitlab-org/quality/testcase-sessions/-/issues/72516\nTest session issues are a\nworkaround for a missing GitLab feature\n. Once GitLab stores test data, we can improve failure reporting and management.\nTest result issue\nEach test is associated to a\nGitLab testcase\n.\nRSpec\n.\ndescribe\n'Stage'\ndo\ndescribe\n'General description of the feature under test'\ndo\nit\n'test name'\n,\ntestcase\n:\n'https://gitlab.com/gitlab-org/gitlab/-/quality/test_cases/:test_case_id'\ndo\n...\nend\nit\n'another test'\n,\ntestcase\n:\n'https://gitlab.com/gitlab-org/gitlab/-/quality/test_cases/:another_test_case_id'\ndo\n...\nend\nend\nend\nThe test failure stack trace and the issue stack trace are compared, and the existing issue for which the stack trace is the most similar (under a 15% difference threshold) to the test failure is used. The test failure job is then added to the failure report list in the issue. Group label is automatically inferred based on the\nproduct_group\nmetadata of the test.\nLast modified July 9, 2025:\nUpdate E2E test failure issue link (\na0220989\n)\nView page source\n-\nEdit this page\n-\nplease\ncontribute\n.",
  "metadata": {
    "url": "https://handbook.gitlab.com/handbook/engineering/testing/end-to-end-pipeline-monitoring/",
    "title": "End-to-end Pipeline Monitoring | The GitLab Handbook",
    "scraped_at": "2025-10-26T20:51:27.984757",
    "content_length": 6764,
    "section": "handbook"
  },
  "processing": {
    "original_length": 6764,
    "cleaned_length": 6747,
    "cleaned_at": "2025-10-27T16:13:42.576127",
    "processor": "text_cleaner_v1",
    "word_count": 920
  }
}