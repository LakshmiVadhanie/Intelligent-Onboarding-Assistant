[
  "The GitLab Legal Commercial team is responsible for all contracting matters at GitLab. This includes, procurement, revenue, channel, technical and alliances. The Commercial Team partners with sales, technical, and business stakeholders to ensure the alignment with GitLab contracting standards, as well as the most efficient timeline to reach execution.",
  "Please note that all links are GitLab-internal only.",
  "Employment law governs the relationship between employers and employees. At GitLab, the Legal Employment team serves as a strategic partner across the organization, providing expert guidance and proactive legal solutions throughout the entire team member lifecycle. What does this partnership entail? We * collaborate strategically with Sales, Go-to-Market, Finance and People teams to develop scalable, compliant employment solutions as GitLab expands globally and responsibly, implementing a comprehensive process for gathering, assessing, and acting on country-specific information. We empower the Talent Acquisition department to achieve its critical goals while ensuring compliance with local laws and regulations during sourcing, recruitment, and hiring processes. We enable the People Operations team to effectively onboard and support team members with location- and role-specific legal support, setting team members up for success from day one. We partner with the Total Rewards team, People Operations team and People Business Partners to develop forward-thinking policies that balance GitLab’s business objectives, team members’ needs, and global legal requirements. We provide strategic counsel to our Team Member Relations team, People Business Partners, and Total Rewards as they navigate complex team member matters, including reasonable accommodation requests, performance management, career progression, and other relationship dynamics. We champion our Diversity, Inclusion, and Belonging initiatives by aligning all employment decisions with our mission statement and applicable laws. We safeguard GitLab’s interests while also providing fair treatment during employment transitions, including offboarding processes and post-employment matters. To work with the Legal Employment team, reach out early in your process, provide complete information about your needs and any time constraints you have. Being specific about what you’re requesting and any deadlines you face will enable the Legal Employment team to best triage requests and support you. To connect with Legal Employment, especially on sensitive matters, you can use the ’ legal-employment@gitlab.com ’ email address, or for non-sensitive queries, you can reach out in the #legal slack channel. Note that GitLab team members with individual employment queries should reach out to Team Member Relations team on ’ teammemberrelations@gitlab.com ’ or to their aligned People Business Partner for support. For cross-functional projects that do not involve individual team members but do require the Legal Employment team’s attention, please (i) open an Issue in the Legal and Compliance Project ; (ii) select the appropriate Issue Template; (iii) apply the label legal-employment :: to-do and (iv) if you know which Legal team member you will be working with, include them as an Assignee. This will update the Legal Employment Issue Board for the Employment team’s benefit, and allow the team to pick up and/or assign appropriately. A table showing coverage for queries by subject matter is available for internal use and can be accessed here . You are welcome to consult any member of the Legal Employment team. It is worth considering the privilege guidelines when communicating with GitLab’s Legal and Corporate Affairs team (aka the LACA team), including the Legal Employment team. Note that, if a communication is privileged, it can be protected from disclosure in litigation or other disputes. If in doubt, there’s an internal, GitLab University micro course on ‘Privileged communication’ , which is relevant to any team member who communicates with the LACA team, seeking legal advice on behalf of GitLab. The training explains the legal protection which may be applied to certain communications between team members and LACA and how best to communicate in order to be protected. It is also important to note that, if you receive any formal documents that appear to be legal notices, demands, subpoenas, court papers, or other potential litigation materials, you should please forward these by email to the legal team immediately (to the ’ legal@gitlab.com ’ email address) without responding yourself. Please add a brief note explaining when and how you received the document. These materials often have strict response deadlines, and your prompt sharing allows the legal team to review and address them properly to protect both you and GitLab.",
  "Corporate Sustainability is a business approach that enhances long term stakeholder value by implementing a strategy that considers every dimension of how a business operates when making social, environmental and economic progress. ESG stands for Environmental, Social and Governance and refers to the three key factors when measuring the sustainability and ethical impact of an investment in a business or company. At GitLab we use Sustainability and ESG interchangeably. Both terms are relevant to our work and both serve different purposes depending on the audience we interact with. The Sustainability Team creates and maintains GitLab’s Corporate Sustainability strategy and programs by driving and integrating responsible business practices and ESG regulatory compliance. The Sustainability team builds and maintains strong internal and external relationships to understand stakeholder expectations - including customer, investor and team members. This engagement allows us to remain customer centric and easy to do business with while meeting shareholder and team member expectations. The Sustainability Team has two primary functions and four corresponding programs: Compliance & Reporting : Manages customer and prospect ESG-related questionnaires, requests for proposals, and sustainability contractual clauses. Leads annual Sustainability report and external assurance process. Monitors global ESG regulation and works cross-functionally to advance GitLab’s culture of compliance with applicable ESG regulations. Responds to investor ESG rating agencies to maintain competitive ESG scoring among peers. Climate Action : Identifies and executes strategic climate programs, including annual measurement of GitLab’s greenhouse gas inventory, emissions reduction target-setting, partners with Procurement to run the sustainable supplier program, identifies emissions reduction opportunities across the business, and purchases high quality carbon credits. Manages team member & customer communications related to GitLab’s commitment to environmental sustainability. GiveLab : GiveLab is GitLab’s team member volunteer program and includes year-round volunteering, GiveLab 30 days of Impact, our annual company-wide volunteer campaign and GiveLab Champions Program. Volunteerism is an effective way to build trust through social connections - this leads to higher individual and team motivation, and greater cross-functional collaboration. GitLab for Non-Profits : GitLab’s in-kind donation program. Manages social impact communications with team members and customers, while developing strategic nonprofit partnerships to advance GitLab’s ESG goals and help enhance our brand reputation by demonstrating our commitment to the nonprofit community. Deeply integrated into our business philosophy, GitLab’s Sustainability strategy is driven by our values of Collaboration, Results for Customers, Efficiency, Diversity, Inclusion and Belonging, Iteration, and Transparency (CREDIT). GitLab’s stakeholders, including customers, investors, team members, and community members play a key role in GitLab’s Sustainability strategy. GitLab conducted its inaugural ESG materiality assessment in 2022. By conducting a materiality assessment with our stakeholders, we identified which ESG topics have the greatest impact on GitLab’s business and where we have the potential to have the greatest impact on the environment, society, and our global communities - those material topics drive the programs, policies and initiatives under our strategy. This page will continue to be updated as we make progress towards developing plans and programs to advance our Sustainability goals. The purpose of the advisory committee is to create cross-functional alignment on ESG objectives and decision making, to go beyond simply compliance and into long-term operational implementation. Members of the Sustainability Advisory Committee Like all functions at GitLab, transparency is a core focus. Every year GitLab publishes an annual sustainability report where we share our approach to managing our key sustainability focus areas, provide updates on programs and policies, achievements to date, metrics and targets, and plans for the future. The Sustainability team works cross-functionally to prepare GitLab for compliance with ESG regulations. The Sustainability team also supports internal teams with customer ESG questionnaires and RFPs. Customers and prospective customers are increasingly asking about GitLab’s Sustainability programs, including questions related to GitLab’s climate commitments and greenhouse gas emissions. Many of our customers are also subject to ESG regulation and we expect customer ESG questions to continue to increase as they look to better align to new regulations. GitLab is committed to doing our part to minimize our environmental footprint, including working to reduce greenhouse gas (GHG) emissions associated with our operations. GitLab’s stakeholders, including customers, investors, regulators, and team members expect the company to operate sustainably and to do our part to reduce our environmental footprint. Many of GitLab’s customers have GHG reduction targets and as a vendor, GitLab’s carbon emissions contribute to our customers’ emissions footprints. To remain easy to transact with, GitLab needs to meet the expectations of our customers by taking action on climate change. GitLab’s Climate Action Program consists of four pillars: Measure & Report: Every year GitLab conducts an annual greenhouse gas (GHG) inventory in alignment with the GHG Protocol, the global best practice carbon accounting standard. We publish the results of the inventory in our annual ESG report and have the data assured by a third-party. In 2026, GitLab is subject to new regulations in the US and the EU that will make these disclosures mandatory. Act: GitLab is taking action to reduce our carbon emissions. As a fully remote software company, the majority of our emissions come from our suppliers. Engaging our suppliers to measure their carbon emissions and set their own reduction targets is a critical component of our reduction pathway, which is why we have set an aspirational supplier engagement target. Please see the Sustainable Procurement Program for more information. The Sustainability team continues to explore other ways to reduce emissions and is doing further analysis on additional reduction pathways. Engage: This includes engaging GitLab team members in climate education and action. In 2024, we launched the GitLab Team Member Sustainability Guide , providing actionable steps team members can take at home to minimize their environmental impact. In FY26, we launched our partnership with Mammoth Climate , a climate literacy and challenges platform, to further engage team members with educational materials, activities, and rewards Accelerate: While GitLab works to reduce our emissions, we are also committed to accelerating climate solutions by purchasing high quality carbon credits to cover a portion of our carbon footprint. We are proud to partner with Rubicon Carbon to purchase a diversified portfolio of high quality carbon credits, financing carbon removal projects that meet Rubicon’s high standards of quality . In FY25, GitLab set an aspirational science-aligned supplier engagement target to reduce our Scope 3 emissions: 70% of our suppliers (by emissions) will have science-aligned climate targets by FY29. Our sustainable procurement program includes the following initiatives: We look forward to sharing updates on this new initiative. The Green DevOps Working Group at GitLab aims to embed sustainability throughout the software development lifecycle to reduce environmental impact while unlocking operational and business value. Its core objectives include lowering carbon emissions and energy use, integrating green practices into business processes, enhancing customer capabilities to meet regulatory and sustainability goals, and positioning GitLab as a leader in sustainable DevOps and green software. Workstreams address areas such as cloud sustainability, CI/CD energy consumption tracking and reduction, community innovation and engagement, sustainable AI and procurement, and reporting. Each workstream is led by the Sustainability team and the relevant functional team member. Customers who are interested in providing insights and feedback on sustainability features are encouraged to contact the Sustainability Team at esg@gitlab.com for more information. At GitLab, all team members do work that supports the company, which supports the enhancement of an open source codebase. This codebase is freely available to everyone to make better software faster and drive progress through what they build. Between 2022 and 2024, team members made over 125,000 commits to the open source part of the GitLab codebase. But, there are also other ways to give back and many team members choose to contribute beyond GitLab. In addition to contributing to GitLab, GitLab offers additional optional pathways for team members to give back while leveraging their unique skills and passions through programs such as GiveLab, GitLab’s Team Member Volunteer Program. GitLab encourages team members to take part in volunteer initiatives such as supporting their local communities, participating in virtual volunteer activities, and organizing volunteer activities as part of team events. Corporate volunteerism has been proven to be an effective strategy for boosting engagement , improving employee retention, and strengthening relationships at work . Volunteering with GiveLab supports team members in fostering connections, building trust among one another and embodying our CREDIT values while positively impacting our communities. Team members may self organize volunteer events at any point throughout the year. To submit a request for a team volunteer activity with a Registered Nonprofit Organization that isn’t on the current GiveLab Nonprofit Directory , please go to the Philanthropic Requests epic and open a new issue using the Volunteer_Support Template . Team members can also request support from the Sustainability Team to organize local or virtual volunteer opportunities on their behalf by going to the Philanthropic Requests epic and opening a new issue using the Volunteer_Support Template . Please write “yes” for the question, “Would you like the Sustainability team’s help organizing the volunteer activity?” All team members and volunteer activities must adhere to the GitLab Philanthropy Policy . Team members must follow GitLab’s paid time off (PTO) policy if volunteering during work hours and use the “public service/volunteer” option in Workday. If volunteering in person, team members may incur some expenses. Team members can expense up to a total of $25 per volunteer event for expenses incurred that meet the allowed for reimbursement criteria. All expenses should be submitted in Navan using the “GiveLab” classification. Please note that GitLab does not allow team members to travel to in-person volunteer events. All in-person volunteering should be local to the team member. As with all company expenses , team members must be thoughtful in spending the company’s money and use best judgment to ensure that all expenses are deemed “ordinary and necessary.” Team members should follow all team member expense responsibilities . Expenses allowed for reimbursement (for in-person volunteer events): Expenses not allowed for reimbursement: As with our unique ways of working, GitLab and its team members have identified and sought out opportunities for impact that speak not only to our values but also to our all-remote nature. To review previous opportunities that team members participated in, visit the historical activities page . GiveLab 30 Days of Impact is GitLab’s annual volunteer campaign created to encourage team members to foster connections, build trust among one another and embody our CREDIT values while positively impacting our communities. We have designed this program with our high-performing team culture and results for customers in mind. GiveLab 30 days of Impact runs annually in Q4 and our goal is to encourage as many team members as possible to volunteer over the course of 30 days. Throughout the month, team members can volunteer as little as one hour of their time to make an impact. We understand that our team members are driven by many different factors, and we welcome that volunteer participation will look different for everyone. Through GiveLab 30 days of Impact we aim to offer many different ways for team members to get involved such as: While GitLab encourages year-round volunteerism through GiveLab , GiveLab 30 days of Impact centralizes our efforts into an annual campaign to have a larger collective impact over a specific timeframe. Corporate volunteerism has been proven to be an effective strategy for boosting engagement , improving employee retention, and strengthening relationships at work . Additionally, this program offers volunteering opportunities around a major holiday season in many parts of the world, a time when many are seeking opportunities to give back. Team member participation is voluntary, should not interfere with work commitments, and time off is required to be in alignment with GitLab’s PTO policy . Travel is not permitted for this program. Team Members may choose to volunteer virtually or through local in-person events. Volunteer events typically last between one and four hours. Managers play an important role in supporting team members in taking time for themselves and their families, while also ensuring accountability to results and coverage for teams and its goals. Our Results for Customers value sits at the top of our values hierarchy, and our PTO policy empowers managers to appropriately manage workloads and deliverables, while also giving team members the time away they need from work. Team Members taking time off to volunteer should communicate time off in advance with their manager. To request volunteer time off, follow the Paid Time Off procedures outlined in our handbook and reach out to People Operations via HelpLab should you have any concerns. A step-by-step guide on how to request paid time off can be found here . Note that volunteer time off should be used towards acceptable volunteer activities and in adherence with our GitLab Philanthropy Policy . Please see our GiveLab reimbursement policy to understand current allowances as they relate to volunteering costs. We have created an internal GiveLab Volunteer Directory that features a list of vetted nonprofit organizations with available volunteer opportunities. Team members can search the document for virtual volunteer opportunities, opportunities to volunteer with GitLab Foundation grantees and search for local opportunities. We encourage all team members to contribute to our GiveLab Volunteer Directory. To recommend a nonprofit organization to add to the Directory, please open a Volunteer Recommendation Issue . The GiveLab Champions are team members who are passionate about giving back to their communities and want to encourage other team members to do the same. GiveLab Champions self-identify to participate in the voluntary Champions group, managed by the Sustainability team. The GiveLab Champions help activate the GiveLab signature program, but also work to organize and promote volunteer opportunities year-round. GiveLab Champions help team members build trust through social connections, build connections within their communities, and help GitLab provide meaningful opportunities for team members to give back. The GiveLab Champions ensure global voices are heard and relevant causes are represented based on where team members live. GiveLab Champions help to make GitLab a better place to work. The time commitment for a GiveLab Champion is estimated to be 3-5 hours per quarter. Participation can vary throughout the year. GitLab launched GitLab for Nonprofits , an in-kind donation program in 2023. Through this program, GitLab supports Registered 501c3 (or jurisdictional equivalent) Nonprofit Organizations in good standing that align with our values by offering free licenses and seats. The program operates on a first come first served basis. Once the annual donation of 5,000 seats is met, the application will remain closed for the year. What are the benefits of the GitLab for Nonprofits program? GitLab is a single platform for project management, collaboration, source control management, git, automation, security, and much more. Because it is easy to use, flexible, and all in one place, it is the best choice for nonprofits to scale their work. The GitLab for Nonprofits Program gives free licenses of GitLab to registered nonprofit organizations. Nonprofits accepted into the program will be provided a free Ultimate license for one year (SaaS or self-managed) for up to 20 seats. Additional seats may be requested although they may not be granted. Who qualifies for the program? GitLab supports Registered 501c3 (or jurisdictional equivalent) Nonprofit Organizations in good standing that align with our Values . A “Registered Nonprofit Organization” is one that has been registered with the local government or authorized agency within its applicable local, state, provincial, federal or national government. For the calendar year 2024, we will limit the in-kind program to 5,000 seats, which was approved by finance and the board in the Philanthropy Policy . Each organization will be eligible for up to 20 seats. This will allow us to assist as many organizations as possible. This will be revisited throughout the year and adjusted as needed. Interested organizations who are new customers may request additional seats although the request may not be granted. To limit churn, current GitLab customers that apply to transition to the Nonprofit Program will not be granted a special request above the 20 seats. What are the terms of the GitLab for Nonprofits program? Upon acceptance, program members are subject to the GitLab Subscription Agreement . The decision to issue a GitLab for Nonprofits license is always at the sole discretion of GitLab. Interested organizations need to visit the GitLab for Nonprofits page and submit the application form . How are applications processed? Nonprofits apply on the GitLab for Nonprofits page. Once the application is submitted, the Nonprofit will receive a message and a link to TechSoup, our verification partner. The Nonprofit will then need to log in or create their TechSoup account. TechSoup provides a rigorous vetting process to ensure the nonprofit is eligible for the GitLab for Nonprofits program and meets all requirements. If a Nonprofit is verified, TechSoup will notify GitLab. GitLab will then undergo its own vetting and approval process. Once all parties have verified and approved the Nonprofit, GitLab will send the instructions directly to the Nonprofit to redeem their license. If a Nonprofit is not verified through TechSoup, TechSoup will provide details on how the Nonprofit can become verified. If a Nonprofit is declined from GitLab, GitLab will notify the Nonprofit via nonprofits@GitLab.com . Please allow up to 15 business days for the application and verification process. Must Nonprofits renew their memberships? Yes. All nonprofits must renew their membership annually, which involves a re-verification process. Nonprofits will submit for renewal the same way they first applied for the program. Where can members receive support? While GitLab for Nonprofits Program benefits do not include product support , program members can receive help with GitLab in a number of ways. In general, we recommend the following: I’m a GitLab Team Member and I have a customer applying for the program. What do I do? Information on how GitLab Inc. supports Registered Nonprofit Organizations can be found in the Philanthropy Policy . Please note that for all Philanthropic Requests, including requests for GitLab to join as a member to an association, program or organization, approval by the Sustainability team and CLO is required as defined by the Oversight Responsibility section of the Policy. If you would like to submit a philanthropic request, please follow the instructions based on your request type. There are two ways that team members can submit a request for monetary support: Request funding from the Sustainability team to support a Registered Nonprofit Organization OR (not currently accepting applications - see instructions below on submitting a non-profit for future consideration) Request utilizing department or TMRG budget to support a Registered Nonprofit Organization If you are requesting funding from the Sustainability team to support a Registered Nonprofit Organization, please note that at this time, we are not accepting applications. If you would like to submit a Nonprofit Organization to be considered for support in the future, please go to the Philanthropic Requests epic and open a new issue using the Monetary_Support Template . You will be notified if there is a future opportunity. If you have a department or TMRG budget that you would like to utilize to support a Registered Nonprofit Organization, please go to the Philanthropic Requests epic and open a new issue using the Monetary_Support Template . Please tag your manager to approve the request if you are submitting on behalf of your department. If you are submitting a request on behalf of a TMRG or DIB, please add the DIB DRI as a reviewer. Please allow a minimum of 10 working days for review. The team member submitting the issue is responsible for obtaining proper approvals and working with Accounts Payable to issue the payment. Please tag the individuals in the approver section of the issue. Once approvals are completed, the team member requesting the donation needs to obtain an invoice from the non-profit that contains the bank payment details and submit this to AP@GitLab.com . For requests related to GitLab Membership of Association, Program or Organization, and includes terms, conditions and/or obligations on GitLab that must be executed, please follow the below process. Open an issue using the Membership Request Issue Template . Complete and attach the necessary information. Note: If you are submitting a request on behalf of a TMRG or DIB, please add the DIB DRI as a reviewer. NOTE: For any request(s) that require payment, please be certain to follow applicable ESG & Procurement processes. At this time, GitLab does not offer a matching gifts program.",
  "The Strategy & Legal Ops team promotes and institutes streamlined processes, efficient tools, and centralized program management to ensure LACA remains agile and able to support every area of GitLab’s business. Check out our issue board to learn more about what we’re working on. GitLab uses Brightflag’s Legal Spend Management platform to process and review legal invoices and accruals. See the Brightflag invoicing process in the internal handbook. Accruals submission reminder notifications are automatically sent through Brightflag to ensure vendors submit their accruals on time. This process is designed to enable LACA team members to submit requests related to attending events/conferences, furthering development, or purchasing tools/software funded by LACA. This process does not apply to equipment , Individual Use Software or other personal reimbursement requests.",
  "The Privacy Team is part of the Legal and Corporate Affairs Team. We provide support and guidance to uphold consistent business processes around the protection of personal data as it relates to GitLab customers, users, Team Members, and other natural persons. We collaborate cross-functionally and serve as advocates to ensure that the data privacy practices of GitLab meet the needs of our cross-functional partners and are continually balanced with an ever-changing global data privacy and protection landscape. Slack channel - #legal is the best place for questions relating to our team that do not require legal advice, deliverables, or any discussion of confidential information. For issues that require action from the Privacy Team, apply the label Privacy::Intake . This will update the Privacy Legal Issue Board and allow the team to triage the issue appropriately. We also use the following labels: For sensitive, private, or confidential requests email legal_internal@gitlab.com . Please do not send emails to this address for engineering, marketing, sales or procurement requests. These should be directed to #legal or an issue should be created in the Legal and Compliance project. Tell people what you are doing with personal data and why you are doing it so that the person can make an informed decision about whether they want to allow it to happen. Do not be creepy about what personal data is collected or how it is used and do not change the way personal data is used without first giving people notice and an opportunity to object, or, where required, obtaining prior consent. Make it easy for people to tell us their privacy preferences and honor those preferences even if they change over time. Build a product or service that has privacy-focused settings turned on by default and let the consumer decide if and when they want to change that. Transparency is a core value and every team member is responsible for the proper collection and use of personal data consistent with our Privacy Statement . Anonymization The process of permanently and irreversibly altering personal data in a way that it is no longer capable of being related back to a specific individual. Consent A freely given, specific, informed and unambiguous indication of an individual’s wishes. Consent is captured by an un-ticked checkbox or other unequivocal statement which signifies agreement to the processing of personal data before or at the time of collection. Data Classification A method of determining types of data associated by risk. See GitLab Security Data Classification Standards for more information. Data Controller A natural or legal person, agency, or other entity which alone, or jointly with others, determines the purpose and means of processing personal data. For example, GitLab is a Data Controller is in the areas of marketing and sales where the personal data of prospects and leads is managed solely at our discretion. GitLab also serves as a Data Controller for all personal data collected from Team Members for employment purposes and any administration of benefits. Data Processor A natural or legal person, agency, or other entity which processes personal data on behalf of a Data Controller. GitLab acts as a Data Processor when we manage personal data native to a Customer’s instance or namespace. GitLab acts as a Processor in these situations because the Customer is the ultimate owner of the data it submits to the service offerings, and our contracts service as Customer’s instructions to GitLab regarding the processing of their data. Data Subject An identified or identifiable natural person. Data Subject Rights Rights granted to individuals in relation to personal data or information processed about them. Because Data Subjct Rights are instrumental to the privacy and protection of data subjects, many of these rights are codified under global privacy legislation, such as the GDPR, CCPA, and LGDP. If a business processes personal data pursuant to certain bases such as consent or legitimate interest, then a data subject may assert one of its fundamental rights and a business is obligated to respond under law. The rights granted vary slightly by country, region, province or state. GitLab treats all users and Team Members the same and will respond to a data subject request from any individual user or team member even if they live in a country, region, or state/province without specific data protection laws. Expand the following section for more information about the data subject rights available. Right of Access A request seeking access to the specific pieces of personal data that have been collected and used by a Data Controller. Right to Correct A request asking for inaccurate or incomplete personal data to be corrected. Right to Delete A request which seeks the erasure of personal data relating to the data subject. Deletion requests must meet certain conditions and businesses are not required to delete any personal data that is processed to meet legal obligations, including that data which may be processed in pursuit or in defense of claims. Right to Portability A request where the data subject wants to transfer their data to another Data Controller; typically seen when the individual changes service providers that share a compatible electronic filing system. Right to Restrict Processing This is a request for the Data Controller to stop processing personal data under certain circumstances. This may also include a request to limit the use and disclosure of Sensitive Personal Data. Right to Object A request to opt-out of all data processing or specific processing of personal data based on consent or legitimate interest. Generally this is a request to opt-out of processing for targeted advertising, which includes the sale or sharing of personal data for profiling or cross-context behavioral advertising. Right Not to be Subject to Fully Automated Decisions This is a request that the data subject not be subjected to a decision based solely on automated processing, including profiling, which would have a significant legal impact. An example might be an algorithm that excludes someone of a certain race from obtaining a credit card. DPIA A Data Protection Impact Assessment is a method to review and document identified privacy compliance risks, as well as evalute higher risks to the rights and freedoms of individuals, including any that pose potential for significant harm. Learn more about GitLab’s process for completing DPIAs here . Personal Data Any data, individually or when combined with other data, that identifies, relates to, describes or is reasonably capable of being associated with or linked to an identifiable natural person (a ‘data subject’), whether directly or indirectly. See also, Sensitive Personal Data. Privacy by Default A concept that should be implemented at the product development stage and uses appropriate measures to ensure that, by default, the only personal data processed is what is truly necessary. In practice, this means a user’s privacy settings prioritize privacy in their default state. Privacy by Design A concept which focuses on intentionally designing a product that incorporates foundational privacy principles and ensures that Controllers and Processors are able to fulfill data protection obligations. This may include appropriate technical and organizational measures such as pseudonymisation and encryption. Pseudonymization The process of altering personal data so that it can no longer be attributed to a specific individual without the use of additional re-identifying information. In order to practice successful Pseudonymization, the re-identifying information should be kept separate from the pseudonymized data. Publicly Available Personal Data Refers to personal data that is publicly available from federal, state, or local government records or made manifestly public by the data subject. Under limited data privacy laws this may also include personal data made public through widely distributed media. Sensitive Personal Data Data that is particularly personal and intimately tied to the core identity of a person. This type of data generally includes racial or ethnic origin, political opinions, religious or philosophical beliefs, trade union membership, genetic data, biometric data, data related to health, data related to sex life or sexual orientation, criminal offenses, and citizenship/immigraion status. In some jurisdictions, Sensitive Personal Data includes government identifiers and financial data. Every vendor that handles personal data is required to go through a Privacy Review prior to being onboarded, which includes completion and approval of the privacy due diligence questionnaires detailed in the Procurement process . Certain vendors who are classified as handling red or orange data under our Data Classification Standards are reviewed annually. Additionally, when new product features are designed, there are times when a formal privacy review is required. This section outlines the process for these reviews. For Third-Party Risk Acceptance, any Moderate/High risk requires VP and/or above approval Anytime a new feature or a change to an existing feature is planned, Product Managers and Engineering Managers should evaluate if the planned development presents a legal risk where personal data is involved. If Personal Data is implicated, utilize the Legal Risk Checklist and Workflow ( internal only ) GitLab Team Members are required to complete annual training which covers general privacy practices worldwide. The goal of annual training is to ensure that Team Members understand what personal data is and how to handle it to ensure that GitLab maintains the trust our customers have placed in us as well as to ensure that GitLab remains compliant with frequently changing legal and regulatory obligations.",
  "The guidance for using open source software has been updated to enable team members to comprehensively determine which open source license types are pre-approved (deemed acceptable) for use, and which require prior review by the Legal & Corporate Affairs team (as their use may be unacceptable). Team members wishing to use open source software should now refer to the comprehensive Blue Oak Council license list, and proceed, as follows: Team members must ensure that we comply with all requirements and restrictions associated with the applicable license (these are typically defined in the body text of the license). If you’re contributing to an open source project on behalf of GitLab, you may be required to enter into a CLA. In accordance with the Authorization Matrix Policy , legal approval is required to you enter into a CLA on behalf of GitLab. If you have the choice between a Corporate and Individual CLAs, opt for the Corporate CLA. Follow these steps to obtain legal approval and enter into a CLA on behalf of GitLab: Contributions to a third-party project on behalf of GitLab should be made using your @gitlab.com email address. Post any questions to the #legal Slack channel. Alternatively, if looking for information on contributing to GitLab see here . GitLab has established guidance to aid with determining authorship of academic papers developed at GitLab. This guidance is accessible to team members only here The purpose behind this initiative is to ensure consistent and fair licensing enforcement for breaches of certain licensing terms, in order to support the continued growth of the open source community. Further information on this initiative is available here . GitLab’s GPL Cooperation Commitment follows: Before filing or continuing to prosecute any legal proceeding or claim (other than a Defensive Action) arising from termination of a Covered License, GitLab commits to extend to the person or entity (“you”) accused of violating the Covered License the following provisions regarding cure and reinstatement, taken from GPL version 3. As used here, the term ’this License’ refers to the specific Covered License being enforced. However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation. Moreover, your license from a particular copyright holder is reinstated permanently if the copyright holder notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice. GitLab intends this Commitment to be irrevocable, and binding and enforceable against GitLab and assignees of or successors to GitLab’s copyrights. GitLab may modify this Commitment by publishing a new edition on this page or a successor location. ‘Covered License’ means the GNU General Public License, version 2 (GPLv2), the GNU Lesser General Public License, version 2.1 (LGPLv2.1), or the GNU Library General Public License, version 2 (LGPLv2), all as published by the Free Software Foundation. ‘Defensive Action’ means a legal proceeding or claim that GitLab brings against you in response to a prior proceeding or claim initiated by you or your affiliate. GitLab means GitLab Inc. and its affiliates and subsidiaries.",
  "The Risk Management and Dispute Resolution (RMDR) division of GitLab Legal and Corporate Affairs (LACA) is responsible for informing and guiding GitLab’s risk management strategies as well as managing internal and external investigations, litigation and other dispute resolution. We seek to support resolution across a wide range of topics, including responding to subpoenas and discovery requests, drafting and revising legal documentation, managing investigations and negotiating and drafting agreements. It is our goal to proactively address and resolve these matters in support of GitLab’s business objectives, coordinating with internal business partners across the company whenever appropriate. In support of these goals, we adopt this mantra: if you see something, say something! There are times when GitLab team members must immediately consult with RMDR to ensure that GitLab is managing its legal risks effectively. These include: If in doubt, please involve RMDR earlier rather than later – we would always rather be proactive than reactive. You can reach out to RMDR via rmdr@gitlab.com . Privileged communication is communication, written or oral, that is protected from later disclosure in litigation because it was conveyed to the attorney in confidence by a client for the purpose of seeking legal advice or by an attorney for the purpose of giving legal advice . Privilege can also be asserted over certain confidential documents created by attorneys for the same purpose. The terminology differs depending on the jurisdiction. For example, in the United States, the privilege is generally referred to as “attorney-client privilege” for communications made to or from an attorney for the purpose of providing legal advice or “attorney work product” for communication or documentations created in relation to actual or anticipated litigation. In many of our EMEA and APAC countries, it may be called “client legal privilege,” “legal professional privilege,” “legal advice privilege,” or “litigation privilege.” Additionally, the scope of the privilege differs by country. It is therefore likely that the status of a privileged communication that contains legal advice in respect of foreign law will be determined by reference to the law of the country in which any action is taken. If you have jurisdiction-specific questions about privilege, please contact a LACA team member who sits in that jurisdiction. Practically speaking, this means that communications between our team members and members of LACA are not necessarily privileged just because a member of the LACA team is involved. As a threshold matter, the LACA team consists of both attorneys and non-attorneys. Communications may be privileged if the person wishing to assert the privilege can establish that the communication was made to an attorney of the LACA team and the dominant purpose of the communication was to seek legal advice. Conversely, if the dominant purpose of the communication - even if made to an attorney - is simply to seek business advice, it is very unlikely to be privileged. Additionally, otherwise privileged communication will lose its privilege in most circumstances if it is further or also disclosed to third parties. Thus, team members should always be aware of who has access to the communication and should be very careful about forwarding it. What are some tips for team members to follow to help maintain privileged communication? Below are the steps you can take to help ensure that any communications you have with GitLab’s LACA team can be considered privileged: For more information, please see the internal handbook here . A legal hold is the process GitLab uses to preserve all forms of relevant evidence, whether it be emails, instant messages, physical documents, handwritten or typed notes, voicemails, raw data, backup tapes, and any other type of information that could be relevant to an investigation, pending or imminent litigation or when litigation is reasonably anticipated. Legal holds are imperative in preventing spoliation (destruction, deletion, or alteration) of evidence which can have a severely negative impact on a company’s case, including leading to sanctions. Once GitLab becomes aware of an investigation or potential litigation, a GitLab attorney will provide notice to the impacted team members, instructing them not to delete or destroy any information relating to the subject matter of the investigation or potential litigation. The legal hold applies to paper and electronic documents. During a legal hold, all retention policies must be overridden. Your obligation to follow the procedures outlined in the notice continues until the hold is lifted, even if you depart the Company. If you depart the Company, all Company owned devices and any material you are holding in accordance with any active Legal Hold Notice or active Company investigation should be turned over upon your departure.",
  "Trade control laws, which often consist of sanctions, export controls, and import laws, govern how and under what circumstances technology, software, and technical assistance may be exported. Trade control laws vary from country to country but usually exist to protect national security and further foreign policy and economic interests. Under United States law, exports, re-exports, and transfers, can take many forms, including oral, written, and visual disclosure, physical shipment, and electronic transfer or transmission. An export can also occur when technology, software, or technical assistance is transmitted to U.S. nationals abroad, or to non-U.S. nationals located within the United States. The export of certain software, technology, or technical assistance to certain countries, certain end users, or for certain end uses, may require authorization from the United States government prior to export, re-export, or transfer. GitLab Enterprise Edition, related technology, and services (collectively, “GitLab Software”), are subject to the Export Administration Regulations (“EAR”), administered by the U.S. Department of Commerce, Bureau of Industry and Security (“BIS”), and various sanctions programs administered by the U.S Treasury Department’s Office of Foreign Assets Control (“OFAC”). The GitLab Community Edition is freely available to the public and is not subject to the EAR. GitLab continuosly monitors developments to these regulations to maintain compliance and to leverage any opportunity to broaden access to GitLab in a compliant manner that allows everyone to contribute. The GitLab Software has been classified via CCATS G178430 as a 5D992.c mass market encryption product with eligibility for export to most destinations under 15 CFR 740.17(b)(1) of license exception ENC. GitLab users may not export, re-export, or transfer GitLab Software, without first obtaining authorization from the U.S. government, to (a) any U.S. embargoed country including but not limited to Cuba, Iran, North Korea, Syria, Russia, Belarus, and the Crimea, Donetsk, and Luhansk regions of Ukraine, (b) any party identified on OFAC’s Specially Designated Nationals and Blocked Person list or the Department of Commerce Denied Persons, Entity, or Unverified lists, or (c) for end use involving sensitive nuclear, rocket systems, unmanned aerial vehicles, missiles, chemical or biological weapons, or for any other end use prohibited by 15 CFR 744. GitLab provides this information, which is subject to change without notice, to facilitate GitLab users’ compliance with applicable trade control law. GitLab users remain solely responsible for exporting, re-exporting, and transferring GitLab Software and any user-developed content in accordance with those regulations and should seek legal counsel as necessary.",
  "Okay, I have you one. Is this YCD wax, um, me T, 2024, January 17. Um, let's see, I'm going to start from the top. I actually have to move my plate to the bottom. Yes, that's a question for here. Um, and I think, yeah, we start with the, so we do not go out, you know, thank you. Thank you. I have a few updates. One is that I'm almost done with the competitive evaluation for fleet visibility and I did link the issue, which has the FIG jam file in it. Um, it is actually very, I hopeening to see what the other products are doing. I won't mention their names, but if you're interested, take a look or just wait for me to post the summary. It's probably gonna be faster if you just wait. And then a couple of things that are coming up. I wanted to get some eyes on to see if anyone has worked on something similar. One of them is that for the fleet dashboard, we're going to be adding a filter to filter by tags. And it's going to be a global filter for the dashboard. So it will filter all panels in that dashboard. Um, if anybody has worked on something similar, I just, I would appreciate your feedback on the placement of the filter there. And if it's clear. And then the other issue is a CSV export for time period. So we have, and the fleet dashboard, one of the panels is allows you to export the usage information as a CSV report. And then from there, people usually take that and like create internal dashboard or filter using whatever other tool that they're excelled or something like that. And now we want to allow them to choose the time period rather than it just by default being previous month. So I'm going to be working on that in this coming milestone. And that's more of just sharing for awareness. Yeah. If there's a good. Now I'm going to talk about the the filter while the filter placement. I'm trying to find the information in my brain, but I think when when we work on. Was it an environment dashboard was. Yes, environment dashboard. I think so. It's just that too many features. I think it's better if I just write down because I need to put an information in my brain. But I do have some feedback about this and also just some. Social validation that was done before. My question here is you have the the filter. That drop down component. Yeah. So you're thinking the future you're going to have more you know elements there and you why if that user can interact with. If we do it would only be one more and it would be. It was time you could filter by some type of time period. Those would be the only two that would be able to impact every single. Data point on the dashboard. But have you played around heavy instruments and with the that filter bar right the search bar where you have like the tokens and chips. Like what we have in merge requests the issues view. And if so why was the drop down. The option that you. Sorry everybody it's like dinner time. I've been to the computer for too many hours and like I'm like. I'm going to need to find out. But anyways, why what this instead of the Mr. Bar. Yeah, so we use the filter bar on the runners list view like the typical view that you come into if you go to the runners page. And we received feedback that. The experience filtering there isn't ideal because with tags. Specifically with tags every single time you go into that bar you have to add another tag. You have to say filter by tag add the tag and then say filter by tag add the tag and there's typically a lot of like there's pretty common sets of tags. So by allowing them to see that in a drop down. I don't know if I added a search bar in the this the menu. Yeah, so you could search for that tag and kind of like stay in one place and do it all at once. And then we just found we've also heard that it's not as discoverable when it's in the filter component because you don't know what filters are available to you. So I'm starting I haven't really edited what that page is going to look like in the future, but at some point we will. I'm going to improve the filtering for that list view. I don't know when it will be. Yeah, got it thanks for the. Take sort of insights. Yeah, I agree makes sense like you don't know what you can filter by right we repeat that. I feel there to search bar. Yeah. How about you also like show fields like below this. I'm mentioning all the tags that are selected because it's not a crowded space you have space. Yeah, because I mean, because this is the only thing that it's being filtered by and you just not being able to see all the tags which are selected. I would say that is problematic to click on the drop down and then get an idea about what this filter is all about. True, that's a great point. Initially wasn't planning on showing them all, but I think I could play around with just showing like the chips. Yeah, like the actual labels underneath. Yeah, I think that's a great addition as we to come and chin and then I also have just really really minor feedback. I just like I like that you're starting to play around with the drop down because I also could hear from you that the concern of using the current filtering bar patterns. Throke it love and then I know that we have a little bit of minor usability issue on that so I could totally get it. But I think my problem when I saw the design was like because I didn't think that the drop down is connect to the whole page. So maybe you could consider I don't know I'm just thinking out loud maybe adding a small borderline below the drop down so make. More visual higher to keep there would be helpful. Yeah, that's a good idea. I've also noticed a lot of other filter like when you use the filter component there's a gray background. Yes, I could try that out to. Yeah, maybe that would help like I guess, but I need to I need to see but you can definitely play around with it. Okay, yeah, thanks for the feedback. And then the one minor thing I wanted to say is I would be curious if people would clue into that being a filter more if it was on the right side over the left because I feel like filter and sorting place and get lab always seem to be on the right and I'm wondering if that would make it more clear or not. Okay, I'll try I'll try that too. I wasn't planning on putting this through solution validation. But now that we're talking about all the feedback I'm wondering if maybe I should just do a quick on. Unlaterated test. I don't know. Like I don't really know if I want to do that. I think it's I think it's going to be good. I just think if you have something coming up like any research that you have coming up, you can just like plug this question in. Yeah, because you implementing the very first version will not be problematic but later for making improvement. Blood this question into any research that is already scheduled. You don't have to like do something like dedicated to this. Yeah, that's a good idea. Okay. Well, thanks for all the feedback on the spot. I appreciate it. I will give it to Emily now. So I only have one announcement since I spent last week watching all the unmoderated interviews. What we've closed off the Kubernetes dashboard views with our improved preview that we were testing. We found out that users really liked it. They were able to troubleshoot, especially like the pod area a lot better than they were. Before using the single stats. So it's a great addition to the cluster UI. And the next steps are actually to work on moving this UI under the environment details page because we tested this on the environment list page. But we know we're running out of kind of space that page has a lot of problems with things loading and adding a big tree on that page is definitely not something we want to do. So we want to test out moving this over. And then also crafting up a more complex version of the tree just to see how it scales. But overall went really well. And I wanted to give a big thanks to Will who recommended this unmoderated test. We were able to complete the study over a holiday period, which I know is usually a slow period for user testing. And we were in to initially accepting to close this off in 168, but we did so thanks again, Will, for the recommendation for this. Yeah, thanks Emily. I did want to add here that you know, I think this overall process was really valuable to go through because. As I wrote the doc, we were originally planning to develop a whole another page. So we're going to have to like go through foundations team to try to get approval. I think Sengen is probably really familiar with with this process based on everything that happened last year. But through like Emily's design process and like collaboration with the P. and Victor. We ended up deciding like let's just keep it on the environments page instead of like having another page. But we, you know, have to like surface to users. So overall great work. If no one has any questions about this, I can pass it over to Vintka. Thanks Emily. I was looking for the link to your design. When I got lost in the position of the addition issue. Let me, let me post link to the figma actually because there's a tiny figma links lost in the issue, but I think it'll probably be easier if I just link directly. I mean without looking at the design, I would just share why I was looking for it because. You mentioned a good point like overloading a page is definitely not a good idea, but I was looking to understand if there is a possibility to provide a toggle between two views. Yeah, well, that's actually what we're looking to do in the details page. Like I've all between two views or two views you can access the problem with the list page right now as it has already so much information that I think added more information into it. Yeah, me, but it's the table overlocked page. Yeah. I just saw the tree view design also and I think it looks really it reminds me a little bit of the pipeline view like the I don't know what we call that tree. It looks all like a tree graph. Yeah, the graph I guess. I think it just looks very good lab. Yeah, I thought you did that was my first reaction that this looks like a graph from good love. Yeah, I used inspiration from that pipeline jobs graph actually because it's the only one in get love. I knew that kind of related size like I'm going to just use that as inspiration and see if I can work this tree into that design. So there's still a few small UX issues like think we have to clarify the arrows a bit more but yeah overall starting from there I think was a really good starting point. Thank you everyone. Yeah, coming to my point so Miran I you were able to make big changes to the way to boost management experience. I know that we are still calling it beauty find a far UI but we ended up like also doing some back in work. That was long pending which was around adding descriptions for variables so that it's easier for someone to you know find a variable that they're looking for because they might be. One with similar like a bunch of variables with kind of similar names that sometimes users create and it's very difficult to understand it is. Through a glimpse that which one was meant for what and why they were created. So now that's going to be easier but that's just one and we have made improvements with validations added a lot of them. We have improved almost like a bunch of health decks and changed than the interior the behavior of the input boxes made the drawer more pajamas compatible and also like contributed to the guidelines for jars in pajamas as a part of this. Overall this was I think a very successful one and we enjoyed a lot so expect a blog from both of us coming soon. The next one that I'm looking at right now is most dream research. I know that I've been talking about it in a very long time but it was really difficult to get people to speak with but I'm just very happy that finally we do have people and this is for the first time and. I would say ever that we have so many people who are willing to share that feedback about most trains. I'll be concluding this research this week and posting the analysis next week or like mid-off next week and I have a lot of insights that are valid for very different teams so just stay tuned. And that's all. I think I can take over and then just voice a. Bonnie's. Notes here they could use not attending. I think most of you have seen that you share the job token. Designed right in the CACD UX. And oh sorry this is the CACD UX. I'm talking at the Google level yes that's exactly the one so. If you haven't had a chance to provide them feedback. Please leave a comment over here the designs. I'm just dropping a couple of comments here and actually press that you know that they managed to use the design patterns and the whites it's really polished. I think there are a couple of things that we can provide feedback on especially on right. I'm just going to ask you a question on. Ording and then smaller interactions. But overall through nice to see them first prototypes them first design. Issue out there in the wild so. Good job Bonnie and also thanks for being there for more supporting them as them onboarding buddy. they made a. I don't know. The way they like explored all the different use cases for this feature and went into the real depth something that we missed the very first time when this this feature was being built on at project level. And we kind of built upon it over time but looking at how they made all those considerations. Before them very very first draft it was really commendable so yeah I appreciate our work on this. Yeah really cool. I'm going to leave a comment here in the document but also in Asia for them I think a good next step is to you know move that acceptance criteria and the comments that she's living in the designs area to the issue description because right about the behavior about the rules. Just the over our functionality it's good to have that in the Asian description. But if you haven't had a chance yet to review it please support Bonnie. And as you also post some questions and scenarios about the CI job token work. It's in I think is the validation issue yes this is the solution validation issue. I think you had a chance already right we to work with them on this one. Right yeah the noise was a really good question so they still has open now. I think Marcil and I we answered most of the questions almost all in fact I invited Marcil because I did not want this to be heavy on my perspective I just wanted someone to challenge what I had written. And yeah I think they has all the answers but still if somebody feels differently I would really welcome you to post your answers here. And Bonnie let us know because you probably watched this later on. And then there's two more point to additional points here she's also mentioning an next steps for that CI job token issue is to create a validation plan and start from the clean the validation so they can refer to Emily's word for dashboard on this one. Emily do you want me to voice a comment you want to voice a comment I never know how to what to do yes. It was just a funny needed any context or feedback around the solution validation that I just did a feel free to reach out and I can chat about it a little bit more. And I just have and if I know not really it's just a comment to tell them that they should create the recruitment issues so because it's not easy and get in touch with Erica. Is it Erica or will supporting the. I've been to Kyra to do to you. It's Erica. Yeah, it's very fine. Oh yes, since they also worked on the scar card and they referring to the one had a chance to see that. And I've cost more aspect that one of the suggestions of the recommendation that she's the she. That's a very good question. So, I'm also good to see right that. We'll mention an engagement also for customers on the community on the work that she's doing so think overall what they has been busy they hasn't had to just join this call us. But it's nice that she's also able to update us here about work so. So. And then if you don't have any questions, I'll pass it over to the studio. Thank you, Sian. So I have to item so the first one is about the think because I shouldn't that we did last week. So it was really great. We didn't chat about any design relevant elements because it was intended to just become a more of a technical discussion. Who was full of this question around how to use API should we change architecture. But I think it was great that I could hear a lot of from back in engineering perspective as well around this project. So. Okay. So it was really cool and we wanted to make sure that we're aligned on this in terms of the project planning perspective so we're working on the proposal from the back end architecture like planning so Bobbi was working on it and then we're also discussing. Shortly after the call and then we're keep discussing around this so the long story short while we're discussing at the moment is like how would the CIC catalog would like to become is it like get left catalog that includes a lot of different elements inside. One catalog or do we want to speak to become a Gillette CIC catalog that includes the ICD components with the city steps the city template type of component. So it's more of a discussion for the future vision and I'm happy that like we're discussing this so that we can make a proper design and product planning so that we can work on working towards the roadmap. And make sure we're aligned on the same goal so it went pretty well in my opinion and based on this we so it's only the empty issues so far but dove and I started to think about like we should validate if this vision really makes sense or not so today I just really quickly create an issue that the research issue service and deeper now. But I would probably need some of your feedback because we wanted to take this opportunity to test things out that is not exist in the market as well as it's not part of the product but we wanted to make sure if it is really aligning with the users needs or not. So it's that and my second item is also more of an FII that I also went through the solution validation it was during the holiday season and it was a moderated test or went fairly like well and. The good thing is so we wanted to test out the different visual by representing the component so currently if you check the CSE to catalog it shows one project in a row but we are asking ourselves like is it better to show the component inside the project. So it seems like it was well received but I I taught in one unrelated question to this research that how would you filter and find the components that are created by your colleagues to test out the filtering experience and actually we got a lot of constructive feedback on this we need more immediate action item. So yeah, but it was a good test and thanks Eric, if you're listening to this call for helping out planning the research issue. So yeah, if you're interested in let me know if you have better idea on how we are going to improve the filtering experience I think it would be a whole topic that I may want to share in the CSE to review meeting at some point. Any questions if not. I don't have a question you mentioned that you would want some help like some feedback but where do we go to provide that. I don't have a really well described issue but I have created one empty issue so I'm going to link it here. Where is the past sorry too many meetings. Thanks, Bill. Okay. So this is the issue that I'm going to work on in the next one or three months and I want to really revamp the whole filtering experience for example on question three needed tap here. And the second question like how does this filtering tap with the search full working well together and I'm pretty much going to start about using this pattern so I'm happy to explore alternative UI for this. Thanks for asking. So move over to hyana. So switch word updates we're seeing hiring. And the update I want to give to the team is that you may sort of change is to the role requirements that you can find the kickoff issue but also they'll review with you because most of you are part of well they're really team right. So the big change is that we are only interviewing or going to be hiring intermediate product designer so when assessing right in interviewing the candidates and also fill in this for a card. And we are moving them to the pipeline into the interview process considering them intermediate designers and also make some updates in which the priority of some of the skills both the soft skills and hard skills for this role so as you can see here. So 3 and 5 three to 5 anyways top 5 the theory skills is foundational research. I think for switch board there's a lot of have a lifting that needs to be done. And a product designer inexperience in research is really important they need to be very strong collaborators with you know the image and new in all the designers. I'm mainly looking for some on the has worked with the design team before or at least you know had some fair designers. We have interviewed designers that they were like the design team of one they were the only first designer in you know a startup etc. I think that especially for if you think of where switch board is right now where we are getting started with a lot of the core functionality of the user experience someone that has you know a bit the more of experience in collaborating with our designers to get the understanding the insights. All of how to use a design system that they are used to you know just figure in things out with a team think that's essential. If they are not already technical they are interested in the nation and CSS. So I'm sure if in your score cards you're interviewed you talk about that about those skills but. I would like them to at least. The you know proficient in basic HTML and CSS that mean to they're going to have a better understanding of design interactions that they will be able to communicate with the front end engineers right about the components that. When review merge requests they will just be able to jump in and. Do the work that we've done. And I already mentioned the usability interactions that we did to design system and experience working on complex products before I was really looking for someone that had the depth to experience. That's always tricky because it's a little bit such a specific work that you all do here. So complex products that can be like working banking you know and compliance in anything that really requires them to dig into this. And that's a messy hairy problems and showed that they cannot lie design iteration. To you know, propose a motion that they can use research skills that they think collaborate with their teams anyways involve engineering in their design process so. And I'm not sure that's what I'm looking for. And then I still have skills technical skills in general right. Like anything outside the scope of HTML and in CSS. As I mentioned, really nice if they have that tool that's to be experience maybe they're a user of GitLab maybe they I don't know the coming from one of our competitors. And also body and platform workflows or admin platforms experience that's also nice to have I think before one of my mandatory skills was that they had experience in onboarding design. But very tricky to find and combine all of that I think it's we make some tweaks there to make sure that we're not finding the right candidate on paper but that you know we find the right person for the job and that for the things that. They they need to improve this was an engineering proof that we create the opportunities for them to gain those skills. What changes I think to you mainly is you know only intermediate so if you think someone is at the intermediate level but they're like I don't know early intermediate or I don't know a very strong intermediate I'll like you to highlight that in your notes. And also when I say intermediate is like a GitLab intermediate right because a lot of other candidates that's. We interviewed recently especially end of our last year which was like two weeks ago. They had a title senior but they were like not GitLab senior right so it's difficult to not difficult but we have to. Kind of set that expectation with the who the candidates so I'll pause now see if you have any questions and if any obviously since so yeah that can I line. The expectations for the upcoming interviews. I just have one question I really haven't been getting any interviews for this role. So I was not sure if that was something was missing there or I was not sure. Yeah that has been the challenge and it's also why. We were making this changes to the the requirements. I've interviewed only a I don't know maybe. Six eight candidates in the the last four months that's not a lot right because initially the candidates that were being as creative that were qualify. They were and then that's going to answer to will question to expensive or there were two senior right they were good designers but switchboard is an area that. If if we put someone that is too senior they're going to finish the work like in a year and then what. We cannot risk like getting someone. Put is a one there so that's to be born right they it's a it's a problem area where the designers the design and they need to have them for growth right and need to be able to learn also in the fly for example. I think that's the experience in research but have never worked with a research team so they're going to collaborate with will right you going to learn something. So yes for this this role we haven't had so many interviews we had candidates that were screened and we're qualified and they moved to the team interview I think. VT coming me soon during interview a few of them but then rejected. After after a couple of of interviews. I think that's the first question that's great. I think you you kind of answered by first question so I did add a like another question. And then you know you've done you know you mentioned six to eight different interviews with some like more senior candidates. Are there any. Concerns that like intermediate candidates will still be able to match up well with what you're looking for for those top three to five. mandatory skills? Yeah, I think so. And that's the assessment we've made after having these interviews, right? And after also looking at the book of applications that we had. Right. I'm sure if I remember at some point I mentioned like I'm reviewing a thousand applications because a lot of people were applying. And as I mentioned, they are seniors where they're like not good senior. And if you will have the experience working complex products that we need or understanding research methodology etc. I do think we'll find an intermediate candidate at this level because farm and but correctly like Gina. Gina Emily and Tunjoon, right? You, the three of you, join as I think to be the level, right? But you all came with a very strong graduate, very strong experience in various specific things, right? And another thing we have to look at is that this team, you're all seniors, right? So looking at the business when we hire yet another senior in this team, right? There's all you're going to be so many staff and manager opportunities in the company. So we also need to think about that, right? The career path and development and room for the road for a new person in the team. So that's really it to the point I mentioned about, you know, compensation expectations for people there to senior depending on the location factors but also budgeting and career progression in the initial. The, as a two question or will. Yeah, thanks for going through that or me. And of course. And then a question. This is a little bit out of scope and if it's something that we can't talk about in the recording also in time of that. But as you mentioned that there's a lot of seniors on our team and that there's, you know, not every. The growth opportunities are only going to be there if there's like a certain amount of openings and etc. Are there any is there any work going on to maybe change up our. I don't know what the word is, but basically like the growth opportunities for product designers because right now like you're saying you're senior and then you're either staff or manager is there going to be like other opportunities in between that. Yes, I think we have a, I'm not sure if the merger class was version of things, so but I know that Valerie and and better to work here on the principal product designer, which is staff plus. Right, similar to what engineering and also product has that something that Christy was also working on because we need to make sure it's right that. Let's say after. Actually, you get promoted for example to senior product product design manager, you could become a director, but then what's in between right. It's a limbo that. That we need anyway, just this, a clarify and I know that this is part of the discussions. That leadership had at least, you know, last year, I'm not sure yet when this will become a. Let's say something that is in the handbook right of a job. Because we also need to have the business need for that. Right, so we didn't have staff designers in the past, right, we also didn't have senior design managers, so as we grow. We also have to make sure that we are not. We're not only adding people there are too senior because that also means we might lose them right at some point. That's all part of the changes for this particular role and also mainly because I think switchboard is complex, but it's not as large as for example. Verify right where yeah, you have a very well established set of functionality that yeah. That will require expertise that requires more senior designers. So yes answer a question, but I don't know what. Okay, thank you. Oh, the. Um, thanks for your questions, by the way, and I know that we are at almost a time, so I'm just going to drop my question here. I discussed this with some of you already, but. I want to see if you're all can help me. I have to disemble it to switchboard by the way, but I have to complete a UX score card as part of a Q4 okay are. That will require me to validate a job to be done right run a score card on a job to be done for a product area outside of CI to the outside of switchboard. I can pick anything, but I want to pick something that relates to verify in release. I'm sorry, verify any environments. It's an a room number that that changed. And my question to you is. Do you have any suggestions do any recommendations on. Cross stage job to be done that makes sense to be used for a score card that can help us, you know. Experiment or at least a sastic with the that that user experience. Taking that the recommendations will be beneficial to your product areas. That makes sense. It's late. What do you think. I have the same suggestion here that I shared with you and everyone on one. You help me like come up with this. I discussed for the designer with the other team of the other team which is go interviewing that's how like. I did not have a chance to find this for testing the usability of merging experience, which is a very wide experience. And I can totally give you the highlights the tags from the up to you that validate this. I would just need some time maybe tomorrow. I think appreciate it. I was thinking, I didn't discuss this with you, Sunjian, we didn't have time today, but I was thinking of a running job to be done, of the Reyescore card, also for one of the jobs to be done in Create, but related to the pipeline, like the editor experience, right, either the coal suggestions or using, I don't know, VS cold, whatever, using extensions, because I think that could be interesting to you, but they don't have jobs to be done for that category. So yeah, that's the type of thing I'm looking for. So I'm thinking secure could be cool. I think that could overlap with verify, just thinking about security widget, vulnerability, that all can expect to like, commit in pipelines. Yeah, that also makes sense because I think that's the way that you will or the Erica that it's Erica, that was working on a study or I think, and I think you see eye adoption and something about that related to related security and compliance work flow. Yeah, it's definitely Erica. It's Erica, right? Yeah, okay. Anyway, I forgot that, you have wheels. Part of the agenda, I'll just, oh, for now, unless will you want to, yeah, voice up coming here. Yeah, I saw that you added the link to the just to be done. Yeah, we'll file, so I was just kind of like, scrolling through it. And I came across this one. It looks like it hasn't been validated, but it touches its technically under distribution. So that's involved with, like, actually installing, get labed and then it touches on Kubernetes, which is covered by the environments team. So it looks like there's a couple different, like stages involved. So I don't know if that might be another area to consider, but unlike the one that Vita got had shared, I don't know if this is like, it's got the evidence behind it as much as their does. Yeah, thanks, Will. I linked here the, the, the, the objective on the file. Yeah, I'll do some digging. You could just, you must be some additional information in, direction pages or these categories, this area, but appreciate the feedback. And then over to your world. Yeah, I don't really have a lot of updates. I did want to just add to what Emily said, earlier about our solution validation study, that I think they did a great job collaborating with Victor and myself on this work, and they was extremely efficient getting everything done, especially around the holidays. And they also did a great job like running the study in user testing and then providing us with updates on like each participant, asking me for feedback on like whether they needed to like, you know reject certain participants and kind of get new ones in, get higher quality feedback. And then they also consolidated all those individual sessions until like it overall. Summery, which was really detailed and awesome to see. But that's kind of it for me. Thank you, Will. And Emily, thanks for the shout out. Thanks everyone. Yeah. Yeah, I never worked. I mean, we want the, never, we wanted to, never, we want to. It's going to be forever on the internet. Thanks everyone for joining me. And first thing a little bit of time. Hope you enjoy dressing today. And that's me, Linda. Bye.",
  "Okay. It works. All right. Okay. Last team meeting of the year. I just want to start off by saying, it's been a crazy year. Thanks for being a crazy couple of years for everyone. But yeah, I'm really happy that we've made it. We have the people to be working with you all in 2022. Looking forward to much more next year. And I just wanted to ask this is anything that you have in mind that I'd like to share a ball's what you're looking forward to. Work related, no work related in the next year. For me, for example, I'm really looking forward to the GitLab. What are we calling that now? Are we calling it summits? We're calling it contributes summits, right? Yeah. I really hope it happens next year. Making all my string blends around it because it'll be super cool to make you all in person. But also, yeah, just to meet again, some of other colleagues in the subject. I think that's a high light from my GitLab. GitLab was just but also to higher the designer in switchboard. It's been a few months and boredom. So these are like my plans. And also something I'm looking forward to. And it can be quite annoying to have your manager ask you like, What do you want to share? But does anyone have something that they want to share in this last year? I'll have to say, was summits as well. So now I'm going to try and think of something else. But again, that's one that I really want to share. I have met many people from my immediate team. I have met a few people from our team, but it would be nice just to for the first time ever to meet like a big jump because of people I work with in person. Which will be really nice. I'm looking forward to figuring out what fleet visibility will look like next year. So like the first time I feel like I'm dealt with a brand new. Not really a brand new feature, but it's a new category for us. So it's the first time I've dealt with that. And I think it will be. Very fun to collaborate with a lot of groups because it's really cross group. Yeah, so I'm looking forward to collaborating and figuring out what that's going to look like. And some it will get on the summit train. Eric, could you want to say something? I was just like, I didn't want to. I said, no. Okay, then let's just be grateful for Eric. All right. This year and more Erica next year. To. Awesome. I think, yeah, I just before we jump into the agenda, just want to say I was not going to take some time off next week, but I will because it's just today's. And in case. Any of you, I know that Emily asked for my coverage for a few days, but if anyone else, that's going to be watching this recording. If you need a me as your backup simply assign yourself in get lab as busy and I don't forget, you know, to do that and also link to your coverage issue because. Yeah, from not able to cover it, we can point people in their requests to the coverage issue and it can leave comments there if you need it. Okay, then we do a start on top start from top yes, then over to Gina. I have a reminder that I'll be out of office for probably the longest amount of time I've ever taken here. So two weeks. And I linked my coverage issue there. Thank you for people who are covering for me. And then I have a few other items just for some ongoing work that's happening in early will in January when I come back. I'll work on a competitive analysis for or competitive evaluation for fleet visibility and. I will not state the competitors there, but I will be looking at, but you can read them. And then go into that issue if you want to see more Darren has already added actually a lot of screenshots. And then I'm also working on auditing existing research in summarizing that into a video about kind of like the broader pipeline performance or how to optimize my pipeline. Erica has done a lot of research in that area that I'm also going to be just like summarizing in one place. And so I'm not to my surprise there is a lot of existing stuff so we don't have to talk to more customers which is also nice because the problems are already validated. And then lastly, I worked on I worked with Graham and Alana who are two new product designers because they wanted to shadow someone while reviewing an MR so. And it was a really fun experience for me we were trying to get pipelines to be in the right states and I was like googling on the spot and. We were all just like working together they had GDK up on their instances as well and we were working together on it and it was very valuable so we. And I'm hoping that I'm able to add this officially to the onboarding template for product designers. You're welcome to jump in there. I have a comment on this one can I say I left a comment in the merge quest you know just in being a big company for feedback because. I will this help you and board bunny and they are do something similar. So I think they had this week the first merge quest shadow call they also were taking a call for like one hour so they might have some. Some feedback and I think it's a great addition because to your point right now that designers are assigned to randomly assigned to merge requests reviewing something out of sort of your stage. And even can be even scarier so I think in general doesn't opportunity to do that for us to also define when shoot that happen right and who should help them with. She'll have to mean the process so thanks for that mark. Yeah and also I met with be this morning and they was saying that she'll create another remark because I they had some larger ideas of how to. Kind of like time box a lot of the stuff that we have in the template so there's going to be more changes. After that but we were able to connect at least on the small change that I wanted to bring in. Throw on the same page there and she'll build on it. And that is it on for me. Emily. Well, um the first one is just an FI I that we're starting a new unmoderated study in 168 for a tribute on the Kubernetes dashboard. We're seeing like a lot of competitors have a tribute of this and it's a concept that we didn't initially explore when the Kubernetes dashboard was first validated so it's something we kind of want to. Sneak in there as we're working on it and a big thanks for well will's been kind of helping me with the screen here for this as well as the scenario so. Thank them for their help with this study. And then. The second thing I wanted to say is Andrew one of the friend and engineers on the team invited me to a Kubernetes meet up in Toronto last week which was a lot of fun. It was very very technical so a little bit above my knowledge. But it was nice to just go kind of network with some of the people working in this area making connections and we're also talking about maybe presenting our Kubernetes dashboard at one of these in the future. So I'm going to meet up with a Vittica to see if this is something I could do speaking about and partner with Andrew so they can kind of answer all the engineering questions that come up. But it was a lot of fun and I haven't done like an in person meet up for a while so. And if no one has questions move to Vittica who's not attending. So do you want me to voice it for her. So it's I'm talking so them first point is there's a discussion going on in PE on the time we show for duration created at started at and it'll be helpful for some early-career and Gina to for and she's like the epic for improvements. And then. Gina I noticed yours is read only but since we probably have time we can. Yeah, I can voice it. I brought this up. It's actually a really interesting issue. I would recommend going into it because it basically like the users saying that weren't misleading when we calculate duration for pipeline. I brought it up with a flea team just because we have a lot of overlapping features that have to do with duration and runners and wait time and everything like that. And I left a comment for Vittica because we have some specific customer recordings of how they use duration metrics and why they're using them to optimize their pipelines. And the just a summary of what the fleet team talked about. We kind of agree with the user that it is misleading because we're not including pending time in the duration, which is. I'm not saying any kind of weird. But anyways, I just they had asked me to jump in and just include some. User stories, I guess kind of what most like how customers are using this today. So that's what I did. Yeah, I can bust my comment to. I had my one of my new Vittica today and I told them there are some insights in one of the environments. That's where we searched issue. I think I did that maybe last year with summer. That has some explanation about what the release managers and that's up in the years when looking context of the payments right when they are in the pipeline pages. But looking at the point of production. What do they understand you know of that metadata what why are they looking for. When it comes to. The ratio of the pipeline or you know. Well, when it started running etc. So it might be interesting for them to look into that but also connect with you and you might have a lot of updated and more insight in that. But just as a reminder, I think related to what you said there's some connections right about those information that we need to make. For many different personas, a lot of people just go to those pages, especially the pipeline view. And look for something very specific. There's a wanna see one number or one tag. So keep that in mind when making this and coming nation, let's also look at the insights because we have them and if you're gonna find it. Ask me, oh my, oh my. Oh my no where it is, but it's it's there. And then research project is the environments dashboard redesign. I think. That's not the group level environments dash that's the original environments. Okay. Yeah, yeah, I think then you all have been a full school started and I finished that was before you join. And I think that's the main thing. But there I remember documented that in the off jail because we specifically asked about the order of the metadata and also. What they want to do. Why some of this info is relevant. But anyways, mission like one or two insights about that it's the environments dashboard redesign. Also just another small note about this. I know that the issue was about the pipeline duration and. What another thing that I was thinking about is that a lot of these metrics are. I think more useful at the job level rather than the pipeline level because each. Even if the same pipeline runs. A pipeline is designated for a project. If that pipeline runs multiple times the same it might have a difference at a job set run every time because jobs can be skipped in it whatever. So yeah, I think it's it's hard to think about this at the pipeline level just because there's so many changes that could happen with each run. And I can move on to our next point. We're done. And the next one is we need to get started. Butifying our UI in 168 there's many MRs that are merged already and now have validation in the form of that work. And I'll voice Bonnie's comment here if you want to take a look at the list of items. Maria and them are working on. I think that's just a question for Vita go and to watch this. I think it's the opposite. I think it's the biggest comment for Tika's comment to Bonnie. Okay, everybody. Yeah, that makes sense. Yeah, because Mida is in front of an engineer in Tinas. No, no, that's right. Mida is a sorry to many to many teams. You're right. No, so we're confused because it could be that 168 beautifying something with Hayes Lumi. Maybe with Mida. Anyways. Yes, they can take a look at the agenda. That's it for. Yeah, so Bonnie and Sinshu are not here. And then my only update for us which more is that still hiring, Steven interviewing. I don't have an interview scheduled for well this year and more. So hopefully by January we'll pick up with more interviews and fingers crossed hire someone. Good evening. And over to Eric. Yes, so I posted the link to the draft of the report for the runner and CI builders build. Belled feature prioritization survey. So we did a canos survey with 11 features to see how they got prioritized. The signal we would be looking for is that there was like one must have that we would want a champion. Actually, they were all either attractive or indifferent. So like kind of cool, but like nothing like that we have a clear signal to deliver on. Looking across the ones that were in the attractive bucket versus the indifferent bucket. We have a signal that users want AI assisted things like for example like custom dashboards are actually not compelling because it's more work for them. But if it can be like AI assisted then it's like attractive but still not a must have. And so Darren and Gina and I are going to go over that report and depth tomorrow. But I thought I was like give the high level overview that we don't have any must have so I think it means that we're on the right track with like figuring out those little optimizations suggestions which is a read we got from that qualitative study. And we wanted to do this just to make sure that there wasn't something that was like so cool across this bigger sample of users that we missed but we didn't so it kind of doesn't change the strategy in a way. I've also noticed that the not the sample was mainly small medium businesses. And I want yeah which is fine like I kind of had the assumption that they had different interests than the enterprise customers that we're talking to that are self managed. I we did have yeah it's totally right very keen. The thing is I think this idea that it would create more work still holds. Yes. So I agree but I guess my point is I feel like they have different needs because enterprise customers first of all are typically self managed bringing a ton of runners. So when I look at the features profile does attractive. I would imagine runner usage and compute minutes are higher up on that then for small business. Small or medium business. Yeah yeah I don't I I assigned a fidelity of signal score to to kind of help us make sense of it. I think what we can do is really look at the the the five features that are have strong. We have strong of it like a strong signal that they're in different to that's kind of the most. Okay, well it's like okay don't invest heavily in these okay yeah oh that's also so interesting though because. The notifications I don't know it's. Yeah because yeah because it's just it could end up really distracting them the notifications parts. Right. And then I think a lot of their flow. Yeah. I guess that makes sense but they're but then I guess does that mean that we just think about different ways of solving for when you're keep performance stinks. Or when your runners are. Erring out a lot like we have to figure out a different ways to give them that information. Or at least make the notifications like customizable as opposed to like across the board so it's like you don't want to get like all of their runners aren't important to them it might be like only the subset so like allowing them to. Opt in. Yeah but in model versus like opting out. Okay. It's like just we did just be really wary of creating. More things in there already busy. Yeah I don't I totally understand that this is really cool though Erica I'm going to look this is my first I'm actually seeing it so I'm going to look deeper into it and I think our meetings tomorrow. Yeah yeah and let me know like what what to do but I and I think it's a really good critique of the. Of of the sample that's like really on point I just think that. The the problems that we're seeing with those features should also have a problem like notifications for enterprise level but would skate that would scale that finding kind of right definitely yes. I was looking more at slide seven of the ones that are attractive because I figured the ones that are set they're set at week there I would have thought that they would be higher up for enterprise users but the findings that inside a definitely relate to all I totally agree. Yeah yeah so we can decide I think the thing is we didn't get a clear I mean I thought we might get a clear like chibby in here. I'm not really important that we don't want to like sprint towards any one of these particular visions and I think that like this AI assisted is the way that we want to be thinking about it. Like yeah behind the scenes they just wanted behind the scenes. Yeah okay I have some more questions but I don't want to take up a ton of time. I'm not a baro. Cool everyone don't you care. Yeah okay. And let me know if you want to sink today too. Okay. Yeah. And then or just slack about it and then the other study I'm working on is this conversational AI study which is like a team of researchers and I'm working with ops folks. And we are asking we did like an intro interview and then they're doing a diary study where every two to three days they let us know the tasks that they performed with conversational AI and how it went and they're giving us screenshots of those. And so we're getting a sense of how we might use conversational AI in the ops space. Although we think it's not related to performance optimizations like we got a signal that they that's inefficient use of their time. It's more like it looks more like they like it like as an idea generator or like getting the right language to use for documentation searches stuff like that. Anyway, but I'm threading the like really technical example tasks in that thread I linked and we'll we'll be doing the follow up interviews with them in the second and third week of January and so we'll be asking people to like give me follow up questions to ask about those tasks. Sort of put that on your radar and then the next thing is I was initially thinking that we would run that shared resources workshop at the summit, but I think we should do it after the summit because it seems like. I'll be like the only nerd being like, hey, let's work. Look at it. But let me know if you want to go rock climbing because there's a rock climbing issue that someone created. I work our rock climbing. That's all I've got. We can have the workshop while rock climbing. That's a good challenge. Okay, we're too happy with that. Let's go. But I think it's a good idea because yeah, you know, maybe some of us will also take some time off after some it's before right is some traveling. I think it's good. Well, once it gets confirmed, we can play around the summit for that and if not, we just, you know, pick a date in. You don't make you to things going to make you to right. Yeah, and if you work it to, yeah, I think it's safe for. Can we. Okay. Think that's that right we'll. Yes, already off. Anything else we didn't discuss we would like to share before we wrap out for the year. Good. This. Who? And thank you Emily for recording. This. Yeah, enjoy the rest of your day. I'll see you later. Final see you later. See you next year. Enjoy. Enjoy time off. Bye. Bye. Bye.",
  "Maybe you can, yeah. But I don't know where this is getting recorded to cloud on my computer anyway. Yeah, so I was saying that Sunjung, I learned a lot from the process that you were following and other learnings that came from that. And so like we thought that it's going to be good to kick it, kick it off as soon as possible, but not wait for everything to develop first and then think about right up like that. Yeah, yeah. This is the right way to go. Thanks for sharing. So my item on there is free a big and rather radical change from the CACD private catalog. So we we discussed this a lot and this came up and inspired me a lot. I did the journey map exercise and I didn't feel it's right to having this private CACD catalogs go for namespace because we have interviews several self-manage instance customer. It could be really multiple namespaces and not going to disclose to exact number, but it could be a lot of course it depends on the organization's size. And now dove announced this change and this will impact a bit of our product roadmap or the timeline. The design lies that impact is not that big, but I think this is the right way to go. So I was really supportive about this change and yeah, you can see that now we simplify the structure. So we'll have one organization catalog and one open source catalog that is kind of similar to the market. And I have personal updates so you can re-through it. I might need to reschedule some of our coffee chat or 101 if I need to. From next week until the end of September. I wanted to here with you all. So I am so excited. Yeah. Immodges are not working. Yeah. It's mostly common control shift that works for me to show the model or the modus. I use it a lot. I'm not ship story space. Okay, so my Anna is not here. So we can just go through this asynchronously. Maybe we can move to a research them. Yeah. Yes. So I am just analyzing all the sessions from how do we use AI to help users optimize their runner and CI builds. And it was pretty cool. We used like a decision tree process from this book on AI that I'm reading. And basically the idea is if you can put the decisions into like clear if then statements, then you have support that you can automate this workflow a bit. So we didn't know if it would be like I think about this, but that's related to this. And then this is really, but actually it's like pretty straightforward. Anyway, so I won't go into the results. But I'm working on the report. And another come out. I think I'll share with the UXR team soon and then it will come out next week. But there's really good information in there about just the details that people need to make decisions. And kind of the outcomes for optimizing pipelines. And the process is very trial and error. And set it and forget it. That's the main thing. So I think that's like one of our CI learnings just like the biggest thing I've learned. And get lab. They don't think of these things in their minds either. Like they specialize in it. They execute and then they go away. But I think that there's also findings related to how to support teamwork. So I think you'll like their report. And then next week or as soon as I kind of like get my mind into that report, then I'll start working on this. How users are using get lab on the cloud. And we'll do a little bit of a good question. Yeah, could you just elaborate a little bit more on the effort? Yeah. So I'm actually very proud of us as a product company that we're like ready to move into this space. So we're looking at kind of the connection points between get lab and the cloud. And like where the work flowing is. Kind of the tools that users are using. And that'll inform and part of the integrations that we're building. Like, June, which is DCP. But then also like long term what works well in terms of the integrating. And what does it? And that's actually where I think we can bring in some questions about resources and whether or not they should live at the project or the group level like how teams access like secrets for example. Like where does those get stored and get labed? And it is like higher up organization. Because I'm thinking a lot about this new. Chains that's coming related to organizations was to new nodes because that's like the new play with the catalog. Which I think is really smart. Which is to put it up there. But then I'm wondering like what else could we move up there? Like maybe the secrets because they're at their organized at this company level. But that's what we can look into. Talking about that Erica, I like can you like later go in chime into the issue that I've created for navigation. And like share your views there because yeah, we don't want Even though I have mentioned about like taking it out of CI CD. If there's any research that points that we should have it maybe as a part of the main navigation or out to higher level navigation. We should be aware of that and that would help us inform the methodologies that we would like select for research. Okay. I think we haven't gotten that detailed because that's actually like really tactical. Most of the research so far has been like what is a secret. But I'll look I'll look up the lens on there, but I think I won't have much. But I think from this study we might get something. Okay. And by the way, I will also pick this up based on your recommendation. Oh yeah. I'm listening today. You can read that chapter. I'll say it. Okay. I had. No, it's okay. I just have another like full hook question. Are you only looking at get lab. Sassy. There's always trying to read through your issue. And I mentioned that because one of the teams that I work with in enablements. Currently the application performance group is changing their name to cloud connector. Okay. And they're focusing on. Sumpman issues are essentially giving them access to like AI features and things that would be available through get lab SaaS, but at the self managed level. So that might be a good team to connect with. You know, in terms of this research. Okay. Awesome. Thank you. Right. I think we landed on the SaaS. Users. But not. Yeah, but either way, I think they at least be interested. So that's so helpful. Well, thank you. I'm embarrassed that I can't quickly find that in the issue. But it's okay. I'm on the other project. Yeah. So if you want to ping their entire group. I can list the the channel there. And then the P.I. can also list the PM as well. Okay. Cool. I just put thank you. Thank you. Well, go team. And then I have this this note. I have to find it in the, but I'm watching the sessions again and again. So it's coming. But there's just lovely quote about how we made a change. And the details people could see about the type lines completing. And this person was like, I love it. I used it the other day to show my executives that I need more funding for my pipelines. Because I could show like kind of the times and how if we organize things, this would impact the times. And then they used that to find more of our product. So that's like the best. I can look this in your portfolio. Be prepared. Where are we showing the pipeline? Somebody. I'm sorry. Oh, no. I mean, I don't know. But when they was telling me, was that the new way that they can look at the metrics allowed them to make this argument. I need to pull up the, I'll pull up the quote. Okay. It was pre-owned. Any other updates before I go or. Yeah, the data technique. So I don't necessarily have anything. Connected to delivery or dedicated this week. I guess just a. Announce what I'm working on outside of that. Doing some research for organizations that I think Eric had talked about in the US week, the call earlier in the week. So I included the research issue and I've been. Constantly like adding and refining research questions there. And then I'm doing a workshop on breaking changes. Some adding people from different departments at the moment and can be doing that. It's going to be kind of a mix of async and synchronous workshop parts. I was looking for Jocelyn in the list because I mean, given how much they has been struggling with breaking changes and I see them there. Yeah, that was somebody who came up pretty quickly in conversations with the PM that I worked with Sam. they was like Jocelyn definitely let's include her. But if you have any other suggestions on who might be a good person to include. Let me know. Yeah. That's all the updates that I have this week. Okay, so with this we are at the end of the agenda. Anything that someone wants to bring up. If not, then the visit. It's in the meeting here. Bye everyone. Have a good one.",
  "Hey everyone, this is the CICD UX meeting on August 2nd. Starting with our standard topics with the, I had not wanted to mention the Q3, okay, as are being defined and will be available soon. So she'll share more info once the details are known. But two of the okay, as might center around the UX department completing the neuro diversity training and resolving usability benchmarking findings across FaireFI. So does anyone have any questions about those two? Awesome. So then we'll move into the product design section. I can voice Hannah's because there's important notice here about how she'll be providing coverage for switchboard at 20%. So hands on design work, milestone reviews and team rituals. And this will continue until that roll is back filled. And they expect to onboard five customers to get liad dedicated by the end of Q3 which puts a focus on the UX. So during this period, if you need support or she's blocking in any way, please be explicit about what's needed and you can ping DM on Slack where she's most responsive. And then currently working on email notifications and the onboarding flow, gathering requirements to improve design proposals for the deployments page for switchboard. So lots of updates to existing work and that'll be kind of where them focus time will be. And they shared a customer call from Switchboard on Monday. Think I'm next? Yes. Oh yeah. No, no, sorry. But if a no one has any questions, yeah, Gina, you can start. Okay. I have attached a report that I wrote up about the mental model research study. And there's a lot of good insights that came out of it. I'm working on recording like a video and sending it out today explaining a summary of that as well. But right now, one of our next steps is to run another survey, which is in progress and already have some data from it. So finalize the terms that we use to explain the concept buckets. And then we're also asking users where they use those things in their workflows. This will help us get a better idea of really what they think those words are. And then we can also use that to look at like pain points within the workflows that they bring up. And then the next item is that our next big thing for runners to look at runner cost visibility, which is focusing on users who bring their own runners. So we're not going to be touching shared runners on SAS because we use like our own pricing method for those users. And an example of this is like if you create a runner through AWS will provide you visibility and to how much that runner is costing you like the machine and to run the jobs and everything. So I attached the issue there, Darren added like a ton of details. And we're just going to work on scoping it down. But I talked with the team today and we're going to run a think big and think small on this because my goal is to have the process of getting the first iteration for this feature out faster than what we did for the NBC dashboard. So I think I'm next if no one has any questions. So I'm just making progress so so you can update it kind of artifacts for design sprint starting with issue templates and slide decks that you can reuse during the sprints. Just let me know if there's anything design sprint related you'd like to see template it out and I'll try and get to work on some of those. So some of the ones I haven't gotten to are each day of the sprint to those issue templates as well as I'm going to make videos that you can share asynchronously on how to conduct sort of these activities or the homework we were calling. So there's a few things I'm still working on but just wanted to share progress on that. The second thing being our we did internal research on populating a service list two weeks ago now we're doing external research. The good news is the results from both internal and external are really aligning, more seeing a lot of the same feedback from both which is great. So we're hoping to wrap that up in the next few weeks and move on to prototyping an NBC approach from this. Yeah that's a good thing that they're aligning. Yeah that's so we were worried about we were like I hope GitLab isn't using GitLab differently enough but there results will differ but there's a lot of the same thing which is really great. Okay there are no questions I can proceed with mine. So first of all thank you everyone for providing feedback last week on the secrets pucy prototype and you'll allow find our advice design on the same framework profile. The next step for me is to create an interactive prototype and share the link with everybody who has signed up for the OLE Adoptal Program for Secrets and then we'll just keep our fingers crossed to see what kind of feedback frozen. Beyond that I mean that that's a big thing that has that is about to be wrapped up this week so now I can start looking at see a job token and variable work again. Yeah besides that I have a chat with the application secure to team here at GitLab. I organized a meeting with our engineering manager product manager the security engineer from upseq MSF and it was really interesting so I tried to understand how is it that they are currently like how are their workflows related to secrets being fulfilled today with the current set of features that we're offering and they kind of walk through it and also contributed to the user story map that we've been working with. So we definitely have to keep in mind and one of the learnings was that we have to keep in mind the special responsibilities are special permissions that any security uh any any individual responsible for taking care of the security in any team organization would be requiring and that's going to differ a little from what we are going to be thinking for maintainers owners. So yeah this was a really good meeting for us and that's a oh if you don't have any other question I can move on to mine um I don't have so much to share for this week um so we had a meeting last week and this is this is this huge that I learned here is the outcome um so we decided to take a step back and then just like let's just forget about like everything and then we just focus on the user flow and then their context and then see what is the best solution for them and in which context are they starting to author the CIMO plot pipeline or maybe they want to come in to the CIMO and then maybe they want to just make some edit and then probably that's the point that they started looking to the CIME template component. So I'd like to just list down all the possible context and then make a journey map for each workflow as it seems like CINA has one question they want to verbalize your question CINA. Yeah it's a little it's kind of related I guess um I just had a question on the progress of the CISCD catalog and the navigation effort because I saw in that page now that Foundation team isn't allowing navigation changes until January of next year and I was wondering like how that impacts your team progress. I think of of course it's I don't know at this point because we are ready to start to take a step back and then I based on the outcome that I come up with like with the journey map or whatever design that we are going to discuss okay which is the best placement. So the short answer would be no I guess so from mind-resenting so okay probably the project navigation is the best location for this reasons then that means we can still ask for the request for the Foundation Pman and have those conversation back with better back up from the UX perspective and then also from the UX our perspective so I I you didn't think it will be blocker for us but at this point where you just like decided okay let's like a huge step back so I don't know we would be a plug or not just to answer your question. Yeah it does um one of the things I'm in our team call them runner today we were bringing up the fact that our project runners views and settings and everywhere else it's in the navigation like in build or in admin areas still called CICD but same thing and I was like yeah I I'd mentioned that your team pipeline authoring is like going through this and it's been quite a struggle um and yeah I'm just I'm a little nervous considering what I've seen from the stuff that you've gone through already so I might end up talking to you more about it depending on I might create an issue just to get like their input so far because someone actually commented about it on the navigation feedback issue they're like why is runners still in settings for project when it's not in any of the other views so maybe that helps but we'll see yeah so my solution would be maybe you already started to getting more numbers and data and also those verbal feedback from users and then just be ready to have those conversation with the foundation in one year really sure about like okay this is the good place for the runner yeah that'll be my only suggestion thank you yeah thank you my issue is also going to come in so I'm going to join the band in a while yeah and I think to genus one that most things that we are placing in CICD settings I'm not like very aware of what's happening with the other settings option but CICD settings those particular items are facing discovery, discovery, discovery, quality issues and I think we just need to see that what we can do and it's impacting kind of silly person the item that's inside the settings so it's not just about runners and variables it's about like how can we collectively improve the visibility of those items overall and yeah it would be a great chance for us to collaborate on this yeah totally agree yeah I just wanted to add that that are protected environment settings are there and we've had a lot of like user feedback that no one can find are protected environment settings so oh yeah yeah I remember that looking and that one is pretty divin the setting yeah it's deep and it also is sitting in an area that people are expecting it to be in and it's not linking you can't link it to the edit or just we recently started linking it from the edit environment but before you go to edit environment and it wouldn't be there so that was even more confusing I have an observation there that in most of the other products because we did a competitive revolution recently so I was just like passively looking at there are many options our like anything that's placed under settings in any of these sections I actually cascading in two steps and that's not the case with other products they have their settings navigation separate from like everything all together so doesn't feel like everything is very hidden you mean they have it like in a separate like almost on the separate level pile yeah yeah I see what I mean yeah and the one thing I noticed is sometimes we just put things like two kind of figure also when sites the setting and is it really setting or is it something to configure and yet that's sometimes confusing to me so maybe this is a good opportunity for all of us to I don't know just some fun work like settings you why version two yeah yeah well yeah we even talked about just removing protected environments from the settings and just moving it into the edit environments page because we're like that makes so much more sense for just actually in just actually those yeah and then maybe have an overview in settings but like I don't know it for us it doesn't quite make sense while it's sitting there yeah and just some a different kind of semantic grouping like for example verbose tokens secrets they would all of be kind of managed the same way but they'll be scattered all across even if it's on the same page let's see well think of something whoa yeah just wanted um if there any other it looks like research is both away this week so I don't think we'll have anything from them oh does anyone else have any other questions if not we can end this slightly earlier oh that one has a great rest of your day",
  "other. All right, today is the 19th July and we are meeting for CICD UX discussions. There are some stunning topics. There's just one impact which is by me. So in by playing security, we are kind of experiencing something like we are getting community contributions, which are not directly related to any issues. And those contributions, they are not very small in nature. So what ends up happening is it kind of like, and some being in conflict with something that we already have plans for and we try to make changes of that, we can accommodate it like we can take some parts from the contribution and get it implemented. But the discussion has been like going really long on those. And so Jocelyn and I we thought like maybe we should bring it up with the contributor success team. And that's the discussion that's going on there. So probably they might bring in a couple more automations to the process or some additional label that would require contributors to ensure that they at least look up for issues which are relating to the change that they are proposing. And that would also help us make sure that we are not discouraging anyone from making contributions because of course if we just continue the discussions for a month or more than that and just keep on changing, making changes to the decisions. It's not, I would say for someone who's taking a time from their personal time to do this work, it's not a great experience for them. So yeah, I'll keep everyone posted on what we decide or changes the contributors success team decides on rather. But this is this lack thread, but it's all happening. So if you want to just follow up. Yeah, Gina, do you? Yeah, because this happened to me as well and it gets a little frustrating especially for designers because we tend to have to go back in like retroactively design based on the contribution. And for runner we saw it was the same contributor every time who was doing it. So we ended up talking with the contributors success team and then met with them plus the contributor and kind of like talks about our roadmap so that we talk about our roadmap and also what they were thinking on from their roadmap so we can come together on those things. And what I suggested, I mean, obviously we have to like be open to them contributing. So I suggested that if they have like a new feature that they want to create, they create an issue first and tag me and that puts a lot of responsibility on us but I also think it gets us involved earlier. So that's what they've been doing lately and it actually has been helping a lot in regards to like making sure it fits in with the features that already exists or that we even like see coming up in the roadmap. Yeah, that's a very relevant example. So like this is case by case like for your team writing but to make sure that we come up with something that's generally applicable to everyone it's adding. Good for the contributors success team to come up with some new rules probably. Okay, if there are no more comments, let's move to product design. So for the first section which is which for Hannah has some updates that she's working on the backful requirement for all this position and if there's anything that any of the team members have been working on with the relief, they can just let them know so they can work on finding alternatives. Any other, I think NFI for Emily that the bears would be rotated by the end of July and for the rest of us as well of course. Yeah next is Gina. Yeah, I'm going to drop a little bit early from this meeting but also the things that I've been working on are mental model research for runners which I completed and thank you, Erica's not on the call but if they washes the recording, they helped me a ton with this project. So yeah, thank you, Erica. And they gave me a skeleton of a report to be able to fill out with all the analysis and still working progress but you're welcome to check it out. I also added a summary to the issue though. So what came out of it was to find groups of the runner concepts that users think about when they're using runners and then we also had them like come up with their own terms to describe certain definitions which almost all were not aligned with what we use at get lab but conceptually you saw some connections there. They just weren't the exact same terms. And then the final exercise was to have them match the terms to definitions like the terms that we used to get lab to the definitions and most of those they did they were not able to match accurately as we define them at get lab. So there was a lot of learnings but what I'm seeing now is the next thing I want to do with that Erica suggested is work with the team to come up with names for each group of concepts and then we're going to send out another survey to like a hundred participants if we can get that many and have them select which name like they feel best describes the concepts in that group and then ask them where they're using that and they're workflow and what tasks they're using it for. So then we can figure out how we want to make changes from there like if I wanted to make the design changes for that configuration example that I shared last week that would be like a way to help us validate that that is needed. But what I'm seeing now is to have the team is very it's difficult for the team to like understand that these concepts were grouped together because it doesn't align with how runner actually works. So yeah it's people are having a hard time looking past like the technical way that it works and then how people are grouping them and I was wondering if anyone has run into that problem and kind of how you're approaching it with your team. Will do you want to ask your questions? Well I did want to give you space to see if anybody has like thoughts on the question that you just raised because by questions a little bit unrelated. Okay. I think what Emily did with environments was something similar because they challenged the existing ideas of concepts that were like that were there since forever in GitLab. So I don't know maybe Emily any insights like how did the team take take it when they learned. But this was rather something that the team was involved in. So probably that's how it was different because it was not coming from outside but from discussions within the team. So the buyer would have been on the boat somewhere. We also had a lot of research to back that our current feature wasn't working. So I think that made it easy to convince the team because through like the group of environments research additional research before we were aware like this feature wasn't really hitting the mark. So collectively I think it was much easier to move forward versus yeah it coming from someone else. Yeah which is totally different in our use case because people are very happy with runners. It almost feels like we internally because we're touching it all the time. We have a much deeper understanding of it than our users, the majority of our users I would say but also the admins or platform engineers who are managing their own runners have a very similar understanding as we do. So it's hard to get it's hard for me to be like they're not understanding it when we know that they are because people love the feature. We want to think that helped us like I know we are at a very I would say nascent stage in the entire native secrets manager concept but one thing that helped us was the competitor evaluation because like the entire team got to like take a peek into how the rest of the industry is referring to different concepts and that also helped them relate with the research data that Erica had like greater reports on. So everything together they were able to relate one thing to another and that helped in like gain that conviction. I did definitely start with that. I have like a Google Doc with competitor terminology in it but I didn't really share that widely with their group so that could be a bit places to start a person. Thank you. Yeah, I just just certainly back to my question. How did you decide to get survey data or you know target 100 people? Yeah, so Erica suggested that we run the survey for I think a month and a half I think it was or we or when we get to 100 people like whichever one comes first and I they was saying 100 because like that's the average number that they've been seeing trends lately from surveys but if you have other suggestions I am very open to it. Yeah, I've used like survey sample size calculators which I can certainly link to here. So if you know like how many people are using a particular feature because I know that we have like it a lot of internal metrics on like who's a user of this stage group or that stage group. You could use that as a little bit of a guide and to like okay if our population is x. Then we should survey this many people to get somewhat of a representative sample size but yeah I'll include one below. Okay, I think another thing was that I was kind of saying that we need to move fast with this so they probably changed them answer based on that. Okay, yeah I mean that that certainly plays a factor too. Yeah, yeah but I still would like to look at that survey sample size and see what we do. Yeah, so I added a link there. If you click into it you'll notice that it has like three different sections. You don't really have to mess with confidence interval or margin of error. You would just have to enter the population size. So that's the number that you would have to either guess to me or you know get some analytics on to populate that field. Okay, thank you. This is nice. Great, the hearing will. Yeah, so is everyone that I noticed they're still typing going on. We're good. So just a small update with the outcome of the design sprint. We're trying to figure out the best way to go forward with the research here and we've started with a just internal customer interviews with the SRA and delivery team around the service concept getting a better idea of what they consider services. How we would populate that list and after we're done those internal interviews which I think they're like six happening this week. A big thank you to Victor for scheduling them. We'll be able to move forward with like external user testing just an update on that front. The other one is I'll be working on the design issue around designing for external jobs and I believe this touches kind of like the job details page, the jobless page and the pipeline details page. I'm not sure if any of those funnel into the verified teams that have designers but if they do just let me know so I can involve you and kind of feedback for these pages. I can help because I like I took part in a lot of free searches for those pages so I can help with any feedback but otherwise there's no designer for pipeline execution. I can also help because runner has a very small portion in this but there is at least a link to the runner that runs the job and then there's a lot of output from runner in the job log that might be helpful. Yeah this is mostly just designing it around this new like external job thing and what visuals will show but I think it'll touch like all of these pages. So figuring that out as I go forward. Yeah and also please slip mean because pipeline all thering it's not just owning but we are also touching some pipeline details page and then job log as well so I'm happy to help. Thanks a lot. Have you liked can I ask a question just on like what external job means? Yeah so this is one that I'm just starting into so I have to kind of look for it that this is as far as I know a say I job that's being executed outside of get lab. Like like on actions so for example on actions okay. No worries it's so what this is is I'm reading this out is like adding a new job status so it will represent the jobs that are currently being executed by a service external to get lab. So adding in like a pending kind of state as that is being run and then yeah so I'll actually link the engineering issue here that explains it a bit more than the design issue. Um That is helpful. I'm also reading the epic and it says external jobs are not picked up by a run and so it might not even can actually mean and if so you don't have to work me in. I mean I heard about this use case in some pre-searchs and also in the conference lately but I don't know I still cannot drop a runals it I need to read through this. Yeah this is new um for 163 I just started looking into it so as I learn more I'll reach out but it's a fairly new um being more looking into so I don't have all the details right now but I'm sure over the next week I'll have more. Okay. Okay. That's it with me. Then I will take up and so I'm mostly focusing on just one thing besides a couple of our community contributions this week that's the like finishing the POC prototype so I created the user map and flow on big jam it looks so good and um based on this particular story mapping I would be like designing the different pages or the different actions for this flow and that's for this. Another thing that I wanted to share was I'm starting to add like I added a slot to my calendar from starting next week for every Thursday morning. Kind of a time that suits all of us like all the members in the CI CD team at least and this is for like to have a sync time with me to discuss just anything that relates to public presence. We can just like use this sync time to discuss a block proposal to edit a block that's already there to like write abstracts select conferences designing content representations. I mean just anything that comes to your mind if we can use this time for that and to be like how you can add yourself you can just like go to the link add it to your calendar and for a whichever week you have booked it others would not look it for that particular week. Yeah and that is it. Yeah you could just do I like I noticed it goes to a calendar block. Do you get notified or do we have to like book it with you to let you know um let's try. I don't know if that happens because when I clicked on it it just goes to a calendar event but no one's invited to it so. Yeah okay I'm also not a part of what that is amazing. Okay now I am. I'll work further on this. Does it look very full? Well some links are getting it together. Yeah are we can just like sync runes like catch up over slack and just book slots manually this doesn't work. I'm not so good with automating things. And that's it. Yeah so in the new you can take it out. No I just wanted to say plus one but yeah it's my turn okay. So I'll type it later. So things be to Kat um I have two items that I like to share that um dove and mark and myself we're planning the Q3 that what could be the CSED catalog beta and then what could be included technically and also from the user standpoint and it's almost like divine and then we also announce a true to team and then now team is some board so that's exciting that means so just to tell you a little bit of more details we will gather more and made a data from now on so that we just just don't need to hold like this depend on the repeat.mb that user right and then this is your component a and b and c like for now like we have to just let them write everything and then just hold the depend on this instruction but you like to kind of provide a better assistance and suggestion system um so this is exciting for me because it'll open the doors for the further UX opportunities that I like to share this and the other point is probably you might see this in the MR's pipeline path um there is a now failed job number is surfacing in those tabs so that was the idea for this packathon and then luckily we get a lot of positive feedback at the same time we started to get a lot of bug reports. For example there is four failed job but so we just have a zero failed job and with even with the tabo emojis like oh okay we should fix it now so we're also working on this it's just popped up but it's exciting that people had a coming in and as they and then if you also have any other feedback please please let me know I'll also link the app to your issues so that you can leave some feedback around UX and also the UI pack as well. I think this was a really good improvement like a tiny one but so impactful. Yeah I was excited and then yeah we will have more issues. Thanks um every case on leave so moved with over to Bill. Thanks, Andrew. So I just wanted to quickly touch on additional point about the survey calculator that I spoke about a couple minutes ago added some information earlier on but I would just recommend you know working with your researcher if you decide to use one of those types of tools to figure out what's the appropriate like margin of error and confidence interval because if you leave it as is that those things are more like academic standard so tell you that you need probably more than you really do so if you have like tight deadlines or you know whatever it might be you might have to adjust that a little bit to get a better sense of what's a more reasonable number of people to survey. Outside of that I'm going to be a leave starting next Monday. I'll be out for four weeks so I'll get back second half of August. I've created my Q3 prioritization issue and linked to that here. A lot of the stuff that's represented there is just carry over from this quarter that's still active and then I'm going to be picking up some projects that are paused. And then since Ali has departed get labbed, coordinating with the PM Lauren and then Hianna to determine next steps for the solution validation project they was leading. So we're meeting on Thursday to discuss this more in sync haul but we're also having a synch discussions about it. If Hianna's going to be able to drive it while I'm out if we're going to just kind of keep it paused for the next couple of weeks until I'm back those sort of things. So that's what's going on with me right now. Enjoy your family time. Yeah. Yeah I need it. Yeah my wife goes back to work next week for the first time in like 12 weeks. So I'm going to be on full-dad duty 247. So give it them a little bit of a break. Okay so with that we have at the end of the agenda anything that anyone wants to bring up. If not then let's play more time back. Yeah let's meet later. Fine.",
  "All right, welcome every month. Today is 21st June and we are meeting for CICD by VTU. I'll start off with making a mention of some of the announcements that Hannah has put in the agenda. The first one is, we do a check-in in process. It started like 12 of June and it's going on and what we'll be using for these check-in says are regular one-and-one agendas. This process is led by team members. That means we have to go there, fill in our achievements, rent, support needed, and affordability areas since the last formal assessment. Besides that, there's another one. There's a 360-feet back that is going to be launched in July. There's not a lot of tedious available right now, and I will keep this posted. Yeah, coming to questions, I see one from China. Do you want to talk about it? Yeah, I can voice it. And then whenever Hannah listens to this, I'm sure she'll answer. When I was filling out the career development plan, issue template, which was the one after the individual growth one, we included a Q1 portion of it. And we've already completed that this year, so I'm wondering if we should include goals for next Q1 instead there. If anybody has already filled it out, or is going to, I'd appreciate if you, whatever you end up doing, just let me know. I chatted with Hannah this morning about this, because I had the same question. I'm like, oh, it's almost Q3, and the top thing says Q1, they says you could also just break that down into months too, so you'll be doing something in like July and August. they kind of put the quarters there as like a template, but if you want to break it down differently into months and stuff like that, you can do it as well. Okay. Well, thank you. That's a better answer than what I was going to say, so I'll just give. Okay. So what sequence are we following today is like, Eric and Will are going to go first, because I remember we did it the, the different period last time. So Eric, tea. Will you go first? Sure. So mostly my updates are about things that other people are working on at the moment. So it participated in Emily's design's friends, over the past two weeks. I've told them this, but she's really did a great job, you know, from start to finish, and it was great to be a part of that process. All the activities that they put together, we're really great is by first time doing a design's, and I'm really excited that we came out of that spread with a prototype that was tested internally, but also we'd plan to test it with customers. So I'm assisting on the late social validation issue that Emily has started drafting. I'm also supporting Ali with their social validation testing. On the onboarding experience that we've talked about in past meetings and looked at them figure. So right now we're developing the screener. And I think he's also planning to work on the discussion guide, which I'll come up with. And then the last one is that the PN for switchboard, Lauren, who started, I think about month and a half, two months ago. When they was onboarding, they completed some internal team member interviews to get some feedback on the current experience related to dedicated and how that process is very manual onboarding customers. At that time was more of like a limited access product, but now it's we've just gone live as of the last week, we're dedicated, is open to all customers. And she's just recently finished research and added insights to the issues, so I'll link to that one as well. Any comments or questions? I do. I have once, you said we have gone live, but dedicated, is it the same thing that Ali was working on? Like is it live now? No, that's a good question. So this just means that dedicated as a product was previously something that was like limited access. I think we only had like three or four customers that were actually all dedicated and it just went general access or G.A. So it means that like anybody who's interested can sign up. That's a little bit different from what Ali is making with switchboard, which is more like an automated onboarding process or kind of self-guided onboarding process. Which will certainly help people as they transition on to dedicated. And that's something that we're going to build as an MVC in the next couple of milestones. But yeah, that's a good distinction that dedicated is a little bit different from switchboard. It's kind of connected but a little bit different. And they're getting some sort of assistance right now. It is so manual right now. Basically, like our sales reps are kind of walking through, walking through different parts of the process with customers. And it's so much like back and forth over email. Trying to track down information that they require in order to set up that instance. And so that's why like having this onboarding experience will really help. Take off some of that manual burden off of our sales team. Good. Thanks for answering. Good. Yeah. And future for me. Yeah, that's a good question. Any other questions directed over at Erica? Okay. So if you haven't yet, and I think everyone could participate this on in this. Who's on the call now, but this is the first week of the AI user needs and. AI fit workshop. So we're done it. But basically the idea is we're going to answer these questions in the survey. There's two surveys for this dedicated feature that we've decided to like go through the process with. So the idea is just to learn about what's a good fit for AI and the long answer is it depends on how we design things. And so that's opened up. So everyone wants to complete that. There's two surveys that be good. And you guys can if you don't even want to. Hopefully Gina, we think a little bit is a pay, but all all the rest of y'all want to look and to see what we're doing. I think it's like helpful just to see what those workshops look like. And then just calling out kind of just a hey Anna knows that we. I'm so excited about this, but we we figured away to differentiate against one of our key competitors for our. Get lab native secrets solution and we something that we've already called out and I like created a deck about it. And then we like finally heard from customers. This is something that we really struggle with in a key competitor, bless you Gina. And then to me that makes sense like why I would be very familiar and why that like problem we keep resonating with me. So but I we're all like aware that we need to like figure out how to work together on this. I'm sure we will, but we just want to like make sure we're mining it so we don't get back into a design corner by accident. And so I just thought I would put it in the agenda there and then. Tina and I are having so much fun working on the mental models research for runners. And she's going to check in with some new today to see if they can like combine efforts with the mental modeling research for pipeline authoring. So anything I can do to support that collaboration, but depends on availability. So and then last but not least is a feedback request that I was hoping people would fall out and just to help me focus on. Tell me what to focus on in the upcoming quarters. Yeah, me too, Dmitrika. Thank you. Thanks, thank you for. Especially for the deck because I am personally interested in that for the differentiation and I want to make a mention that I have highlighted like there's a tag in my new research project and ductile with the variables and environments and today I'll be processing those into insights and I'll be sharing with them. Okay, so moving upwards. Singing is not attending but they has a couple of items here that you can take a look at it's about the design think that they was. Like there was a design to think around see I catalog and the other one is a solution validation. For how users would want to publish their C. I confidence to the catalog both interesting ones and next up is me. So we interviewed nine participants last week for the solution validation research for variables it was like specifically about the new layout that we were designing for presenting the variables on the project setting page because that's where users get to see. Custom variables defined at two levels projects and who were so group so they inherited and the native or to the project ones. And it went really well like at least I was not expecting to speak with nine participants all in one week. There were no no shows. There were technically but then the risk at you that we still got to talk. So one learning that I would want to share is. I'm a standard follow up email a few hours before the schedule meeting that really helps just like stating that looking forward to talking to you in the upcoming interview and something like that. We shoot and dovetail product link is tagged here if you are curious for what's happening there but I'll hopefully record a video by end of today and post so my goal is to like wrap up this one and wrap up the sketching exercise before I leave for the conference next week and. Apart from that I have also written a blog with Patron on the work that we did for beautiful for you. I good thing is I met with Jackie yesterday and they mentioned that customers are noticing it and they are happy with the changes so. It was scary. I am going to be speaking at Penbot first it's a tool which is an open source prototyping tool but there is simply like. They got funding last year and they have gone GA I think in January they had this official launch. So there'll be a lot of organizations present there like us like Red Hat GitHub. It will be an interesting gathering and yeah. I'm looking forward to it. It's happening in Barcelona and of June. And if no other questions we can move to Emily. So I know I already reviewed this during our feedback session yesterday but the three days of the design sprint we finished up. The last week or the week before I'm losing track of weeks at this point. But we kind of have the highlights from the hallway testing summarized so just to give some context hallway testing is the third day of the design sprint where I get everyone in the sprint to kind of. A potential persona at GitLab and given interview so we have some highlights from those three interviews and then the next steps here is to run around a solution validation over 16 to 163 so currently working with will to put together that testing plan in the smile stone. The second the one some of you might have seen this in the UX channel but we're celebrating not moving forward with a concept so we're deciding not to move forward with the group of all environments concept mostly because we realized part way through these interviews and with kind of stuff that came out of the design sprint that we were moving forward with a concept on top of a feature that wasn't very strong initially. But I think what we want to do is go back really perfect the environment's feature itself and then move forward with something at the group level versus kind of building on top of the feature that's not working currently so that's kind of the outcome of that. And the final one is I'm looking to put together a mini design sprint training guide just wondering if anyone is interested in kind of being a pilot for that. Yeah, I mean, what we are planning. It's going to be very different in nature but I think the general guidance around that is going to be very helpful for us. Cool yeah because I'm going to plan to just put everything into like a template and kind of share that out with like best practices so I can start with like just our immediate team before sharing it out with anyone like further than that. Yep, I think in support we definitely yeah benefit from it. And that's all for me unless I knew and hence any other questions I can give it to Gina. All right, I have been I actually talked about this a little bit yesterday in UX weekly, but the whole runner dashboard MVC has been quite a ride because we have run into a lot of issues performance wise. But I know I've been still fighting for the things that I learned from research when we did solution validation around this feature. So we know that the metrics we're showing are the right ones we just need to figure out how to implement it. Come up with a POC using postgres, which is our database that we currently use and go from there so we'll see how it goes. And then my other note here is about the mental model research that Erica brought up. I met with them yesterday and I'm very excited for this because there's been a lot of like heavy discussions happening internally on the runner team about disagreements on the terminology we use for different parts of runner. So we're going to focus on mostly external users to understand how they think about runner concepts without using get labs specific terminology and will be talking with people who have not used get lab before so will be more general. And then we're also going to ask some just five internal get lab team members. And we set out a plan that has four parts which I can also not update once we update the call trick survey but the first part will be a card so we're. Just like the typical ones that we usually see where you're grouping terms and then you name the groups and then ranking order of importance of concepts I think we have a list of 16 or 18 even right now. But maybe minus the duplicates it would be less I think that's what it is. And then we're going to do a fill in the blank section kind of like madlips but not really and then matching the concepts to terms so we'll have like a list of the concepts in the terms and they'll match them together so today I'll be. Doing that like putting that survey together. I'll read you one of my voice that that's probably yeah yeah so yeah cool. So I guess I'll. I'll. Do my section yeah. So I'm more human finalizing. Our solution validation that we're going to do for the designs that I've been sharing over the past few weeks. So yeah doing proper working on the screen and discussion guide and recruiting and then I'm also working on story mapping. For switchboard initially I'm going to do a pass and then I'll do it with the team next. So yeah hoping to get that done this week. And then I'll share with everyone as well. Yeah can you elaborate a little like what you're trying to achieve through those story mapping exercise. Yeah so we know that. We we want on boarding there certain things that we want customers to be able to do. Such as. For the customizing we are dedicated instance also customizing when they want to do maintenance and then providing monitoring. For their dedicated instance and some logs and there's some also some other tasks that we also want to do so. Which is on a map. And so what that will look like. Yeah and yeah heavy discussion team and see what everyone has been thinking because yeah. It seems everyone has different thoughts on what switchboard should and should not do so I think this will be a great starting point. And this was good because I have never done like specific exercise for like a story mapping exercise for any of the things are just thinking like. Can I. Like getting some inspirations from you. Yeah that's it. Okay. Um anyone has any questions or anyone anything else to. Discuss. What life didn't with this answer to recording.",
  "Okay, everyone, today's the 26th of April and we are meeting for the CICD UX meeting. And today I'm filling in for Hannah and let's start with those stunning topics and FIIs. So, I'll just like, I'll mention like, the important items. So first, just Hannah is going to be back next week on Monday. And next week on Thursday, we have our very first design review meeting. So that's great. And anybody who wants to volunteer to share a problem with the team for design feedback, please add it to the yetto nine advance. The agenda can be found in the calendar invite. So it's probably not the same one. It's a different one. Then the next one is by Syngim. So do you want to localize that? Yeah, it's more like a FIIs or a read-only item. And I thought this information from the CICD Keller project that's like, we redefined this name because I'm working on the experiment phase of the features. So probably it might affect to other maybe AI projects or your new feature. So I think it's just good to know because if we name it using the experiment batch, because I was using the alpha before, but I had to change the experiment. And then there are another node from seed recently that like, so all features are should be just public. I think that part is also added at the very end of the talk. So I just wanted to share with you all. Thanks. My main main feature is that I saw like it was mentioned that it just slows us down. And we release a feature only internally. Does anyone have any other points for the FIIs section? Or we can just, okay, we'll just move on to the origin items. The first one is by Ali. He, I think, is not on the call. So quickly, we're obliged. they has thank everyone for the reviews on the minimal onboarding design flow. And he's working on incorporating all the changes. And I can totally understand like there are so many comments. So it's definitely going to take some time. Does anyone have, oh, Ali, you're here. Do you want to take it up? You're item? Sorry for throwing that on you. Like, so suddenly. Well. I think we were, I think Ali was still connecting to audio. So you might have not heard you. Okay. Okay. Ali, I was just mentioning that I was kind of covering your items for you. Do you want to take it up and work a lesson? Okay, cool. Sorry. I didn't realize again. No problem. That part. Yeah. I wanted to say thank you for everyone for the reviews and it took back. I'm working on incorporating them. And yeah. I'm working on improvements. Yeah. Yeah. Just wanted to mention like great work there. And we understand like how many feedback there are on the issues now and the time it's going to take you to incorporate this. Moving on to Gina, they is out of office today and there will still be holding sessions for the selection validation for runner fleet dashboard. Does anyone have any comments on the runner fleet dashboard? Validation. If not, then I'll pass it on to Emily. Well, so my main focus this past week has been planning for a design sprint within environments. We want to kind of rethink environments as like a deployment tool. So just, I don't know if I'll all of you know, but I still run design sprint and teach how to do design sprint that my previous company. So I'm taking the time while planning for this to help fix up some of our templates get everything organized. So might have waited this a little low given kind of some of the stuff we're having to do, but hoping to have that complete before this will be my next tip is I'll be out of office for two weeks starting May 12th. So my covered issue is there. But yeah. Oh, see, there's Vita Gahez a question. Yeah. Very well. I mentioned about like a re-looking at this whole experience of environments environments and deployment. It kind of reminded me about the secret manager, like native solution for secret management. And I'm just curious that how you and your team have talked about it, that while you are looking at this bigger effort, that's definitely going to take some time. In that mean while how do you plan to look at the smaller improvements to this area? Yeah. So that's a really good question. We're hoping that actually the design sprint lake day one will really help our focus in what we're going to be kind of going into in some of the takeaways of this will actually be to have think it's like three or four. I'd have to double check on, but issues that are ready for development to take on. So while we are looking at kind of reimagining the whole experience, we're also looking at getting out smaller issues to kind of work our way there. If that makes, I hope, is that the question you're kind of looking for? It is. I understand that there couldn't be a very structured answer to this because it's something that we just explore and figure out. But it's good to see another fellow designer in those same position. And just to get inspiration from. Yeah. And I'll be recording all the sessions for this too. So I'll be able to share those out. I think we're looking at hosting this like the first or second week of June and having it run for a week and a half with split async and sync periods. So still trying to figure out how everything works together. But hopefully we'll be able to share it the process and maybe it's something other designers can kind of take on as well. Nice. Thanks. Does anyone else have any questions for Emily? I would just, I would like to be included in those design sprints. That's note. And then the other thing is just, I had created that deck that highlighted the trouble with variables and environments. Sorry, my maintenance people just came. So I was like, okay. Okay. Well, I had created that deck for y'all. And I will link it here. It's just that we have not been like listening intentionally for, but have kept hearing about this paint point related to variables and environments. And so when that happens, that's an indicator that that's something that's particularly painful. Be a part of that design sprint, but also to elevate that deck again, which I will like, assume it's like invited. Well, great. Thanks, Erica. I also keep keeping eye out for that because I mean, the changes that we are making. Yeah, it's related to deployment, it's related to environments. So yeah. Yeah, we want to make sure that this is like the beauty of this meeting and this team, right? It's like, let's make sure that that experience cross-functionally is working. I'll link the deck. Welcome back. Okay, thanks. All right. So the next item is, I wanted to share the progress that we are making on the beautifying UI 16.1, which is going to start in the next milestone. So Patron and I, we met to do a small prioritization exercise because if you look at the issue, there were a lot of issues shared with us many epics. So we just like went through the list and picked up items that we can work on with the time limitation and which also makes sense to work on with all the current priorities. We like, put aside a bunch of issues, then we plotted a chart of like what's going to be impactful and visible because it's purifying UI literally and then we plotted that against time. It's going to take in how much time we have. And you'll see like in the description, I've updated the table of the things we're working on. Most are like small but impactful improvements, but there are two that would require some design work. Which is the last one, the table. One is unboxing pipeline detail page, which is kind of ambitious, but we'll still give it a try. And the other one is rearranging the tabular layout on the jobs list view to match the pipeline list view. If you like compare the two today, there is a difference in style and there's also difference in how we are organizing data. The jobs view has like so many columns which just makes it difficult to have and be like change the viewboard size. It doesn't look very elegant, the kind of shifts that happen there. That's one. And everything else is just like regular street group work. So I'll talk about that in some other meeting. If nobody has a question or comment, I'll pass it on to Sunjum. I have one comment. I'm trying to find it. I'm distracted by trying to find the link. I did this analysis of the suspect for Betham for the last two quarters, which will come out at the end of this week, they report. Part of that was identifying paper cuts. Some of you got pulled into the issue. Yeah, and so I created an issue and the idea was just to get verification from the team about whether or not it was a paper get. But less than if they didn't just start thinking about how to fix those things. But I wanted to call it out because some of them are small things that relate specifically to pipelines and those pipeline views. So Vithika is soon as I could find the issue, it might be worth just kind of scanning to see if when you end up hating do that work. If there's any other little things you can support. And maybe that team would pick them up or you can get a little help. So there's that. Yeah, definitely. So we were a little conservative without planning because, yeah, I mean, we just did not want to over promise. But I have this hunch that we would, in fact, have some time to spare and we can definitely squeeze in some small MRs then. Okay. Singen. Thanks Vithika. So there's one excited moment for me and for the team was the detailed stage of the catalog has been shipped. And it's being reviewed. And I believe you're ready to break things down for the implementation. So the front end team is working on like how can we break things down starting to communicate it with the back end teams just the usual development flow. I think we're good if you check the issue like we got a lot of feedback. Those reading exciting and also the design is done. So I think the team is ready to work on this on 16.1 until 6 in.2. So that's exciting. And the other piece that I like to share with you is like myself. With our amazing tech writer is working on the very initial onboarding flow. Let's say for less experienced user who haven't create any pipeline so far. And then if you check this example review, I have like this is targeted for those audience. And then like I just tried to stop by myself like it was so nice and it was so helpful. Like they put all the like comments just next to it's Yamul's in text what does this means. And then you'd expect to see some failure attacks. Pass after running this because of this reason. Oh, sorry. So we were just working on this type of guidance. So I was excited and I was excited to be in a community. Kinipate because I made some trouble. But yeah, so it's yes, the dark huge starrous and then they have really cute dinosaur icons. So that was exciting when I successfully build a pages on my namespace. Like this is cute like really big dinosaurs were on the page. So I think it's a good example. And if I am for two weeks and coming back on May 15, I edit my cover this shoe and yeah, that's it for me. So I and I saw here so maybe we could use verbalizer comments. If you don't have any other questions, sorry. Okay, that looks like we are clear. So if we are being panked in the community contributions for package, we need to assign that to Pedro because he's I think covering for our staff groups that don't have a designer. And here are the like changes that were made to the magical review in relation to that. All right, with that, we are kind of through with the product design items and now, I was again passing it onto Will and Erica. Thanks for your time. So starting to wrap up and hand off projects to others before my leave starts in a couple weeks. So I've added my parental leave issue above and also to the template since it will go on for a period of time. And then I'm also going to be making a Q2 research prioritization issue. A lot of it is going to be carried over from what has have been completed in Q1 because it has been pretty proactive about letting me know what research needs they have. So I'll you know, paying you know Emily and Ali and many others did I work with when that gets created. Also wanted to shout out Erica for you know supporting Emily with recruiting for them solution validation study. I just wanted to thank you for you know joining in on on that comment thread and really helping support them with recruiting. How's it going Emily? That was one of my questions, Jessica's it working? Yeah. Oh, you need it. Right there. There's a vacuum I think so she'll be muted. Oh, oh, god, I got it. Yeah, that's that's that's that's it. All right. Yeah, I'm I'm like very interested in the progress because I'm going to come to you soon Erica for recruitment. And I think with our big success this quarter will be that you guys can sort of drive that and be more self-serving or that sounds funny. But yes, be able to get access to this participant. So be the give you want to if you anticipate like in two weeks starting to need that participant will we should be asking Caitlin for a push now and then that way you guys are like in a spot where you're like no I need this participant. No you need this participant. Okay. Yeah. And then my last comment is that I reviewed Ali is minimal onboarding design. I think maybe sometime last week and gave some feedback. I really appreciate you know you putting those screens together. I think the kids spoke into this before. But you know there's no prior designs to just clearly leverage. So that's incredibly difficult to just try to create something from scratch. And I think it will spark to you know open it up to be back from the whole UX team and also bring it into the UX showcase to get some additional feedback and comments. That's all I heard. All right. There we go. I did not make notes yet. I can't believe I can't buy this paper cuts issue. But anyway, I want to talk about I am doing meetings with everyone because we kind of like had that benchmark stuff and so there wasn't any way to juggle in new research topics because that took up a lot of time. So I'm setting up one on one meetings like really next week and the week after to make sure that we have scoped out like forward-looking research projects. And then my research prioritization issue will get finalized on May 10. So just to note that that hasn't been finalized. And then what I was out, but I saw that there's a thread talking about naming for the catalog components. And we did have an issue for that, but it's silver. And so that means that don't drive it. So I did it to elect like a little bit of data for them and they can use, but it was very narrowly focused on like how we name the group of components. And so and that's already been done for him. Yeah. So I did that for him, but I don't have the agility to like do it again in an easy way. And it's also silver projects. So they should drive it. Does that make sense? So I saw that there's a thread with Chrissy. Well, I don't know what to like quite what to do. Because you were like, oh, this is happening. Oh, isn't happening. So anyway, I just wanted to note that I'm not driving that project. And I did like, as like that's what I always am trying to help. So I did try to help by getting a little bit of feedback just on those two, like how do we name a group of components. But if we wanted to do other research, that needs to be like loan up and reprioritize and going through that process. So I just thought it would be good to sink like talk about that. Because I'm probably not going to chime in on the fact that because I feel like that's one of those things we don't really need to like surface it. Like that goes, it's in dose court. Yeah. Okay. Let's see, like the right thing to sink about like face to face. Okay. And then another thing that we're doing is we're working on the CI components alpha which we can't even call it that because we've now like changed what that means. So it's now like we're pre experimentation. But we have people coming in and they're using a sample project to use a CI component. And we looked at their satisfaction with the CI templates and then across the assignments. And so they were more satisfied. So it's really good. I was a little nervous. Like, what if they know satisfied? Then we have to do all of this other work. But they're looking like their satisfied. So we now know that there's we were ready to take the next steps. But so new we did like scaffold their approach in that assignment where they use the sample project. So then what we need to do is then like break out how we scaffolded that and then make sure that's happening in the in the catalog view when we're ready. Yeah. Okay. Is there any like for these sessions that are happening very users are coming in and testing the CI component. Is it a video we can watch like of them? Yeah, they're not. We're not. What we did is we gave them assignments. Okay. And once I saw it, like dove has just so much happening that I'm just like trying to make it quick and easy. So I'm running the interviews. But actually we gave them a survey format of the assignment. And we actually one one video where they made a video them cells and shared it. But we kind of are just getting more of their self-report and then we're doing follow up. So it's not as neat as being able to watch them use that. Got it. I wonder if there was a solution like user testing but something that we can control and not truly like go through their recruitment channels. And we can share the link but that way everything would be recorded. Yeah. Yeah. Oh, by having them use it. Yeah. Yeah. The good idea. Yeah. Because they might not be mentioning a few things which might be worth observing is what I'm thinking. Yeah. Well, this was easy enough where, basically we put the links on the include syntax in the ReadMe files. So it was pretty easy. So I think, but the livers on the concept of being able to use include to kind of get the components in your pipeline. But I don't think it would be like white worth it. But that's a really good idea. I keep in mind. Like as we go, as we move forward and include more participants. Yeah. I like it. I just find it funny that how important it includes and like when it was initially launched nobody sort of I want to know what most people did not realize they important. So it's powerful. And Erica regarding the naming research like we have a lot of research already like opened for the just for the catalog project. So we need to discuss the priority. And I'm not so sure about the priority itself because like it's it's own doves. So we can discuss. All right. Does anyone have anything else to mention? If not, then we can just wrap it up and we can get back to our own things. See if sometime. All right. It was nice talking to you all of you. Thank you. Bye. Bye.",
  "everyone this is the CICD UX meeting on April 12th and I think it looks like Gina you have the first point if you wanted to start us off. Yes, I honestly when I was filling out the agenda, I wasn't sure what I should be focusing on. And I was so I wanted to bring it up with the group and just ask how you've been feeling with the structure of the call. The specific thing I was confused with was if we should be focused on a design review or if we are normally like going through all of our group updates. I did notice that the designer view has like a time box on it, but the group updates do not. So I'm wondering if something like that would make it more clear. Yes. Also are the items in the group updates actually read only. I think that's something I haven't been following quite as close to the cabinet. I have neither. Yeah, looks like it says items are really only by the focus that meant read only. But yeah, I think that answers your question, Gina. Yeah. Well, do we find it beneficial to still get group updates now? I think it might be like the UX weekly where if the designer reportion kind of takes the entire time you just leave them as read only and then if you have time we just go through them maybe something more like that. Like focus this meeting more on the designer view and then if you have time we can go through the group updates. That works for me that makes sense. So we would have to do more than one design review than. Oh. I think it's more like if the designer view takes a while it can like we don't stop it from taking a while and then if it doesn't we go through. The updates. But should work pretty well for it. Okay. I think I tried somewhere as you would. All right, that works, that works. Thanks for having that discussion. And I have an exciting. Okay, so the design this shouldn't really shouldn't be. I've been. I've presented in the past how we're updating our runner creation form, which is really nice update because we get to do a lot more things in the UI and and explain what different runner concepts are versus before it was just in the CLI. And then the problem statement that's still kind of around this whole thing is it isn't clear how a new developer who doesn't know anything about runners can create a basic runner quickly to be able to get started to use their CI city pipelines. And then also runner concepts are unknown to these novice users and they're they're not sure how it kind of fits into like the larger scope of CI city. And then the feature that I'm trying to work on now is making the the registration form, which is the the first iteration that I created for the new form. I'm trying to make it a little bit easier to digest, which it's super long right now so it's kind of hard to do that. And this would be mostly for developers who's admin like restricted their shared runner usage so they can't use shared runners and they have to create their own. And then we just one of the known constraints is that we only bring in configure option configuration options that are basic. So if you're an advanced user you can go into your config, Toml file, which is the configuration file that is created with each runner and you can configure it with as many advanced options as you want I linked to documentation about what that means, but like you can make it run more jobs at once there's a bunch of different things that you can do to it. We don't show those in the UI though it's only in the config file. So now I'm going to open up my thing. All right, so to give you just so we have a before state. This is what the first iteration of the registration looks like. Or creation recalling creation. And when you want to make a new runner you have to select the operating system or or whatever platform you want to make it on and then after you select it you get this like form of different fields that you need to fill out a lot of them are optional. But the only thing that's not optional is the tags you have to either add tags or you have to select run on tag jobs. It's one of the one of the other. And then once you create it you get you still have to go in the CLI but you get like this one thing that you can copy paste it in the CLI and then you have a runner. And it was looking at like if we have any patterns and pajamas yet for I would call this like a stepper but I guess you could think of it as a wizard as well. And I saw that we had an issue that was already open that has a lot of work done so I kind of brought that into this view. And I'm hoping by. Breaking these up a bit more I can help. One users understand the concepts a little bit better because. Kind of the most important thing is the tags which I broke out into its own step and then I can also get out the fact that you either need to add tags or you have to market as. So the design is really just like breaking these up so it's not as long so if you click next year you then go to tags. And it's the only one also that's not optional. So you would have to select either add tags or select this and then go next and then this whole step is optional. For details and configuration so you could just go next immediately. And then you get to that same screen at the end of the registration. But I think my main question was. In this pattern is this this pattern seemed like something that any of your groups would need as well and are there other use cases that maybe I'm missing. For me I don't have any other like adoption for this but probably in the future yes. And so I was like looking into the other issues so this is outside of verify but I have seen that there's a new it's behind the feature flag that get left pages team. There having similar we sort. And so I think that's the main thing is on the UI I'm also sure like it could is delivered by any of designers but it was implemented by. I've run it in general sure that issue was like found that and I'm pretty sure a few team needs one of this step or at some point but at the moment they don't have designer so not sure when they can work on this but. And then I think that in a couple of years. Would that be for like installing it lab. Yes and then making those two different sides to making a geo connection so that they can start mirroring all the. Data inside one killer been so's to the other one. Okay. That makes sense. Yeah. Yeah, I was going to say the same thing not so much on my current team but on the growth team these were like the step count like how you set things up I know we're playing around with these quite a lot and I don't think we ever actually came up with a component. But there was definitely a use case in most kind of setups like setting up your account setting up and getting onboarded and certain things so I do think it'll be useful to actually finally create a component because this is something we circled on for months on that team. Okay. Yeah, also in my area. And we're working on the onboarding flow and it's also very form heavy retired ways to kind of cut it down and include some navigation but. Yeah, we certainly didn't. Think of going this step of direction but I think yeah definitely use it. If it's available. Okay. I know when I was working with anti abuse. temporarily we also did like something like this except it kind of went down the page so it was certain like. Clawbsville sections that reopen yeah it was exactly something like this. Okay. Yeah, I think the thought was that and Lee Moore was doing a lot of work on this before so they had created a bunch of different options like vertical. A lot of. Sometimes you can jump between different steps so there's that option as well. And then there's horizontal and then. This linear option as well. I think the only other thing that I had in mind was something. It's more like this where you're it's more it's like looking at a process so in this case it was updating runners we don't even have this available today but in the future we might. And I was thinking we could reuse the same icons that we used for the MR widgets. And then just like give status of each step that you go through because there's something happening in the like I could. And this is all kind of steps that are happening in the back end that we're trying to give the user notify the user where it is within the process. I do like. I do like a green check like I like that visual but like you've completed that step. Oh yeah, that's one thing that kind of felt was missing from here. I like when it's completed it's just blank and I wasn't sure if that if we should add some in the further indication. I think even just like a checkmark icon like so the number. Yeah. Like this. Yeah, I could just the color that's something like that. I'm going to play around that a little bit. I know you have some comments you want to voice them. Yeah, mine is just that I think when you're ready to show this to folks we can recruit from the substance respondents. So I'm just working on a project where I looked at the source for a bit and for the last two quarters. And just as a side note, runners and pipelines popped out as to pay that's particularly confusing. On the bright side that means we can find people who think letters are confusing and ask them to participate in research for you. So that was my first note. And then. Yeah. So as a part of the like such process. We'll create an issue either by self or or Nick. Depending on who's on leave and who's not. We'll be creating an issue for. So I think it's like traditionally called like a says responder. And this will be a mail. This is typically made available to PMs, but I certainly think you could recruit via that sheet like just find any like relevant quotes and you know, pull them into to your study as Eric will say. Okay, awesome. And I have some from the previous quarters that I can pull for you. Okay, yeah, I'll be helpful. And then another thing that's coming up in the. And so I think that's the first thing that's coming up for beta analysis is that users want specifically onboarding content related to like learning and documentation. So we've been pulling out that learning and documentation is important, but it's targeted. So this is helpful, like which you're pointing out there like what you're kind of doing is an onboarding widget almost. Yeah, I think it would be helpful to just remember that I mean you're already thinking about this, but remembering that these people are kind of. And it's just because they're new. Yeah, just kind of layering in as you can. Like yeah, not in a way that's not too heavy, but that kind of like gives them a framework for what they're doing. Yeah, I think I could add more. Like explanation about platform, I think that's. I added a lot about tags, which was nice because we never were able to add any documentation about that. Just that that's like how. The tags determine which types of jobs that the runner processes so then it gets like a little bit more connected into the. The CI city process and then I I like to documentation stuff as well. But I think that there's more that we could add. And even stepping back like it's like, how did they get to this point in the workflow right like how do they know if they should be doing this or not. You know, like shared runners or not this. I'm thinking. So, but like how do they know if they should be using that widget. I see. Yeah, like where are they coming from within the flow. Yeah, yes. Okay. But nice work. Yeah, and I think on the topic of like novice users. There could be some opportunities for like tool tips or something implemented over the course of those, you know, different pages or steps to kind of communicate like this is why you're making this or if you're confused. Like, here's some information that can help you make a more informed decision when you're choosing between radio options or what should I enter here or what if whatever they be. Yeah, okay, yeah, that's a good idea to. And then by next question, like, would you be able to pull out the. The prototype again, because I was a little bit confused about that optional text. I don't you said that like it was something where they had to choose. Oh, yeah, like. So yeah, I think we're in this one. Yeah, that's more. Yeah, this is the current one that we're using and. You have so I think this was just more of a mistake that we made you have to either select that the runners get a run on tag jobs or you have to add tags. So even though we say this is optional. You actually have to do one or the other here, so that's why I was trying to like break those out into their own. Section because that's really the only piece that's not optional. Yeah, that makes sense for trying that. Yeah, maybe just include some language there like if you select run on tag jobs, you will need to select tags below. Um, you. It's so it gets so confusing. Okay, so. You can hot, you can add tags and you can run on tag jobs. So our runner can run jobs with tags and it can also run jobs without tags, but you have to at least have one of. Like you have to say which one or both does that make sense, but I think I could add text that explains. Yeah, my it's like you need an and they're like an or choose one or both I guess. Yeah, yeah. Okay, I'm going to think of how to explain that a bit. All right, thank you a lot for the feedback. I think. My action items are to see what other information I can add in there that helps explain the concepts and then. I'm also going to work on trying to figure out how to contribute that stepper slash wizard design to pajamas. In the same thing. Well, I guess I have the next item. So I am continuing work on the onboarding flow just to finalizing it now. I had a meeting today where we're just going over some of the settings and what what that should look like. And then also working on messaging as you can tell from genus form that yeah indicating things like optional and all that. Yeah, you have to be clear. So I'm working with our technical writer to make sure that yeah, we communicate clearly. Which settings you can change and yeah, once I'm done, I will open it issue for review and I think I can also do presentation here as well. And then yeah, we can take a feedback required to any validation internal folks. Yeah, I'm not sure if you're already wanting to do this book, feel free to you know, tag us. I'm more happy to provide feedback on that minimal onboarding flow. Awesome. Thanks. Yeah, that's it. Oh, is that huge enough? Yep. Thank you. I'm running solution validation sessions on the runner fleet dashboard, which I've shared in the past and I've run one so far. And the early insights were very, very positive to excited about and I summarized those insights in the issue. And I'm still waiting on more enterprise customers to meet with. I guess it's me. So in environments we're currently working to put together a glossary, which I think is much needed just a common terms within like the deployment area. So we're getting that on track, but looking forward for this to help with like a certain communication, the design sprint and just in general talking about deployments. And I just wanted to bring it here. So all of you could see kind of what has gone into it so far. And then just wanted us. I'm also working with Eric and well to test it the common screener for my solution validation study for group level protected environments. So kind of excited for this to test it with self serving option and let you know how it goes. And then the final thing to have is just more of a question. So I don't know has any one ever been assigned a community contribution that's not in their group. I was assigned one for package and I did notice in the experience weekly. Let's like Pedro is one that supposed to be reviewing these, but is this something that. I should take on is it something I should pass off to Pedro. I'm not sure if anyone has experience in this area. And I must say. I have an experience. Yeah, I think it's not similar, but I have an experience like selected by boat automatically. But I found one issue that is dedicated for the distribution team and then I just think that design manager that I can review this so because I already have this that will be my GDK. So I had this discussion with hyana, but from my understanding the community contribution without any designer goes to Pedro. And I'm not so sure like how we can make those change in our boat. But I think that's the process. So if there's no any no designer on that stage group goes to Pedro. So that was my understanding. But if you are willing to have those review or if you have capacity and then you can assign yourself on them. And then P. Pat Broke as well. I was trying to review myself. It looks like it's one that I need to have like packages and images set up and MR review doesn't have instructions on that. So I did ping Pedro if they hasn't set up already. It's quite an easy review. If not, it's something I can look into. I think I just need more instructions on how to do it. Oh, thanks for the feedback. Oh, thanks for not taking away. Yeah, so P. Pat is on leave. Maybe I can move on to my item. So there were a lot of discussion going I really appreciate Erica. We're taking a lot of time for this and moderated research and then I as Kayana like hey like. I mean, the feedback and then just provide some feedback how we can move things faster and there are a lot of discussion on going and then so in the end. Too long discussion to read. But in the end, what, hi, Anna suggested was like, okay, let's just step back. And then we have run the first unmotorated solution validation using the user testing.com and then we got already just one cycle of outcome. So let them decide if it is enough for them to make decision to put it inside the left side navigation or not. And corresponding to their feedback, we just choose the direction if the answer is no from the foundation theme. We start from the pipeline editor and having one small button there to access to catalog. And then in the meantime, we we still gather a feedback from users. Verbaly or also we need some more metrics to use snowplow that also require some front and implementation. So that was the outcome of this research. Yeah, thanks Erica for your help on this and for everyone. I'm jumping into the discussion and the other point that I'd like to share with you all is about syntax actually. So this is something that I try to onboard myself like how to create a pipeline as I want and then how to choose the right keyword to keeping a certain job, for example. And then most so pointed out that like, hey, this is also a very crucial part of our UX like we should focus more on this terminology and also the experience on how to choose the right keyword. Is it easy enough so we started this Tim discussion and then it will lead to another round of user research and also the team discussion and then I'm very excited for all of the team members are. Okay, so I think it's part of our crucial user experience so just one of the shares and we find one with you all. So hi, so packages and these social we move on to the UX research will. Yeah, I'm just going to go quick updates. I created my breath relief issue. I think to it within the doc. There's a couple of sections within it. That I'll be adding to over the next couple of weeks I get closer to the leave where I'll be assigning you know certain tasks or things that I won't be able to cover to different people. But no action items as right now just making you all aware. I'm also going to look over Emily's comments on them solution validation study and I'll respond to that comment. I'll leave today Emily. And then I watch all these video. I think it was with for in and Fabian and a couple others. I thought it was really informative so thanks for recording that and sharing that. And just wanted to let me know if if you need help on any of those switchboard related issues and kind of being pulled out of different directions so just make sure to mention beyond anything. Any comments or questions for a hinted over the air. I'm going to take some time off next week. I'm still taking some time off but I need to be around to send out our CI components assignment three which is also our friends and family day but I'll be in on Monday doing that. I'm going to take some time off because we're finally able to send that out so people in our Alpha program will be using some components and some inputs to create an assignment. So we are kind of supporting that in a way by we're giving them like a pre selected list to select from. So we'll want to remember that if we see really good success race. But anyway, it'll be good to get feedback on that. And then hopefully I think Jackie and I today will meet to finalize the next steps at least for Q. To for the benchmark like our 10 issues to champion for Q to. And then I've been working on a cross functional analysis of those susper betams it was originally an okay R for. I was thinking it would be okay R for Q to but I really like analyzing data and so I finished it. So now we're kind of socializing that around to look at. The next steps for that. So we'll see how that goes and then I think we'll wait to prioritize the research for Q to for Q to until until we think it comes back. And has a chance to like time and with them projects. Thank you everybody who's chimed in for Q to research so far. Well, I think that's all on the agenda because anyone else have anything else they need to discuss. Like a we can have 10 minutes back. Awesome. Well, thanks everyone and we'll see you later. Thanks. See you all. Bye.",
  "Hello, this is March 29th, almost April for our CICD UX meeting. And we don't have any standing topics to review right now. Is anything blocked or at risk for anyone? No. Okay. All right. Then I'll just leave it to Emily. So to give some background on this, I think a bunch of you know, I am now working with the the configure team and release we've grown together into the environments team. And with part of my onboarding was understanding what Kubernetes was, which is, or I've heard quite a bit, but during my onboarding I was reading about it. And nothing was sticking until one person told me about Kubernetes as a post office. And I just wanted to go through that because I chatted with Gina about this. And we were both like, oh, everything makes so much more sense now. So I just put together a very, very tiny little presentation that kind of goes over what I learned during this onboarding. So going back to it, I did a lot of reading about Kubernetes. A lot of it was in a very technical jargon and nothing was sticking until I came across the post office metaphor where it kind of subbed in Kubernetes as like a post office management. And everything here then started to make sense with me. So this is just like a cute little story about that. So a post office as we all know is responsible for processing and delivering thousands of packages each day. And the goal being that the packages are delivered to the intended recipients quickly, securely and reliably. Kubernetes kind of does something very similar to that. To help achieve this, there's a team of postal workers responsible for processing and delivering packages. However, with packages, there's many challenges such as sometimes there's an influx of packages coming in. There's incorrect addresses that need to be fixed. And this is where the orchestration portion comes into play. So when you think about Kubernetes in the same frame as a post office, you can think about containers, which is a package of code as like the mail packages. And when you get a group of containers together into pods, you can think of this as just a group of mail packages that need to be delivered to the same place. So you have now that group of mail packages needing to get somewhere. And then there was no emoji for postal worker. So just pretend they is a post worker. Kubernetes makes each group of packages. Known as the pod is assigned to a postal worker, known as a node. And that all these groups of packages are evenly distributed across workers. So we're not overwhelming certain workers or certain workers aren't getting any work. It also makes sure workers have the resources necessary to handle each pod, such as enough room in their delivery trap, which is the CPU or memory. And then Kubernetes also makes sure that each worker is not overwhelmed by packages by doing the load balancing or adjusts the number of workers based on how many packages are coming in, which is the automatic scaling. And if a worker calls in sick or a node becomes unavailable, Kubernetes can help get the new worker on the job so the delivery goes uninterrupted. So yeah, you can think of Kubernetes as an operating system that manages the processing and delivery of packages in a post office by ensuring they're all assigned to a worker and that the resources are allocated efficiently so workers can do their job. So it's just a very, very tiny story I put together, but when doing my onboarding, this is the one thing that helped me really, really understand what Kubernetes was. And I thought it was cool to share out that with everyone else. That was so great. I love that. And it makes it like so much more obvious, I think, as to what Kubernetes means. And I have one question for you. Yes. Do we, the information that you're saying like CPU and memory that is there and if a node goes down and stuff, do we get that visibility into GitHub or do you only get that when you're using whatever Kubernetes platform you're using? Very good. I'm late on Ali here because I'm still learning some of the stuff that we're actually showing in GitHub. But is that kind of the work that we're doing around the Kubernetes dashboard currently to get more of that information showing into the UI? Yeah. Yeah. That's what we're trying to do with the dashboard. OK. Sweet. Where I've had to deal with Kubernetes a lot lately with runners as well because runners are sometimes in the way that you're saying that there's a coordinator. It like the runner acts as that. And he's like the head and then tells whatever machines to go work within the cluster. But a lot of people have brought up the fact that CPU or memory could be an issue. And that's why the runners aren't working as expected. So I think we're going to start exploring that probably within the next couple of years. And there's going to be a lot more connection between the runners and Kubernetes in general. Yeah. I just wanted to point out, Emily, I love the presentation. Super simple with the emoji family love it. And then what I feel like on this feeling, I made it this like three years ago when I started to work on the distribution team. I, with a lot of peers, we have a lot of time watching the YouTube developers talking about Kubernetes. It wasn't easy. Ali is left because they knows that Ali was reading a book about Kubernetes. So this is what I need to thank you for that. And I also really like the point that Gina just mentioned that this concept could be work like load balancing and then it's kind of made things more scalable. And then I think it could be also applied to runner and many other places. And I think that's the reason why Kubernetes getting more popular. So I'm the person who's in thank you. Yeah, so things seem super simple. I wanted to put together, but when I was talking with Gina during our one-on-one, I was like, oh, this makes so much sense. I think it'll be helpful to share it to everyone. Eric, I think you're next. And yes, thank you, Emily. I wanted to share like the origin story, which I don't know if you know this, but this really helped me in as much as I understand Kubernetes. So I don't think anyone ever will. So there's that. But so it started, this is like an air conversion. So fact will, don't, just we're going with this story or an story. Okay, so Pokemon Go was this big app, right, or everyone was trying to catch them all. And it was this huge craze. And it was a Google startup that was in charge of it and spinning it up. So what happened was they didn't anticipate that so many people would be using it so quickly. And within the first three days, everything crashed because they couldn't serve those users. And then they were like, well, how could we scale things more quickly without having a big overhead cost? And then they bore Kubernetes, which is this idea that you don't have to have all that compute power all over the whole country. But when you need it, you scale it up immediately in this localized way. And I didn't really understand it. And then I had that like, I remember when that went down. But that was like the computing problem that then kind of led to the creation of Kubernetes. And then just one more note that I've heard it also, I think the male person perspective is perfect. Because it's like more relatable to like I can think of a male person like a male, male or male person person. But also like this idea of shipping containers is another metaphor. You'll see a lot. But yeah, I don't relate to a shipping container person as much as a male person. Okay, go. Anyway. Yeah, Erica is the person of analogies. I remember when you told me about the Homer and the scooter stuff about secret management. Wow, it just made everything seem so simple. It was a great presentation. Thanks, Emily. And it actually like, it kind of explained in such a simple way the whole like the environment. When I talk about everything related to Kubernetes like load balancerers, workers. I mean, what's the individual role? I have been through some pretty complex comic books in the past. But they did not do this job. So yeah. I took the inspiration from one of the courses. I did actually it might have been the documentary. You will just mentioned, but someone said this and then that's how that was really my my light bulb moment. So all the things has to go to, I believe it actually was the documentary. I'd link their own thing in my slides, but the documentary will kind of link to your has was great in helping me understand Kubernetes. Yeah, in the documentary like briefly touched on what you covered in your slides. Like maybe the first two or three slides I didn't go like very deep with that metaphor. So it was nice to have a better understanding of it. And then it also I think it's like a two part documentary because the whole thing's posted to YouTube. I think there was a section of it that also touched on what your convention with Pokemon Go. This kind of that example. I do remember Pokemon Go crashing on me that side. I remember being part of that. Thanks for sharing. I came across the story when I was the one getting in Konfigur. But yeah, I think in retrospect though, yeah, the community is definitely going to stick now. So should we move on to the next items on the agenda? Yeah, I'm telling you. I'm the one starting. So I'm working on the minimum onboarding flow for switchboard. I recorded a video of a workflow, the initial concept that I'm working on. And yeah, it's been a great way together. Information also during my conversations. There is some information that customers have to input during the setup process that they can never change again. Or if they lose, they can't access. Get lab. Oh, we can't help them. By the way, is there a way that we communicate this type of info? And then yeah, I'd appreciate any insights. Or if you can point me to something. And then I'm also using that to have conversations with engineers to help me with the scorecard that I'm working on to understand some of the stuff that they do. Um, Ali, I have one question. So how would you um, how would you work on the scorecard? Because I don't think there's existing workflow around switchboard like how would you handle that and how would you approach to work on the scorecard? You're just curious. So today it's something very minimal. There's just the switchboard platform and then um, uh, as I raise kind of pace chasing file in the and kick out and kick off a bunch of jobs. And following. Yeah. So it's around that. But then also trying to understand some of the stuff they do outside switchboard. Um, and because we also building for them would like them to do also the stuff they do outside switchboard inside switchboard. So it's kind of a hybrid of mapping. Let's scorecard. Because the idea is it's like a bit, yeah, it's going to inform the next phase. Oh, god, I think. I have just a question about the, your, when you ask if we have an approach for telling the user about information they can never change again. Is this some, uh, are they selecting like, or what, they're configuring it and they can never reconfigure it after? Yeah. So they're bringing encryption keys to encrypt, um, their keys left, uh, instance, um, and so we're giving them the option of bringing their own keys. Um, and um, I think once, uh, they've put them, we can't see them. And if they lose them, we can't help them either. Oh, I see. Um, this sort of reminds me of, well, actually, no, it doesn't. I was going to say we deal with tokens that are only displayed for a certain amount of time in the UI for runner. And we just tell them like, this is going to be displayed only for a short period of time. So copy, we give them the chance to copy it so that they don't lose it. Mm. But then if they lose it, like, saw them. So that's how we tell them right now. I don't know if that's helpful. Yeah. Um, I don't know if it's, uh, something I think, uh, I'll lean a lot on the writers to kind of help me communicate that. I guess, since these and kind of an approach, it's all linked to my, too. Sure. Awesome. Okay. I think that that that's it from me. All right. Um, mine, the first one, which has read only. And then I'm starting to validate a runner fleet dashboard. You might have seen. I shared it in our York School working channel. And um, I'll just share the issue that I'm doing this through because we have a very hard time finding enterprise customers to meet with. And there's this, um, process in the handbook that you can lean on customer success managers for that. So yeah, if you want to take a look at that issue of that applies to you in the future, it might be helpful. Um, Gina, have you, um, have you reached out to any like technical account managers? I think sometimes they're very like reactive to our request. Yes. Okay. So there now they're now called customer success managers. Oh, okay. Thank you. You know, that's a great. No, that's yeah, that's who I was saying to lean on. Okay. Um, because yeah, they've helped me in the past, just like meet with customers just to hear what their pain points are. Yeah. So we have a list and I'm going to list that Darren and I are keeping. Yeah, thanks for clarifying that. Yeah. That's it for me. Emily, you want to go? Well, um, so I just had one open question about a larger designs that are put in through a lot of small MRs that are kept behind a feature flag. I was getting this question from some of the engineers as if they get a UX review for each small MR or a larger view at the end. Mostly being they were doing small reviews, personal MRs, but we are getting people wondering why the experience wasn't complete. Like you couldn't go through everything because it was just one piece of the MR and then the rest seemed broken. So I was just wanting to get other people's opinions on this. Yeah, this was so relevant to the token like re architecture that runner was doing and our devs did UX reviews for each small MR and then sometimes our front end of will include a table in the description being like, this is where you are and these are the other MRs that are adding these other features or they'll just add like some description text to tell people when they're bringing up the changes and then I linked an example there. Sometimes they'll also just ask me to review the MR before they ask like the random UX assigned reviewer. It's been like a mix. Yeah. Well, thanks. Yeah, I think the problem was we're not like clear enough where it is in the experience because the issue it links to links to the entire future, not just the little portion. So I guess just being a lot more clear about what the MR is changing and what is out of scope for that particular MR. Yes, exactly. We did the exact same thing and linked to the entire feature that MR was not creating. So I think just like that text that that they had added was helpful. It took a did you want to? Yeah, it was very simple to what Gina said. So this I experienced when we started to work on the CI job token. I'm trying to find the MR but like that proposal, it had to be broken down to like a few parts like some preparation by the front end, some preparation by the back end and then eventually they would like club all of that to form the final to work on the final development and implementation. So for that what we the process we followed was engineers used to invite me first to do a UX review and to make things easier for them. Like once I reviewed, I left a very detailed sort of summary for the next designer who will be assigned by the reviewer to look at. So I explained to them that this is the bigger proposal. This MR only takes care of like this small part of that solution and eventually this will lead to something else. So yeah, that's how we did it. No thanks for sharing that'll help us a lot with. There's two big initiatives going on on my team right now and I think we'll have to do this for both of them. So okay. Yeah, my final thing is I'm finalizing the group level environment solution validation study the week. So hopefully this will make some progress after being paused during kind of like the team switch time. I'll pass it to litica. Thanks. I just have this small update like besides all the stage group work that I anyway keep sharing and go working on other channels that in preparation for the UX team workshop that I thought I would be conducting next month. I figure that we don't have a vision documented for a pipeline security yet. So like the very first step for me to prepare for the workshop was to meet with Jocelyn and write down our vision and do that keeping in mind the information that we have at hand like all the insights from Erica's researchers, the existing epics that we have, the highly-witted issues that we have, the market inside the jobs to be done. So I created sort of this homegrown template to have that conversation that discussions are that eventually like we make sure that whatever vision we arrive at it is done like after being informed of everything that else that we have in front of us. So the first mural is where we started from. I just made a copy when I created that so that was the very first state. I brought together all the information that we had on different areas and create two sections. One was for each category. The plan was that we will create clusters like we will be bringing together a item that could form the one team and we ended up with four groups of information or of like the work that you want to do and then we just would it on them. One of the options that we had was to maybe take it forward and instead do a like come up with the rice score but we refrain from doing that since we are going to be doing the UX thing workshop anyway like in future. So this we just kept this very simple and once we identified the larger themes the next step we took was put them like use this business model innovation framework to bring together like who are we making who are we creating the solution for. How we are planning to do that and to achieve that how what is it that we would be working on in terms of features in terms of changes then why do we think like why are we confident that these set of features are going to like solve the problem and the good part with this innovation framework is like you change if you make slightest of change in one part of this diagram you will have to like make adjustments all throughout. So it's always balanced. It's never balanced and it worked out pretty well for us we came up with our new vision which is re-enable organizations to adopt good practices for secure handling of sensitive information and I just thought like since it worked so well maybe I'll just document this and share with the team. I've been done that yet. Yeah that's all. So for the pipeline offering we are focusing on the solution validation for the placement they were replaced this catalog feature is it the left side navigation or is it more embedded version on the pipeline editor and there were another option in the navigation but inside the export tab which is the same level with the organizations and new tab but it's slightly behind that so it's the second step. So we just tried to work on another round of research so things are cut to jumping in so we just started this conversation how can we proceed with the new test and then once we got the result probably we can more confidently say okay so we should play the feature to where so I'm also working on that I will work on that also the rest of the week and there's another very critical discussions which is mostly about like how we architecture how we create architecture for the back end which will eventually impact the York's work so the here is the MR like I just don't want diving to the two details but it's more like if we design API this way then there's two there's some impact to the user flow and then if we design API in the B-way then it also changed the user behavior so I'm I'm really glad that I'm participating in this discussion and just trying to follow up what they're saying and then if we make this decision then we our MVC scope might be slightly changed in terms of technical perspective but we not a lot from the UX perspective so this is still ongoing just wanted to share with you all and yeah that was my agenda that you have any questions feedback you know then I'll pass it over to Erica sorry do you want to verbalize your call yeah so I think that this has been like really good work and we're trying to figure out like the way to approach this solution validation but what we're going to end up doing is having an approach that other teams can use and basically like what we've arrived at is having two groups one that has the side nav in a prototype one that doesn't have the side nav in a prototype same tasks different entry points performance comparison maybe satisfaction question in there and I think that's what we're going to need to make an argument for the side nav so just wanted to like say that this was a hard problem and to give props to say good job being patient and getting through it and then I think like we're going to have a model so that next time it will require so much thinking as much thinking to get to how we approach it yeah thank for sharing that Erica because it wasn't easy but the good thing is that it's a full-the-first front of validation we could eliminate like a list one option and now we have two so that's good and then I think since it's a new process like there are some challenges it's just not our team there's some other team also going for a similar process at the moment and then I think once we design nicely and then come up with the results I think probably we can also add it to our handboot and then provide better guidance on how to test these things around the placement yeah I've been thinking about this Erica and like wouldn't it always be the case that whenever we present to users an navigation option that's placed at a higher level it will always end up getting a better score yeah and exactly I've been calling it the bagel problem or like we could ask them to search for bagels in the product and if we had bagels on the side map they would always just go to the side map so yeah so that's why I think having the two groups there where one they just don't even have that option so it's not like bagels on the side map then we can see if they can still perform or not and that's why it's with it that's why it's two different groups yeah I'm just you go to see like if you figure out that let's say without bagels being on the front shelf if there's still happened to find it how do you still just to buy to the team that you know they were still able to find it yeah and then you think they found it much easier on the higher level so that's why I think it's like if performance is the same with those two groups we don't have evidence to add it to this okay it's only that if they are failing without that side map option then we can say hey it's important okay and we don't we don't know with the other approach I was like it's bagels like they'll just go to the where it says bagels but so with this approach we don't feel like we have a sense of which one will work and then that's when we should be doing research yeah thanks good question yeah I just had a question about how has the rest of your team been responding to performing this research and if there's been any learnings that you could share with us if we have to run into the same situation so first of all I think they're excited that we're validating this because the input is coming from the user then like we could really be more confident to say like we're placing this menu at this place because of the this outcome so I think they like that from that perspective but on the other hand like I think they are still having this own and more behind the future flag and I'm not so sure they I don't think they haven't they have merged it so of course there are also some frustration because they are ready to make this change happen but at this point they need to just wait for the result as that was the reason why the timeline and timeframe was a little bit tight because it's working progress so there are kind of like mixed feeling but in the end like the industry like of course like if you have more strong like I bet it is that's good and then I just try to like illustrate okay what's happening in this version that they know what's going on for this research so that they could be more patient nice yeah thanks for sharing you're ready um so we've few don't have any other comments then I'll pass it over to Will thanks Ajahn so just a couple quick updates um I was on a customer call Emily led a couple hours ago to learn more about users and pressions of the group level environments you concept that's going to feed into them social validation study and my thought they did a good job handling you know multiple users or customers on the call and like trying to pivot to get to the questions that you really wanted to know given some of the time constraints that we had on the call so good job there I'm also working with Ali and Pedro, the brainstorm just be done for switchboard so we've started that in an issue and now we're moving over to Google Doc to put that in there I've also drafted an issue based on an initial team call that we had with switchboard that that group as I was writing it up after the meeting I was a little bit confused about the request so I'm going to need some context on how this you know fits into the foundation research plan that Hayada has drafted so I've Ali had I've all used to attack you and I had offer for some additional feedback Erica see your writing did you want to elaborate well maybe see if the team wants to respond first anyway so I think we just need to see how this fits into what we're doing now and make a call because yeah we're trying to find out what the customer wants but then also I mean how some of our users are also internal folks so I kind of feel like we're trying to do the same thing and then maybe my not been necessary to have two issues to do that but that's just my feeling maybe we can get some feedback from Hayada as well yeah and that's why I want to clarify that before like jumping in because if this is like duplicate or redundant like let's not do that in that case um so my first note is just that there I wanted you to know that there's this foundational research happening like in the back burner but we've run some participants on the life cycle of an image and understanding how those are environments and how that relates and kind of whether or not people want one pipeline for them or how they kind of structure that so that's happening and I can I'll just catching up on life but I will put I will link the dub tail and it might be helpful for you to watch some of those videos that's my first point but then looking at the foundational research I think we have a bunch of this just from the the secrets and security related research and I think I'll look I'll take a note to look through all of that but one thing I can just quickly make note of is with the the personas we know that there's this like shift left with security so even developers are that was like a big thing that we keep finding is even developers are getting their hands on security and compliance stuff and we did in the secrets features prioritization survey we asked uping up the finding but we asked them if they knew what compliance requirements they were working under and surprisingly they had a sense of it even the developers building me pull up that work but I can dig in here and help you piece together what we will we know because it might feel like this is coming from nowhere but it's actually I didn't really even this is a nice summary I mean it will to be like oh we know some stuff about this so good job in framing the issue there everyone but I can be helpful so let's figure out the best way for me to help you guys okay okay awesome well and then the last point I'm working with Erica they may speak to it a little bit below but um helping them pull some like customer emails later in the week from our past us analysis so that I think they and them team can do some like future like follow-up calls tell me guys that for me yeah since we have time I can actually just share my screen and show you the benchmark report okay so this is a one side slide summary of the performance and I set up a benchmark finding epic that has like videos of overall like so this is all detailed and in a way like we issue a ties this report um but basically they're we're in good we're doing good but with each of our workflows that we tested that to me mouse there's like one sort of really painful task in each of the workflows that we need to address so it's using includes in tax identifying the failure the reason for failure and understanding the test unit tests and then the first of the find and six pipeline error workflows and I so this table here kind of gives you a sense for each of those workflows this column gives you two to three two to three word summary of each of them so for the author of pipeline workflow we found a barrier to entry with the includes in tax which is important because that's the entry point for our CI components catalog um and as a companion analysis I looked at all the sus verbatim for verify for the last six quarters and did an alignment exercise to see how much the pain points for each of the tasks and then each of those UX themes in that table below mapped to the sus verbatim and and it was kind of astounding so 13% which we're calling a significant amount of those negative sus verbatims were related to this author of pipeline workflow and then looking down here at these UX themes one of the themes across all the tasks was just general confusion about yamol and that was 8% of the negative sus verbatims so we really want to focus here on making that whole yamol related workflow easier and then it occurred to me that we now actually have all of these people who gave us these responses about the yamol experience so we can actually that's great because they're hard to recruit right it's hard for us to find good matches so here we have this lovely sample of 43 participants who gave us feedback on the yamol experience there's like all these different categories where they made points but basically it bubbles up to having a hard time with the yamol experience so we'll do thank you will it's going to give us the yamol context for those and what we can do because we can't really have although people would probably try we can't really schedule 43 call but what we can do is run them through that CI alpha components program and those assignments and then we'll get a nice read on the satisfaction scores and how those are increasing right now we have like a dedicated really well rounded sample where we can do deep dive interviews but actually they're pretty satisfied with the current template experience when we ask them so it means that it's harder for us to raise that bar in terms of their feedback and getting them into a really satisfied place so these folks who gave us the sus feedback and were negative we should get a good read on if we can move them up to positive then we're really doing a good job so that was what we was talking about and that's the author of pipeline workflow and then understand and adjust unit tests two words for that is their hidden treasure so it was amazing I just so one of the things we did at the end was we gave them this job to be done rating question where we had them agree or disagree on a scale of 1 to 7 where one anyway so we had them look at their agreement and they gave us really high scores here and they were just they were delighted they were delighted once they understood they didn't understand what was quite happening with the unit test at first so it wasn't discoverable for them because they went into the logs and they weren't looking at the UI and they did this like circular thing where they were like oh I've arrived at this artifact don't know what that means and then they would like arrive at the artifact in a different way and they're different way and and then like when they then we kind of like pointed out they the artifact is going to be helpful for this task and then they were like what is this artifact how does it relate to this error but once we did the reveal they were like thanking us at the end of the session like they were like and so this rate in here this 6.1 is very high because they were just so pleased about it so I think that there are some small I mean I'm not a designer but if we can make it more discoverable and a little bit more obvious to them how those things are related like an example is so in the in the unit test it showed them a screenshot of what the website would look like if it displayed as per the code and they weren't sure if it was what the website should look like or does it look like so we just need to like connect those dots for them and then they will make them so happy and here we saw only 3% alignment with the sus verbatim but that actually like tracks with this hidden treasure idea right where they're not quite under that's not discoverable for them and then for the fine and fixed pipeline errors 9% they're waiting too long another way to tell the story there though is that they learned which is really cool so if you look at this so we had fine and fixed pipeline errors in build and then one in test and one in deploy and so you can see here that they kind of bombed that first one but then on the second on the next one they were in green again and basically what it was is if they could step back and look at the patterns in the yaml file they could use that to quickly come up with the solution as opposed to like digging into the logs so if we can figure out how to help them take that step back maybe it's AI I don't know but to like look at the discrepancies in the different stages of the yaml file we could really help them succeed there but here you can see that this job should be done rating is not as high and that's because they dinged us because they get really frustrated waiting for the entire pipeline to run after every fix so that's a theme that came out here and it's actually that specific theme is small in terms of the percentage of self-provedem I think that's because we logically have a smaller percentage of enterprise respondents and that's a particular enterprise problem that we were getting feedback on so another thing that will and I yeah we'll know like our working on is to track business size in the self-responsive now and so I think that will be helpful but yeah so this frustration with running the entire pipeline for every fix I've heard that before but it was really resounding and we see them bringing down our satisfaction scores or agreement with the job to be done ability and that's because the user behavior in terms of fixing a pipeline is just to throw a fix at it and see if that work and throw a fix at it and see if that work they're not like now with this work let me check on the documentation like they're not doing that kind of thinking and so then it becomes really frustrating they're like I just wanted to try that thing and now I have to sit here and wait for however many minutes and I asked so I did my like due diligence follow up like tell me about your tell me about your work flow and and like is this really a big thing and they're like yes yes yes this gets me out of my flow gets me out of context I'll go watch a YouTube video and then I'm totally distracted and not useful um yes so that's the benchmark stuff in a quick summary and then I let's go to comments and I'll stop sharing I had a question about how you determined if the suspect back percentage was significant considerable or small yep so there's documentation also that's already out there I can just look at that no it's totally no I love that question so um we I put that in the report and it's just mapping percentages okay so it's and it's just because later on if it just has 3% or not like I put the percentages in that report right like 90% later on and like Jackie's question was like is that good? so yeah so we wanted to be able to characterize it in those ways and so just being transparent about how we're doing that but I think it's legitimate because if we look at like kind of the other findings 33% of them were not categorizable right so like something about inconsistent behavior and CITD pipelines like I don't know how you map that to much but so and you might think like that's a lot is truly be concerned but actually like it's pretty to me and legitimize it because it means that there's a bucket of things you can't force fit into these benchmark paint points and themes and so like having the assert of it right be around number is good um yeah to answer your point we just came up with these kind of categories um that's just opening it playing it well thanks yeah but they're mutually exclusive so it has to fit into one of the categories and only one of the categories and to do that I ended up having to parse out a lot of the verbatims because they'll talk about all these things and so to get the one to one's boring and I think it was 317 verbatims that we had. Wow okay. And Erica when you pull those sesame for betams that I'm gonna you know find emails for later did you only focus on people who indicated they were open to follow up conversation? Yes sir. Okay, cool yeah just try to make sure I wasn't at first and I was like oh what's this oh that's important but I thought I did I got it. Yeah and then I just pulled out just to try to make it easier so it's not lost in the issue verse. Here are these four pipeline authoring design related tasks that we have at a critical severity level so those are the ones that are critical so like a way of like prioritizing all of them those would be the most important and then yeah the one that I pulled out I can lead is bringing those people into the yeah I have to program. Erica I just wanted to say really that this was really great work maybe because it related to things that I was working on so I was like more interested in it but yeah this was this was awesome and I love that we're seeing feedback across like the whole pipeline experience it's not just one section. Yeah actually when it touches upon the places that we have always like talked about there's never been like enough evidence that we should really focus on that work and improve those experiences so I'm very hopeful that the results of the benchmarking would like help us prioritize things which are really going to make big changes. We're good. Yeah that's us analysis was pretty amazing but I didn't expect to see that much overlap and and some people kind of just did like a one sentence like that we found this also in the sess but I'm just extra so I was like I need to know the precise precise percentage of self-provenants that are mapping to each of these things but it away is good because then we oh yeah because then we can make this statement that 45% of the negative sus verbatim overlap with those like as an aggregate is 45% of them which is more than the 33% of the edits so I think it's good stuff. Thanks thanks guys. Yeah and then later this week I'll work on the Q2 research prioritization and so we'll start pinging in that to start getting threads of what we should be prioritizing and then the last but not least is I isn't linking yeah I put I put it a deck together after kind of now having this idea that we are focusing on environments. I was like oh I can think of a key problem that I've heard so like across these four studies we keep hearing this problem related to coordinating variables across environments so I just pulled out slides from each of those reports because I would say that that's a big problem. We're not even asking about that it just keeps coming up. So I linked that deck. I'm glad to be back I missed everyone I was just only working on that one study. Thank you for sharing all that too. Very excited. All right um does anybody have anything else? No, all right we'll have a good rest of your weeks. Talk to you later. All right buddy.",
  "So, thanks everyone for joining. I wanted to get in touch with all of you all because I am working on a project with the permissions. Some of you may have already seen the work that I've been doing, a couple of you all have already provided feedback. So that's great. Let's start with this real quick. So just a brief overview in case you're not familiar. I've been working with Amelia and Andy on re-doing the entire permissions architecture in the platform based off of the idea that we're going to make customizable permissions. And so Amelia had gone through and the first round of organizing the permissions based off of what they have here in our documentation. On this table here. So, you know, analytics would be grouped as one and then we would try and find out where does the clusters be gone to, what is container industry, et cetera. So, that was the first pass at it. After we had started looking at some of this, we started seeing a problem where as an example, where if I were to look at a individual permission called view project code. And I was to disable this permission. If we were not looking at what it links to which just look at this table was like, well, individually doesn't do anything, but logically in the platform, it would turn off all of these other permissions without noticing. So I've done is gone through and mapped all of the permissions to try and see if I can find these sorts of mappings. And tied to this issue specifically. The devs are looking at consolidating this permission to view pipeline and view pipeline details, so that instead of it being two permissions is just one. Kind of like consolidating line item here in this table or the same thing here. The idea is that if we're going to move forward with having a prototype where an admin can go and toggle individual features. If we try minimizes complexity, that can help on the backend with the problem that they describe here that. They would have. There wouldn't be a need for overlapping overdund and permission so in the case of here they have the same access level. We wouldn't be less confusion here and then. It would make things easier to undo or to make changes within the the code based without being so catastrophic to where's like if you allow something. But they shouldn't have access to they wouldn't necessarily cause any sort of negative impact in the in that sort of. Permission if you were to enable that permission right so the reason I need y'all to to sync with me today is to kind of go over this. And I think it's more or less okay, but I just wanted to kind of go through as part of this work that I'm doing here where I go through the entire. Permissions architecture and meet with every team that kind of has insider impact with this to make sure that I'm thinking of everything in this model and then also see if there's opportunities to merge or group things that don't necessarily. Need to exist individually. And so with that I will open the discussion for anyone who wants to kind of jump in and provide feedback. The first question from me Daniel is like. What is the like basis of consolidating I you thinking of in terms of. Page access or is it dissociated the primary permission is dissociated from the page access and. Something and entity of its own. So the idea would be specifically in this case where view pipeline page and view pipeline details page the question presents itself why are these separate. What is the use case where the job to be done to have them in dependent permissions and so if there isn't a real realistic or definitive purpose for them being separate. And then can we merge those the benefit is that it reduces the code. The amount of code that we have and reduces things that are it's touching. So kind of improves security and that instead of having to watch or monitor to code code points you actually just looking at one. And then that sort of logic would apply to the whole project that I'm working on right. So minimizing the code base or reducing it in terms of complexity as well as what sort of improvement that will present on the front end where. An admin doesn't sort of toggle two of these features and you can just toggle one instead of and receiving stuff to and then make it simpler for them reducing the UI. Got it. So one thing that I just noticed in the link that I just shared is just a realistic permissions which are specific to pipelines on the docs. And while looking at this table if you see the we have separated out view pipeline details feet you pipeline page and view pipeline tab in MR and when I kind of cross checked dot with. The documentation that I have in my personal excel sheet the only difference that I see between. The pipeline list few versus the pipeline tab in Magic West is that guests cannot access the pipelines in a mode request. So that's something that I think we should also cross check with the team if there is a possibility to consolidate that with these two permissions that you just talked about. And there's a very compelling case of not allowing guests to visit that particular tab in a logic West but I'll see in time be able to look at the pipeline list. Well, so one thing I guess I should probably clarify is that this change doesn't necessarily have any reflection on guest reporter developer maintain them owner. The idea being as that as an admin I can then customize all of these two offer those individual permissions so if a guest only had access to one particular permission. I could then enable that they would no longer be a guest so any sort of restriction that you're seeing. By a non member or a guest not having access to that doesn't necessarily play into this particular problem I don't think. Apart from what do they have currently and can I enable or disable that. The idea being that an admin would then give custom feature or custom access to something. The impetus for the project is our permissions are either too permissive or too restrictive. So somebody can come in here and say I want a guest role, but I'm going to also give them permission to run a pipeline and then disable all the other things that could be possible. But we're looking more so is that. Any sort of problems that might arise by making those changes by if I do allow that does any sort of security concern arise or. Again going back to the idea of merging stuff if I merge a particular permission does that have impact elsewhere. Right in that case I think it definitely makes a lot of sense to kind of treat the pipeline tab in merge request the same way as which we treat list view. The only thing that I don't think I have the I've complete knowledge to comment on is. How that plays with the access to merge request page. Because eventually like the same pipelines are also going to appear on the pipeline list view so if somebody is able to view that then should also be it would if you this is just presenting the pipeline list you in a context in the context of a particular merge request. Yeah, I guess that's also something where I was looking for your knowledge is that so as it's grouped so far we're just looking at this CICD screen, but. It doesn't necessarily just stop there right so it touches merger quests and you know parts of the repo right so are there connections there that I'm not linking correctly because there and these little boxes right should this be a more. Connected prototype or not kind of prototype but connected mapping here. Right. So I mean I'm just thinking of this habit critical scenario that. Is there a possibility that I might as a user be given access to view pipelines but not take part in merge requests. That's that's possible that's the the whole idea of that if an admin wanted to create that custom role or custom policy then we would offer that ability. And how would that play out if I still have access to like if I if I can still view all the pipelines just that not through that particular location. Right and that's exactly where I'm like thinking okay what sort of problems as I'd create like like the one I used here of view project code is like well I turn that off but then everything else below that should turn off as well. Yeah, if you don't have access to merger question, I. And have. No, but you should you should have view pipelines to have an MRs right that would just automatically be shut off because. Okay, so that's kind of what I'm wondering is that if you would be able to see a merger quests or if you don't have merger quests you wouldn't be able to see pipelines. No, I don't think so. I think the whole logic if if I'm not allowed to look at more requests, the enough course I cannot access that page and the tab is. And even not going to be available to me. But I don't think that impacts pipelines page by itself right that would be a separate permission. Yeah, it's separate that's what. So I don't understand if you if you can't access pipelines though can you access jobs because I was wondering what the difference between the pipelines list page and the details pages and I'm wondering if it's because the details shows the job so then a pipeline and sometimes. Specific users can't see the jobs because they contain whatever sensitive data. Yeah, so it's a question that we should ask back in in general that if there's a let's say if there's. The asked a asked like compliance related jobs that are running as a part of pipeline are they inheriting the same access as the parent pipeline or can that be controlled. So Maya assumption was like you'd look here. At the pipelines and then look at the pipeline detail. Or is that now this is the comic page commit. Of course. That's the thing is that where is the detail shown. Would that be in the MR. This is the detail here. Okay, so this would. Yeah, and the list you can see like there's a list of jobs down there too like and it's own tab that. And then you could like view jobs but technically I guess you could do that from the pipeline many the little mini graphs as well. Here. Here. So the information for. Yeah. Like the list view pipeline. Yeah, I'm here is the. Yeah. So it's kind of tied if you're able to view pipelines and view the pipeline details and just view pipelines you can also view the jobs and job details. Okay. So this sort of all these screens then need to be looked at as a linked. Linking from all of this right it's not just independent. Time back to here. Okay. And that's kind of what I'm also curious is if you were to disable that what does it look like. From the UI is basically just disappear as these navigation items against. That's how we are handling thing right now. I mean we've just basic permissions right if you just don't have access. Nothing will appear right this tab would go away. This theoretically would go away. I don't think that goes away that ever goes away. So anyone who has access to the more requests has access to the pipeline widget. There is one restriction that they cannot run a pipeline if the pipeline feels but I think recently we made a change that if a pipeline feels. Developer should have access to the run pipeline button which is inside the pipeline staff. I mean. Let's see where it's about. Yeah. So there's run pipeline button. Oh, that's one. Yeah. Oh, that's our leap placed. Okay. That was not available. I think to not maintain it as if I'm not running a check. And so if a pipeline feels for a magic question here, the developer working with that you probably could not run the pipeline manually. Okay, well, I mean so right now I am not a maintainer on the get lab projects. I don't think so. And you can see the button. Yeah, I could probably push it, but I don't want to. Okay, yeah, I don't know. If that you think that should not be that way. I think I'll find the issue. Anyway, what I'm thinking is like, let's say if I don't have access to this merge request. Would these pipelines not be visible to me on the pipeline list view as well? Because they are there as well. Hmm. That doesn't happen today. Right. So that's where I'm curious. Is that what amount of data would be visual? So like you wouldn't see the MR. But for some reason you could see. You could see the pipelines. If for some reason they were turned on, but you just couldn't see this content. And maybe the changes. Yeah. And the commits. What what, how would that information help? Like what what would someone use that just the commits pipelines and changes for an MR for? I'm just wondering if it even makes sense to just show those without the actual MR description and everything. So I'm think let me jump in real quick because I want to make sure I'm understanding. I think this might just be a bad example. And I think there would be an admin would disable that or enable that to allow that sort of flexibility or to to prevent seeing something here. I would look at it more holistically across the platform as like saying, is there something that would negatively impact it. The example we're using I think is is a fair example. But it might be like an outlier case, right? I think the more relevant example might be. I don't want an external contributor to see code, but they can look at the the merger question. Whereas on merger question. It's a thing of a matter of security perspective, whereas like, okay, I want a contributor, but I don't want them looking at something. Potentially problematic, right? And so disabling pipeline might not be an example that would be valid. But it is the one that they're working on right, where was that issue. I lost the issue. Oh, here it is. Where do they want to emerge these two? Yeah, okay. I think for me that the problem is I'm more afraid of what happens when they go to something that is actually. More likely to be played with and disabled. I think that might be why they're going after this one in particular, because it probably nobody's an MS with that, right? Like there's no reason to disable this. Right. But this would be these two are available for every level, right? Guess, does access to this. Yes. Okay. Yeah, so I think that might have been why they chose is because it's super low impact. Right. But jobs like permission for jobs are definitely tied to these. So if somebody has access to view pipeline, they can definitely look at the job details and job list. Mm-hmm. Okay. So I think what I want to do next is talk of my engineers and ask them. What do they see? Impact wise from that outline example, if somebody did for some reason to disable that permission. What does that look like in this case? Because I'm not exactly certain how that works because as you described, it won't just be contained this pipelines page. It actually goes all the way back to the merge request. And this whole screen. I'm understanding correct. That's correct. So like out of the 12 trigger sources that initiative pipeline, come it is, I think one of them and come it is again related to the changes and Like for security purpose, if the changes have to be hidden from someone what happens to the pipeline permission. Okay. Mm. One other thing to throw in there, it's not fully live yet. It's only enabled for this project for get live projects, but if you go to CI CD, we also have artifacts now. And that depends on jobs and pipelines. So it's like the way that we had to go was just saying if you don't have access to a pipeline, you don't have access to the jobs. And you also won't have access to the artifacts. Gotcha. It's like a whole tree. Yeah. So I guess that's something that I need help with over here is. Can you help and fix this tree with me to make sure that the links look correct from your perspective. Yeah. So I think that's my my ask for the team is that just double check what I have so far and make new links or break links as you see. Related to your group. And then also just you know feel free to note or call out anything that might be weird or problematic and we can talk about it async. And like I said, I'm also going to pass this through with the devs so they can see what we're talking about in our concerns. Okay. Okay. We can do that for runners now that I'm just looking at this is I never even know add runners to name space is an existing permission. Sorry come again Gina. I think so let me. Find it no only six links. It says add specific runner to project it's listed. Yeah, okay. Oh yeah, product will be in namespace. It's limited to one those inventingers. Yeah. Okay. I'm just trying to think about all the things I'm going to think about it a little bit more runners are like the permissions are so complicated so I'm going to take a closer look into into that. Cool so yeah this is hopefully been helpful and I hope. I have explained what I'm trying to do correctly. I guess if you all have any other feedback. For the meeting today, I don't want to I don't want to keep you longer than our schedule. Okay cool so then yeah like I said when you have opportunity. I'm going to add some changes here or links that I'm missing that you think should belong here especially like across. These sorts of features. I think that's mostly where I'm lacking is where they touch across the platform. There's definitely an overlap with security and compliance in the create features. I mean that and also package I guess. Yeah, my assumption was there should be a lot more links but that's kind of what I was hoping to have these chats with everyone to see which ones I'm missing. Yeah. Awesome. Well, thanks everyone. I appreciate your time and it was super helpful for me and I'm glad I could catch everyone in the same time slot. I hope I could keep anyone up to late or wake anybody up to early. Cool. Thanks again. Good to see you all. Have a good day.",
  "I can introduce the date also. This is the CECD UX team meeting on November 16th of 2022. It's almost 2023, which is crazy. I'll just leave it to you. All right. Thank you, Gina. I can see the agenda of my iPad is acting up. Anyways, I think my first item, it's about severity labels. I'm not mistaken. So just a heads up for product designers. Please don't forget to add severity labels to your UX issues, especially the success impact you want. The bold will annoy you if you don't. So it's a good way of reminding us to label us issues. It's just the core and we can have the public prioritization. But also I've seen some issues. You might see in Valerie also doing. Some housekeeping on those issues and living comments, but there are some issues. There are not labeled UX, but they do have UX requirements. So I leave you one for verify today. There was a back and issue, but it changed settings and it changed UI copy. But it didn't have UX or a severity added. So just a reminder for everyone to please. Make sure that the issues that you and your team are working on have the correct labels applied. Let's one. And then my other updates about hiring, you have any product designer joining the pipeline insights teams. That's a lot of will be joining us in the coming months. We don't have a star date yet, but they will take over from pipeline insights to the Gina can transition full time to runner. So it's going to happen. And then once I know more about that, the star date and yeah just to onboard you all that everybody know. So that's that for me, Gina you have a year of next. Yes, there's an issue that I linked to you that Amelia had brought up about discussing how to better collaborate with. With designers, but I think it also applies with research and even technical writing cross stage or cross group. I just mentioned it to this group. I think a few of us have already jumped into it, but I think this group does a really great job of collaborating. So I was encouraging you to share your thoughts. If you have time. And I think we were going to try to start from the bottom of the agenda today, Erica, if you wanted to start. Well, that's a great tie in because working backward from my list. One of the things was that we have. I wanted to like celebrate the my my updates today are framed around welcome back. Hannah. What is yeah. Welcome. I wanted you to know that Gina and well, I actually got sick and like tested since that I couldn't go to the conference. And so Gina like stepped into this leadership position will really delivered. And we have like four reports, I know, amazing. I coocon four reports that we hammered out because of the data they collected. And then one more on the way, which which ties into the issue that Gina just showed about cross stage collaboration. So we we set up like a game we came up by the interviews instead of running them. Just like in a conversational way. And we were able to get great data and I think we got actionable data. So we're still working on that report and it's setting up a secret scan. Which we kind of all want to be working on anyway. So that was really good. And then I guess my last item to is just asking if you all would like to open up the H2. And I think that's the first thing that I want to do is to verify and package common screener for solution validation studies. So I just wanted to check if it's worth like making that change with Caitlin. And I linked a PDF of what the questions are and as long. But we have like 500 participants in there and some of them have been used. And so you can just mention me in the notes to give you time to look at it and just let me know like how many studies. We might recruit for. And then my other findings are kind of just an overview of the Q flight Q for prioritization. So the big one is that we have a pre work issue set up for Q three. To do some pre work related to a benchmark. There I say for package like a nervous but but anyway. So yeah, so we'll hopefully do a benchmark for a package in Q one. Fiscal year 23 starting in 159 waiting for design and PM resources to kind of come online. But before then I'm just doing work to like kind of crosswalk the stages that have done this before. To kind of like make sure what we do is on par. And then we also kind of related to package resources we put on hold this like cycle of an image study until the new PM joins. So that would be the study that we did kind of with secrets and see I templates where it's like how does it start what happens next what happens next. We would use that kind of framework. And so that's on hold for the new PM we think it's exciting for the new PM to work on but I think the benchmarks would get priority and then it would go to that study. One more thing to mention about that is Gina had it's a really cool issue a research issue around. Looking at the life cycle of logs and so part of me wants to try to pull that into this study that's now on hold. But I think we're getting feedback that we need to like scope that. Gina's study down a little bit so but does note that I have like a plan because I think it's really smart like in foundational research terms. Sorry, I didn't wait for Hannah to say that things for the heads up on the benchmark. Yes, sorry, my. The Google Docs keeps getting. He's crushing on me and it's like enough finish writing down my question. So yeah about package I have a question for you Erica I cannot open the issue now. Okay, so on my iPad but the pre work issue is for the benchmarking right for package. Yes and correctly. Yes. And it's it's all things that I want. Thank you like I'm comparing the screener questions because I think that and I worked on benchmarks it a lot of previous roles and one thing we want to see is how much we can compare across stages. Which kind of means looking at how comparable the samples are and do we all use the same screener and like what's the alignment. I mean that so that I'm not making us be too rigorous with like finding a counterbalance table. But like whatever we've done is an amazing iteration. But we just want us to track it explicitly so we kind of know. So it's mainly me doing the pre work of like what were the screeners. What's our screener looks like I actually have our screener drafted and so whenever Tim had time they can kind of come in. And the idea would be we would treat it like a common screener and then being a position to run the next benchmark like we would have 500 participants that we could select from. If we kind of start rolling it out as soon as we're ready and so we're just waiting on 10 to have time. Yeah, so it's like what were the screeners how are the samples comparing. And it will help us know like I think when I'm seeing so far is like we're mainly small medium business samples which is fine to know right, but it means we don't have to then stretch to do an enterprise recruit kind of doing it beyond part. And we're just looking at all of the mechanisms that different researchers use to like get feedback like will has this lovely. You're all approached that they used for jobs to be done like deciding on the tasks. And then working with them to figure out like what the team has capacity for I feel like we'll go more bare bones which is also okay, but. And a couple weeks when we get back from the Thanksgiving holiday, I'm going to meet with Tim like give the updates and then see what their thoughts are related to the. Kind of the next steps and I my plan was just to use those little half hour meetings that I have set up. So I don't take too much time and then the last thing I'll look at across those stages areas is just like the level at which the tasks were framed. Because that can impact performance to. So I think we'll also help like elevate the research program with this work. Okay, I'm taking some of the thank you. Thank you. Thank you. I'm pretty overview that that clarifies my next. A couple of questions and then I just want to say please keep me in the loop because if we know. A bit ahead of what the the UX I'll say like hands on design work for package is going to look like. I need to know to prepare the UX coverage because we won't have a US location for package until next year. Q 3 q 4. Okay. Yeah, we've made a decision to because team and Victor also Michelle. They talk about the deliverable plans for package now and that's for everybody. Kind of me aware that they're hiring developers right so they don't have for example front and location to build UI right now. So we are not going to be hiring a designer for package right now we move the headcount to a different team and we won't have a designer for package until next year right once development pays up. But if there is a the research is going on and we have. Well, the hiring for development also picks up and we know that we have a need for package UX deliverables then yeah, I'll need to know ahead of time so that we don't work on a coverage or borrow plan or hiring plan for the for the design backfield for Katie's backfield. But just so you're aware that yeah we're not planning on deliverables for package because we don't have anyone allocated there. And maybe we were backwards from that to. I don't know I like really wanted to contribute to the okay are so I don't just care or we're trying but I think I think it would be okay to get those findings and then have the designer as they on board like pick up with them. As long as we like set the expectations. So everyone knows that that's our plan. It seems okay, but we'll let Tim guide us. But thank you for that. Okay. Keep me keep me to go. Okay, well. Sure, just got a couple updates. I'm using the same prioritization issue in Q4 as I used in Q3 and kind of trialling. Just a longer term prioritization issue that goes to quarters as opposed to one just to see how that process goes. I did add a comment in the issue. And with just some updates on like what projects we accomplished in Q3 so if you want to check that out you're welcome to do so. And we're still collecting projects for Q4 but I've listed within that comment what projects we're expecting to take on this quarter. Aside from that, also met up with Emily on Sunday, which was awesome. We got to have dinner. It was nice to just meet another person. I've met like half the people on this call, which I never thought would contribute. Got canceled for the year. But yes, it's just been great to slowly meet more and more team members as a bit of part of the company. And my final update is that I've been reviewing scenarios kind of often on for Emily's CMS study on environment management and she's been really putting a lot of effort into that over the past couple weeks. Any questions for I turn it over to Emily. Okay Emily, you could take it away. I'll go a little out of order because I'll get to my critique one at the end. But I was mostly curious now that I'm kind of getting to the stage of conducting the CMS interviews with internal users just kind of some of the things you did to recruit people. I know we're using some people from the delivery team who've already offered to volunteer but just any other options to get people into the study I'm looking for. So it's like will and Gina both head to comments and in that. Sure, so I haven't done this at ton. I did this probably the most like after I started to get lab just because I wasn't sure how to get internal people to begin with. And I've like posted on Slack channels just I try to keep like a very concise message of you know who I'm looking for what dates. You know just any like kind of a summary of details about the study. And just try to post them on different channels. Sometimes I've like leaned on the PM to try to help direct me to like the right channels to go to. But since you're working a lot with the delivery team they might you know help you know where to post or you could just talk to the participants that you have signed up and say like hey. You know now that you've gone through this study you know is there someone else on your team that might be good for this. Your mind was just plus wanting to what will said I have posted in what's happening at get lab before that has gotten traction. I also found that linking to the research issue helps cutting allow them allowing them to get context around with the research is about. Awesome. Sounds good. There's a high enough left to come into those of hustle and. Yeah I'm trying my. My. My. My. I think I've rolled down about yeah looking of course in the head book right we have a section with the internal customers for each stage group. And then on which pages that on the handbook product slash categories. And if early stage you know it's the delivery distribution team security so just echoing what the will and genus say. Most of those groups they have other own select channels so can drop that same message in there and then we reach out directly to people. I think for the release of the delivery team to have super active so it's easy to find those connections through them and also ask like. We someone that is working or has used X Y Z feature functionality and then can contact with them. But in Gina and we'll they are ready to get the best tips so just echoing what they say. Cool. Cool. The second update I wanted to give is we adjusted the deployment snavigation so now when you click on the high level deployments you land on the environments page not feature flags because there's a lot of data showing that people would land on feature flags and navigate away as well. There was comments about this and are like benchmarking study so that is now in production which is really great. And then will I know see you at a comment on that as well. Yeah, as you talked about we did see this a lot in the benchmarking study and I would just constantly see participants like click on the link and know that they weren't going to go to the right place and then they would just like get frustrated and then have to you know use that extra click to go to the right page so I know that's going to be a big time change. And to do a time to do a little kind of design review I think we still have like 20 minutes so I try I will I'll try not to take of all the time but just wanted to make sure I wasn't taking it too much time. So the background of this this has been a long standing issue that's opened that basically we want to design a page that for MVC starts out to hose production environments across a group. So we've seen a lot of research showing that users are having a lot of problems tracking environments at the group level and they're having to go to each project bubble page kind of track statuses on there so kind of crafting up a page here that. would be able to see like a high level summary and then be able to click in and take action if needed. So I hi on I think you for telling me to kind of just step back and start from scratch because that really got me started quite well but I'll go ahead and share my screen. If I can figure out what screen I have to share this on. So how I started this is I really took a step back and went through the research and kind of this page is interesting because it's not a typical flow users wouldn't be going here to complete like a typical flow but I did want to get on to paper kind of like some of the tasks that. the research showed that they were looking for I don't know if I should go into this if this is going to be public but you can kind of take a look at kind of some of this and then just taking a step back and really figuring out. So this is like a high level view what do users really want to understand and starting from like the information architecture point of view here not even designing something just trying to figure out. from a high level what we should be showing on this page so with some like a team feedback I've done some like St. Calls with the engineers on this I kind of landed on something like this where. we would show kind of production environments a top level summary of like your environment health across the group so like how many environments are healthy are you having problems with any of them. So a little TPD on what to show in this area but really having that high level summary and then being able to dig down if you need. and then when you go into the environment showing an environment level summary of that production environment with like environment health project the deployment the most recent deployment health and then some actions you can take. as well as showing that most recent deployment so you've like context of what is going into that environment currently. I've cut it down quite a bit from some of the original proposals because this page we really want to show them. what is going on and not bog them down by a bunch of different information that they could kind of dig into and find. So I've kind of moved it into this again as you can see this is like a really big TPD I want to create a nice summary at the top. but kind of showing this into like group name environment at the production tier kind of like is the most recent deployment success tools or anything action you have to take and then kind of showing details about most recent deployment underneath it. with options to like view and project and kind of debug problems going that way but by condensing this information down reducing the amount of like page nation you need so being able to show things all on one page and being able to show just the information you need. to kind of take the action that you need to take so open to suggestions on this but that's kind of like how I've started this it still fairly rough. so there's like I do want to run this by some users as well but but I would get a first feedback look even though this is kind of like a rough low fidelity right now. I had one comment just saying that I thought it looks great I didn't even see this the one that you're showing right now I only saw the I used up so I think it I think it looks. like with the all the information that you have to deal with which there's a lot like you did a really good job of summarizing that. and making it clear I also the thing that came to mind for the summary view up top I think that this single sat component is always good for that type of stuff. so if you you could consider using something like that for up there I've seen other pages do that as well. and what runner does that and then there's a like a DevOps report type of thing that kind of does it. awesome and that's called the like single stat component yeah I'll link it to you from pajamas also it's pretty flexible to which is great. then my my only other comment was. for like this would be adding a new navigation item for for groups and. we have to do a similar thing for runner so I would consider talking to the foundation team just to make sure. like I think you have to get approval from them now I can link the handbook page but I also know because they have all their navigation efforts going on it may change. and I think I have. yeah I know when we're trying to do building on the growth team we're running into similar thing there was like a process in adding something to the nav so I will definitely kind of communicate to this idea with them and see how to go from there. okay yeah. okay. Erica I think you had the next comment yes thanks for sharing this I love that you're sharing that's on this in this meeting. so one thing that we're we've learned about the workflow with CIC e variables and a subset of those are secrets is that one of the reasons people want to use the unprotected values is because. they tend to use the wrong ones pro environment because it's confusing so yeah like a subset of that finding is that they use different secrets values. for the different environments. so I think you could add clarity here if there's like a light touch way to even like allow people to dig into the different variables that are being used in different environments. and they do I think that would help them and it feels like if we're going to do an overview like that that that would be something. to highlight. or think about. I can definitely think into that I'm still in the process of trying to figure out what is the best information to show here what should be still cut out because of this deployment information is just kind of copied over from the environment index page so. to do a bit more exploration on like is this the right amount of information and if there's additional information like you said the kind of secrets. how do you show that here so thanks for bringing that to my attention. well thank you all for the feedback by the way I see will is next. yeah I think for the summary view some of the things that could be helpful is just being able to identify not just like how many. environments are in a successful status but also if there's ones that are like pending or if there are ones that are like failing or having some sort of like difficulties just so that people can like easily. like click into those and be taken to those somehow. and then also like how in your design you're not like using that carrot Sasha accordion style menu that that we currently have just because it's nice to be able to just see. some of the specific data that users were having to like really stumble around to try to find. awesome yeah thank you that was kind of I know a lot of our research has shown those. so that's a lot of the things that we're going to do is to be able to see the actual appsable sections when you're trying to find a high level view of everything was just not working out right so. I was trying my best not to even collapse any information and just if there's information you. that needs to be hidden maybe that's not the right place to put it on this page so appreciate. then hi and I think you have the last comments. yeah so just personal what we'll say about. showing information without using that. also pattern all for your spending collapse and it just hides all the info. that it's essential in this page very much in both in this case the group but also the project level environments view. and also plus one in the summary blog I think this will give users that at a good understanding of how their environments are doing across the board and that's important for us not only for the. developers but you know the managers the director of why a person anyway is anyone really that is interesting how. the application is doing at the higher level so. I think that's going to be a great addition. and have a couple of full of questions Emily and sure if you have the time but we may think those the just things I was thinking of while looking at the prototypes. what type of environments will be displayed on this overview just like the protected environments production only and also was only how users set up this overview. has a team considered if this would be something that will be just pre populated you know coming from all the projects. that had the environments that meet a specific criteria or we users be able to let's say managing customized that view based on what's important for them to see you know for each project. yeah so this is a good question for MVC we've really landed on we want to show just production tier environments and then. figuring out later we'll need to scale this up to show the different tiers but kind of pre populate this based on like tier of environments. this is actually where the empty state comes in I don't think I'm the one that designed the 70 state I kind of grabbed it from one of the others but. if you don't aren't using environment tiers using this empty state to kind of encourage users to kind of set that up so that they can pre populate this page but also use this feature which we don't have any area now where we're really encouraging them to do so. so having the empty state as both a bonus of setting up this but also encouraging people to use environment tiers. so hopefully that answers your question for MVC we're just going to stick with production tier environments and to set it up would be enabling tiers in your environments to show them pre populated on this page. yeah thanks that is my question and I think following up to that so. and thank you all too is that when you have the chance look at how the MVC plus would look like because for example if I'm not mistaken you can have multiple. and the environment some of the same tier right so if you set it up in the CI file you can have I don't know different production environments label production but for a different name right so how would that look like. in the UI how would users customize I think will be a good next step for you there see how this page would grow because we're not a challenges that we had with the current environment pages that. while designing and also coding it we were not the they off how that paid would scale so I think you have the the ability here. to predict some of the edge cases but also to avoid you know unhappy unhappy bets in the in the UI and the real UX. yeah for sure yeah that's something and where I'm early enough into the designs here now that I have to kind of build out what does like unhealthy environments look like what happens when you have like a lot on this page so I think we still have quite a bit of time to kind of build out all these edge cases and then. what's we certainly more than just the production tier how do you set that up what does that view look like and everything like that so. think there's lots of work to be done on this page but it'll be good work to finally get out to users. yeah. awesome. then my next point is about that. this seems like if you move forward with this approach right up we could potentially deprecating for our room. dashboard view. or what are the team's questions about it if if there's any discussion going on around the deprecating or replacing the page. if we're often this group view. yeah so there hasn't been any like official conversations going on but I have chatted with like Andrew on the team of the reasons of moving away from it and just. the performance issues on that page were so hard to sort out that that's kind of where this idea has come from and kind of like why we might be moving forward with this and some of the performance issues are really hard to kind of solve or but I think we need like some written out kind of conversation with. the PMs and everyone on that team to figure out is this a like a replacement can they work together. the main pros of this pros of the environment dashboard and really sort that plan out as well. also yeah I think that that will be. you know a good. but I put that. just vacation right for deprecating or moving away from that environment dashboard view. so that's a lot of the traffic there as far as I know and see your point there's so many. restricts in terms of the. also for that performance of that page that you know. I'll say. if you can it also when you have the decisions that are positioned the team putting the proposals to right that how this this page will or the group potentially solve the jobs we don't solve the problem that's the environments dashboard view does not solve right. thank you and. no sorry. no I just thank you that's like something I definitely have to think on so we'll get that right now. so. and then my last thing back to just about it's a spot the y and then if I. I'm assuming here yeah. when I did the validation for the environments. page right. I learned that that information about the commit message it's irrelevant to users or it's usually relevant. when that commit is merging or branch or anything into master because they often shows that same you know the fog message. merge branch and then branch name and that's not we readable and that's not a very far motive to users. so my feedback here would be like. check in the. the insights I don't remember correctly now what what's the most relevant information that that we should be displaying here to users and see how you know and if it could be. we if you could replace the merge branch message because that's what we have today in the environment stage is just the same message everywhere with the link. and as I already tell much. can use that space in now in a more a different way. rather than just showing this message. yeah I agree I think there's stuff we can. and that if we can say real estate on anything in this page and take out things that they don't need at this viewpoint on something I'm working towards right now so that's great to know that something we can potentially take out of this. awesome. thanks everyone for your feedback I want to give Gina enough time for them points as well but I appreciate kind of taking the time to let me walk through that so. I think exactly I have one other question for you I noticed that the. the way that you were like. for each row there was kind of like many columns of metadata in there like the job like all that's up. have you heard a gotten any feedback around how that impacts. like scan ability I guess across different deployments. yeah because it is a lot of information so as like a side note I've kind of added these in here to this I'm still considering it like a low fidelity I've just added in what we have on the environment index page and I'm planning. in like the next version of this to kind of go through see what information we can remove from there see what information is like the most important. based on conversations with the engineers to kind of for MVC start with what we have and kind of take away from that if possible just so we can read. just so we can reuse some components so yeah I agree those sections I think need a bit of cleaning up and figuring out what exact information should be placed there. like the merge branch message taking that away but yeah I agree I think there's some simplification we can still do in that area. yeah I'd be like if you end up testing this I would be interested in seeing if. people say like if they if they if they want to scan I guess my column like does. formatting the information in that way impacts that because I mean we're doing that in runner and there have been like two. or two customers who have been like I don't I don't want to see it in this list view I'd rather see it in a table but the majority have been saying it's fine to see it in the way that it is. but the view I that we're using is very similar so I think the insights would carry over to them. well good to know and yeah I'm planning to run this through some solution validation as well when we have a more finalized design because there's such a big. lift to do so hopefully we'll get some of the usability comments from that as well. and then I have one more point there like jumping in before it's but it would be that when you do the solution validation I think try to include like more personas than you might not like try to push yourself to include more personas so we make this work for more. people because I think it can have a bigger impact. yeah because I think right now the dashboards are welcome is not working for some of our personas so opening this up to a bunch of other ones is probably like the best. Well thanks again for all that I will pass it off to Gina. I think I have two updates one of them is for pipeline insights. we're dealing with this problem of flaky tests forget if I gave a definition of these are not but the general one is that when you run tests they can sometimes fail but the failure isn't real like it wasn't actually detected it was because like the test is actually written incorrectly or maybe. I think it's a test that that test relies on failed something like that and if it fails more often than it succeeds without actually detecting a failure it's considered flaky. So we're trying to understand from users like their pain points right now they're work around with how they're dealing with flaky tests and then definitely how they define them. So the insight for us here is how they define them because we want to be able to when we define them for this MVC want to make sure it matches their expectations. So I included some of the insights that we've heard so far we will we met with three users so far but we have a few other participants coming up as well. on the runner side we this is like one of our our bigger. Well it's a small feature but it's it's an important feature that we've added for runners. It kind of has to do with the whole runner fleet monitoring slash Q stuff I've been talking about for a while so it's it's difficult for users to be able to see if a runner is running a job at the moment and the reason why that's important is because. If they were to update the runner for example. It would stop that runner from running any jobs so they don't want to impact any current running jobs or else the code just it doesn't go out. So they want to know if. If that runners actually running one. So we've added a badge to be able to see if it's running or if it's idle is the other word that we're using. The tough part about this is that now we have two status badges we have one about if the runner is online. And if the runner is like running a job so our next iteration would be combining those into a single status something like active where it's running a job and it's online. And then that will allow for less less load on the user. Make questions or anything. I just want to say I love the idea of combining status badges into one thing that works because I've seen it quite a few time and I think it's in like the environments area as well or there's like multiple status badges and you're not quite sure have here really to each other so I think that's a great idea. Thanks it will definitely be a tough thing to do like because even with runner because everything through the CLI to people can now get a list of all like online runners but all those statuses would have to change so it's going to be like a long long process. I think that's it. I think anybody has anything else so. Thanks for meeting today. See everybody soon next week.",
  "Hello everyone, this is the CICD UX team, we're meeting stay on October 19th and there are some manager announcements in the beginning. I'll just go over and then we decided this meeting that we're going to switch up the order so we're going to start at the bottom of the agenda. So there was a there's a thread for OKR's progress if there's anything blocked or at risk. I don't know was asking for you to list it but it doesn't seem like anything's there. And then there's some upcoming family and friends days dates that were released for November through January. And then the talent assessment officially kicked off today. And it's open until November 4th to get that first down. Maybe it's a specifically to fill out the performance sheet that we were all given. Anything any questions or anything. All right, so then if we scroll all the way down, will do you want to start off and maybe if you know if Erica has anything you could go over that too. Yeah, sure. So I know that Erica is also going to be a CUC on all be there as well. I think you're also going to be there. So be great to actually see a handful of people. I've met just a couple of get lab team members before but excited to actually meet people within the department. So we'll be out doing some research. I think she's doing Erica's doing like them own survey. I think Gina you've been working on them with. I'm doing something for distribution team. Like a survey and some interviews and then Erica and I are also teaming up with the market insights team to do some like buyer persona research. Where we're trying to identify people that are likely to buy. Get lab and then talk to them for a little bit and then see if they're open. To like focus groups later in the week. So we're going to be quite busy with research next week. But what I have time. I'll be checking like messages and things to to keep up with stuff. Aside from that. About halfway through the benchmarking workshop that I'm doing with the release team. Basically the team is come up with solutions to the identified pain points and is giving feedback on everyone's ideas at this point. And then tomorrow I'm actually opening up a final part of that workshop where we'll essentially vote on the top solutions that we want to work on as a team. And then I'll create actual insight issues that will incorporate into the roadmap. And then I've been helping Emily out with some research that she's doing related to them CMS scorecard. So that's it for me. One of the stuff that you're saying that Erica was doing for Qcon. I only have insight into one of them which is about secrets but she's been there was like some previous work that. they had piloted and ended up getting like a lot of data from around. I think that one was specifically secrets within the workflow so kind of figuring out like what developers were expecting. Ideally for how that would work. And she's going to continue looking at that for Qcon but focus on finding out metadata that's important around secrets. Okay, yeah, thanks for the context. Yeah. So Kevin, I think you're up next. Sure. Thanks. Yeah, for the null of dates but mainly one of the issues that I've been working with and that I shared a last time is about not really massed for our eyeballs. And kind of what I've heard is after discussing with the team we kind of agreed to. They can not have and kind of diverge on this and decorulate secrets and variables. So I've got to sketch out some really broad wireframes of what that would look like. If anyone has some thoughts, please wait in. But essentially the next steps are going to be to they have a bit deeper as to what this would look like introducing a whole path for creating and managing secrets. And that is the first point. Second point is you may have seen this in the UXCICD channel. But there is a proposal from an engineer for it's to be designed by applying over view. Bage. So instead of having a like the pipeline I think it's by plane graph you go with the different jobs and stages that would be a different visualization that kind of highlight. More like the number of fail jobs and also like higher pipeline is is doing. So I'll be helping them kind of iterating on this design but potentially also good through research and validate it. So that's it for me again if you have any thoughts on that. Feel free to wait in the issue. I think there's a link to their video that actually created an issue otherwise you might able to find it in the slack thread. So yeah that's it. So this one looks to I was going through a proposal and like crunching the comment box to a small area and landing straight on the summary tab. Did you also I haven't read through your comment that was the discussion around removing the fail jobs or that's something that's. The fail jobs happen you mean. Yeah yeah. Yeah. I kind of mentioned that we kids instead of like showing all of the fail jobs just showing a bunch of them and then sending people to the fail job tabs. I think that's on direction. Instead. Yeah. All right. It's good. Oh, sorry, next is me. Dave and your friends are okay. All right. So for us to have had enabled tracking for a bunch of pipe and related actions and now what we are doing is. I will quickly find the size and slink. So we are able to get a lot of information about what are the actions that our users are performing more frequently and which are the links they're clicking on on the pipeline this view. So we had our monthly check in around that information here's the dashboard I'm thinking get here. And this is the dashboard and we kind of thought of different ways in which we can act upon the information that we're getting from there. So for example, we already had a bunch of systems related to speed. So what our front and team did was they used lighthouse runs to figure out like which are the areas which are costing us the most in terms of performance. And how can we tie in the insights which are is we were saving through this set of data and come up with you proposals. So if you go down, I have proposed a new method to kind of just suggest a proposal. And that would be broken into three parts like proposal the assumptions that we are taking into account and the evidence to support the proposal which can be a combination of both. So metrics we're getting through the data tracking as well as the insights from previous researchers and at the end like once we have a bunch of these we would do a round of voting. And so far my idea is that we would vote on the basis of like which one has the least risky assumption associated with it and it would be most impactful. So keeping those two parameters in mind. Yeah, and then we would just get started on the like design proposal for that particular proposal that kind of gets the highest number of words. Coming to the next point which is the PNPS and sus feedback assessment. So we revisited feedback from past four quarters because we really wanted to get to like work on such impacting issues that would have the highest impact. And we were desperate to take a different approach than just like going through like burning down through list of S1 and S2s because we wanted this to align with what our users are feeling and how they're like sharing their experiences with us. Now this assessment I was able to understand at what are the most frequently emerging themes across the feedback and the two that were most recurring were one was definitely around improvements to talks like adding more examples and improving the instructions around CACD. And the next one was reducing the number of steps for primary task this was like a lot of users mentioned like share feedback around. It taking a lot of time and a lot of number of clicks to get and to perform an action order to perform a task which we can say is primary to the area. So we want to make a collection of all the existing issues which are sus impacting which relate to this insight and bring them together in an epic with a very clear exit criteria. So we are actually able to go through like going down all the issues inside the epic and also close it by the end of the quarter so something very realistic. And that's the next step for me like I'll be creating that epic and adding issues to that. What next quarter yeah. Any comments any feedback. Do you want to voice. Yeah, I'll voice that one. This was related for your first topic. It was it's just interesting that that that issue is more about like load performance which makes perfect sense and that we have an in pipeline insights. We have a feature around load performance and it's supposed to help track those types of things. But it's clear that the products that like that your team is using is showing results or data and much more depth than what our feature does. So it gives me some ideas of how we could improve. That area we're not even focused on performance testing as like a whole in pipeline insights but something for the future at least that we could think of. I was at a very rough this so far and this is the first time looking at once it's proud that provides these informations. Yeah, they do a good job. Yeah. All right, so that was me passing it on to Emily. So last week I was kind of wrapping up our solution validation around pending deployment approvals introduced and just there was some interesting stuff that came out of the study that kind of correlated with some of the competitive reviews we've done. Slack seemed to be the most popular tool users we using to notify each other since we didn't offer it. They were figuring out with bots or doing it manually through Slack channels. But interestingly enough like users were looking for a way to integrate pending deployment approvals with Slack so they didn't have to depend on the get lab UI. And we saw this when we reviewed harness as well harness was using Slack integrations for pending deployment approvals more so then their own notification system. So good takeaway of this is we were going to implement this within to do's and we think now a good MVC is just to allow users to kind of integrate these deployment pending deployment notifications within Slack and within their current workflow so that's kind of the way we're going to take this. They did like the idea of being notified they thought to do's made sense but there was warnings about how to do's are pretty busy already. We have no way to prioritize to do's they kind of just land in the list. So I think there's additional work we'd have to do to get them in the to do's but they would also see that workflow as being something useful just there's more work in there so our MVC we're now landing on is focusing more on integrations. And yeah I linked the research as you and Deb's till study if you want to read more but yeah a big thanks to Will they helped and supported with like all stages of this so big thank you for all that support. And then the second one is one of the bigger design initiatives we've had is supporting multiple approval rules on the project level protected environment settings UI this really gives users a lot more flexibility into setting approval rules so now people who can approve don't always have to deploy you can set who can deploy who can approve different types of approval rules on which we're really excited about because this gives them a lot more. Configuration options within the UI whereas before we only gave this through access with the API so excited for that to come out as well. And then my last thing is I didn't mention this on Slack but I will also be having lower availability next week I'll be using my visiting grant so I might be just lower availability for sink calls might be late responding to messages if you need me so that's more just an F. an F. And no one has questions I can pass it off to Gina. All right the first both actually both of these items are on pipeline insights I have work going on for run or two but I felt like these were more interesting. So the the first one here is about the new artifacts browser design. So also kind of goes along with what we've got was saying about having basically like allowing for less clicks to get to the thing that you need to get to. So the browser right now if you were to go into a job and browse artifacts from there you have to click into each folder it's like it's so there can be so many nested folders to be able to get to that final. So what I ended up doing if you look in the design there. I kind of consolidated all of those folders if they're empty into a single file pack and then I just. And then did the the file with it like underneath there so it's clear that it's still part of that folder. But if you have any feedback on that design I also linked video if we're going through the proposal in the York's coworking channel. If that helps as well. And the other thing I had here was we are we did a bunch of research to understand for review apps kind of like we heard that the view app button wasn't prominent enough people couldn't find it so I wanted to understand really why and what was going on. And we found out that it it's really just not integrated into the review workflow as much as people were expecting it to be so what we're planning on doing is adding. The view app button into that code drop down when you go to a MR and this also allows it to kind of be like stuck to that global header because that. Um, adding is sticky when you scroll down the page and it also is closely integrated into the the review workflow there there's some. Some specific things were like only certain projects have review apps enabled so we won't be showing that. Many of them all the time unless they review app is enabled for that project. I want to say I love this change because I don't know how many times I said trying to scroll down page looking for that like view out button so having it just in one place would be so nice. Thanks yeah we're definitely I think it will definitely be better because like we're saying like people were having trouble finding it and said that it doesn't always show up in that widget on at the same time so. I think this will help. And then my last thing here is I'll be I think I might have done that with zero is why did they look like that I did. All the out of office next week at Q com. Uh, but I'll probably be on. I'll have my computer so like if there's anything that you need just feel free to reach out. So 50% of the population here is going to be a. Yes. Yes. 50% yes. So since Erica is back maybe they wants to go to them items. No, did I miss Kevin. Kevin. Yeah. Okay. So yes we're gearing up for a coup con and then just if my personal life my child has been sick and then yesterday we tested them for Kobe. We all have come in. So it's just so I'm like oh no, the conference. So I'm going to have to figure that out. So we'll continue to tonight. So I just am like waking up because that's why I was a little late but miraculously I woke up. I was like oh there's the meeting. So I'm always just glad to see you guys and I'm glad that I showed up because those were great updates. So we now have to kind of figure out what to do about. My potential absence but maybe I'll be healed. But what I can do is show share with you this deck. If I can do it. Um, hit well. Let's see if. I can just give you the general updates. So we are going to be at coup con doing a lot of things will and I both have a survey that we're a fielding. Um, and then we are going to be doing some interviews with buyer personas. The pms from ops, especially have kind of come up with. Some questions and so people will kind of come up to the booth. And if they're a buyer persona, they'll get put into this buyer persona interview round slash recruitment for focus groups. And then if they are. Not a buyer. Then they can either come to the area where we're going to have a station at the booth or there's actually two booths. They might also just complete these interviews from the pms. So it would be good to get your eyes on that stuff. So I'll link that issue. We have like seven questions that we're going to ask. Um, And then we've set up. Um, Qualtricks so that all those questions and then questions for the buyers and all the other questions are in Qualtricks. And then that'll be a note taking mechanism where attendees can kind of take notes on those interview questions. And then James was going to kind of lead those pms in a sus like approach. Where they kind of summarizes it in an issue the findings and then we're going to invite people to follow up with those participants. So I'm sure it's all going to work out and I'm miraculously not have COVID in like a day. So, um, And besides that, we're working on the prioritization stuff for Q4. So if you haven't had a chance yet, We'd be good to link the Q4 projects that you want and we're going to put that through the research prioritization, But because also our pms are going to be at coupon. We're going to wait to finalize that until everyone gets back on November 8th. And another thing that I'm probably going to pin you about is I'm going to try to do the research prioritization of the research center this. I forget we have like a longer name for it, but basically we're going to go back through and according to our research questions like summarize. All the research we found for this quarter. So that will be something I can link. So I'll just be asking you to include studies that you would like. Kind of included in that synthesis and the idea is our great Jackie will return and we want to like have that as a way of helping them come back is to kind of summarize the research so far. And if I don't go to co-continue to be really bored. I don't know if you'd like please tell me things going clear. And then I think another thing to put out there is I and I posted this on Slack, but to help us like digest the secrets findings. As a team we've set up. Three meetings the first is totally, it is optional and informal and will be me reading out the. The secret to features prioritization survey responses with some pms like cross functionally pms so they'll be like in that report we can do like a Q and a and then the second we give no member. We have a think big set up. And so y'all should attend that and I will. Maybe easier from me just to post the slack. Meaning but there's two such the slack of the slack comment where I linked all of these things which is in the city channel. But there's two time zones so that should hopefully work out for everyone. Hopefully you guys can attend that and hopefully we're getting this on your radars brilliant enough. So that you can plan around that. Okay, there's the slack. Sorry that I'm a little just can buy really did. No problem if there's anything that we can do to help for Q gone at the very least let us know. And take time to rest. Sorry about the coven situation that's tough that really bad timing. I know I was like well I'm going to I was like it. I have a whole plan for like quarantine when I go back. It's just yeah and all of you I think even if you make it all three of we should be really cautious during the event. Yeah, though at the last one a lot of people kind of had it. I was like really like OCD about it and I put the did you know this story I was I didn't get it I could kind of traveling to Spain and then I came home and my partner had it. I don't know. I remember that. So it's just you know whatever we can do. But but yes so Gina we're going to need to kind of decide today like a backup plan for that yeah the inner. It's stuff yeah okay we're going to probably need to meet and we just because I can scope down that whole project. Okay if we want and so it just depends on what you want to do I had even talk to James about. When we met to talk about the thing big James and I had kind of talked about scoping that down anyway and just making the question could we do this research. So it kind of scales it back but yeah hopefully we can find some time to meet today to go for that stuff. Yeah definitely I'm around like all afternoon. Okay it's fully fully available so it's do that. Right well I think that that was all of our items anybody else have anything that you wanted to talk about. Now all right well have a good rest of your week and talk again soon. Bye everybody.",
  "All right, so this is the CI CD, UX-NET for September 21st. So first of some standing announcements, right, and update. So okay, our progress, get left a comment here about the SUS, the S2 issues for package. There were plan for 15-5, they're not going to be able to deliver that. they already left a comment in the mirror, you're lying on this. Emily, I know that for release, everything's already done. And I think we have a couple of issues open for my client, authoring. But yeah, what I just want to voice is, if in the future, or we are looking at, okay, ours, right, they relate to SUS or issues that, yeah, we have a commitment to deliver. I think it's good to align with the stage groups with the teams that if you're not improving, they use the ability to the commitments of the OPR, then what is the improvement that the team is proposing, right? So that's, we make sure that we're talking about a trade-off and not, yeah, we de-prioritized things happen, but what's the plan to later prioritize those issues or the usability improvements or what are we, what are we training off, right? So I just want to put this comment there, but thanks, Katie, for leaving the update. And then next up is the tele-assessment. It's coming up soon. We're launching media October, so October, October November, we're going to have the tele-assessment. Logistics, closed, exact dates, TPD, so I link here, the handbook page. And I think they're also changing something's in the process. I think the team member assessment is going to be optional. The manager is mandatory to member optional, but that might change. Now that we are under product, things might change in the process. So now, I am an manager is going to update the team, but keep an eye for what's in the page. And Katie's not here, but I'll make the announcement since this is going to come out. It's going to be a public knowledge soon. So Katie is going to transition to the machine learning team, so they applied internally and she's changing team. they would be managed by Tory, starting October, but they was still recovering for package half the per capacity and team in backfield, the low. So she's transitioning out in 156, because this milestone she's doing beautiful in my UI, but once that ends, she'll start onboarding the new team and then she'll be able to run in the backfield. Which I'm getting very very set to see Katie go, but it's such a great opportunity and I think she'll do great in the machine learning team. Right. Gina is not here today, but I'll just quickly go through them updates, run it to sleep. Was it evaluated at complete? That's huge, right? You can check the updates in the VOMTL project. And then they has an async comment here about browsing a job artifact file. They're going to be working on making easy to find the file in this particular issue, which isn't here. So we can find more details. Is that, oh, it's an actual, it's an insight from fully disability. That's for pipeline sites. Right. So that's that. Emily, do you want to take over for four please? Yeah. So I don't have much of an update. I'm catching up on like a little over two weeks of pedo today. So not much from the product to update, but I will be hosting another really office hours tomorrow with some focus on like UX and front end. So how community contributors can get UX feedback, front end feedback on their contributions. So I'll then update on how that goes on our next meeting, but excited because our last office hours had a pretty good turnout and people were open asking questions and everything. And looks like the ticket is also not here and is on some time off today. So. I think I've got a Katie's comments as I mentioned, she's working on really finding out why this milestone and now that also the Nadia left, like it, my is less than what's yesterday. Katie's taking over some of the issues and some of the proposals that Nadia was working on less milestones, so that's super cool to. And then which is working with on right from then engineering. And then we have a comment here. Do you want to put a stand. Yeah, so I came up with a bunch of ideas for beautifying our UI, but our login page ended up taking the whole milestone. So I kind of have a bunch in that issue that if are any are interesting. Katie can kind of take them over. And but yeah, our login page went out, so that's really exciting. So yeah, you'll see a different login page down. I was like, oh my god, it's in production. I saw that's a earlier this week was nice. Yeah, thanks for that. Thanks for the heads up there. And then I'll just read out Katie's second point. They're working through us adding a banner to the product UI as a call to actions for survey. Costing was stretchable for recognition, reaching five. Erica, that's a good. I hope with that one. A little bit. Yeah, so yeah, so tell me more about that. It's with you. So they're working on the integration for package and how they're going to support that. And so they wanted to get just like tactical quant data around which packages, which types of packages people wanted to import and then like how large they are. And I think they're asking like a background question on company size. But that's when we don't want to do via email campaign because it will be hard to find that. But I think that'll be really helpful and because we asked it in a more global way, which is not like just that that one are the factory migration. It should kind of help the team if they can get quant data around like which one might be next to be somewhat people are asking for. So that's right. And this is going to be rolled out in both sass and self hosted. Great. It should be. We should follow up. Thanks for making it about that. Yeah. I'll be here. Erica. Thank you. Julio. And then the else. Yeah, the comments on the on this one. You know, just jump to I'm reading out all the. Where's our team like people are going back to the you know, all in different times on so it's funny because they had everybody like. Like for a period of time, that was nice. Nadia. Let's get lab and then Kevin Kevin commodity brought design it for growth. He's going to be covering for pipeline all three as a borrow until 158 so we'll be allocated 60% of the capacity. And I'll link here the transition. For a pipeline all three so you folks can see work. And so Kevin will be tackling mostly the some of the research items Erica there were a pending order on going for pipeline all three so they starts looking to this tomorrow and they started onboarding on the production next week. And there's already a plan with dove with a PM about what are the priorities. So we have. And there's that issue. Other than design issues for the. CI CG templates. There's a social validation for the catalog like the the EAMO syntax right breaking down that one and also secret management. Not if finished off the jobs to be done, but then. I know the dog wants to prioritize secret management and then start to design work so you have to ramp up on that. So if they asked for anything and then. Now just let me know also so I can we can help them out, but I think it's good to triple check if there is any research. Fendi or if there is any if the plan so if I quite already have changed. So if you need to know was an F dove because he's on this making those decisions right now. And then there's also solution validation for retrying trigger jobs. I don't think they has started. Mother has started with that only yet. they just has the issue. So I I was thinking I'm I'm so glad that was so quick. Yay. We have the plan out there. Yes. And I was thinking that I would create an issue to like walk people through all the research to date. Because we have like a research program around some secrets. So good to know I don't have like three weeks. But I do that next few days and then. Like link link Kevin and then I will also invite them I set up a bi weekly meetings every two weeks with dog. So I can also invite Kevin there and then if they has any questions I did get some resolution yesterday when I met with dog about. It's a double negative but it's like should make the unmasking. A default the ability to unmask or unmasking. I default and not yet had paid. And and was wondering if we needed research and you had suggested to them that we might do it at KubCon. But I resolved with. Do yesterday that we don't need research on that. In part will be my announcement later. We have we were able to. Because of Gina's help and not to be able to use those pilots to just get great data. So we ran 11 participants in our secret workflow and we saw that. Debugging specifically. They're using unprotected secret value. And they're using the CI CD variables. So. While it's not good practice. Yeah. We also got one alienate users. And one thing that one of them said. So the prompt in the study is like, what if we encrypted these values, what would you do? So that would be like the proxy for if they're inaccessible. And one of them was like, I'll file a ticket with get lab. So. Look at the full of like we don't really need a mass amount. In flex and our tickets. Right. So yeah. So I'll find this. I will make a note to comment on the Erica to find issue. And make a note. We need more research. Like we're just going to make it configurable whether or not the default. Yeah. Okay. Yeah. And I think that when Jackie and I did the initial Robin validation for sequish management like two years. Baty it didn't have years ago. We all I also remember hearing this type of feedback that's why it's experienced materia like checking with Erica, maybe you want to ask people. It's not anything has changed. And then indeed like vault and then sequers management that's why we want to separate CI variables from city could. OK. Yes. Yeah. We're all right. Pat and then also with our. With some of the changes in the survey. that that one person was like, I'd file a ticket. So we want to like in place have the like documentation around what to do and like think even the release program. Okay. Awesome. Um, Binging issue. I'll give some of my updates after everybody will with sort of their items. But I also have context and I worked on secrets management before. So I can help out there pointing out to whatever. Uh, maybe historical knowledge that that you are in the team might need. But I'm not sure. I don't remember exactly don't told me yesterday that I'm before yesterday, but I don't know when they wants to scan to any of the secrets work for design just yet. Uh, they has a the team has all this large stuff to work on like the secrets and then catalog and the trigger jobs and then trying to make a business face for something else. But I'll double check. And what one more update around this would be that I saw that the engineering team was like wanting more preparation for being tagged and needing to respond to stuff. So to be proactive about that, um, I asked them if they could set aside a little time for plan. As we get who come secrets research like that should be big juicy stuff. So we'll want them to like digest it. But we also want to ask too much. So the plan is the first or second we can November to set up a thing big, think small. Exercise around that and those might be. Uh, with the idea that that's like low. That are we think just brainstorm. That's like, I was like, should this be a thing? But it's like, no, do it sting everyone can brainstorm and then they can like let go and walk away. But okay. Yeah, have you talked to to Mark about that Mark. Okay. That's close. Another, but these are the three loops to close. Okay. Yeah, that that has been a challenge because they are they're working on a lot of stuff and then. There's no buffer to to into a lot of things. Yeah. Okay, let me know. Ping me in slack and then there's a thing around that and I also try to. I don't know, do my magic. Hey, yeah. Okay. Awesome. Um, Cool. You know, um, Erica, do you want to go over the research parts go through wheels and your full such you? Um, and so I know that they has a draft of their benchmark report, which is really good and exciting. And so I'm sure he's really excited about that. Um, they also had the assistance performance workshop. I think I was sick. I was sick. And so I missed it. But one of my things is to watch it. And I'm excited to see how that worked even with our team, right, of doing the sink. Um, because I have been like, no, no, no, we should never do that. But I think it went really well. So I'm excited to watch it. We should maybe link to it. And then mine are just that we have these four reports on the secrets secrets in the workflow. So it's the debugging workflow creating a CI template. Creating a secrets policy and what happens when your block when your MR is blocked because you have a secret value in there. And so with TLDR debugging, we need the unprotected values. And so we need to solve for that. And it will create a bottle of vekin that workflow, especially because the ops are usually the only ones who can access those values. So there's going to be a back and forth. That will add time. And then we know that that's don't sell a bad best practice because they don't have time. And so we just want to solve for all those things. So that's the debugging. And then the MR report, we want to look at. I want to look at what happens when your block and now we want to look at when we go to a coop con. We could unblock you in advance. Or like I'm one of the things was that the team said. The the create team said that they have something already in place to prevent secrets from going into repository. But I don't know the values there's new about it. I think why. So I think that there's like a grander thing we need to do, which is as we roll out our secrets solution, we need to be like, and have you. Do you know about these things right like so I won't just be like with dove and team are working on it will be like our suite of offerings. So we can put those together based on this finding. And then part of the creating a secret policy which I think is helpful for us and will be helpful for. And so the thing that we're going to do is to know that is like obvious, but it's important is that as they're creating a policy. So there's like three drivers for the policy developers. Ops people or compliance requirements. And so because the ICD variables can be a secret or not a secret and explicit step for them is like, okay, is it a secret? I thought it's a secret and I think that's really helpful because. It's not on my rodeo, but for the design calcable who are like, we're trying to figure out what the elegance solution is. Maybe building on that decision process until we have a long term secret solution will be helpful, right, so like if we think about how to clarify all that setting stuff so it's not. So, complex, maybe you surface the complexity after there they have about decision, but this way I'm always happy to hand off. The artistic or like the like design problems, but. So I think thanks, Eric, that's really helpful and. I think. And I didn't have to get them also like some like there's an issue with like a list of things around secrets that they thinks that they found relevant rights to onboard a ramp up on that. I think we can follow up that when that with with Kevin. See if there's anything else that they can consume many other information that it's more up to date, like what you're saying about the reports or yeah just stuff that will be relevant not just to build that like. That knowledge of secrets, but here the things that we need to address now. And as you say, building that decision process. Make a nice. Yeah, actually simple. I remember I did the UX I did a mature to spark art with the Jackie on vault integration. Many moons ago and no one to complete this core card with this scenario, because it was so complex to set things up. So yeah. We'll see. Yeah. Awesome. Anything else? Any only cool stuff. Actually, I want to I have a comment. That's what I learned to talk about. So we're going to have three openings in our team team for out of the line opening soon. So for packaged for five planning sites behind another designer. Gina will be moving to runner full time. So now she's played right right inside the runner. So Gina will move to runner and we have pipeline altering. So I'm working on the requirements for the roles, but once I have those open and we have the jobs postings. I'm going to share with our team and you know someone already that you think you're not going to fit for our team right. And in my way, we got to tell them to prepare their. We're thinking profiles and the CV. Um, because yeah, so we'll be three new hires this year for all teams really and we are back training. So yeah exciting times. Any questions any other thoughts anything want to share. I just have one thing to say. I was going to say one thing about. I was going to say one thing about. Just learning the transition from packaging I'm thinking that I have like a gold project. That looks at the lifecycle of an image that we wanted to. We were planning for me to start executing on then I'm meeting with. Can't until today to talked about research priorities but maybe that's another reason to wait. on that because we could bring that designer in and Tim said also that they might hire a new PM for that. Yeah. So maybe that's like those two things are enough to make me, I mean, on the other hand, if I can pull it off myself, that might be helpful for that. As they land. So, but I just wanted to say out loud, but I, that made me debate more if I should meet on that. Yeah, checking with them and then I'll say also make your recommendation, right, because she's she's still now she's they won't be covering for integrations anymore. And then I also don't know when we're going to back feel the role right and maybe that when doing a liking a monitor to or for months hopefully not. But if it's a go project and yeah, there was a plan to execute this year, let's say. Right, then team, I think they would only to make some tradeoffs because Katie will only be at 50% of them capacity. Okay, this and then the common milestones. Just exactly why I said it out loud. Good job. And then also just to say like, I think it's really great that Katie is like worked with us and then we'll do the ML thing because it has really good. And I'm tired of our team right. Yeah, I also thought it was I just saw them integration step because they had a question in Slack and I thought that was smart to like, oh, I think it's just make sure that we're. Really touching all that it's good it's good though, because I think like we want to figure out how to cross policy. exciting. It's a huge product, you kind of have to do it. I'm leaving now. I'm looking for a complete different area different perspective also. It's difficult to know. No one knows everything, but it's also difficult to be in that context without actually working on the further area. Yeah, awesome. Right, I think. I think that's that. We can let we'll know that we finish without him. We finish the scene. Yeah. And then I'll see you. I'll see you next time. See you. Good. Bye. Bye.",
  "Okay, hello, it's August 24th almost September, which is crazy. This is the CICD UX meeting and there's just one announcement that we have friends and family day on the 29th, which is Monday. And then, hi, on ahead, I'll also ask for us to just give progress on, I think this was supposed to be for Q3, okay, ours, but it says Q2. Does anybody have anything that's like blocked or at risk? Any other announcements or general stuff? Okay, all of, I'll move into the items for PYBITN sites and runner then. For runner, we're running a category maturity score card for the first time ever for runner fleet. And going really well, where I've done four sessions, I have one more scheduled for next week, I think. And we're shooting to be score that complete. So right now we have that for those four participants, we've gotten to that score, so we'll just see if we stay there. And then for PYBITN sites, this was something I wanted to share with the group, because there's a lot of overlap with our groups. I'm just going to share my screen. Okay. So we, in a test report for a PYBITN, if there are child pipelines that are included, then the tests from that child pipeline will be aggregated into the single report at the parent pipeline level. And the problem is the jobs, aka the tests that are in those jobs that are listed here, we don't like tell you if they're from this pipeline or if they're from the child pipeline and there can be many children. So what I wanted to do was indicate which jobs are from which pipeline basically. And I, I, I added this child badge here because it looks like we were doing that within the pipeline visualization, I'll zoom in a bit here. We use this like child badge. I thought it would be a good way to reuse that pattern, but what I did differently was added the pipeline ID because I assume that there can be many children and I wanted there to be a difference. And then I was thinking that you could just click on that badge and it would bring you to that child test report. So it would be like a similar page to this, but it would just be for that pipeline. Is there any feedback that you have anyone has on this? I have a little questions, which I think you both human not yet could answer. So when I come to this tab on the pipeline overview page, I expect the experience to be like very similar to what I would see on the job stage on the job style, right? The next. Now I have added a link here in the agenda. That's for one of the pipelines that's running currently for good luck. And when I navigate through the multi project and the child pipeline like upstream downstream, so what I see is the list in the jobs, it doesn't change until I go ahead and select the pipeline in the craft. Like for example, if I'm in the first pipeline, the job list is not going to have the items which are in the child pipeline until I go and select the child pipeline. Okay. So we don't show the jobs for child pipelines, basically at the parent level. That's what I failed when I checked this in the morning. I'm not, I wasn't aware of this actually, so I had no idea that we have some kind of connection there. So just to confirm when you expand the child pipeline in the pipeline graph, only then we show the jobs from the pipeline in the job staff. If you just look at the badge and see when you know clicks on the on expanding the downstream, it doesn't change. Like the number of jobs inside the tab, it doesn't change at all. It doesn't expand and it doesn't give a new list until you click on the pipeline, like child pipeline numbers to express the name that now I'm looking at the details for the child pipeline. Oh, like that. Oh, yeah, make sense. Yeah, I mean, it sounds like an issue. Something that we have to consider separately. I have never heard this come up. Yeah, it seems reasonable to update it if you expand the graph. Right. What you guys doing is they experience that's expected, but the overall experience for the job staff, it needs to be a bit as well. Yeah. So I have a comment around the, around the usage of the badge for this. So currently the badges on the child pipeline are not applicable. They're just meant to show you the type of the item that it is and oftentimes the badges in the UI are not applicable. So they don't have a strong visual affordance that you can click on them and users are not necessarily used to that. So my concern would be that this link would not be discoverable. And also placing the ID inside the badge makes it kind of more difficult to read in a way because it's together with the child, the world child and makes more difficult to copy and paste it. If you need to if you need to search for the pipeline for example, so these are just like my thoughts on using the badge here. I do like using badge for the child just to show that it's the child pipeline because it's exactly the same what we show in the pipeline graph. But maybe the ID could be a separate link or yeah something that the user will immediately see as an navigation item because we do use a linked IDs a lot in the UI to navigate between five clients and jobs. Okay. Yeah, I can play around with separating it out. I agree. I like the reuse of the badge just because it's already something that we use. And I was thinking of maybe doing a full other like column that includes the pipeline ID. I'll all think about that more though. Also, this might be unrelated but we were actually finding the opposite where we had a success badge on the deployment, the environment page and people thought it was clickable. Even though it wasn't because it was a badge. So I think I know why because of the badges on the pipeline page. They are pickably. Yeah, so I'm wondering if you could style the badge a little bit differently where it looks like it's clickable. I don't know what options for badges there but I feel like if there is like a badge version that looks like it's clickable. And when we made it not clickable, people are confused. Is there any guidance from pajamas about whether or not these should be interactive elements? I think they can be both. Okay, cool. Yeah, I'm trying to think of like issue labels. I guess those are technically labels not badges. But those are clickable. And sometimes not clickable. One other question I had was just thinking about like the idea of having the sophisticated simplicity like thing that's going on right now. I was wondering if it made sense to maybe keep this like the child pipeline test collapse by default because we do that in the pipeline too. Like you have to expand it to show the child pipeline. So I'm wondering if it will be worth exploring, I don't know, a show hide like toggle to show and hide them. It was just a thought. You mean in the pipeline craft? I mean like in this all-moved list. Yeah, I mean like a toggle here. It sounds like something that could be also a filter like a drop down because you would filter by a type of job sorting mechanism of sort. That's for the bridge or triggered jump can be expanded. Like the job that's calling the downstream or the child pipeline that can be a little that can be treated differently visually and can be an option to expand it and go up. Am I just be something that I need to like, validate a little bit too? Because yeah, I feel like I don't feel confident enough to be like let's complicate this by adding filters just yet. And I think you know what what you can do too is come up with just two or three key tasks and then look at the impact on the flow. But I'm thinking that we want to optimize for when they're debugging. Yeah, that's a good idea too. This stop sharing. Thank you for the feedback that was really great. So everybody in the on the call. Like live brainstorming. Okay. I know it's very useful. My last thing, I mean, we can take this ace a sink if we wanted to. But I just feel like I'm taking forever creating issues with the feature that feature detailed template. I feel like there's a lot of different sections I need to fill out, label the ad. I was wondering if people had best practices around making it more efficient. Or yeah, I just wanted to say that I can relate and I don't have any specific tips because my process manual, but I see that we think a mentioned templates and I can also second that is very important to use templates. Yeah, but it doesn't really solve. I mean, it applies some labels actually, some basic labels. So yes, mostly you have to delete what that is. But I'm talking in terms of efficiency because you highlighted that Gina, I would say, it makes you efficient, but you're not very different. For example, it really makes people think about the problem statement when they're filling out this detailed template. So in pipe and execution, when we started to get to the like very heavy battle of that first therefore, it doubled about 3.5,000 issues. So we started to be very careful about like what exists there and what we need to process duplicates and what is not valid anymore. But we started to notice that people open issues with just two lines like, this is what I want, this is how it should be done, like with proposal. So we started to like discourage that and every issue when it used to come to me for charging especially through that body should that's created over the weekend. I always used to make it a point. I still do to like request people to like apply the template and fill out the questions. And that has really made everyone think about the proposals that they're trying to put across. Like what isn't that they're trying to solve? Who is it for? Is it just for that one person? So even it feels very heavy to do that at that particular time in pipe and execution that has like really helped us. I just had a comment that I don't currently use templates. I totally get what you're saying though, Vitaca. I guess I don't know if it's required to use the template, but maybe for me the reason why I don't is sometimes we'll just have like a small bug or something that needs to be addressed and I never want to be barrier to document that in an issue and it can always be refined later. But maybe I'm a bit lucky that when my team is creating issues they usually have a strong why and like a you know like maybe I'm just a bit fortunate in that regard. In terms of expediting I set up a keyboard shortcut in system preferences that will apply the kind of like 10 most common labels that I use. So then I just literally just have two two key strokes and then I have like a the labels and then I could just edit them from there. That has helped a bit. That's really cool. I didn't even know that that was a thing. I can make a like a like a one minute video of how to do it and I'll post it on our channel or on you access something. Yeah that'd be great. Please. Yeah that would be awesome because I remember when I had my coworking session with Vitaca I was asking about like how do you copy and paste labels are there a more efficient way to add the same labels to issues like creating UX themes all of them head the same labels but I had to manually add them so if there's any way to speed up that process. So I use a very bad little bit so I keep like the shortcuts to create those labels that I have to based on the issues handy on my note that. So I just copy based. Very cool. Okay. Thank you for all the conversation Emily. Do you want to go through your items? Yeah so my first item is release held office hours last week which was actually a huge success. It was a surprising how many people we got to attend the first one and during this time office hours we really walked through like how community contributors can contribute like open the floor to ask them questions. One of the engineers kind of went through how to find issues that are available to take on and to centrics on how to get help on MRs like how to tag us in those. So it was like a very helpful thing to do and we're planning to hold another one in September around UX friend 10 which hopefully will increase the amount of like community contributions we get since I know that's a big thing right now. That's the exact thing I pointed out to my product manager. I guess within the meeting that Chinese had an office hour I looked at the agenda. They clearly they highlighted the opportunity for a contribution so well and like I'm not sure if we have the bandwidth to do this at this moment but yeah I'm really happy to like learn from it. They call that meant. Yeah and I'll just some of the like main questions we had were just how to get feedback. So people who wanted to contribute or curious about like when they should like create the MR can they do it when they're still working on something if it's still a draft and how to tag people to get feedback on things. Tips on how to find issues in like the languages they're comfortable working on and all of that and we also had some questions too that were a little topic of how to look for open jobs at GitLab. So I think just be aware that some people might be coming in because they are also interested in working at GitLab and having answers to that. Yeah that's true. I just I'm sorry. Oh and I'm just saying like a closing statement like I hope more teams are able to do something. I put the question what are office hours in this context but I'm gathering that you you had kind of an open conversation with users of GitLab is that what it was? Yeah so what we did was we created a I think is on needup.com just like a release office hours added in an agenda and then the release team kind of advertised done LinkedIn are we kind of went to our older community contributors until then that they could come to this. So we like advertised it out a little bit to just the broader community who would be interested in seeing how really worked to come with questions and yeah it's like open to absolutely anyone who's interested. The only thing we did learn is that it's important to have this figure like meetup or another site and not just have an open zoom link because apparently zoom bombing is like a big thing if you just randomly put a zoom link out there. So having kind of like stricter access into the meeting was important. That's also a such a good idea. I'll have a closer look into it. And then the only other thing is on release for planning and onboarded onboarding focused improvement to our empty state pages because we realized kind of across the board of the empty state pages they're not very like they're all slightly different design-wise they could have more helpful like CDAs for people just landing on them. So this is like an idea we're doing but just wanted to share it out because I think it's helpful like across all stage groups on that get lab. Well then that's it unless there's any questions. I have a quick suggestion for the empty states just like a quick study that I have I don't know if there's probably reasons why you did this way but it would be interesting to see the buttons placed underneath the empty state you are copy and say the station so I think this is how we usually deal with those empty states but I guess there's gonna be like a table here or like a list of items and then the buttons will be at the top but I think usually what we do is we have the action buttons inside the empty state and then once there are items to show then the buttons are placed above the items list. Yeah I think right now all three of the empty states and deployments are at look different so I think the first kind of like getting that CTA the CDAs to be consistent across the three of them getting like a good CTA and I think some of like the copy so I think there's some really simple things we can do to fix it up but yeah the main yeah sure the main thing is yeah like you said I think the CTA on the release page is up in the top right corner which is kind of the things so I think just ending the CTAs in the empty state would be an interesting one to do. So um if that's it I can pass around to VitaCath. Okay yeah so I wanted to update about the insights that I've known through a very recent validation exercise that I it was unmodulated on user testing and it kind of gave some good like beeping to how users are using their username space today and what kind of projects they host under their how many projects they host. So it turns out that users usually put just like small personal projects directly under the under their namespace and those are not kind that are very engagement heavy like it's something that they only interact with by themselves and um that's the reason like they also don't have much concerns around what's the CICD minutes consumption because they might not even be a biophype like for this project and there is no contribution related to consumption for sure for these projects and that applies that there's little or no need to control the mid-consumption and user namespace related settings. I mean we did provide them with certain tasks in the test but it was really difficult for them to go through those setting options which are existing today it was not even something that I had added on the top because something that had been there since long for example we are still able to see the usage code for the projects which are directly under your namespace through the user settings usage code page but the way we land on the user setting is kind of here because today if you click on your profile picture and you go to preferences that takes you to users settings preferences and for me that has been my gateway into the settings and that's how I always land there I don't know if there's any other way that someone else uses and that gives everybody an idea that maybe it's just something that's used for customizing like how it looks for you and like not do anything deeper than that. So some resonated with this thought and the others expected the quota to be controlled through the existing usage code app because it was fairly clear for them that this is code and I'm getting to control my code as it has to be through this data but the interesting part is we never do that like so far we have never done that it only kind of shows you like what a consumption is like but that page has never historically been used for allowing users to kind of set any configurations as far as I remember it's mostly just to view and like consume the information about the consumption. Now apart from that what else? Yeah so this feature as we had already expected is as mentioned that it would be more useful for groups and subgroups. Now I'll give a little background about like why we had started with using namespace so this feature is a cognitive only allow users to control their minutes consumption. Minutes is the resource that's required to run the pipelines. The only allowed them to control this through the admin view and all that is done today is the admins are able to add like standard cap to the usage so they can define like all the groups can only use 2,000 minutes like they cannot exceed that but at a more granular level like when it comes to projects because a group can have a lot many projects it can have subgroups and some groups under that and under that many projects so it gets pretty complex. Now at project level maintainers who are working on this projects they would want some like some sort of control because not all the projects inside a group or a subgroup has the same amount of importance so they would want to make sure that this particular one that sees a lot of contribution from my users and is very critical to our business should always be able to run its pipeline and it shouldn't happen that this other project that's like badly to it which is not as much of a priority to us. It ends up consuming all the CIC minutes that's a lot into the screen. So to avoid that situation we started working on this feature but right like why we were having the discussion on how we would make this happen. Be realized that the moment we like touch upon groups and subgroups this is going to get so much complicated because then we have to take into account like how there'll be the subdivisions of the minutes and how we'd be surface the quota like this much out of this much is used by this group. This is what you're left by this is what you can do with it. So we started with the easiest path available so that we can also validated. We started with using namespace because that's like flat that's just one never like the projects which are directly under your business space and once that happens what once we get good insights from those we decided that we'll create issues and we'll make improvements and then we'll move to group subgroups. I see that we're very close to Daemon Naniya also has to go so I'm having the day questions on Slack as well and I'll pass it on to Nadia. Thanks, Vedika. Yeah so this milestone I'm participating in beautiful fine UI. There's an issue where I'm gathering all of the ideas that I want to work on brainstorming some solutions. So I'm trying to keep it like one thread for one improvement. So if there's anything that you would like to work on but maybe your team doesn't have capacity or anything like that feel free to drop your ideas into that issue and I can't promise that we'll get picked up because also the engineer I'm working with they has a limited capacity this milestone which is unfortunate because I dedicated half of my time to this and I think they dedicated like 20% of their time to this. But we're going to choose like the top impact maybe also easiest to do kinds of improvements and run with that so drop your comments there. Yeah I see that you have a lot of suggestions but let's give it only for the sake of time and another thing I wanted to share is a result from the secret management. Chopstead we done research so it was meta analysis of existing research that we have around secrets and there's lots of great insights that come out of it that you can check out in this issue that I linked. I summarized everything in the issue description so you can just skin through that if you want and one at the point out that secret is our top priority right now for pipeline authoring. Generally as far as new features are concerned our main focus is secret management and the SISC decadalic work that we're doing and there's NMR for updated secrets jobs to be done and there's a lot of overlap there that we're finding with compliance and security so we'll be collaborating with those teams to make sure that we connect the secret management work flow to management of your security policies and compliance policies and so on. Yeah and that on to Katie. Cool I first once just an FYI in case people don't know we have a dedicated product analyst named Nicole who we can make UX data requests to they can help with structuring the kind of the right questions to ask to move bias and implementation in the code for tracking things and then also SISC and Stashboards. they is across all of ops so they also works with many pms so she's got quite a lot of competing priorities so they did request that when we are creating issues to kind of indicate the urgency and the priority but I just didn't know that we had this relationship so in case anyone else didn't and not much else to report for package I'm still covering ecosystem until like November but we're working on some process improvements in package about how we refine and how issues come into the milestone and I've also got to the opportunity to speak to a number of enterprise customers because our pms on parental leave and you might have seen Eric and I discussing in Slack yesterday now that I have those relationships with those enterprise customers and tms I would love to recruit them but Eric all wisely pointed out that you know we should be really strategic these are very valuable and hard to find research participants so I just wanted to have a group discussion in terms of like does anyone have any ideas about any light process that we could use to make sure that we're utilizing these to the most high value research amongst us or maybe amongst Gidlap in general. I mean one thing that I can add is that I've mainly worked for tms or worked with tms to like get access to large enterprise customers I think we maybe have some within like our first look panel but I'm not entirely sure I think it's relatively low. I think it's important whenever scheduling these research sessions with large enterprise customers since there's not a whole lot of them trying to not overuse and you know over leverage that group because you know they are so hard to access and you know we're essentially talking to like the same handful of people over and over again so that can influence the design even if we do see them this like well they're you know they're representing a large company that has a lot of users we tend to just talk to the same individuals from those companies they're representing their set of users. Yeah that makes total sense. I wonder if like if we have some kind of process that we can also track who spoke to which enterprise customer at which time so that we can kind of avoid what you are mentioning well in terms of biasing for three customers or something like this. And and that's why we have kind of set up this in part one of the reasons why we've set up the enterprise company profiles and personas is that we kind of just want to cobble together all of those interviews and touchpoints and then like abstract them away on what if we can so that we can really do the like small business enterprise comparison so just advertising that we have that so if we can get consent through that forum that's linked in Slack to record and then put those in the Dovetail that's linked there. I have it in Q4 plans to begin to like put those together and when we start on that like in a more full-fledged manner which isn't cobbling I'll be like really asking for help on recruit for that but they won't be in Tokyo for. Oh that's all good. I'm just wondering um you know because I have these relationships now and I would love to just speak to these customers anyway but I'm wondering if yeah should we even just have informal conversations amongst ourselves to make sure that those customers aren't needed or they haven't been kind of overused as well as mentioning or should there be a more formal process or does anyone have any thoughts on this? We could start in that um Dev Kelishu just a table where we mark who we've talked to and bring them I have an intention to bring in the one company that I won't name so we can share this out but that will and Hiana and I think Tina has also met with so maybe there's just like an informal table but if it's in Dev Kelishu maybe it's like accessible we can cross-reference it with the videos we have. Okay cool so I'm happy to create that table. Did you say you wanted that on the get-live issue that's about that at the process or do you want to end off tell itself? I think Dev Tail because then we can okay video. Okay cool yeah I can set that up. Cool thank you. Katie can you tag us once you do that too because it's in my to-do is I'll do it. Okay yeah sure. Cool um I can pass over to Will. Yeah and I guess before I talk about my section just to add on to the group discussion I think this is something important that we could bring to the larger UX research team to talk about like logger term strategy for how we deal with this but I think Erica's on board with for on point with like how we're gonna dress it in the return at least. Sounds good. So the only update that I have is that I'm halfway done with my benchmarking city so I've got 10 out of 20 sessions complete I've added the videos to Dev Tail I'm continuing to get them tagged and I have another 10 sessions of around the next week it might bleed over until at the end of next week but hoping to have it done pretty soon and if they're not any questions I'll pass it over to Erica. I guess so I didn't make a little point about this but my Q3 and Q4 plans are kind of set so in the way that's good for my life but that also just you know that if possible like for example with notias like job to be done stuff I can sometimes fold in or like build out a research question if there's pressing needs um so just remember that we're locked but we have some freedom within that structure and then what I'm working on is just the secrets feature survey and that will help us to understand the trade-offs between the developer needs and the SRE slash maybe security compliance depending on who we can find and we're going to build it for quite some time because to reach those two groups we know we need to go to cook on and then we need to have a long email campaign and so I'm sprinting towards that and then also just say yay for the team that Nadia and and Gina maybe in reverse order I are working on a really cool participatory design activity where we're going to kind of map out this secrets workflow so it's still emerging but it's exciting and and I think we might have a new paradigm there. I wanted to ask about that so I know that there are some feedback there that I was trying to provide and I wanted to ask what's the latest time that you need this by because you mentioned that you want to run the pilot next week and I'm taking the family and friends day on Friday so I'm a bit short on time this week so maybe you can just message me let me know what's like the best way for us to collaborate on this or point me to an issue comment or threat where I can jump in and help out. I think you can come in after the pilots we'll use the pilot see if it stands and how it looks more okay okay sounds good yeah with the secret features we might need your feedback I think we're actually good on it with the survey stuff and I think we'll okay okay you've got well I will catch up with you on select about that as well too Erica do you want to do your oh they they're read only. Well did you want to voice it we have for us yeah so um there was a paper posted yesterday in the security research channel and they said it wasn't a good paper which I think means it's like not we can maybe follow it because it's not that it takes to be complex and good but I actually felt that thunder really helpful because it takes a few competitors and kind of talks about their different roles in access and then gives an overview and it gives not in a way that we should feel like concerned like I wanted to be careful like it's not that they've found a new idea about security breaches but they basically go through and explain how in these different platforms also including our competitors secrets might be leaked so yeah so that's not like a pressing need but I think it's a nice resource and I also did this thing where when I first started and kind of saw that security was one of our product focuses I was watching like devsuck up conferences and taking notes that's kind of you really to remember anyway I turned that into a plus white papers and so I'm like taking notes in that issue as well thanks for sharing I think this is exactly what I need to dive into yeah if anybody ever wonders like what do we mean by hard-coast secrets it's like right there so we can I think this will be a good resource for us moving forward yeah I have one one other question for us before we wrap up would we I'm just thinking about the order that we go in when we're going through this meeting would anyone be interested in swapping maybe next time so that people near the end have more time in the beginning seeing more of head knots yeah I think it's a good idea how would put in please search for a student that is in quarantine yeah we can swap the order of design too so I'm doing it exactly the opposite of what it is today go ahead and start okay cool all right I'll do that next time thanks great thanks everyone have a good day thanks",
  "Hello, this is the CI CD UX team on June 15th. The America's thread and I'll just start by going through some of the manager announcements. So hi, on ahead, added if there was OKRs that are blocked or at risk and if we need help with them, but it doesn't look like anyone added anything. Cool, it looks like we're on track. Unless does anyone have anything for that? OK, sweet. We have a friends and family day on June 24th next week. And then high on ahead, send out a message about midyear check-ins and created a tracking issue for these. They are team member led check-ins to assess how things are going from both the team member and the manager's point of view. And then share feedback to help inform performance and development plans. And just make sure to dedicate an upcoming one on one to do this before July 22nd. And welcome Emily to the team. We're very happy to have you. And then Katie says that she'll be in Europe for around two months starting late next week. She's taking a few days off to deal with jet lag. But that could be a good time to set up coffee chats if your time zone doesn't overlap. I know for me it's like the last hour of the day. Anything else in the announcements that anybody wants to say? OK, I guess I'll just say thank you for the welcome and excited to be here. Oh, yay. OK, so I'll just go. I have more of like updates on my side for pipeline insights and runner. I'm going to go through them quickly since there's four of us. The artifacts page research that I've been talking for. I think for a week now about is finally complete. So we're moving forward with creating the page. It's a project's page for artifacts that list all of your artifacts in that project. And we got really great feedback. And so I'll be making on updating the list view based on that feedback. We also sent out a survey in Erica helped so much with this until to Caitlin. We sent out a survey to validate artifacts jobs because we have no data really around. The jobs related to artifacts so we just wanted to quickly like get something. So we did the survey route. We've gotten 80 responses already, which is great. So we're just going to cap it up that and start analyzing the data there. Erica had asked if I saw any differences in self managed versus SAS responses. Because Jackie, who used to be the PM for pipeline insights had asked that. I haven't looked into it yet, but my assumption is that self managed folks are focused on storage related and management jobs. When it comes to artifacts versus SAS is probably focused on using artifacts to debug jobs and pipelines. Because we have like automatic cleanup for SAS. Beat up. Do you want to voice your question? Yes. So I was looking into build artifacts as a category and I know that both job and pipeline artifacts are a part of that. But since we had stopped using the world built many different parts of the product is there a plan to maybe rename this category. Rename it to build artifacts or what do you mean? The name currently is build artifacts. Is that a plan to stop using the word build because that's confusing to many users. And even internally, it's a very confusing term. So just wanted to ask about that. Yeah, we don't. There is there's no point. But I completely agree there's been so much confusion about if artifacts means like packages or build artifacts. So we need we need to do some type of clarification there. Maybe. I get a lot of we call them job and pipeline artifacts. So there's potentials are just call them that. Rather than even build artifacts. Right. Okay. Well, do you want to voice your question? Yeah. I guess going back to Erica's question when you mentioned that there were 80 responses. I haven't really dug into the data. But how many of those 80 responses were self managed versus SaaS users? Do you know that off hand or have some. And so I don't have I don't have numbers, but when I was scrolling through it looks like about half it was half and half. Which I wasn't expecting I assume we would get more SaaS users. Yeah, usually we've had a little bit more difficulty getting self managed users. So that's that's good that there's more of a balance this time around. All that you know next time we meet all. Bring like the actual numbers and is all exported from. Quaterics to. Okay. Well, I have a question for you that. Ideally. What is recommended like how much of a balance should we keep the sample size for SaaS forces self managed. I know that in our direction as an organization. I don't know if it's a very important thing for us to focus more on SaaS. But at the same time, we also want to understand like. Why self managed users. I mean, what would it take for self managed users to become SaaS users? Any recommendations there. Mm, it's a good question. I think like I mentioned before, we've traditionally had a lot of difficulty finding self managed users. I think at least if you're getting like. You know, 20% self managed when you're specifically targeting a mix. I think that would be fine as long as it's at least 20%. Anything lower. You might like want to like talk with your team about and kind of look more closely at before you. Okay, I say, this is what we found from. Self managed users. But it depends on a lot of different factors. Right. Okay. Thanks. Yeah. I promise. Okay. Last thing was the runner list view. I was also it took on three research projects this month, so I'm which was a mistake, but. This one is the last one. So I did unmotorated research and so on. We've got that and it was purely quantitative data. So I wanted. Hold sessions and I'm holding sessions with customers to get qualitative data to make sure that they can complete their jobs with the new view. And I'll have some updates around that. And we added an upgrade icon if anybody has the upgrades within their area. So this wasn't specific to get lab runners, you would update the version and now we have an icon to represent that anybody. Emily. So I don't have too much to update on just like the next few weeks in 15 to my focus. Really be on onboarding. So I think I've sent coffee jets to everyone on the team just getting to know like the release area really well and all that. So that's going to be my focus for the next little while. Hi, Anna has also given me like two tasks to help me with onboarding the first one, which I'm going to tackle. And of this week, start next week, which is really deploying a project and creating release season get up. And I will be I will be we're chatting gene and I will be taking like if you notes throughout it, I could capture some of like the screens and what the flow looks like for those interested on but yeah, but focus will be kind of just getting used to the journey. And I see will because the question. Yeah, for the first task, I'm definitely interested in whatever you learn. So feel free to share once you have gone through that experience. I'm just connected with so many teams I haven't like dug in deep to understand like that end to end experience so. I'll be interested to hear how your your process goes. And then for the jobs to be done task, is that a plan jobs to be done study. So that one, I'm actually going to get into I have to do task one for so I ultimately haven't read into this one too much. It'll probably done in like the second half of 15 to but. I don't actually know I have to read into this one a bit more I can link. I'm just going to ask you a question with hi on our there's a bit more detail so you can read into that. Okay. There's the link to. The conversation around it. And I think the point of this is really just to I think it was one of genus first activities to onboarding onto the team is like a good onboarding activity. So we can do that. So we can do that. And then we can do that. So I think it's going to be to go through the process and ultimately and growth. We didn't do a lot of jobs we done because we were working cross stage. So it will be my first job to be done here at get lab as well. So kind of just get in process and that. More about later, but. We use it to essentially just prioritize like how researchers are aligned to different projects and how we prioritize the work. Sounds good. I'll keep you up to date with this. I expect to finish the first task pretty quickly. So let you know like give you a heads up when I'm finishing that up and starting with these so we can figure out how to go. Okay. Sounds good. I think that's it. Mine. Okay. I have a lot of follow points from this discussion, but I would like mention those points and context to what I'm about to share. So I recently wrapped up a foundation research for PIPEN execution. I created the job. For continuous integration when I started off, which was about more than one and a half years back. And in the course of this time, what I realized was it was very much based on my very. Like initial understanding of what those teach group was all about and what this whole thing is like what verify stands for in the DevOps process. And I understand that the jobs to be done the core jobs to be done is not something that kind of evolves, but because my understanding evolved of those jobs, I thought, by not like take up a very basic foundational research, which is not very much tied to any specific area in the three categories that we look at. But something which is generic enough from where we can extract the core jobs to be done, the high level ones. So we did that. And because I deleted the history of my browser, I couldn't find the issue. I'll do that and add this here. But in the meanwhile, I, so will you mention that you have taken, like you have kind of did a few JDBD studies. Now, when I went through the whole process, when I read the description and when I wanted to like do things from scratch once more. What I figured was in the documentation we have mentioned that a problem validation is a really good way to go, but from the recent problem validation that we were engaging within the pipin execution team, there are two focus. They were very focused on the specific capability of your specific requirement. So I was not able to get much from that. And that's why I connected a whole new research and with Ericos help we did this in a very different way, which I have mentioned in the YouTube video that I've added. And this is the outcome from that. I know that that's a lot to consume and provide feedback on in this short while, but in case all of you get time, please look at the video and I would love to hear your thoughts around the process. Because I'm also planning to write something about this process and like document it and publish it as a blog. So any feedback is helpful. Nice, thanks for sharing. I'll also add a link to the issue as I find it. You can see that it was all for me for today. Do we cover the April threat, so. How much time do we do have a lot of time? Well, well, do you want to cover your stuff first and then we'll like go back up to the effect that. I did have a quick question for Vithika. I opened up your merger class and it looks like you know you've added your jobs to be done to like a more extensive yearnl file. I think when I've been a part of some of the other jobs to be done studies. They typically will also like. I think add a section of like a product direction page or category page and like add tables with you know the jobs to be done that have been determined based on the research. So that you know once you do like a category maturity scorecard, you couldn't like fill out the scores. Are there any plans to do something like that? Yeah, so the reason I picked it up was I was working on the maturity plan for the categories with our PM. And when we laid down the plan, I figured that for each one of them, we are very heavily relying on the job should be done and the other ones that I don't have enough confidence on. That wasn't a good place to be. Uh, yeah, so once things are finalized and based on that, we will kind of make plan with the research like what's research is. We need to do in the upcoming months like the very close milestones that we need to hit with the maturity. And we usually, I mean, this is how I have been documenting jobs to be done specifically and we don't replicate that to the direction page. We only mentioned the maturity plan. So this kind of shows up in the pipeline execution you a job stood down page that I've set up. And I mean, I myself not aware of there's a different way of doing it. I'm based in the link here for the page where I added. We do the same on the runner and pipeline insights team to document the jobs. I just added that will. Okay. With the links. All of the had a bunch of them, they did not like some of them just never had just to with anything. They were very hypothetical and they were just one person thought to God it as the DVDs. So I wanted to get rid of those as well. Okay. So just to clarify like are. So once that you like the high level jobs to be done are those like mentioned on this link that you just added. Yeah, so the. How they're documented is the high level ones they appear as a once with a more bold title like the shot and one and following that are like what are the sub. And if you can also point me to the researches that you have kind of that's like and also get inspired by the process. Yeah, yeah, can we to the. I'll do reminder, just so I don't have to try to find that in the middle of this meeting. So yeah, I can talk briefly about some of what I'm doing in release within the UX research thread below. So Emily for your. Information. Erica and I have included our prioritization issues. So minds. Right here of highlighted it within the doc. And I basically have like all of the research that's going on in the teams that I cover so I cover all the enablements and then roughly half of ops and Erica covers the other half of ops. And so I've tried to specify to the best of my abilities like which projects there's like a column kind of in the middle of that particular prioritization issue. That says. If certain work is connected to release. So there's about three or four projects in total that are listed within that table. So some of the things that I'm working on currently I've got a research epic for my usability benchmarking study. I've made a lot of updates to that just in the past couple days. So I've added a timeline checklist to that epic. And I'm also going through a set of tasks that I worked on with hyena and Chris. And then. I'm also in the process of making a UX cloud sandbox. So I'm following the handbook documentation. And that project that will eventually create will be used for data collection. Taking users through very specific tasks for release. And that study. I have as close to solution validation study. I think within the past week or so. And then linked actual insights. Actually, I'm going to say issues to that research issues. So if you're curious to see what came out of that work. And what's on the backlog. It's all there within that link. And then finally Chris the PM for the release team is wrapping up interviews for their project that kind of covers a couple different stage groups not just release. So it's focused on Kubernetes deployments. And he's conducted about six or seven user interviews in total. And hopes to have insights later this month. I'll pause any questions on any of those things. I know we put some time aside next week to the Open usability benchmarking for release. So in preparation for that, I'll just make sure kind of to read up on this from any like specific questions along like. Kind of I noticed this is going into like September probably when I'm going to be fully onboarded. So like what I can need to help in the featuring all that but this is great. Thanks for all the links into this and how definitely took a look. I know Chris has talked about the interviews been doing as well. Yeah, I think one thing that might be useful to check out. Within that epic is I went through like a sink mural activity with Chris and hyena. As referenced in the comments section of that epic and we spent about two or three weeks. Going through different parts of the study set up trying to determine what tasks we were going to do. Who we were going to recruit what metrics we were going to look at. So that mural board is linked and available in there. So I think that would maybe be a good thing to look at ahead of time to. Awesome yeah I just is the one that's like part one part team. Yeah yeah so I just I just want to. Awesome. So I think that's all that I had. If we want to go back up to the apric. Stuff. Yeah I think so. They also had already when they have the meeting they took a recording of it if anybody wants to take a look at that it's in the channel. Katie completed a solution validation for container registry cleanup policies and they links the dovetail and it allows the user to set up roles or policies to delete items from the registry to save storage space. Their them findings were in line with them assumptions, but they did discover that users want a way to make a template of their policies and apply them to other projects which sounds cool. Should I read like the whole conversation after that or should I just move to the next. I can move to the next one. Okay. And 15 to there'll be implementing a feature that will release to a small subset of users and monitor with snowplow the reason is despite two rounds of validation we're still not certain if this is disruptive to people's work close so we are taking a cautious approach and this will be. Katie's first time at get lab doing a phased roll out and she'll keep us posted. And finally she's oh no that's not true she's consistently hearing from customers that the integration with package and release could be better. An example of the feedback this captured in that link. Will and Emily that might be good for you to look at. Okay. And yeah they said I would like to work with Emily to share my findings and see about improving things. That would be great. I know I've set up some time with them next week as well. So we can check it out this. Yay. them focus for 15 to will be mostly research heavy and will be improving the package detail page and then she'll also attempt to implement the missing front end events tracking so we have better data of how customers are using the product. That was in sure I don't know if anybody had time to. Think Katie either recorded a video or shared in a previous UX meeting but they found all the front end events like. Through the browser and tracks those and that was really cool. Especially if your team is lacking to the geometry right now that might be a good thing to look into I know we we are on runner and pipeline insights. Not yes said that this milestone and 15 three should be focusing on pipeline components mbc as we're starting to get as we're getting ready to start the implementation 15 four. And we've recently added the guidelines for in product reference information using drawers. To pajamas and that's a good thing to check out as well. I think that. Lots of links so if you have time would be good to do it. Yeah, I'm going to share the issue that's created by. By the product manager of package for those snowplow tracking events. I'll be sharing that with my PM as well because. Yeah, that. We are also facing some issues of making a decision regarding filters and similar functionalities where things are not so black and white. I mean the insights are not so black and white that we've received from the validations and still we have to make like we have to proceed in some direction. And we have to do it cautiously. Yeah, that definitely would be nice. We're seeing like similar trends on both running runner and testing and also even for purposes of like investigating bugs for developers. Sometimes it's really difficult to recreate the bugs. So having more like insight into what was going on with the event at that time would help them move faster. Well, do you want to read through air gust of. Sure, I did notice that we didn't touch on this general update. I think Erica must have added this but. I was like we're seeing a higher overall no show rate for sessions so just ahead so. I think this might just be too to like seasonal variants so it may be. Related to like you know, a lot of people are out or you know have holidays or have you know summer vacation or you know whatever it is depending on where they are in the world so. I just want to provide heads up about that. I don't know if anybody's noticed that with with any of the studies that they've done recently I haven't noticed the ton. Erica and I discussed about this I think the previous week that this has been happening a lot for us. It never happens when we're actually through platforms like respond in but if we rely on the our internal recruiting process. And out males and like nobody responds to them for a very long time even when they do it's like pretty much after them whole analysis is over. And I am not very sure if that's for. That's that's due to seasonal variants but I mean that's how I have been trying to. The reason by telling it's because there's some hindsight bias that's going on here that I'll maybe it's what it's because this was going on they didn't turn up because this has been happening throughout the year and our when we internally try to record users. The reattach which we get a positive reply it's always pretty less so I think we need to figure out what's happening there. Yeah, and I know that we talked about it, which is like the research team last week and some of what came out of that was that, you know, respondents and like a lot of reminders and also has, you know, that panel of users that are more likely to, you know, apply and attend for the things that they sign up for. So there's been kind of some talk within the research team about ways that we can try to remind people a little bit more. So like maybe getting Caitlin involved and reminding them to just send out reminders or if you have the ability to like have the list of emails. And then you can reach out to people before sessions and say like, hey, just ahead's up, you know, sessions going to happen in 24 hours. Can you confirm that you'll be there or you know something like that. Right. Yeah. I definitely don't send reminders. So maybe that should be a practice that we should follow. Same, I don't either and this I can for the artifacts research that I did get a few no shows and some of them like if they missed it, I would email them and be like, oh, sorry, we missed you do want to sign up again. And then they sign up and then they wouldn't show up to the next one. We're done. I had a afternoon a few on morning and to these on growth to where someone wouldn't show up, I'd email, they'd reschedule and then they would show up to the second one. Yeah. Okay. But I can provide some updates once we know a little bit more. I think Caitlin and our other new research ops coordinator. I'm going to try to work on some of that to see if they could build some things into their current workflow to take into account that people need to be reminded ahead of time. Because I think there's a way to set that up through calendar. So that it just automatically does it instead of having to remember to do it. But I'll provide some updates once I know a little bit more. Any other comments or questions for I go to Erica's points. So let's see. She's asking if anyone can link and add the studies that they would like to be included in the verify and package research registry and synthesis and this issue. She's 1738. they is also asking to update studies in them prioritization issue. And then some specific updates related to them prioritization issue. they closed out the ops product direction survey where they went to cube con. So she's included the link to the report there. And has a link to the a sink discussion issue. And I've looked at that report to us very detailed. So I highly recommend checking that out. And then she's got a couple of read only updates. A thing else. I'm not good at pivoting or transitioning. Nothing goes. All right. Well, we get 10 minutes back. So yeah, good rest of your days. Bye.",
  "It can record. And we don't have a ton of items to get to. And I might be able to do one that might be fun if we have a little bit of time. So corporate events, I think I saw a little, I put this in Slack and I saw a little bit of noise around it, which was good. You know, the nutshell here is as we've kind of restructured and tried different things. The event support that we need is as nailed down as it needs to be. So the current tactic that we're going with is go to market team, signs up and kind of sponsors that event. So you support it as a PMM, your campaign manager does the campaigns for that event, et cetera, et cetera, et cetera. I don't see anyone in the, maybe they're comments in the issue. I don't see the header updated yet. I thought we had in Slack sort of farmed each one of them out. That's so I guess the next, so it looks like Ty put in some folks. It looks like this looks good. So that, let's see, needs support from GTM teams. So I guess the ask would be to work with your GTM teams. So let me ask it, I saw some Slack, I think, at R Slack. But did you all, were you all able to connect with your GTM teams? On Slack only and on the issue actually. Yeah, so I'm not in real time, but it sort of speed back. I got one person responsible, so it may end up sending you being you and I just pick in the one that we want to do and then they can back us up. If we don't get anymore feedback. Yeah, do you all, does anybody have like a regular sync still? Are those all been canceled or is there? Okay, so we have a real sec. Yeah, we're on like the two week cadence. Okay. Yeah, good ops has been canceled, huh? After the in-event. Cool, so I'm just trying to catch up with the thread. So it looks like maybe a platform on reinvent. CICD on Google Next and get ops on coupon. Is that sound right? Yeah. Yeah, that's where we were last to hurt. Cool, so then I think, I think we can help the core events team. They do a lot of like cat hurting and you know, keep on tracking people down. So I think if this team can take the mission to like try to help track that down. So if you, you know, get the commitment specifically from your campaign managers. Hey, like we're we're signing up for a coupon. You know, can you comment on the issue that yes, I can commit to this. Excitor, et cetera, et cetera, et cetera. You know, so that just so that they can get that that event support. But that looks good and I appreciate. Thanks for the link to you, Simon on the rules. Product announcements. So I appreciate, Brad, for adding this. I probably should add it, but. I had two questions about that one. One is over what time frame are we looking at. So so in theory, this is this could be the same as the get that 14 lunch where we're saying basically since 13.0. What has, you know, what kind of big improvements have we made. I'm not totally sure of all of the kind of the interplay here, but I think I think this is kind of the general just of this assignment is okay. We have commit coming up. We have some amount of like we have a stage of you know, a metaphorical stage to say something to the world and we'll get some amount of press attention because we're having an event. Right. What kind of announcements do we make? I get lab it's really, really tough to make product announcements because our entire roadmap is completely public. Yadiyada yadiyada. So the thought here is to. But also because our entire roadmap is completely public and because we ship these tiny little NBC's and a new feature will come out, but it'll be not really usable. So it takes a while. So if you look back over the past year and say, okay, like what started in the last year, but now is really like a full-fledged feature, what would we would be coming out of beta, right? Like if we were any other company, then we started a beta program in this last year, what would be announcing is GA at commit. That's kind of that's kind of my thought on it. I see a couple of head now. So what do you think, Sydney? Yeah, I think I was inclined to group some things to say like vulnerability management because there were tiny little NBC's all the way along, but if you look at over the course of the year, we went from this to this. It makes more sense to me to highlight that than in any individual little thing. And then the other point was. And then we had 14.0, can we just can we reuse some of those things and plug them in here? Absolutely. Yeah. Yeah, and vulnerability management was was one of the, you know, the features out of, we looked at 14.0. So I think, yeah, this is like, let's take this stuff from 14.0 and then maybe add a few more so that we can hit kind of different areas of press or give, give our PR team. This is kind of like input into our PR team to give them fodder to go out with. And are we trying to hit three per stage? Yeah, ideally there's just, you know, three, you know, three times per stage. And then I think y'all made some good notes that okay, we need to add managed. So I see manage in here that's excellent. And integrations, we don't. Well, actually we have some pretty exciting integration. So we have the ju, the ju is stuff is pretty good. And there's a couple of things and integrations with the S code that could be notable, but. I can I show what I did for S.C.M. just to get some general feedback on it and if someone hasn't done it, maybe that'll also. Okay, I was going send this direction here, which was thinking, you know, a lot of, and then I call them key iterations, the sort of specific things. I listed a few specific things like three or four per each as key iterations, but I called them something overall. So we would have like one thing to call them. There's several key iterations aligned with a get a little cluster. Several that roll up to a research based user experience. And I was thinking like. I was shy and calling out UX as a bucket except that actually that's that's super typical. And when those 11 or anybody who's rolling stuff out, they almost always have UX is one of their three things. And then they mentioned a longer list of stuff that aligns to that. So I, you know, forgive myself for doing something that first I was kind of like shy about calling out UX and and bucketing some things there, but actually when I looked around, that's pretty much how everybody does. I've been in a big launch in terms of the excitement level that also like I went in thinking this is just a two. I guess part of it is like I feel like we're almost fixing something that's broken and that's not something you want to shout from the rooftops about but actually someone that's really cool. So I gave it a three excitement level. I wasn't sure exactly where to place things. But I figured I wouldn't like the Cindy's comment have something that's a one here anyway. But I the only way I could make sense of like the iterations was to to bucket them with something. And so that's kind of I came down on it. Yeah, I've done a similar I've done a similar approach for monitor with incident management. And there were a bunch of things that we released. Although the core of incident management was part of 12 or X seconds. So I did the same with the address. Yeah, I think that makes sense. Yeah, that would help me with the plan stuff as well because there are some things like epic boards that people have been asking for for years now and they finally have and that's great. I think you know like the the milestone burnout charts. That was a two and that's that's helpful. And I was looking through features and you know actual monthly features that were released in a given month. I mean, that was one of the more important ones, but it's not very exciting, but we can bundle that with some other things and and up level it. So that would be helpful there and also Brian about the VS code thing. And other cool thing about that is both of those VS code integrations that hit the same month or community contributions, which is also kind of cool. Is is that is do we have VS code listed on here. I didn't add it, but I can I can add that in. I've got good notes on that. The extension that had been around for a while became official was kind of one of the things, but there's some other stuff that's a little juice here. And that I think that's a that's a pretty good note as well. We did that with like our our terraform module right there was like a community module, but now it's officially supported so that's that's the you know that can be the line yes or no, whether you can use the thing. For a lot of businesses so I think that's good one to. I think our, we've measuring excitement levels one through and three is. I was I was looking at. Maybe a me you as a metric to perhaps measure whether customers have started using that are interested in using that or not. We probably may not have it for everything, but at least some of it, but it will be have it, it's probably something we can use there. But of course, we need a benchmark level of what MAU we want to call one to a tweet. I think it's a little bit of a judgment call. Like, you know, for example, a core mac was saying, like epic boards is something that was asked for for a long time. Now, depending on how it's asked, or maybe that means it's exciting or it's not, right? But usually when something gets a lot of upvotes or when there's a lot of demand for it, then I would bump the excitement level and something like that. Certainly, it's something shifted a lot of people are using it. That's another good measure. I don't know that any one of those needs to kind of be exclusive. I think it's a bit of an individual judgment call and just like what is, what is your feeling based on, you know, could be anecdotal like you talked to customers and they're like really hyper-excited about this. Or, you know, maybe not, which is okay. I think it's okay. Okay. Our responded to my comment about why we have the low excitement ones and just said something about having them sort of stacked ranked. Yeah, I might even constrain us is we're not going to highlight low segments, but we want to see the full spectrum, especially in the case we have slim pickings. I'll turn it off if there are double j's and entries, then we can stack rank. So that's kind of also helpful there. So if we have three for all of these, that, I mean, it looks like we're going to get there and that's going to be quite a lot of features. I might constrain it like this. Maybe you can only give out one, one, two, or three. And, and it treat as a stack rank rather than just like a raw excitement level that doesn't necessarily somebody's one or somebody's three may be more important than somebody else's one agree on that. And I had, I started by just looking at what was considered a key feature over the past year from from create and, you know, there are at least a dozen things that I'm not mentioning that could be on the list. Like I could give you a 10 things instead of three. Give it, give this just like the rough like pass and like a lot of things recently have and moving between docs and spreadsheet and the spreadsheet to docs. This, you know, this might end up or some iteration of this might end up in a spreadsheet where we then try to stack rank and PR is like okay, out of all of like the, you know, there's maybe 10 boxes here, three, each out of a 30 items which are the top five. Actually, let's just, let's actually just do that. Let's just do this like top top five overall. We did this one is a PR driven to some degree. What about like the new pin christie's product keynote at commit or we that have telling this with that? So this is exactly where this is headed to. Is the idea that during the product keynote and then ideally during kits sits keynote as well that there's some level of like an announcement that we make that then the press cares about that announcement. Again, really tough to do at GitLab because it's all been around for a while. So this is, this is our time to head to that area is to say like these are the announcements of the event. And yeah, maybe it's some things that have been around for a while, but like now they're at a level of maturity. Now, you know, there's, there's reason to be excited about this. So that's kind of where it's coming from. So I put a top five overall. Maybe we can just, you know, you should reserve a spot for plan, but I'm going to have to go through and do some aggregating after this. Just go through the list of what's shipped in last 12 months and re-buck at that. So maybe we can do like five minutes kind of like um just just time box and kind of look at these here. What do you all think is a top would be a top five out of the list of, you know, 20 or 30? I would say if UX does end up being a flag that we fly, that's an easy one because there's more than just maps to the creates stage that would be considered UX improvement. What else? We need to have a security one in there. We could have either vulnerability management or um, I was when I've been struggling with a little bit as I'd like to kind of group the some of this proprietary scanning. Um, without making it sound like they're scanning improvements because that sounds like they weren't good before. Yeah. Let's let's go with vulnerability management for now. I, I know I would agree on that one and I would say that some of these we did do some pressure on and the the fuzzing acquisitions was one thing. So we might not be able to do that. I mean we did the fuzzing acquisitions a long time ago. Was it within the past year or longer? I thought it was within the past year. I think it was in the last the little oversie expanse or so. It was last summer, right? So it was like last spring or summer and then we did another set of press around the integration of it because the PR team liked all the I mean we got a lot of attention on the acquisition. So they had me do a follow up on the integration. I just feel like it's kind of worn out now. Right. That's what I was saying is that the fuzzing we already did press on through probably will not get into the chomp at that. So I think let's go with vulnerability management. Unreviewed. Well we also have in terms of proprietary stuff we've also got we replaced one of our scanners with some group and we did we have our own proprietary DASTS scanner now that's in it's in beta called Brouserker. So it's our answer to scanning single-page applications which represent a unique challenge. I think I mean if I could have to it would be vulnerability management and Brouserker probably. Okay. Some bref that get picked up as a online item in a couple of pieces about get back 14. Which between the proprietary ships of the vulnerability management which would you pick as number one out of those two? Probably vulnerability management. Okay. I'm just kind of scanning the list. Our probably say like Kubernetes agent is something that we've made a lot of investment in. Although. I think the Kubernetes agent and from an integration point of you perhaps the DERF of integration I think we have a lot of customers actually using that already. So I'm going to agree. I'm just going to call those get-ups and I'm going to put like KDS agents plus S-E for integrations. It's like a bucket of capabilities that is probably worth talking about all. Oh well let's you know let's try to this is due Tuesday I think we want to try to get this done. So maybe just review this kind of like let's just kind of pick top five maybe something from plan and something from CICD. I plan editor's definitely an option for CICD. Yeah there might be a sort of a no sorry there might be a value stream analytics story and there too. If we aggregated all it's a bummer that customize the value stream analytics is 12.9. But yeah there might be. Cool then I'm just going to I'm going to ping you on this core back to add add a top five plan. Cool I think. person that's a pretty heavy pretty heavy list just looking at it you know it's pretty cool yeah that's okay. Yeah and this is something we don't do which I agree like we don't we don't often stop as a company and just kind of look at our winds. I was really I don't to jump did anybody miss what do we call it assembly the assembly. If you missed it I recommend I last because like what assembly reminds me of it like when I was in like a early-career child in grade school. Yeah. They'd have this big stack of like carpet they're like squares of carpet and you go like you go into the gym and you pull off this square of carpet and all the children would sit on a square of carpet and that was like you'd have an assembly. Yeah. So that's better to put everyone in the gym or like convert the half cafeteria gym you know take away the big barrier between it so that we can have more room and then take those carpets that have never been cleaned and just you know sit on them and it'll be a regression. Besides it's not from the goofy name I thought that and of course we can't talk about any of it on YouTube but person that was like a really awesome look back at like here's some winds and here's some exciting things that we've done and so I think we just need to get better at this as a company. I think this exercise and opportunity that I think we do a little bit of that but this is doing it more. Sami you have some questions here. For a leader. Yes. So in the competitor sheet I was I mean I've already had the features for CD configures as well as monitor getting it reviewed from PM. My guess was or my understanding was that we wouldn't have the same set of competitors that we're going to compare to but the right competitors for that particular stage. Right so for example for for monitor we may not have like a get-up or something like that we would have monitor based competitors or was that the understanding because we identified that entire list of competitors and partners for every single stage I thought we were going to be using those competitors to compare against. So I just wanted your input on what because I saw some of you have compared with the five competitors already listed over there. They may not be relevant for example cloudbeats may not be relevant for monitors they did all. So that's what I wanted to check with you. Yeah that's the case I need to go back and look at this spreadsheet. I mean if the competitor does not apply that particular stage it shouldn't be on that tab in this spreadsheet. So are you saying that you see competitors on that tab for a stage where they don't apply? Yeah I think it was copy-pasted. Yeah so each sheet has has a DO at last you can get up Jenkins, J. Frog and Cloudbeats. Right so that may not be relevant for monitor for fun figure it would be a different set of competitors that we need to include which I think we already identified the while back I think we identified top three competitors for every stage. Yeah we feared that's only tiered them right tier 1 tier 2 tier 3. So this this where we are right now is we're looking at just tier 1 competitor. That's probably our current pace then because those are all tier 1s. We're just focusing on tier 1 right now. So if they don't apply to that stage don't worry about me make sense. So just pick the ones out of that list that apply to our stage. Right I just you'll be just use the tier 1 competitors and if they're not if they don't are not applicable then we don't have to fill out anything for that. Yeah for now but then we'll move to tier 2 and tier 3 then we'll look at those other competitors. I mean to add a line item for good lab as well because I think that's the same over here. Yeah we should I think you asked me that before right or someone asked me. I'm just looking at it for I announced. Yeah yeah we're good. Yeah because the way without it you're basically putting all the things that we're better at. Yeah for sure. Yeah right so I did. I deal with when we pick like the 10 to 15 features. Those some of those were like get lab only some of those were like get lab didn't have. Well I thought it was supposed to be not none of them should be get lab only right it should be all through the lens of. Yeah yeah exactly yeah it should be like market lens so an ideal world most of them are like this is what I'm shopping for this solution. Some like some of them might be get lab only. Some of them might be like competitor only so that is so somebody would look at it and be like this looks honest and trustworthy and like a accurate assessment of the market. Yeah yeah yeah and then yeah I think some of this just to kind of reiterate for this one we're only doing these five competitors so we'll do the other ones in a later stage and then for if the vendor builds like builds themselves as a platform then we should specifically call out that there you have a zero so GitHub builds itself as a platform it sells itself that way same with Azure DevOps same with J Frog. Well they all do for Tier 1 except Jenkins and Cloudbees. Yeah Jenkins Cloudbees is not you know but what is it you know Azure DevOps GitHub had Lassian and although at Lassians we still need to figure something out there. Right is it matter of fact that I go back and add a Lassian because like based on conversation I think we have to do it I don't think we can leave them off. I don't know if they'll look at this version. Yeah it is Lassian is on that sheet. Okay yes I went back and added them because based on a discussion like my my I wanted to take them off completely and just leave them as a partner but we can't do that so. So yeah so for for those platform you know we should call out the fact that they don't have any monitoring if they have like zero out of 15 we should call that out same with the configure stuff or this you know any those kind of capabilities. Maybe I think if we took that step further to be good to even describe it in the way that doesn't just say our product stage and use like a value based description of what monitor and configure mean because otherwise we're just no that's not going to do any good force. Have you guys seen the new infographic that the design team has come up with? Yeah. All you have it. No. Do we have a link to that quickly? Well you know I don't know. Or you can throw it in the notes if you find it. Let's see who can find it faster. You're taking it with the amount of tabs on how open. Oh my god that's one light it's probably will be made. So this is why I send everything to a Google Gmail because the search is so fast so I literally have a folder where all of my get lab things go and I can just search for infographic. We could look at first. I found it. Oh. So this is the one so there's two. This is the one for the single two comparison. But then for the but it's gone look the same but then here's the one for I just put it in chat for you guys. And here's the one for the platform player. So we made it. We made a couple of decisions along the way. So one of the decisions was to just go with stages. It would have been like a whole nother layer of okay if we don't go with just to get lab stages the 10 stages. What do we use? That has to be determined, reconciled, all those kind of stuff. I don't know how long it's been since we updated those pages have like not been updated. But we kind of are just trying to move towards some sort of towards some progress. So I concur that maybe configure and monitor is not as descriptive as it could be. But the place where it will so actually I'll share one thing. It just seems like the right time to do this, right? Manage is is even less descriptive than that. So so the way this is the way this is getting built is off of a data model. So in theory these could change or be updated where the underlying data remains the same. Right? We're separating like presentation layer from data layer. So that's it's not going to be as hard to update in the future as it currently is where it's a messaged spaghetti code and it's like really really difficult to update. And then the other component is then not in this iteration we need to get something live. But in the next iteration you'll click on verify and it'll go down to the list of the 15 features. And that's where you can describe what the heck of verify is. What the heck of manage. Okay. So we'll have another two that because I was going to say you're not hate me for this but like we're you know what you're being sick of go about the same problem we have. There's been the audience coming in and not knowing anything about these specific stages. Yeah that was one of the big things it's like okay 15 15 features what what is what are they why do I care you know yeah to say that means nothing to me looking at this this page but quick questions. I could be a dummy down there. No we're on top of it. Actually if you read the thread I brought that up but they said we can't do it like right now which I understand but it's small thing what do you just think about the colors. I usually the designers handle that stuff they they like I like I like the fact that there's no red on there. Oh you like that that's what was going for you like it's not it's not obviously negative so we're saying because it really does lend itself to being a comparison more than a competitive piece because of that because there's no you know these folks at 37% are in the red and they're terrible they just have less green or we would have less green so it's not it's not being worse it's being less good. I think that lends itself to working with you know all the co-optician situations we're talking about. Yeah that's that's a goal is we want we want to generate a helpful asset for the industry. This is not just like marketing skill this should be like a helpful page so yeah the goal is to have a comparison comparing DevOps tools not a you know this is all of our competitors and why we're better. I think it's one of my competitive mindset and for me I'm like let's go hard let's put some ran on there and go on that's just the way I think right so but I'm going to have an effort now we're going to stick with the green they work a minute we stick with the green and see how it goes but I don't know I was feeling the creating yellow too. It is easy on the ice it's you know there's something to be said to that so. Yeah cool well we're almost up on time but I did want to share one thing that kind of came in like basically Friday it was like late Thursday for me. So this this is another thing a lot a lot of these things that I don't have a katana context on. I just know like we're just trying to up our game so like hey let's move fast and do the best we can do. So this is a little bit of a messaging framework and then the assignment that was given to me was to to fill in these boxes here. So and then this was the fodder that I got. So there was these ones that said like from roadmap to company vision we are transparent and a single source of truth countless possibilities. Honestly I think this ones are like really pithy and catchy. I really like it. I really liked what's the other one that I like that not everyone does. All in one for everyone so I just I don't know I like I just think so there's something catchy about that but I know that kind of catchy is not everyone's cup of tea. All that's to say is the assignment here was that I took it was to write a pithy. Few words like punchy statement for each of these three things. So I ended up with a single source of truth countless possibilities. I like that a lot. This one I went with end to end control over your software factory. Not as pithy but like not as catchy but I think what I'm like what's the difference between that slide and the next one that doesn't have anything under security. This this was the honestly so that so when I first got this it didn't have this and it didn't have anything under security. So this was like it was your iteration of it. Yeah this is this is mine. This is I just put here so that I would have like the original statements like on it you know automatically anything collaborate on everything. I kind of like that but I you know this one I hate scale up speed up test up. I don't think anybody tests up I think that's really goofy so I hate it. This one I love that for me it's I love it or hate it. Right. I love how I love that. I just like bam. So anyway the what I love in just in five minutes now and then we can kind of and the call is kind of like anything that you would change this out for anything that you would change this out for and then actually let's start here. This one I couldn't pick and I'll I'll tell you why it's because I like things to have parity in in their tone right so this is maybe like super nuanced elements of messaging but I hate it if it's like a single source of truth that's like in noun phrase and then control that's like a noun item so you could say with GitLab you get a single source of truth with GitLab you get and then control and you can't say with GitLab you get move fast with confidence. No but you can't say more speedless risk I like that one the best. I don't like the last one. That's that's why I put this one at top was for that parity and then so it sounds like kind of y'all's thoughts or that's that's good as well. Yeah the only thing it might be missing but I don't know how we do it without over complicating it is well I guess less risk also implies higher quality I guess that kind of bundles the quality and the security together so I've talked my self out of not liking that so yeah good. Cindy's last blog post that a really good turner phrase that I stole for give that 14 and they was out it was like secure the software factory and all the stuff that you're making it. they said it really elegant and it's just kind of deliverables secure the stuff that I created still deliverables. Yeah I thought it was good to emphasize both is that mean yeah. Yeah so you could like secure and control your software factory and it's deliverables maybe that would encompass both thoughts. I'm not a big fan of the it's deliverables is there can we say like your software factory and your software or your software or in your product. Product sounds like car manufacturer. I can say IP here but it just doesn't sound right and that's always to always shorthand. Yeah I like this one better. Yeah I think I do too but I appreciate the thought. And then the last thing I'll say is so this is this was my attempt to channel my inner ash withers. I think ash is like super good at just again just like the catchier like the turner phrase element to it. And so like this kind of idea like single source of truth countless possibilities or all in one for everyone there's something catchy about this so here I was trying to like envision what is it that we actually give you with this velocity. It's like it's velocity with confidence is what is what you get. I like your move fast with confidence better than increased speed and stay on track. Yeah so I was trying I was thinking of like you know if you're like if you're in a race car and like you go like super super fast you're like let's say you're in the bike race right and you're going so fast and somebody holds up the sign and then like half of the bike race collapses. Right. So it's almost kind of like you can you can keep going like faster and faster and faster and if somebody like jumps out with a sign in the middle of the race track you're not going to get tripped up by it because get labs you know it's testing is going to catch that and security is going to catch that all of those elements that allow you to move faster but to do so with confidence because otherwise you're like the faster you go then it gets more dangerous. So trying to encapsulate that in this like that was kind of where I was like stay on track but I didn't like it either. Did you just open the door or mask car partnership? Hey, mask car goes fast and turns left because it get light. So you're a new Ricky body and immigrant. So yeah so I don't think I like that one and then I think between these two I like move fast with confidence but I don't like the the verbage of it because it doesn't have parity so that's where I think. What do you want to add? Maybe we can add high confidence or more confidence at the end of your first statement so it kind of combines on a fit so more speed less this high confidence. I'm just going to overuse anyway like I've seen a lot of competitors of vendors using it I really like the first from just more speed less bam no tradeoffs you know just how it is. Who no tradeoffs? That's one of my go-toes I love that one. This this gets into the no tradeoffs. The engineer in me says there's never no tradeoffs that's like saying like 100% secure. Come flick this is why you always say mitigate right we always risk or less risk you never say no. I'm just more speed less risk with confidence. What yeah. The Ricky Bobby and me really did like the no tradeoffs that Parker. Yeah. Oh is that was that from no but it could have been it's something Ricky Bobby would have said if anyone hasn't seen Telodega Knight's they should. That's the homework for this week and that's definitely not super back and we talk about it on Monday and I live so support. I often say thank you little eight pound five ounce baby. This is the goal of this I say that's so often that I just think everybody has seen Telodega Knight's but then I realize that people that haven't are like things really weird. And then next week we'll watch stepbrothers. That's another great one. So much room for activities. Okay I'm gonna go with more speed less risk. I think this is due at the end of the day so any additional thoughts I'm actually gonna untie. Me it's strong all those are you know. Those are good. Awesome. Well this was kind of fun to do a little bit of like working together session and keep it around as you dance. Keep it rocking. You'd to see everybody see you soon.",
  "So, sorry, this is a good question, Samya, that, hey, as we're trying to plan things out, like, you know, will Harsh have their own take, they almost certainly will. And so my thought is, I don't think that there's going to be any objections to, we dug into Salesforce, and we looked at what the win loss was, and we looked at the reasons for our wins and we looked at the reasons for our losses. And then we even dug into some of those deals specifically, and we found out that these were the commonalities for deals that involve CI. These were the commonalities for deals that involve Agile, right? They tended to use this type of message generally. They tended to go to these personas generally, like, no one is going to object to that work if we can do that research or we can document that. That's my strong feeling, although, like, I'm kind of, like I said, I kind of welcome challenges to any of this kind of thought process. So that's kind of my thoughts, Samya, is that I think that Harsh very much wants to see what's going and kind of keep the ship moving. I don't think they wants to pivot the ship. they wants to keep it moving, and any new changes in insight, wisdom, experience that they brings, I think they wants those to be kind of incremental, and that we all make those changes together. they shared a story with me that was very similar to that kind of language. So I feel pretty confident that we can make a decision now, and hopefully we don't end up in too many pivots in the future. How does that sound? Yeah, I mean, if you feel confident with, because we haven't had a discussion with Shiet, so I think it looks like that. Yeah, and it can't really harshen I have not talked about any work stuff. So I haven't talked to them about sales plays, I haven't talked to them about, probably the most I talked to them about work stuff was I kind of said, like, this is a little bit of the history of the team. You know, this is like, you know, what things were like when there was like just a few of us, it was like Cindy and John and me and Ashish, that was like a whole team, and then a little bit of the evolution. So that's what we haven't talked about specific programs or activities. Just imagine to Quentin Tarantino film where we all have our like characters and we're like all coming in at different times. Right, right. Where is that sniper film where that you do that same thing, but it takes four hours. True. That seems reasonable as far as the research is that mean kind of from here. Do should we should we get a lead at a share some of our insights on how to navigate through these things and use the, you know, we're going to be building our own reports. Or we're going to have access to someone that can help us with that data because in my experience, that stuff takes forever. And it's tough and they usually know what's what's the best way to go about that or do we just kind of dive in and enroll with it because I've done both ways. Yeah, so my preference would be that we NBC iterate this. Right. Like let's, let's not wait until we have everything perfect. Let's not wait till we have perfect knowledge, like, you know, let's make decisions with imperfect knowledge and make the best educated decision we can. And I think some of you and I've had a little bit about this where you've done and done some research already, but the data isn't there or it's not accessible. And so I think as we go through this process, if we can document those shortcomings, if we could say, like, here's a link to the Salesforce report that I ran, right? Or like, here are the fields that I'm looking at. And this is why they're inaccurate or here's an example of why it's wrong. Therefore, we need to change the process or we need to slice the data better. Maybe we need to do this. And honestly, if you watched the last call that the one that I'm linked in the notes, I think this is a point, Sakamoto brought up where they said, you know, yeah, we know there's some work that sales option needs to do to maybe even Hong said it himself. Like, like, this is something my team needs to do with the data needs to get better. But that's kind of my ask is that we start with the data that we have and the tools that we have. And when we run into these roadblocks that we just document that, so then we have like a reasonable way to ask to say, like, okay, this is the outcome we want to achieve. And we can't get there. We can't get X because we need Y. Okay, let's get together with sales ops and marketing ops and the data team and say, okay, like this is what we think we need to function as a mature business. What's our path to get there? Do we want to have an app? Do we want to make an epic and then link off some individual issues for us to do our research and our respective areas? What is there, or do you have an idea of how we'd want to do that? That way if people come in or if we do need to pay like, you know, data ops or something like that, they can at least understand what's going on. I love that. Parker, would you be willing to make an epic? Yeah, that is, you know. So, I'm your product marketing that cool. I don't think you can make an epic under product marketing. I think it has to be under the epic group level. Good call. But yeah, if you just make an epic and then we can, you know, have an issue and then at least have a sink point of collaboration. Thanks. Make this big. Oh, there they is. Okay. Thanks. Cool. I think that there are a couple resources for us. I saw that there was a competitive who added um, that was me. Okay. I was hoping maybe you'll lead to added it because they has, uh, so. So I think there are a couple of resources. So one is the deck Parker made. Um, do you want to just like bring that up for a moment? Yeah, I was going to add the link, the feature list link as well. Just one second so that we have that. Because I know that the leaders, uh, or I know that we committed to that as well, let me, oh yeah, you got it cool. You want to talk to anyone, we talked to you. Uh, I'll, I'll just give it a brief overview. Cool. Um, the, the, the, the, not all of this, it part of the correct me anywhere I'm wrong is that, uh, this is based off of a process you ran at your last gig. When you ran an end and sales play process that started with research and then culminated in sales plays and those sales plays were data informed. Rook. And so some of the idea here is that we need to define like ideal customer profiles, uh, you know target tactics, create some hypotheses, and then, uh, you know, viewing, you know, through the data that validating or invalidating those hypotheses, or even through testing, right? So at some point, we might say, okay, well, here's some things we know are successful. Here are some commonalities in some, uh, you know, some messaging like we saw these 10 actual plays and they all kind of went to this persona in this message. So we think that that is where it's going to go. So here we've developed this play and we want you to run it. And when you run it, tag your ops with this thing and sales force that we can track it, and we're looking to look to create like we created 10 of these types of ops. At, you know, uh, 50k each for, you know, there's these small land ops. And we want to create 10 more. Right? So our hypothesis is if we run this play, we'll create 10 more at this size. And then you could run and validate, you know, like shipping a feature. And so, um, anything else that you kind of would want to just highlight in here, Parker or anything from your previous experience? No, I mean, I'd say take a look at it and you know, ask the questions about it. But you know, this was all built around and exercise to identify what an ideal customer profile looks like and then uncover, um, the repeatable pieces or the people motions inside that that the reps can go out whether it's, um, the talk track or the scripts or, um, the paints, right, or the current situation they're in. So, um, you know, it's about you building the data and then building a model where, you know, using these characteristics or the indicators that we have, you kind of get to the bull's eye. And that's kind of the sweet spot. Um, and so yeah, it should be something that we can, um, at least leverage from process perspective and help us kind of guide us to the research stuff. So, um, yeah, and we'll probably have to adapt it if you got ideas on how we can mesh this better with, with what we're doing as we go along. No, please, um, please do let us know. So, I think Parker's kind of document in some of the process here, like some of the steps, uh, just at a high level. And then I think Alita has a nice, like, this is the output of them report and let me honestly see if I can get some of the deeper, um, notes from her, but if you look at like, here's like, they does this quarterly. She's done this a few times. And them sources were Salesforce, deal stories from the GitLab team, um, alignment points actually. I don't know what that is. Um, they chatted with analysts at some points too to get, but this is like, and we've done the same thing. So, I think some of this stuff we're already doing, right? Like, you have a sales play and you have a concept, you have an idea and you schedule some time with Gardner or Forster to review it, right? Like we're already doing that kind of stuff. So, it's not, I don't see this as like a hard pivot. This is more of like, uh, augment and just, um, acknowledgement almost that like, hey, there's a research component required here. Let's make that a little bit more formal if document what we're doing on the research side that's inputs into the output of the sales play. And so, you know, you can see here where Alita has come up with some of the data. Um, and, uh, what I can do is, is maybe on Monday, let me, let me see if I can ask Alita on Monday to walk us through them sales force report. I'm happy to do it as well. It did work one on one with anybody who hasn't like, mungent in sales force before. Um, I think this is a muscle we need to build. Um, you know, I think there's, there's a lot of things that we're like have high competencies in. And I think this is a competency we need to, that will serve us well as at this stage of the company and moving forward. This kind of data rigor. Yeah, I think that'd be an awesome idea. Any, any other thoughts or questions on just kind of like, what I view is more of like, additive than a pivot on taking a step back and doing some research. Um, I was just looking at Alita's report. It's brilliant. Right. I think she's done this before. And it's, it's a great report. Um, we tried to do something similar for, um, take off. And I see a few challenges for the one is the ability to identify. Peels that are either the cops lead or even have the tops is very, very difficult. Right. Um, so for example, there are chorus calls where you know, some of the keywords that we have identified as related to get ops are being hauled out, but we never see anyone who was in SFC. So there will be deals, but then they're not necessarily that the skit-offs, the notes on SMBC, don't call it out as skit-offs. So, um, we can perhaps, we, I mean, I have most of the data create a similar such report for the dogs, which I also need to view SDRs and Sall's, some of the bin stories and some of the lost stories that can be put together. But it's, it's a very small sample size because we weren't able to identify enough these that were that had to be. So, um, at what level some is this like where, so like before we, in just a waiver with that, with that slide deck I showed you before we went through that process, I had a data person tied to my hip and like we went and put a field in Salesforce that the sales reps had to go and retro actively fill out that like basically our value drivers are our use cases and they, and they didn't like it because they don't like to have a making extra click, but we had to do that in order to get back and exact these deals with what we needed. So we may need to consider putting that asking early to date and so we have we actually have that theme. So when we started the use cases last year John worked with there, I think put that theme in there. Some deals have that, but not all of that, right. I think 90% of the deals don't have that information. So that really makes it difficult. I mean, and the way we've categorized those use cases also is very difficult to, I mean, we have a complete DevOps platform as one of the entries there. So it is possible that, you know, a sales rep doesn't want to put in all the effort and just tags everything as a complete DevOps platform. It might be a security, it might be a digital free, but they just tag it as a complete DevOps platform. So I think that is, that is at least from a data point of view, that is one challenge that we will face. It's possible to kind of work around that by trying to map a course call with an SFCC. If there were some conversations on your product, your topics, on the course call, then potentially assume or maybe reach out to the sale and find out that this deal actually have CIC or the course of whatever. But it's going to be a manual process So that field isn't mandatory then in SFCC and the same thing. It's not. That was what wild the feathers in my last year. They did not like that, but we had to do it. So yeah, so this is essentially I feel like if we, if we just show up now, we say like, well, we can't do research because we need the field to be mandatory. We may or may not get somewhere with that proposal, but I think, some of you, just even had like a word document or an issue that just like had written down, these were the deals I uncovered, like this is how I know it's a, it's in course it's a get-up steel and SFCC it's not. And it doesn't need to be detailed, but just a little bit of documentation. Then we could, yeah, then we could make a proposal and say, look, we think for the rigor of the company, this is, this is a way forward that we need to have some documentation about like we need to have this field, it should be mandatory. What's, what's solution is that is the land solution and it can't just always be a platform play and needs to be like, what are they, what are they starting with? That they started with security or like, what's the order of operations so we can document it? Cool. Yeah, and I don't know that I would recommend trying to do a mandatory game going through it once. It was not, it was not a great process and it did take some time and all that kind of thing. So I mean, it wouldn't be efficient. So I think I think this is the best way for sure for now. Let me ask this since we all have a gut feel or even, I've experienced exactly what you've had done some munching and I know the data is rough. Any other suggestions for work arounds or anything else that you kind of have done at another place that was successful or and just any ideas on, um, hey, we want to try to get some data around this is the thing that works and we need to categorize it so we could say this is our win rate for X. Any thoughts or ideas on, you know, we could like, you know, make the field mandatory? When we've seen a very similar at least high level stats, you know, in McBees decks, we've seen things like this percent of our deals are this kind of a land. Who did that work? Do I know? So we do have things broken out by land or expand. And we do, I think it's in this tab here, let's take a peek. I've seen stuff like 29% of our lands are SCM deals or stuff like that. So I have a rough idea of what the numbers are, but who did that? Yeah. Okay. Do you have a link to any of those decks? No, of course I don't. I'll have to find it. Okay. But the other out there. Yeah. I definitely have seen like this is our 25% of our deals are land. I don't know that I've seen 25% of our land is SCM, but if that exists in a deck somewhere, then we can go and ask like where did that number come from? That might have been on the product call recently, Brian. I think I was on that. I think it was Taylor McCaskin that mentioned something about like 50% deals SCM, I don't know. So I might have to go back and look and see if I can find that as well. It may be the same thing. That was recent. I think it may have been on the last, one of the last two products called. So I'll go back as well. I think I may have seen Donk with those numbers in hand too. I'm looking. And yeah, I think part of your point about working closely with the data team, I think that is an eventuality. I don't. I'm not optimistic that we get a resource like that ahead of time. Sure. And the rationale there or my thinking is that I just know where our data team is like our team. They're very, very lightweight for this high-sqm company we are and the demands on them. And so I think if we can build an ask, then I think we can definitely justify like we want to do this thing. And like this is what we could do on our own. And we need data resources to do X. Completely reasonable. Yeah, it was the SVP at the last place that basically said you're working with him. And so it wasn't really a choice. It's a hard ask. I completely understand, but I wanted to caveat it so that everyone knew. Cool. Then this is, I'm just going to put it to do like Ryan to do track down slide. Cool. Then I think our next steps here are pretty clear. I'll have a lead to do a little demo on Monday where I'll ask them if she's willing to. If not, I'll give it. And then I'm also happy like you know, feel free to schedule one-one time with me. And I'm happy to walk you through SFDC. I've done a fair bit of munching. Anyone else have a razor hand at Samu or a new one? Would you would say like I'm I'm familiar with SFDC and would be happy to one-on-one coach other folks on the team. It's okay. I didn't do it to some extent, but I don't call myself an export on this. Okay. Fair enough. I don't just, I think a lead is probably done the most. And so I'll see if I can report. I mean a lot of ones that are broken. That's for sure. So just to William, you mentioned about best practices from earlier. Yeah. I was just thinking about that. And one of the things we used to do was every quarter we used to track the top 10, 20% of the teams, which playing the maximum revenue. So between the team, we have actually kind of slipped by region or you know whatever to actually be developed. Specific deals go through the deals. Maybe work with the sales sales reps for those deals to understand what's driving these deals. So one so in general, it used to be probably around 20-30 deals. So spread across you know a team of five or six, it would be about six-70's each person would be handling. So they have to in depth information about the productivity. And then we can use that information to punch the data on both for the paper and for the paper. So that's one thing that we need to do in that field. I love this idea because we already do some of that to some extent and this shows up in KBRs. I mean that this is effectively what KBRs are. Each rep comes and says, these are my top deals with the quarter. Now that's for like every single rep. But there's also honestly I know that pile has a meeting where he's, it's like pile's top deals meeting. That is the dashboard. See it's for dashboard. I'm just going to put it here. This is the SIPC dashboard. This is the SPS dashboard which tracks the top deals for the quarter. So we can, you know, we can even use that team. That's a pretty good. I'm I'm going to add this as an agenda item for like the next call. Let's keep this as, I don't want to set an action point forward now. But I do want to set an action point on this by the end of the quarter. Like I think like going into the queue, I think at the end of Q2 we should have a list of Q2's top deals. And I think it's related to this effort. They're not, they're not completely separate. I think they're related. And honestly, maybe this is even a way to get at it. Maybe we just look at like the top revenue. Well, there's one other problem. This is why I don't want to get too much into it now. We should chat more about it Monday because forget lab, the most important deals are not just the top revenue ones. For us because our net expansion rate is through the roof. We have this like best in class like customers. If customers buy us, they will grow and they grow a lot. So what does that mean? That means we really need to focus on new customers. And all that matters is getting that new customer even if the deal size was very very small. So right now the focus for the business is this first order logos. And the reason for that is because our net expansion is so amazing. So I think there is value in getting the top deals with the quarter or the top deals just knowing what those are. But there are, it needs to be coupled with some amount of like that. And this is how we're getting new customers. Yeah, I think we can slice that based on what we want to focus on for the quarter or you know, let's say, you know, for the quarter, we want to focus on mid-market. And say that maybe one on this time, how we are going to market in the mid-market segment which in cases are working well, what we can do to the market. So it just doesn't have to be the top deals. It could be a specific focus area for that particular quarter. And then the key does be shared that and then shared experiences and then come up with some kind of support that's required for the best type for the cool cool. The next thing I want us to chat about today, we're starting around short on time. But, Samya, you had you and I had chat and you made a proposal to say like, let's focus on STRs because we can drive immediate results. And this is exactly what I want to do. Like this is exactly what I think we all want to do. Like the idea, this is kind of what I'm saying. Like, hey, there's some balls up in the air. But like we can make decisions within perfect information. And we can just look around and say, what's best for the business? And if we're always acting with that kind of bias, we're not going to have too much trouble justifying what we went and spent time on or, you know, aligning like other people are going to be like, oh, good. I'm glad you didn't have to go and get a bunch of alignment. You just did what was best for the business. So one of those ideas is that the STRs actually, I'll just kind of like, would you mind just kind of pitching your idea that you just do the team? Yeah, I can do that. So one of the things I did as a part of the GPM motion was also in the view of the US VRs as well as some VR managers, right, to understand what is it that is kind of missing from their workflow? Are they able to have a specific conversation? So let's say a big ops conversation based on some of the bonus balls that I had listened to. None of the STRs were able to have a big ops conversation, obviously we've never probably enabled them on it, but every single time they just used to kind of go with the standard pitch of single application or security, without really listening to what the customer's point of view was, right? So the customer might be saying that, hey, I wanted to infrastructure automation, but the STR would say that, hey, Hitler is great for everything. It's a single application. It can help you forever. You know, not really actually talking to the customer's main point. And I first listen to those calls, let's go to the STR managers and I understand that they don't have a standard process. They don't have calls groups across the board. They don't have outreach sequences that can help the can help STRs. And this becomes important specifically for commercial STRs because they have to turn customers normally the only fast, right? They don't have the luxury of an enterprise STR who's able to then call in a sale or they say for a conversation with the customer, right? So an commercial STR needs to turn a lot of customers' owners in the room. So if they have to actually start, you know, reinventing the week or every conversation that they need to have, then it becomes a bit of a challenge. So finally, the conclusion of all of these discussions was that, yes, there is a gap. They also have a gap in terms of subject matter expertise and that's where we've been coming. And the immediate ask was, one to go over the outreach sequences if there are no outreach sequences, then maybe come up with some of the people's staff who have helped. And the second thing is to help them with some false groups that will help them have the relevant conversation for what if you're doing this. Now I have a discussion with William. I think we haven't prioritized this for you to be mindful of the doing with the TTP. But I'm going to kind of try to work with the SDR team to kind of pivot the pilot this to actually see if if that is a problem that we can solve and what to say to the camera people for that. Right, what is there and kind of that too? So that I have been hesitant in the past to like double down on this and the reason why is because every SDR team kind of managed their own things. Just like Samu said, there wasn't like a unified, this is the template we use everywhere. And they wanted that to some degree. They wanted SDR to be able to do what it took to get the deal done. And to adapt to regional differences, etc. etc. The challenges of course is if there's a hundred different outreach emails being sent, you can't really say like this one's performing well or it's not. But if you have like these are the four standard templates, you know, or these are the two standard templates for get-ups, which one performs better. These are the two standard templates for CI or for security. Right. So, can't know if you've chat about this. Who Parker, who were you working with on SDR? I mean, I've worked with a lot of SDR like Matt Malcolm, Hannah, and most recently Megan Thatcher. I've been replugged in with them. Megan is really passionate about this. So she's recently gotten into a new role and part of them charter is this exact thing, standardizing the outreach templates. And so I think this is an opportunity for us to get involved. This is kind of we didn't plan this at the beginning of Q2. So I'm not necessarily saying like go drop everything and go start doing outreach sequences. But 100% Samu is doing it as part of them sales play. And I would encourage anyone else like this is probably a place where like if you're just looking for some extra time to go do something working with SDRs, this is probably going to drive some results quickly. Right. So if you want to drive some results quickly, this is a place where we could probably see like a quick improvement on you know you can just imagine going from customer conversation of like yeah I'm the you know director of platform operations at sessions such a company and I'm really interested in infrastructure as a code of infrastructure automation and then our responses like let me tell you about our all-in-one for everyone like it's going to fall in death years. But if we can enable them with a call script that's like you know oh let me tell you like here are five things to say about security to the security person or to the security minded developer director of DevOps or whatever right here's your call script here's your outreach sequence like that will prop like we could have a strong confidence that that our hypothesis that that would drive more immediate results so anyway just sharing that as well I think Samu is doing their part of your sales play but wanted to raise it to the rest of the team. Cool any other thoughts or questions on SDRs? Just wanted to add a quick note there with them I think there are two people on the SDR teams I think Nathan is dealing with nine motions and it used to be Elcher was dealing with the expand motions and they are both trying to standardize that so we probably need to work with both of them who's on land? Elcher is Megan is on that. Megan. Okay cool. Let's come back to this in a moment I'm just going to jump ahead to contribute I just wanted to point out that if you haven't read the contribute FAQ here's a link to it and I don't want to lead you straight definitely read it on your own but my synopsis of it is I don't think that there's a lot for us to do or I think there's only one to do now and I think all the other to do is are like once registration opens then they start booking your flights for you and that kind of a thing but the one thing that you might want to start looking into is a travel visa for the Bahamas so it's in FAQ's a reference is it? Here's a direct link to the site and anyway I just wanted to raise that to the team. The competitive feature list is anybody still I know Kormax still has to get their in is everybody else done or is anybody else still working on adding their features? I'm still working on it I'm making progress. Yeah mine's open too. Cool. What is a reasonable timeline to have your features in the spreadsheet? Oh I was doing an innovation. I just need to be cloned I'm sorry. Yeah yeah and I know that's just like this is why I want to ask like what's reasonable. I don't even know anybody now HTML that would be a big help for me. Somebody can out debug some HTML. I do. I'll help you out Cindy I've I've got some open slots today let's do that. How about any Brian what do you think will be a reasonable due date for you to say like I can get my 15 features together by date x? The only thing that's slipped is I was actually going to talk to my product counterpart about it and we lost our call so I can just call it. I can also do that. So I can get it done this week if you just want to get it done. I'm very deadline driven at the moment is the fact of it so if you set it that mine I'll hit that. Okay can you put in some features and we can always iterate on them but could you have 15 features by end of day Friday? Yeah totally do it. How about Parker would you be able to do that? Yeah and Samja? Yeah I can. Okay cool and then Cindy and William. Next week. I work. Yeah and I know I've added more things to your play and I know other folks have too and so I've asked reasonable let me see how much I can help you. I can definitely help you with the HTML. You can have me in the batter's box if you need extra help I mean help with that thing too. Cool. Who added number five? Maybe core Mac. Maybe core Mac yeah. Okay so we have an alliance with VP that's exciting I didn't even know this. This is so cool. I just saw it roll in but yeah otherwise I didn't know either. This is awesome. Okay so what's confusing to me is I thought the alliance was in marketing but Nemo is actually reporting in June like me. So that's that one of the moves? No so alliances has for a long time been part of sales and if you remember Brandon Young. Yeah I think they initially reported a Sid for a short time and then they reported to McBeat for most of their tenure at Get Lab. So this is the new Brandon right? Yeah this is this is exciting. So Colleen is ahead of alliances marketing. I believe or ahead of partner marketing. Yeah I had a tech that funny cheese cream. Yeah yeah Colleen is awesome. So they is partner marketing for both alliances and channel and then Nemo who looks like is our new VP of alliances. So this is who like my own team will report into Nemo and it's really exciting that we have a new head of alliances. It's super cool. Um Brian. I just liked that somebody did that. This funny pile on the product team call they starts out by saying I'm looking to narrow the guard rails of what sales plays look like and like you're talking to the product team but that's how much the sales play issue was on their mind. they opened their discussion to the product team by talking about sales plays but they was actually there to present what's in this this deck and I thought well that was like a nice to have take away from all the QBRs. Was here everybody in product here's what you should care about from QBRs and it would be nice if we're going to do something like the QBR task again if for the marketing team there was something like that too where we could just say in five or ten slides here's marketing team what you should take away from the QBRs. I just liked that they had it you know nicely summarized for product. So I'm confused in my apologies if you can back up one step what was the context was this was a call or this was a deck that pile put together? The latter and first it was in Slack and then it just got added to the product team agenda. So it became about ten minutes of the product team call. And so you look pile made the note in Slack? I think actually Scott made the first note you made it note in Slack. Did I go to it? they made it actually quoted pile I mean I don't know that's sure but I just liked that it was done I thought it was a nice amount of take away it was actually like a useful amount of takeaway for everyone in product I thought everyone in marketing should have some amount of takeaway from the QBRs which maps to what we were saying earlier as well which is like especially for going to go through that whole process let's surface the really important stuff or the stuff that we heard ten times and that kind of thing the patterns. So this is you saying in in piles QBR in their leadership QBR they had a summary. Scott attended that QBR liked the summary and linked to it in Slack and then added pile to the product call. Yeah and I thought it was useful even in some follow up conversation with folks in product I thought it was actually useful to them. It's good whether they're going to change decisions or it was validation or it was a little bit of both but it just felt like something we should also have in marketing could be the same list of stuff but like this is take this is a summary takeaway from QBRs. Yeah and it's something we could do we're sitting we're sitting through them we kind of do it anyway just chatting to each other but I don't think we need to do it if it's sort of being done we might just need to filter it or a resenter it for marketing purposes but. Okay I my thought on this is that we make this a Q3 goal that with Q3 like I don't want to go back to our Q2 QBRs and say like let's derive a summary out of it but I think that looking ahead to the next set of QBRs and how we engage with them as a team this would be an artifact we aim to generate does that sound right. Yeah is this public news Parker can I put this on YouTube? Uh, we were making our public announcements be a press release later today at 9 a.m. Pacific and that was yesterday so as long as we announced it. All right awesome. Which I can go check our link there or something in confirmed. We were planning to yeah. Yeah awesome. So I thought that was really cool I just checked out their website and saw what they were about looks really I mean it looks right in line with where we're investing you know and that's either the product cast as well. And look at that it's on tech crunch love it. Okay cool so we're good. Cool. Yeah just so you know you were saving your speed. Yeah yeah so yeah so this is should be the notes and all this there should be public right. I don't think I I didn't click on like when I clicked on the sales for support I didn't show it. So hopefully everything in this video and that I put on my screen is YouTube YouTube or the I think we're okay yeah so uh hey thank you team Let me just take a quick peek your Cindy do you want to look at that Hey you're HTML stuff? Hope you all mute. Sorry I just pulled out the offending part and got it to run and I will go back and re-added as a separate MR I updated the deathseq offstage and needed to get it out there because MQ stuff just went live this morning. It's driving people to it and it was making me nuts because I couldn't get the stupid syntax error but so I just removed the offending part and we'll go in NBC too. Re-added. Hey looks like sounds like a plan. Do you uh cool I want to let everyone else on the call you know run and let me stop.",
  "Now we're ready to report. So commit boost duty. Simon, thank you for I saw you already posted on the thing and Brian did too. And so Parker, if you could grab a slot on the schedule there and a leader will need some slots as well. So we can cover that. And then core max indie, I recuse the three of us from commit boost duty, given the other scope of stage architect stuff. Thank you. That was nice. So now I'm going to try to do last year. I did the entire 24 hour live chat. And that was a mistake. But I'm going to try to be in there for as many chats as possible because I don't think that I think there are there any other spaces for the speakers won't be able to make it. Or be sure there's someone in there to answer chat questions. Yeah, I'm doing the same thing. At, you know, this is one of those things where we knew this, but we didn't account for it. So cover, you know, cover commit chat for a pack hours. That is an agenda item. We should add to our architect sink. And we're like right up on the heels of it. So I don't know if there's out of who, like, who we can get to sink that time. But let's add that. I would try, you know, in some cases, it could be the speaker could cover it. And the other case is depending upon their time zone. And the other case, you know, we could probably get an essay or a PM that's in a good time zone for it to cover. Right. I remember doing that last time. And I remember they're being a scramble around it. And there's just no, like, these are all the things we need to do for commit. Like, that's a thing we need to do, but it's not on a checklist anywhere. So, so. So, Q3, okay, R's. So let's, let's chat a little bit about some of these things. I have to do, do, do, do, do, do, do, do, just gonna share my screen here. So, well, I'm pretty excited about as we are marching towards doing this in a more organized fashion that, you know. I don't think we've had this, this level of rigor. And we should be looking to do more rigor as we, we've on. So, I did a link here. These are CIDs, okay, R's, which are a GitLab managed future. Conversion from free. And even Prouder to Work here. So, what's nice then, is, Craig's, okay, R's, roll up to that. So, Craig's, okay, R's are increased funnel and drive pipeline, elevate marketing messaging, positioning, and maintain high team member delight through strong prioritization and collaboration. So, what's nice is these are rolling up. So then, when you get, and then I link to Craig's, okay, R's deck here. If you wanna poke into that, there's more info there. So, when you start to look at our, okay, R's, they roll up to that, to those, you know, they are, R's, R's really roll up to harsh, harsh as roll up to Craig's, Craig's roll up to CID. And hey, alignment. So, that is exciting because in an ideal world, the projects that we are planning aligned to the strategic goals. So, and some ways this dock is still in draft. So, for example, I need to get, I have a call with Ryan this week. I wanna get like a full list of what can we expect for R, F, and reports so we can plan that bandwidth, right? Similarly, there are things on here, like our corporate event support. I think these ones, we've, are well documented, which ones were covering the field marketing events. So, ideally, what we're doing here, and I see that some folks have already kind of started to chime in and been like, yeah, I can pick up this one. And I think that that's good. What I wanna, what I basically wanna avoid is I wanna avoid like, you know, Cindy has like eight webinars this quarter. And like, I have to, or, you know, that kind of like imbalance. So, between field events, demand, and webinars, partner webinars, and ABM webinars. Like I wanna make sure that we kind of balance out that load. It's kind of what I'm aiming for here. Here, we have a list, and then it has a link here, and this is the list of proposed field events. So, we did this last quarter and got, I think, eight. This quarter we got, eight team, that gives me a little bit more confidence that we're more, a little bit more comprehensive. So, I have an action item to go through these, and try to, I might pop up in a spreadsheet or something, so that we can look at like, how many's part are doing? How many is core-mack doing, you know? Any questions on just the webinars for the quarter? Cool. So, sorry, I missed part of that. So, you wanna us to put in what we signed up to, or you wanna, or you're putting them in based upon the request. So, ideally, we kind of like batch process these, so my current, what I'd like to do, if I ever get like five minutes of extra time, that I'm not, you know, just jammed with stuff, commit is taking like a meaningful amounts of my time, but in an ideal world, this list here, like, what do I want? So here, so, in some ways, this is nice because this is, you know, all in issues. So, but it, it's kind of makes it cumbersome to filter. So, ideally, what I could do is I could look at this and I could say, like, are these evenly distributed across the team? Does everyone on the team, are they picking up a few, right? Rather than like one person being loaded with a ton? And are they, like, you know, is field marketing asking Parker to deliver like five events, the same week that, you know, major project plan is due for really marketing or something like that, right? But when you might think we can manage this by, like, we could sign up, we could look at the list and assign ourselves to the ones that we think are appropriate. And we can self manage if we've got too many in one week or big conflicts, we can say, hey, I can't do this, can somebody else do this. But yeah, that's a good call. There's, the managing conflicts versus your projects is, I think, good. We need some type of all team collaboration. We need, we need some way. So for example, like, I looked at the ones from last week. I don't think everybody put them in there. Uh, wherever we had. So Brian had none. Cindy, you had, I don't know, one, two, three, four, five. But I had too much going on. But I have a list there. I'm sorry. But I wouldn't want you to look at that and go, you have too many, you need to farm some of those out. Because sometimes I'm unable to reuse content from one to the other. Some, they're all devsickups topics. Some of it was on, I was the spokesperson for the devsickups survey. So a bunch of them came from that. And honestly, I just tend to have more of those and of the customer meetings than other people. But that's OK. And maybe I have less of something else. I don't, I feel like it's a little bit artificial to feel like you've got to distribute it for us. We have a list somewhere. I'll put it in. Thank you. So what we, what we need to do though is so we need to make sure that for all of these projects that we're signing up for, and a lot of them are like horizontal. So for example, like launch plan development, right? Like this is a new practice that we haven't really done before. So we'll need to look as a team what launches are coming up. We need to be done. We just need to make sure that our priorities are in sync and that we have coverage across. So I'm not necessarily saying like we need to kind of artificially flow it. And I definitely don't necessarily want to like, dole out like you're doing this one. You're doing this one. But I do want to make sure that there's some spread across the team. Right? Now I do want to make sure that like everyone's at least doing some events. And I do want to make sure that we cover them. And I do want to make sure that we are getting to our other priorities and content generation. So those are, that's kind of like the, we got to get some kind of wrangle on this. And then frankly, I like, I personally lost a meaningful significant chunk of my time last quarter due to field last minute asking me for stuff. And I had to shift things around. And I had to like chat with FMM managers. And like I don't have time for that this quarter. So like the last quarter we did like everybody just grab events. And I prefer that. I like I prefer to centralize. But like I cannot commit the time this quarter to like what fell through the cracks and what are we miss. So I need to be injected somewhere in there to say like, look, we have a plan that I feel good about. And like my time won't be sucked at the future. Is that kind of fair? Yeah. But I think I think if you tell us what we, what, you know, you've told us the objectives, I think we can. Sign up, manage ourselves and. Yeah, like. Let's let's do this then we just we need them to all be covered and we need them to. Not so so what we also need to do to is across these 18 events. Like some of these are for PMM and some of these are for PMM. Mm hmm. So that's that's all it just it just needs to be managed like. Um, I am not comfortable saying like go and sign up for stuff and then I'll just see what doesn't get signed up for. Why not? Because that didn't work last quarter and it was extremely painful. What didn't what part of it didn't work. We didn't sign up like we were supposed to or they didn't give us the full list and And banks like they were supposed to. I think that the full list wasn't there. Um. That that's a good question. I can I can kind of go back and maybe think about like okay what what went wrong. What what were the kind of problems? What are we trying to optimize for like. Like. Where I'm going to do this. I'm going to review all of the items. That's what we're going to do. So if there are ones that you want to sign up for. Go ahead and comment in there. This will be part of the process this quarter. Instead of commenting if we'd assign it, then you could. You could do a board or a filter for which ones are not assigned or. Uh. You know, which ones are assigned to each of us. I'm just a thought. Well, there's problems with that too though like like some of these are already assigned to people, Some are assigned to multiple people like they're not they're not consistent. So like. We need a consistent view. Uh. What else. We question on. Yeah. Are we going to take up all the feed marketing events or are we going to prioritize. Based on the OKR that we have actually said for us, which is. I think pipeline and. I'm going to. I'm going to. Yes, yes, 100%. So. Um. In your intuition, I think it was though. Well, so there's two there's two elements here. We got it. We should chat in a moment about KPIs. So KPIs are going to be different than OKRs. But they're they are related. Um, so here that the. The OKR. The key result for this objective is to increase funnel loss the indirect pipeline. So yes. Bye. Uh. As we look at these events, if we can't pick up all of them. Then ideally we're asking questions like like which one of these. What's the revenue potential? And we make sure that we pick up the ones that are the most. Um. Like we're prioritizing we're prioritizing based on the key result we're aiming for. Absolutely. I don't know that we're to that level of sophistication yet. Um. Like I said, this is like a step of maturity up from what we did last quarter. But eventually like ideally what we would have is for these KRs. We would say we're doing this and we expect this out of it. We're doing this and we expect this out of it. So we we haven't done that level of rigor. I don't we're not going to get there for this quarter. But certainly on any of these that that is the lens to look through is like hey you for this we're trying to drive pipeline. 100%. Cool. So we're trying to get these finalized point else. So one other element to this is. This is the. OKR epic. So this has Craig's three OKRs. And then if you drill into one of these ethics. For example, like you know increase pipeline that we were just looking at. This does have some specific results like you know web direct purchases. That's super interesting there. And that's on dunks looking for web direct for first order. So I just anyway I just noticed that. But here's an example of like product marketing reposition. Free product individuals and paid product of business. Honestly, I'm like just double clicking at this now because I'm trying to think like how does this align. To this. I'm also wondering if that is that public. I don't know yet it's not confidential. OK. Yeah, it is. Yeah, these are all public. I think this was this was one of the ideas that Craig had for the pricing paid a bit. And I think that's the first. Where they said that message on the free should say for individual users and. For the paid to say for business users or enterprises or something like that. So that's in our pricing page back up. But I don't know if they had something else in mind as well. Just topic. So that we we might need to add something here that aligns that. Honestly, we didn't like you can see in our doc we went from like Craig's to the teams. So we didn't go to that level. The one that I know about. Is. For example here. In this messaging and positioning. We have. This golden pitch right. So this is something that. Core Mac is leading up, which is like. Golden pitch certification. Honestly, some of this also needs to be. Rethought now we were going to run this at contribute. So maybe we I don't know if it's still on the doc it and we run it at. You know, a single probably actually this is a good agenda item for a call later today. The reason I want to point this out to the rest of the team is this comes from Craig and then Craig has one that cascades down to harsh. And then for this one. Harsh will probably just like a cascades right down to me. And then at cascades right down so core Mac will be the assigning here like this will literally be. Core Mac is leading this project. So ideally for each of these things we have. An okay are issue in this marketing planning. Project. And that's on my like Tracy's already logged all of them so this is like a to do for me to do the reason I want to bring it up to the team now is because it means we'll have some duplication. And then you have like your normal issue where you're working on your stuff and you can you can organize it in structure it and then you know if it's an okay are there'll be like some accompanying okay are issue. And what I don't want to do is I don't want to impose the constraint like you must work your project out of this marketing planning project. I think that'll cause all kinds of mess so the the way to roll it is. So it's there'll be some duplication so in some cases like I might have an issue and you might have some projects that are under that issue. And some cases like you might yourself might be assigned to that issue and it kind of questions on just this the okay are sort of planning the way they're trying to roll it up. Cool. So KPIs. So we had a. A solid discussion on this last time and we've iterated here this has been reviewed with Craig and so the idea here with okay are those are quarterly right the KPIs are intended to be like longer term. Right so in theory like our okay are should be driving our KPIs they should be related but but one is a femoral and one is you know intended to be like a longer like we're we're tracking these things as a team over time. So some attributes of this. You know, perk on a samus comments last week and Craig wanted this as well and harsh to and I. Me too I've been sold by the team that we want more of a direct line so as an example if we say okay well we're delivering web content. So we're going to be responsible for something like you know inquiries on the website. So if we're just responsible for the total inquiries number and we share that with say Danielle's team. A there's some confusion because like who's actually responsible is it us or Danielle and then be like we don't contribute to all the inquiries so. That doesn't really make sense. Is that we as a team should be incentivized to make them successful so that's kind of like like we as a team work horizontally across teams and marketing. So that's why you see like alignment with Danielle's team alignment with dunk's team alignment with Evan's team. And then. So that's the horizontal and then here is the ideally we're trying to tie it more of a straight line to the work we do. So quite frankly I don't know how we're going to instrument for this we start to get back into. Some of the some of the goofiness we have in the past. I think there's a few guardrails here so one is I don't want to track views for like. All content ever when we have some complicated matrix and we're trying to like track down every YouTube video and all of this kind of goofiness. Like we should just have a web dashboard that is like this is the web content that we put out and we can track things like page use and voucher it. Yeah, what do you think so. Yeah, I think this is great it's moving the right direction. I think page views is still a little bit goofy because like like we discussed previously as well we. We don't have control on how people are going to land on this page right yes we can do a little bit of SEO but if the solution is not let's say at the top of the. On our home page header then no please going to be able to find a particular page. I think that goes back to the question on whether we need that page at all for not on and whether we should invest. And we need to keep going on that I think bounce rate is a better metric on the content itself. Because it shows that if a customer is not engaged on that content then they would move bounce rate is one and time on page is is the other metric that we could. Look at rather than having page views that's. So we we need to track if the. Content is valuable for example from an essay of perspective if if people are searching and landing on that page. And if. A pages valuable in a customer journey we need to be incentivized as a team to collaborate with the rest of marketing to get it into that flow. Yeah, so what metric would you propose to incentivize those things. So if it's about collaboration and working on the journey then page views is a good metric right because then we need to think about it from a customer's point of view. Customer lands on the front page then wants to say let's say wants to know more about CI CD or get off right how do they land on that page. Today for example, get off they cannot land on directly unless they land directly on that page through an SEO search right because it's not part of the top header. So we don't expose the solution that any more on our home page other than at the footer of the page right and there are many, many such pages like that. We don't have one specifically for continuous delivery as an example. So. We have to work with the extended team to get that in place then we need an overall. Information architecture like we spoke about right like, well, how do we how what's the journey that the customer needs to take and what use cases that we want to. Showcase to the customer and only those are things that we should. As a team pick up and work on rather than putting together 10 different pages like we spoke about this team pages for for pricing themes. There's no way that a customer can land on those pages except through SEO right we wouldn't link to that from the pricing page we wouldn't link to it from the main page either so. That's mostly going to be just an SEO effort. Right so that. The. Essentially we want to have a decision matrix like I'm going to have page A or page B which wouldn't should I invest time in should I generate a new page or should I refresh an existing page. Like overall views is something that like page views on PMM page content is something that we want to track. The other end of this two in Craig was like really open to this was. Ideally these are long term and then we're try we're tracking trends over time. But given that our KPIs have been so goofy and ridiculous for a year plus. We just need to try something right so we need to measure and get some baselines and maybe there is a better metric or we iterate next quarter. But this is kind of like a quantity and a quality metric so we want to look at both of those we both want to get like. And then again it's like the idea here is like if we generate more top of funnel volume. In this case we're measuring that by page views but that the assumption there is that it's a leading metric to feed things like inquiries and self service. Right so that's what we also want to track not just so we want to track that like this is a page and this page individually performs well like when people land on it they don't bounce. But we also need some type of measure that we are contributing to the downstream thing which is the inquiries and the in the self service signups which page views would also get to that so. So similarly here for demand and content. I don't know again I don't know how we're going to instrument for this it is I'll tell you what it will not be is it this will not be us architecting our own separate. Machine like for all of these like whatever we measure like this measure like these measures need to come through Google analytics like do the whatever the web normal measurement thing is. Like our measurement for our KPI can't be like what we need some other tool to do that we have to like work within the. The confines of what we're measuring so it's the same thing for demand gen right like demand gen has this. Dashboard which I wonder if I can like pull it quickly actually I probably can't show in a public video but. You know they're already tracking things they're tracking things like inquiries and saos and mqls and they track linear attribution so that's already a metric that's being tracked we just need to segment out the pm content. So in theory here and this should be like everything that drives a pipeline like if it's in. And it's pm contributed like we should be able to pull a number out of that I don't know how we're going to instrument for that I'm open to ideas. Think about that one. This one should be a lot easier. Essentially like a while back to you all remember we had this thing and there was like five levels of like you know did you write the content did you review the content did you all like it was really really goofy. Like had this extra job of going and like coding all of that we really need to avoid that like as much as possible when we measure stuff. It should be like a normal part of the process like we went and did this work and then like there's not some meaningful significant extra task to go and measure it so. For field events they already track the linear attribution it's already part of the Salesforce object so this should be as simple as as like looking at you know this this list of events and saying like these were the events for the quarter we know what the list is let's go pull the linear attribution these ones are like pm contributed events. So that's kind of the the thought there any any kind of other thoughts on KPIs. Measurement. Yeah this might be a little down in the weeds but eventually are we going to get to the point where we are. Like how we attach ourselves to that is going to be interesting to figure out like our we attend percent of that are we 20% of that are we competing with other groups for that like what is our. Because you know we could we could contribute to something that's hugely valuable for the company but. How much time is still worth putting into that if we're going to budget the needle 5% versus 60% and something that's ultimately less value for the company but we might actually be generating more value. Is there a lot of that small or whole. For instance I kind of comes to mind. Yeah so feel. A reinvent. Maybe we put in 50 hours. For reinvent and reinvent hugely successful but there is really another people working on that as well and like how do we determine how much impact our participation had and that versus the other folks and then judge. Yeah so that that is not a KPI that's that's on here now corporate it's a corporate events. Is not on there that's a great call I don't like this is not comprehensive right this is like a stab at. In incentivizing meaningful things that will move the needle right so we know that this team is team of subject matter experts this team knows the customer knows the product knows the market. Like no one else can generate the quality and type of content that we can for the web for demand generation or for field. And so and we know that when we do that we know when we put stuff up on the web like it drives outcomes for the business we know that when we do field events it drives outcomes for the business and that's why those are on the okay ours as well. So this is like kind of picking the low hanging fruit of like we know this does drive business outcomes that's why we want to track it. Yeah for something like a you know commit. Like you know we're putting amazing amounts of time in the commit how do we get credit for that as a PMM team I'm not I don't know yet. Yeah and how do we know like part of it's getting credit is part of it is just knowing where to spend our time. If we can if we can double if we can double the value of something that's worth a third as much versus increasing it five percent you know somewhere else. Yeah so I have to have two bits of guidance on that right so. Well let's think it through that for the most so I would say one if if there is. Some projects something that you believe if I invest my time and think x it will meaning fully move this needle like to your point is like this could this could like increases by 50% not just 5%. Like that should be easy to justify even if it's not like a specific KPI and maybe let's like have a conversation about it right like let's bring that maybe the whole team should be doing that thing whatever that is right so like if you see that thing and you're like. I can have big impact here that should be like the overarching. decision matrix right like as you're looking at like all the stuff you spend your time on like what's driving meaningful goals. The other one is like we got to keep the lights on right or what we call like business as usual so like this doesn't track like sales and able. The city lives on the government of the governments that doesn't track messaging and positioning really like it's OKR for us. But we're not like, you know we don't have like a KPI that's like. How many people used our messaging, like there's things that we need to do as a team. product marketing association or something. Do they have like a library of things that they share where you can see examples of what other people do? They do. So the challenge is how, so I've looked, I looked in all of that as well and they do actually there's a PDF they put out. If I can track down the PDF, I'll share that with a group. The nutshell of it is that PMM works really differently in different places, right? So in other orgs product marketing owns campaigns, they don't have like there is no Jackie's team. Like this team is Jackie's team and like this team has an MQL number that they need to hit. But like that doesn't make sense for us because like we're not the campaigns team. In other orgs product marketing might even own like a revenue number, right? Like when I was at Chwillio, like every product team function pretty much autonomously like the PM was a little CEO and the PMM was a little CMO and we were responsible for our business. Like we had a weekly meeting where we had like this is the revenue that our product is generating and the marketing plan had to contribute to driving revenue for the product. But we don't work that way. So in like the things that other, so these are metrics that have come from other. So there are things like other PMM works, they track their web content performance. They track their webinar content performance, right? They track like the demand, Jen content that PMM generates. Those are those are things that other orgs do. Some of those other metrics though are like don't make sense for us. Is bounce rate? Set and soon do we know like what pages that focuses on? I've always been a little iffy on bounce rate in general, right? Because if it's a page, if the intent is to have multiple views, if you have if the intent is to go to multiple pages of multiple views and a high bounce rate is good, right? No, no, so bounce rate measures like if somebody lands on the page and that content's like not meaning full to them. Like because you have bounce rate and you have exit rate. So this is the page bounce rate buffer. Okay, all right. So we want people to, we want to know about it. On the page in because if we want people to view if the success of the page we're talking about depends on people going to more than one page than a high bounce rate is bad. So we want people to go through a journey and go to multiple places. But bounce rate would be like I came to this page and I backed out of it. Right. If they come, if they come to a page and they're like this is the next step of my journey and then they go to that next page, that's good. Okay. All right. So but you both the, okay, there's just some pages where bounce rate wouldn't make sense, right? Because we don't want them to go anywhere else. No, no, no, let's let's you and I think on what bounce rate is because it's it's a little more nuanced than that. Okay. I will share with the team that another potential metric here might be like clicked through rate. So the idea would be if we identify it on every one of our pages, what's the next step, which might be go to another page or it might be fill out a leak app or there might be some action. And then we would measure that action like was the action taken. The reason I don't want to do that this quarter is because we're not instrumented for it. Yeah. So in order to instantly attempt them, right? Or you know, a lot of times it's showing like a symptomatic piece of a journey as opposed to being indicative of value. But yeah. Well, we're just, we don't have the measurement for it. So Google Analytics can do that, but we don't have the trackers on the page to measure. Not to okay. So this stuff we can measure today will do that for this quarter and maybe in the future we get more granular or more specific. Cool. This is cool. Sales QBRs. Optional. This this quarter. We probably should chat about what kind of a sync review we would want to commit to or we need to think about this. If anybody has a proposal, I value like a proposal. Like I think the team should do this. And then the an idea here is kind of if you think about it in like an 80 20. So like you want to get like you want to do enough research that you understand something and then you want to generate like more content out of that thing. So ideally like we're not like you know diving 50 layers deep into like customer stuff. We're just like we understand the customer we know the customer or the customer expert. Okay. Now let's go use that information and drive our all of our other content we need to generate. So thank you for the time team. Let's catch up a sync on some of these other threads that are still going on. Cool. If anybody happy Monday. Thank you. See you.",
  "That's right. So do our weekly agenda. Coremea, move gears up to the top. Ooh, I feel so fancy. Thank you. Do you want to kind of show you that? I will verbalize. Yeah, so I was just wondering, we have this strategic marketing off site this week. And I was looking at the agenda and I dropped a comment at there to a leaders point. Just that we should involve product. I think in that discussion about Azure boards. But yeah, it was just wondering if there's anything we should perhaps You bring to it. So we, you know, we can get the grant run. Nice. I noticed that we had a a one to three year portfolio marketing strategy conversation planned. And I thought, well, we could read our three year get lab strategy because that is something relatively fresh. But then I see a counterpoint. Well, you. So, um, It should be, it should be no prep. There's no, there's no ask like go and do this and show up ready with things X. It's, We're going to have some fun time and we're going to have some, Think about different stuff time. If there is a conversation you would like to have together as portfolio marketing. Did I share with this group that we're now portfolio marketing? Well, yeah, I don't know what call that was. That was the dot. Tod. Yes. On our last portfolio marketing all portfolio marketing calls. We efficient things that need to portfolio marketing. So, If there is anything that you would like to chat about in longer term format, Please do propose that. Tie and I were kind of like on one planning track and then. Tod was like, hey, I had all your ideas to do so. I think Tod may have some ideas and I'm not necessarily including those, But. It sounds like there's no prep and there's just like if there's something you want to discuss is all portfolio marketing. Like add that to the doc and so it looks like a leader you added. Something about Azure boards. You know, so we may or may not discuss that, But if there's something that you wanted to discuss, We will have like a two hour block. I have a feeling that if we do multi topics, we'll fill that up quickly. So, bye. Yeah, we don't have to talk about I just added it just so everyone is aware of kind of what's going on with that. But we don't have to talk about it. Well, so I would my request then would be if you if you want the team to be aware of it, Please add it to the like the portfolio marketing team agenda so that we do all see it because I don't know if everyone looks at that doc. But if you want to specifically say during our off site where we have like a two hour block of like extended discussion altogether. And you want to discuss that thing then add it to that doc. And that makes sense. And so no prep, but if there's stuff that you did want to discuss one of the proposals is, you know, We do some game storming if you all the purer that on strategy. So any other questions on just the off site. Cool. Then focus Friday's a permanent that is very exciting. And this is something that like it's for us or is this. So company wide, you should make every effort to not schedule meetings on Fridays. So Fridays Friday should be a catch up day where you work asynchronously. And so this is a. This is a nod towards having a bias for async putting fewer like we should just always be working like this. We should always think like how can I put fewer meetings on the calendar. How can I have a sync workflows and it's just the it's just the most inclusive like we're a global company. Everybody's in different time zones across all the teams that were on. And the most inclusive way to work is asynchronously. Of course, sometimes we need meetings like the one we're on right now, but we should keep those to an absolute minimum. And so. And in order to do that more Fridays consider Fridays basically no meeting day don't schedule meetings on Fridays. And this is a company wide guidance doesn't mean you can't have a meeting on Friday, but. I find that Fridays are my days to catch up except for last Friday where I had a big plan of catch up and then like five things route to my plate of the last minute that's okay. Brian was involved in one of them. I didn't want to talk to the call. So. Cool. So cute so cute to goals so. Ideally. What I what I wanted to do was ahead of so welcome to Q2 we're now officially in Q2. And this is the. YouTube goals issue which I don't think is anything confidential in here. And so I structured this around a little bit. And I want to chat about these ones a little bit more in depth, but. Ideally, like so in the next two months we'll still to execute on this. And then as we start getting towards Q3 or even now if there's anything big that didn't fit on this. Let's talk about as a Q3 goal. And so ideally when we start Q3. And so we have an idea of the work that we have planned. And I want to do this for several reasons ideally if we know what our priorities are that way when last minute stuff comes on the plate. We can say okay well if you want me to do X. What like this is this is on our plate what do you want us to drop to make room for that so that we can have that negotiation. I don't know that we this is one way to kind of show all these things that we're doing. And the other one is. You know common. A common area of struggle I think both for our team and for other teams. I think it's felt both ways is in the in the ways that we were cross functionally trying to negotiate that work. And so in the past sometimes it's come in ad hoc or last minute. Okay I'm working on this thing but all of a sudden this analyst report that if I would have known about a month ago I would have planned for it. But now that I dropped on my plate I have to shove other stuff off the plate or this field marketing event. So the goal is to try to avoid that like shove off the plate and plan for this stuff. So I asked the field marketing team to tell us all the events that they need. And they did. Has anybody looked at this yet. Yeah, it was a few days ago I think but it was that we're like three big events was what it really well found to you right. So yeah the other thing I'll mention just for because maybe you'll answer it or not but if I ask it first you will. Just so that it was a little hard to tell which ones were already taken. And each of them that I clicked into ultimately I found they were taken. I've been after reading through the thread and that kind of thing so I wonder if we could assert a label or is there a label that I'm just missing is there's some way they indicate we've already got the PMM for this. So that is a good question so honestly I asked for these and like a spreadsheet and I my thought is that field marketing would have asked us for like 20 events. But in reality it was only 10. And so among a team of like six people including myself so five PMMs in me that would serve as like speakers and moderators for these events. And Alita if this is something of interest to you we could also like include you in the loop and get you kind of doing this kind of thing. But that that feels kind of reasonable that's like less than two each for the quarter does that seem like a reasonable amount of. And I think we've done much higher than that. I think we've done much higher than that. We've geased in the last quarters. I would say I've done a case four to five. Yeah, I feel the same way too, but. Yes, I'm surely I thought this was going to be a lot longer list. Is there an allowance for some number of them that will still pop up. I'm guessing are ones that they may not have thought through my my explicit ask was. Is can you tell us everything you need for the quarter and is that reasonable if it's not reasonable then let me know. But is this a reasonable asking I was assured. Yes, this is a completely reasonable ask. So to your point, maybe everything's not on here, but at least we have a we have a framework so something else comes on this quarter and it's not on this list now. We have some kind of a framework to say we either can or can't support that. So to Brian's point. I am wondering. If there is like a way to sort by like a sign. So I think a two ways to do this Brian one week, like poured all of these into a spreadsheet so we could look at them and say okay well there's 10 of them but seven of them are security and they all want Cindy right like that's that's not going to work right so I don't have a good way to sort these to now. I just kind of wanted to just wanted to chat about it as a team for ideas. I asked for them to spreadsheet there like no, no, we work out of issues we want issues as I guess use this fine. We'll work with the issues but to your point Brian this view doesn't help us so any suggestions on how to like. Parts this. We can just have a of you know two state label got a PMM don't got a PMM. Something like that. Oh, I'm looking at a summer quest as sign with me. Yeah, that's what I was thinking but that is. Are they each individual? Yeah, that would work. Okay, so could be like label. We've we have one. Yeah, we've we've got it there. That's right. Yeah, I hate these labels but hey if it becomes helpful. So let's let's see actually it would be label so it looks like two of them have that. So we would want label. Does not equal. SM request. Aside. Yeah, well then is usual it's label hygiene so like if somewhere in the comments someone says yeah, but I got it. But then the label doesn't flip then then it still whatever. Maybe it wasn't a big enough concern to like to engineer a solution. But yeah, I mean it it would be. Well, there's a May fifth event there so hopefully that's the sign to someone. Yeah, look at that that's like tomorrow, right? So that's even tacos and tequila. Is there anybody else? Oh, for for furnish take in this one and this one got moved actually so yeah, that's from last quarter and it or maybe it did guide move to the 20th. So. And I was I was thinking of Emily's comment on the issue that where they mentioned that they need help on Google next. Cook on and AWS. So that's that's also on the list and that's under corporate marketing. So so field marketing and corporate marketing are like they both run events. Right, and so corporate marketing are large company wide global events things like coupon Google. That's where it seems like there's more because there are more. They're just kind of derives differently. Yeah, so like big events like reinvent or coupon those are corporate marketing. Field marketing will be like a regional event and in a non and noncoped times. This could be an in person event, but it usually would be for region. These days are, you know, they're all virtual because of COVID. So that might be some of the reasons why we feel like we're doing so let's chat about corporate marketing in a moment. I'm hesitant to prescribe the label because it's like just an extra step if there is a way, but if that becomes helpful, maybe like being go through and try that out. If you pick one up. Maybe change a label to a signed in. Since there's only 10, I'll try to go through these by the end of the day. I think my ask would be like, can you go through. Maybe that's maybe that I just need to do that. Maybe I just need to go through and see if they have a signed. For field. So what's. Do that. Okay, so field. I'll do this today and I should have done it for this meeting. To see what's not assigned. If I ping in the Slack channel for folks that picked stuff up, does that kind of work? And if you see any that are like, oh, this is my topic. I can take this and then please do pick it up. Common. And every. Yeah. And I only commented because everything I checked was ultimately assigned. Like somebody had somebody had picked it up. And there wasn't a way to see that. And it was like 30 or 40 minutes of reading, you know, comment threads to go through the list of them. I was like, well, we probably all don't want to do that. So it's it felt like, oh, what's. What's a better way. You know, better ways you do it. Yeah. So a 1% does it. Yeah. Maybe I can make a board because you can put these onto a board. That's good. And then you can have like. And then you can have like a lot of columns for people. And so if it's not if it's not assigned to like somebody on this team, it'll be in like the not assigned column, right? Maybe I don't know. Let's. Let me think on that. It's there's a reason why I didn't want issues, but. If it's user easier work with. Okay. So corporate marketing. This one's a bit more complex. So field marketing. I asked for the quarter. I was told these are all the ones for the quarter. Let's see how it goes. And the corporate marketing has been. A lot of back and forth. And. So one there's kind of two ways proposed to approach corporate marketing support. One would be. We as a team ahead of the quarter. Assign a PMM to each corporate event and say you're the PMM DRI for this corporate event. This is kind of what we have done historically. The other way would be for GTM teams to adopt events. And this is what Todd would like to see. The idea is your entire GTM team, not just you, but the campaign manager, the content manager, like. Everyone on the team is responsible for that event and supporting that event. And so the way that you would think about it is we are a GTM team. And this is the case where I think I've said shared some of you and I have had this conversation where like the names of the GTM teams are increasingly become meaning more meaningless. For example, like the CICD team, are you really a CICD team? Probably not. So just think of you because like did you, you know, did you run a CICD sales plan? Well, kind of. It's really a just like off sales play. So. And then the point is, okay, if you're the CICD team and you pick up, let's say, Coup con, are you going to only do CICD stuff for Coup con? No, I would not expect that. I would expect you to like run the meaningful campaign for Coup con that needs to be run. Right. So I would just think of yourselves as we're across functional team. We have a PMM and a content marketing manager and a campaign manager. And other folks too, I forget everyone was on the court team. It's the team of person and everybody, right? So the point is, as think of yourselves as we watch across functional team. And for the quarter, you have certain activities. So you're going to generate a sales play. You're going to support a certain number of corporate events. You're going to do something with campaigns. And hopefully we have enough time on this call to talk about campaigns because that's confusing to your changing or something. So does that kind of make sense? Is that a good framework? Like, we're a team and we're just going to execute a certain amount of activities together. Is that kind of like a good framework to think about it? It is because I think because, well, first of all, thanks for, thanks for addressing me, I'll fit the room and saying that that, you know, there's a disconnect between the names and how we operate because I think that's getting potentially a little confusing. You know, we talk about things like, Get up, take out like, if we're doing a platform, get up, take out, do we avoid the, you know, CI, CV showdown and talk about the benefits platform when we're doing that, you know, so that that's really helpful. I think that also helps to when it comes to how we were the sign ourselves to these things because. Yeah, I, Cubecon is like a good example, like if I'm going to get up, team, I look, Cubecon. But well, that seems like it might make sense for you that AWS might be too broad. So, I still think that those three events might not necessarily. They might not all be equal and that we might have, I mean, our sponsorship level might be different, so we might have different demands. I could see I could see two teams maybe wanting to be part of something if we really need the. We got put and we have other things going on. Yeah, like, I mean, just case and point, AWS is the biggest event of the year, like whoever picks that up, there's more stuff to do than with other events. But they're all a big lift and. I think it would make a lot of sense say, Samya with the the area of things that you work in if you're team picked up Cubecon. Now, just, certainly, I mean, there's a lot of things in cloud data that have to do with security, city road, whole book cloud security, like. Since you could your team could totally pick up Cubecon, like Brian there is like you could tell anyone on the team could totally pick up Cubecon, I don't know that it's constrained like that and to your point, core Mac. We should make the choices that are best for the business, right, like you should not look at like, okay, here's a campaign we're working with, here's a sales player here's an event we're supporting. And I'm going to constrain my set of activities because of a name that somebody picked, right, that's like the worst possible reason to do something like you should be thinking like what's the thing we need to do for the business, what's the what's the talent that we have around us, what are the skill set with the knowledge base and what is the business need like that should be our decision matrix in my opinion. The proposal here and so it would be another issue so just like I have this field marketing issue where we're going to pick up things there would be like a corporate events issue and it would say these are the corporate events in Q2 and. I can drive that because I have the list of all the events I think and then the ask would be for you to go to your GTM teams and say we need to adopt. We need to make sure all the events are covered this quarter so there's four that means one team needs to pick up two. Right, and then if you're the team for that event support and the whole team is on deck to to do all the things to run the campaigns for that event, you know, the the pre campaigns to get people to go to it to follow up all that kind of stuff. It does it have to be a single GTM team. A particular event called. The topic of a particular event puts fan multiple GTM teams and we could have potentially two GTM teams working on the same event for example like AWS if it's a big event we could have to GTM teams working on it. And and maybe sharing the responsibilities of campaigns and so on as well because I think it becomes very difficult to draw a line and say that this is only in this particular GTM motion, especially if we are saying that. At the end of the day the metric that we are going to be tracking is you know the number of leads and you know the number of. A R R and so on for a particular GTM team then you may have multiple GTM teams wanting to life for a particular event. Right, your team's in my so some of the feedback from the events team is we're struggling to get support. We're asking for support and we're not getting it not necessarily from this team I've really really asked okay like is it a steam not a celly from this team but it's they don't have everything they need and so. Teams the GTM team should be fighting like everyone should be saying I want that event because these events are high they're like generate a ton of leads and a ton of pipeline. And like all of that those metrics get attributed to your team. So when you look at like the success of your team if you are the team that's supporting an event you get to count. That events success and so so some yeah maybe maybe I would say reinvent is not this quarter so. This quarter let's try the framework of one GTM team per corporate event and kind of see how that goes and what the workload is. But as you're thinking about as a GTM team what's the stuff I need to do this quarter I need to get out of sales play I need to do some stuff with campaigns and I need to support corporate events there might be something else there but I I think those are the big ones. Cool then look look for that issue as well I think that that needs kind of like probably a dedicated issue hey GTM teams who will pick up which event. The next one then is sales plays I think that one we can do quickly. There was a due date where there was an ask last week I don't know that it was super explicit or I don't know if I asked everyone on the team can you commit to this due date. But the due date was Friday. So now I will ask is there anybody who. Like so the ask would be today can you put in your proposed sales play and the proposed delivery date. Not the date when you can run any campaigns around that sales play but just like when can you deliver the document when do you think you could have a usable document. Is there anybody who thinks they could not put in that proposal today. I don't understand the process so are we proposing what we think it should be and then gets vetted and agreed with sales. Exactly or are we having that conversation with sales and you want the vetted answer. So that's a great question Sine because I think it could go either way I think if you've already talked to sales which I expect you would have I know saw me you. And when we say sales we mean everybody from the sales and the AEs to all the way up to to make be or whoever you need to talk to you. So this so my expectation would be that you have already been having some amount of conversation with sales. But this would be a formal proposal to specifically pile and oh now. So last quarter there was. I think it worked out okay it was mostly done in like. Phone calls or was phone calls and there was notes from the phone calls and if you wanted to understand what happened you had to like go dig up all the Google Docs. So this is trying to kind of like short circuit that and say okay here's one issue and these are the proposed plays and we're going to get explicit. Approval from pile and oh now to go forth and if they think no don't go forth on those or know those are not good dates. Then we can have that conversation it's a documented so that's the the idea is that like yes you'd be talking to sales but this is the documented official place does that kind of something good plan Cindy. Yeah it sounds like a great plan. I guess I must have been asleep as a wheel and not realizing that that was what you were asking for so. I could give you my opinion. For today and I know Parker was there was there were conversations in the CI series flat channel among us and the marketing team about what they might be but I don't think anybody's better than the sales yet. Gotcha and you were not asleep at the wheel you got like a ton of last minute heavy hitting projects put on your plate. And then you were out of pocket and I did talk explicitly of Parker and Parker did tell me well Cindy's not a Cindy's out for this and I'm out for this. So. My expectation is that you would get input from whoever you need to get input but that you are the DRI and so if you can't make if you don't feel like I have enough input to make that call today which it sounds like Cindy you probably don't because you want to collaborate with Parker. When it. Yeah we need to collaborate with sales. Gotcha when do you think would be a reasonable date that you could give a proposal to pilot oh now. When's there a Thursday but I mean. Yeah when's there a Thursday okay. Is there anybody else who needs extra time or could you put a proposal in today. So. So you go ahead. No, no, please go ahead. Yeah, so good. I think we discussed this last time as well. I don't believe that we need to have another place specifically with get off one place should be sufficient. So. I'm happy to work on some other play if there are 30 plays and we can work with this particular GTM team on on those places. So that's what I would propose because from what I'm seeing what I'm hearing from from SDR managers that I'm talking to and with the sales I'm talking to you know a single play on get off which kind of covers I see and so get off and the whole infrastructure automation concept. Should be sufficient it should not it I mean if anything more might be overloading them but additional place. I completely agree you know I've said about this a lot so I mean I 100% I think I've mentioned everyone individually on the call but I'll say it here and I want to try to document this I've got to think to back love to document but. I asked by how many plays do you think there should be total and they said like nine and I said now how many plays should there be total and they said like four and I asked. You know so where's how many like if we have eventually have a bookshelf how many plays should there be to pick from and you know so where's like less than 10 so. At some point yeah we're just going to. This should be the sales plays that we run and we update them we keep them fresh but we're not just adding to the library so I agree on get off some of the do you already do the enablement on get ups. No so that's blind end of this month. We hope make 24. Okay let it you get me a favor do this let's consider that this quarter sales play then and then for next quarter. I don't even understand who made this commitment of like the GTM teams are going to deliver a sell a sell like each team is going to deliver a sales play each quarter. I was never asked for that commitment so. I'm just running with it for Q2 because that's what I was told but for Q3. Let's re evaluate that so I'm kind of trying to dig in at this to figure out and this is the so where's as asked for this so where's it what's a total number plays that we want let's prioritize them. So, so I'm going to consider your get us play that this the one for this quarter if you could put that in the issue and then core mechanism right and how much time would you need to be able to have your proposal to pile and oh no. So we have the proposal and they're already but we just don't have the dates. So that was. I if I pinned you down and said what's your what's your best guess at a reasonable date that you would have like. 80 90 percent confidence I could deliver something usable by that date. Well let me ask a clarifying question on that when you say deliver the sales play do you mean just the play itself or do you mean all the campaigns stuff around the play just the play itself. So it is the finish line the enablement session like is that it's done now or what's the. The order of operations and I try to outline this in the issue or in that epic is these are great questions and candidly this has been very confusing. I think these are all super reasonable questions and we sorted all of this out and one of those like 20 mRs that we did. So it's like if this is not clear it's I think that that's it's reasonable so the order of operations this isn't the handbook somewhere now. The idea would be you propose your play and all you're saying is this is the date I can have the handbook page. And not that it's even like a completed finished handbook because nothing that gets ever finished everything's in draft right but this would be a usable is what I would call it usable a sales person could take that page and run that play and it would be usable. clarify that here in this said that summers and anybody else that's looking at this understand everybody that the same common understanding for what it means to be finished delivered. usable. Nothing. Or we call this is what usable web page. You that's this is a great question usable handbook page. So everything at get lab is. And draft. Will always update. Iterate it's never finished but we want to see something we want to see a handbook page delivered. And then we want to see what is usable by sales by the due date. And let's let's think offline and refine this if it needs to be more clear but the idea is you this is like the date you can merge to the handbook. And like a handbook page is live. And then based on this date of when you can have your handbook page then this is on somerson team. And then you can see that there's a lot of them to then decide when do they want to schedule the enablement. And it might be like the day after. In which case like there's high pressure for you to get your. You're thinking delivered on time and it could be like a month after it just like this is like when you can deliver a usable handbook page. At which the assumption then being. Any point after that. So where's could schedule an enablement. And then you can just go to the next one more stupid question remind me what q two is what months. So it's this month it's a may June and July. Thank you. That's a great question is that's not a dumb question but it's they're awkward because January is last year. I always forget I know it's one way or the other and I can never remember which one. I count on my fingers like every word March April. It's cute. Cool so so the idea would be like you say the date you can deliver and then somers comes along and says this is when I can enable. And then pilot or now say thumbs up we approve that and if they don't. There's a means by which we can have a conversation. Again ideally this would be have already happened but. I feel like this is better than what we had last quarter so we're making progress. So what's the date so the get ops one is may. Right so essentially we could say get ops like get ops could be like get ops the play would be like get ops. And then the date would be like you know. Done. Got that no so I mean had the date why not put it right here you put you put get ops and here you put. Oh five dash 24 so the enabled. The reference that the top means a date to. Is it not done is it does it's it's it's it's it's it's it's it's working progress. Okay so so that so put a date here. XXX so so yeah so put whatever date you think you can deliver that by would you be able to put that in today. Yeah. Cool. And then. Some are already has a schedule so when you all get your dates in here. Then they will then go and or their team. We'll schedule here and then we'll ask for approval. One more thing on the dates. So I'm you have your release manager for me and you're doing this on the 24th. I highly recommend swapping with someone. It just about killed me to have. A release for this and the release post at the same time. I think the release. Well thanks for letting me know in Sunday. I think the release post is the week before. I think the Saturday before the week of the. Uh, say it's an ablement and the enablement is I think on Thursday. So I will have about four days. So I'm guessing I should be okay. But we'll see. Um. Think thing about us on me on it. If you do decide you want to swap just let us know as soon as you decide that. And if not, we'll consider you on deck for it. And. So core Mac and Brian, when do you think you could add your proposed. Play and the date you think you could reasonably you're like 90% confident. You'll have a handbook page up. And we're talking about that now. So I think we can have it done within 10 15 minutes of the end of this call. Okay. Perfect. Then. I'm the whole doubt. Sorry. And no, you're you're you're good. I think we're way ahead of the game. I think last quarter we didn't have this at all. And, you know, you had a lot of last minute stuff last week. A lot of heavy hitting. If you all didn't see Cindy's blog post. Um, they put out a pretty significant blog post last week. Um, I tweeted it, but you should share it as well. So it's a really great. So in addition to 24 hours or less. It's a lot. If you look at that post is a lot of content. There was like, how many how many different people around the or do you know how many people contributed to that. I ping probably they're probably six or eight different because I had to get AR. Approval had to get Jonathan hunts had yeah, it was. And so this was something said wanted. And thank you, William, for pointing out that Todd really wanted it published that day. So it was on vacation Monday, Tuesday, come back Wednesday and see. Uh, that Todd had been had signed me up for doing this thing. And William, including me in that, oh, and they wants it like tonight. And you got to done so. So I'm from my perspective. I think we're firing all on all cylinders. We got out of great blog posts. And you did and then like we just get to like bask in the glow of that success as a team. But in terms of you and Parker, I think it's completely reasonable to say by Thursday. You and Parker will have a proposal in there and that's completely reasonable. Would they see them in that. Uh, thank you for that. No, it's right. You do it. Yeah. I've been in the other. Please got. So I have them out today and tomorrow is what I'm showing on the calendar. Yeah. So. So Thursday is reasonable. Cool. Then. Can you leave a comment on the epic to just say like. Parker's on a pocket, but we'll have our proposal in by Thursday. Yeah. Cool. Uh. Moving right along. We did sales plays. Really good discussion there. Corporate events, field events. Um. I don't know that. I'm going to have time to get through all of this stuff. So. Uh, at a really awesome call with a new. Melissa for new. I think Emily Kyle was on the call as well. And. Normally I'm not a huge fan of this like we went and had this tiny little call and then we're going to go tell the team. But in this case, I think it was helpful because we kind of just did some bigger dreaming about how marketing and product collaborate. And so out of that. Uh. We realize like there's bigger surface area and for this team in particular. Um, I think that you and all of us, we already coordinate with product a lot. But. Um. Something that the PMs may not have top of mind is that. Um, when corporate events are coming up. So we talked about a lot of things, but one proposal was okay, here's these Q2 events. The ones that your GTM teams are going to pick up right. Um, if we tell our product managers, hey events are a time where you could promote capabilities. And you may want to adjust your roadmap so that something ships before the event. I've done this in the past. When I was working with Orie, they shipped our first. AWS container with the command line of the container and that capability they moved up in the roadmap and we shifted before reinvent. So that's could just kind of one opportunity is just to have a conversation with your PMs and clue them into the hatey's events are coming up. Um, that's one area. I'll talk about that on the product call as well as just like, hey, this is one way that we can have more collaboration between product and marketing. And then with this with the product marketing team being the focal point of that collaboration. Uh, we don't have a ton of time to discuss, but any just thoughts or questions on on that kind of collaboration. That's fine. Is that related to the tool I haven't clicked on that one? Oh, and then also yes, then during that conversation, um, our newshad like these two tools. I know that like Brian you've already been using some of them. they has for feedback on them. And so what number is that? Number six. So I logged in issue. I pinged everybody in this you. If you would please, you know, take some reasonable amount of time. If that's 15 minutes. If that's an hour. Play with the tools and then think about how what I use these and then just provide that feedback to far news. Um, would you all be able to do that this week? I think Apple already provided feedback. Done. Cool. That also came out of that conversation. Was that for you said, Hey, I've got these two tools. Here we go. Feedback. Cool. So, Uh, Technically the call is over. And so I'm happy to end the call. Really quickly. I didn't want to interrupt you when you were kind of flowing. Um, Back to you queue to play and at the beginning of the setup. I think I have a document where I've already started kind of outlining kind of what the plan is for upgrading them out tools. I was planning on sharing it on our next call with I think I'm more concerned. But some of the we may have to tweak a little bit of you know what I have in the document or what they had like for example I don't I don't see this training kind of me but I think you had a lot of things. I've been up to five ten features or something and a document I have I had five prep category but we can do ten you know whatever you guys think is best. I would say a little you or the DRI and my ask to you would be can you make an explicit ask to this team. The same way I've asked field marketing field marketing can you just define what do you want the team to do for the team. I would say two your teammates can you just say PMM this is what I'm asking of you this quarter can you commit to doing this. Okay. Yeah. Whatever you. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. In that. It's you that you have. Yeah. I added a that an item to our note start for this meeting for that if you can link to whatever it is we're talking about there that would be great. Okay. Which number are we on. Well, I added 11 item 11 for Lita. Oh yeah yeah, rubbed it into about tools see doc. Okay. Okay. Okay. Okay. Yeah. Yeah. And I would say if you could just summarize the ask a Lita like I want you to commit team to doing ABC. If you can put that in the Q2 goals issue, whatever you whatever your ask is that's what we'll see if we can commit to. I am on mute. So yes, I will add it. Cool. Then ask for some feedback and several of you gave me really awesome feedback. I was so freaking happy. So I know I asked everybody in this anonymous so I don't know who gave me the feedback. But man, y'all gives a really really good feedback that I like super appreciated and if anybody else has any other feedback. The link is I think it's like number one from last week. But what are the things that popped up was, hey, we are the product marketing team. But whenever a new partner marketing manager gets hired that reports in the dunk, the team member updates channel says new product marketing manager. And that's a little bit confusing. And can't agree that that feedback form is not the only place I've heard that I've gotten a bunch of slacks about that. So hopefully in 60 seconds I can clarify just a slight bit of that. And if there's more questions, let's talk about it more. Feel free to ping me. So there is a difference between the name of teams and how somebody's job is defined in bamboo HR or HR system. Right. And so in bamboo HR, we have job families. And the job family does not necessarily relate to the team that you're on. If that makes sense. And your specific role could be defined as any number of different job families. And so partner marketing in alliance is marketing is actually defined in bamboo HR as a product marketing role. And so that's why when the people last group makes a new announcement and says this person is hired as a senior product marketing manager. And you're like, well that's their title, but they're not on the team. Well that's not really their title. The real title is like, you know, senior alliances marketing manager or something like that. But it's just defined in the system as product marketing. And there's a lot of reasons to do that. You know, that takes probably more than 60 seconds to go into like why you would define one role, but like you can kind of imagine if you created like unique job families for every single role in the company. You might have too many of them. So it kind of makes sense to consolidate this one of the reasons. Any just clarifying questions on that or any this other questions on that. You're really good. Good point to bring up.",
  "And, Sam, are you brought up a really awesome concept last week? And, I said, hey, let's have some more discussion this week. Do you want to kind of chat through your initial thoughts on kind of item two there? Yeah, so this is what we used to do at HV. So, in my group at least, so one of the things we used to do was track the top 10-20% deals which bring the maximum revenue. The goal there was likely different basically the goal was to maybe assist the sales teams in case they need help from product management, I used to be in product management at that time. And then we used to work with the sales teams, they don't accustomed calls if required and so on. Now, I think the goal that we have here is probably slightly more different. It's more from addressing a messaging point of view, you know, perhaps improving our messaging based on the deals and the conversations that sales threats are having. So, we might need to listen into a few protocols, talk to the specific sales threats. So, I'm guessing it might be 20-25 deals. I haven't looked at the dashboard lately, but that's what I think. And we might also then want to look at some commercial deals as well. So, in total we can my thought was we could take an overall of about 30-40 deals and split it across the team. And then, you know, maybe in a few quarters we have a good understanding of how the conversations are flowing all the sales threats, where the gaps are from a messaging point of view, working cases are working, what's not working and so on. Right? A lot of that information might be qualitative. Things that we are not going to get directly from SFTCs, we might want to start working with the sales working directly with the teams and getting this information from full assist fund. So, a couple things on packed there. So, I think that our goals as a team in keeping a breast of and reviewing some segment of deals that we are involved in. And let's chat a little bit about like, is it top revenue deals? We have to have commercial in the mix, which, you know, any one of those is not going to be like a top revenue. So, we have to let's talk about that a little bit. But even ahead of that, let's chat for a moment about our goals in this exercise. Because I think it goes far, far, far beyond just messaging. And I think it's about the charter of our team like, what are, what are we responsible for and what, what should, what should be within our domain. And I would say that there's kind of two things. So, yes messaging, 100% and then in addition to that there are two other elements that come to mind. So, one is to assist in the deal. Also, I would say that in most of the places where I've been a PMM that the times I felt best about my role is when my PM has said, you could swap out William for me. Like, I've had enough of the relationship where I understood the product, the roadmap. We had a tight enough relationship that if I was in a customer call or an analyst call or whatever, whatever feedback I receive, I could convey that with high fidelity to the PM. I think that level of type PMPMM kind of relationship is difficult when we have like a 1 to 10 ratio. But we have almost a 1 to 1 ratio at the group manager level. So, all that's to say is I would say that I think Cindy, you do this really really well. I know I used to do this a lot more and candidly I haven't done it a while, but especially when there used to be a lot of Kubernetes deals. I would join calls and serve as the expert on that. The market knowledge of how the industry was working of what other tools were and how the ecosystem played and in particular what Gillab's capabilities were. So I would say that idea of like helping the deal move further is absolutely something that this team. Should have as part of like honor you know that utility belt. I don't know that analogy makes sense Batman had like a bunch of stuff on their belt so they had like you know if there's like 100 things on the PMM tool belt. That's at least one of them. I'm kind of rambling. The second so help the deal alone and then also for us to understand the buyer's journey as a core competency. So I would say a goal for the entire team should be if you gave us a whiteboard we should be able to construct from memory. All of the steps that a buyer goes through from like haven't heard about get lab yet to talking at commit. Right so from like acquisition the our pirate metrics like you know to referral to becoming like a referral customer. What are all those steps in that journey and we should be able to whiteboard that and so in order for us to understand. The the half of that that is like okay now there's an opportunity and then sales goes and works out opportunity. We should be familiar with that process and know it and understand and deal the whiteboard it and. Be able to help optimize that that's essentially what a sales play is at all though there's we're still defining sales place. Just an aside harsh has done a ton of sales plays that I think is really really going to help us out here so just want to side there but. I'm going to stop talking. What do you all think about those points helping sales and understanding the buyer's journey. So in my previous role as PM. I used to do a bunch of those things right so like like you mentioned but here since we still. Defining the roles accurately I that's why I call that messaging but I absolutely agree with what you say about us being point on. Because talking about the market knowledge about where the industry is going what the competitive environment is and so on so don't agree. Cool and and then city I know like I said I think you do this really really well. And they just kind of thoughts now on as we just kind of set goals or directions. That you share with the team on just being engaged with the sales process. Well in terms of what where how I contribute and what. The purpose I guess of my participation in the sales processes to. To accelerate the sales cycle. I'm by by removing barriers really overcoming objections at kind of a deeper level than what the sales team can. I do give feedback to the PM's as well and pull in the the appropriate PM for an even deeper discussion when appropriate so I'm kind of doing a little bit of triage to try to shield the PM's from. Generic discussions. Yeah, but in terms and in the messaging yeah absolutely I try out. Messaging on them and continue to refine it you know one of the things that. When I was shadowing said they was doing the. The non funding funding tour you know we're seeing is talking to investors without trying to raise money yet this was just to plant the seeds. And every investor meaning they would go into they would come out and say what could I have done better every single time. And I've tried to do that when I meet with customers what could I do better how can I evolve the message. Where's a miss you know. So it's it is to some is point about messaging it's an opportunity to continually refine the message. So yeah so I think there's there would be like four goals on us being involved in the in the sales process and the sales cycle. Primary research of our messaging and Parker I think you listen to this call as well. I think I linked it maybe last week. It was a last call I had with pile somers onel hung anyway. Oh, now I'll said this they just said this concept of it was like. Our research on messaging should be research on. So, so one of the things that they wanted us to avoid was something like going to the sales team and asking the sales team what messaging works for you. Which would be like a step removed instead we should be directly talking to customers and prospects like Cindy. Is doing to try out that messaging directly on the market and get that direct feedback and I just kind of think of this like. Yeah, and the same way that a PM would iterate on the features and what you know they ship a feature and who's using it and they get feedback on that same thing with us on messaging doing that primary research. So it's not just sales calls to you can get that from events and round tables and totally agree. Yeah, so our our higher level goal is like market tested messaging. And then there's several places to do that one of which is the sales cycle. And so coming out of from the other end we're saying like why should we be involved in the sales cycle. And while it it hits that goal of of market tested messaging. So say market tested messaging knowing the buyer's journey assisting sales on key deals as a subject matter expert and. PM tree treeage assisting. We get feedback and pass it to them there's like an element where we we act as a the hand of the PM or an assist you know assisting them on on their direct feature. Work. The same way that I think that that they do that they would do that for us for messaging as well that there would be a team. Cool. So quick questions in the on the calls that you do get on with with sales is it something that you look up on S. PC and talk to the sales rep and get on to those calls or visit the other way around you get invited to those call. I get invited. Yeah. I was going to say it's organic for you right you you naturally get invited nothing probably to much higher rate than the rest of us. So my question was going to be Leo get up buddy. Sorry. How do we get the same. You can get a you. You can go in there all going so I want to add one more net new we need to be looped in. Well you need to if you establish yourself as a subject matter expert in a particular topic they will naturally loop you in because if they're talking was somebody. It's going to go deep on that topic. They want to have someone there to back them up on questions so. You know whether it's CI or Kubernetes or. You know what to get off spick a topic and just become the expert on that and part of it is knowing not only what we do and how we do it better. But what the the rest of the market so how to how to our competitors work. And what are the common objections what's going on in the market. You know, let's get all that I'm just I had a week but had like it's still there's a forcing function that we need to be invited like I think we're you know we can't overnight change the perception of other people and I think we all have a pretty good. I think we have a good area where we're subject minutes. But what how how can you get holding is it's like. I'm like once a week but what I so the other thing that I do though. I have relationships with some of the reps and I've done a few things with them so that they just naturally like David Wells calls me into every security deal. He's found that they can go faster when they does. But the other thing is in QBRs I look for big ultimate opportunities and I have kind of a running list that I keep and then and I. If I don't hear from some of those reps. I have on occasion not very often but on occasion I've reached out and I could see where you guys definitely would do that. To get your foot in the door with them so find some big sea ideals and reach out to those reps and say hey you know. You could either offer to help or offer to just ride along and listen. For feedback either way I think they would they would welcome the engagement. Yeah yeah I think all all of them and coming back to like all there's so there's kind of three bits of advice there. I think one is. Being an SME and deepening your your subject matter expertise and maybe even in some ways of angelizing that. So it's like being the SME. Building the relationship with sales and keeping your list of top deals. I would say that that's been the same thing for me when I've been invited to calls. It's been because of those things like folks in Vittanyan because I knew about a technology and. Candidates is probably why I used to get invited in a ton and it's tapered off a bit because all the reps I had really good rapport with or you know maybe left get lab so. It's now incumbent on me to continue to build those relationships and I think all of us. And then towards the keeping the list of top deals that's like the topic at hand right so the sum is original point of why should we keep a you know keep a breath of. Kind of top deals with a quarter. Yeah one of those ways is we can do a reach out we can reach out to that. And so I think that's the way to get up and be like hey I saw that you're working on deal X and that deal is a sea ideal or that deal is a good up steel. I do actually I got pinged on get up the other day and I think I sent them your way. So I'm yeah. And it's not coming to mind what the specific deal was but I think those are kind of the three. Three ways so this is like. I think that's the one I miss because personally I throw myself out there a lot like every QBR every every interaction I have on what they work here uses and very very serious about it so. Yeah happens it's not the way that I would like. I think having that list would be good. You might need to be more specific about how suggesting how they can move so. You know, you're very specific information about. You know I can help you overcome concerns with Jenkins or I can help you over you know that. Yeah. The thick. And as otherwise it's a great idea. But they may not. I think to engage you because it's abroad. Yeah. I'm not sure what what they could do. I think I think if you think about it as well like what are the. I think if you think about it as well like what are the biggest challenges for our sales team right like they want to. Excell ultimate that's like their number one goal right so. Security is the is today is the way that we sell ultimate. It's a fabulous quickly becoming a way that we do that. So Cindy and Kormack are they're just going to be pulled into more deals. Yeah. And we're going to see that the so on. And we know that we can. We can't wait to say. But there are a lot of emotions, there are land with get upsmotions. There's a ton of accounts where we. We can't get in with the dev team but we definitely get in with the off steam and the folks trying to do I see. Yeah. So that land motion I think so me is one that you could get looped into and then Parker I think that. There is a lot of either land with CI where they want S. C.M. NCI or here's this SCM account and we need to get them to adopt more things. And see guys the gateway to security, right? So in a lot of ways, if before they can't even have C.M. You come and help them and talk about how great security is, they really need to get on the C.I train. So. Yeah, great point. So anyway, I think I think C.M. You coremaker always going to get pinged more just because that's where the that's where the dollars are. Because they rock. Well, and because they're great too. So coming down then to chat about keeping track of some number of deals. Each of us has like this is our list of deals that we track. Let's see. I'm going to start like a new item here item F. Which deals to track. So let me let me ask this Cindy, I think you probably do this the most formally where you have a list. I had had a list in the past that don't currently does anybody else have a list or report or any thing like that. But let me ask this are all of your deals Cindy enterprise deals or do you track any SMB or mid market. Just enterprise because up. I'm I only get involved in the really big ones honestly. So. Let me raise this question which I think I think makes sense I think when it's a very high dollar amount that's warrants our time. And also those sales cycles tend to be more complex and involve more stakeholders and require our time. But. What do you. How do you all think we get involved with SMB and mid market what's what's our path to surface area there. I don't know I mean honestly I don't have time to get involved in ones for 30 seats or something I I'll only do the small seats if it's. A big company that has 2000 developers so they're just trying it out with 30 seats but they have a potential to grow to 2000. And it's just not worth my time. To get involved in all of the the ones they chooses I think it would be good to understand what challenges they have and I if I had more time. It would be nice to go listen to some of the chorus calls to see. Sorry to see how those conversations go and understand what barriers they come up against. Don't have enough hours in the day. And I would say the way the way we should look at like the structure of it is not necessarily like if I had more bandwidth I do acts but like what are we prioritize. So the so in my thought process is if if we're only involved in enterprise deals. And it's not that's I don't think that that works for the business and there should be some amount of bandwidth so maybe there's like if we're like have our top seven enterprise deals. Maybe we only get involved in the top five and we just saying no to those other two. And the reason we do that is to have some surface area to mid-barkiness and be. And the thought process there is that if we. Consumably like hone the messaging and hone the process right we understand that buyer's journey and so we can. Understand the process that's working and we can proliferate that and help to proliferate that. You know if you have a good SMB motion and you can you can figure that out with with some small surface area but then you can scale that and that can scale really really broadly quickly. So we could similarly drive a lot of revenue right. So we can use the SMB and the micro just proving grounds in certain areas right enable better and like you know I don't know get things ready. There are certain years where enterprise is going to be different right it's going to be different messaging with different pains level blah but where they aren't as far as enabling our team. You know like spending time to make sure the SDRs and then marketing and SMB are a rate or rock and then performing at a high level right and like doing things to kind of like. BRIs and years while we're there to be able to focus more time on enterprise I agree with that. So I've got. Yeah got. I've got two two thoughts one one is that some in market deals can be like enterprise deals where you know it's has a little bit of a longer cycle and there is a key stakeholder cell. And I would say even though the dollar amount and the eventual vision of any individual mid market deal you know so you might go into enterprise you might be like what we're selling we're landing with 30 seats but there's the potential for 2000. And you might look at this mid market deal and it's like well we're selling 30 seats. Welcome, core Mac we're selling 30 seats but there's the potential for 500 so the potential is in their high. But the potential for all mid market right if we can hone that process and hone that messaging potential for all mid market can be can be huge so it's it's worth it for us to be in this. One mid market deal where the potential's only 500 seats because we're going to scale that across the mid market. So so I think mid market is a place to get involved with deals and then SMB again it's kind of like understanding their cycle and and for them they're just like they have so many for kind of counts they can't reach out to them all personally. So they're looking for like templates and scaled ways to reach out whether that's like scaled emails or content they're looking to do a lot of like automated processes. And so again it's kind of like working with the rep to understand their process helping them hone their messaging it's almost like the work you're doing somia with the STRs. Whereas the R similar like they're they're reach out to so broad they're templatizing it and and you know I think everybody probably gets like crappy email templates every day you know how painful those are. So if we can help our reps with some you know some good messaging and some good emails to send out I think that that helps out a ton so. Brian and Quarmac what we were just discussing was the teams cadence on being involved in sales deals and so. So I'm brought up the the concept of maybe each of us tracks the top five to seven deals by revenue. Let's say over the quarter we are saying these are the top deals with the quarter and then that seems like a good idea and then the only caveat I'm adding to that is that. I think one S. and the dealer any one mid market deal is never going to be the top deal by revenue but we need to have commercial as part of like the work that we do. I mean, I think it's also looking, and it's in the shared folder, we're just looking at that agile, the agile opportunities reported, I pulled. I was surprised that there were a few opportunities, mid-market opportunities that were actually really big and in the top three or four. But I don't know if they were initially tagged this mid-market growth to enterprise. So that could have happened over time. Our numbers are awkward. I think other companies, I think, stop it like a thousand. If it's a thousand and above, we consider a thousand to 2000 mid-market. Right, which I mean, we are a mid-market company, which is, so yeah, that's... Right, we're as to other companies prospecting to us, we've been enterprise. We'd be part of their enterprise segment. Yeah, I think I've worked at places where 500 plus was small enterprise too. So, and if we're landing and not, if we're landing small with vision, some of these enterprise deals, could be initially smaller than the mid-market ones too. But one of the things that I've been looking at with the agile is I've been trying to make sure that I look at the top and from each segment. And I feel like, maybe that's wrong, because maybe the bulk of our revenue is still gonna come from enterprise. But it seems like hedging our bets. A lot of this mid-market deals is going to the SMB QBRs and the mid-market QBRs. People are always upset that their deals have grew them and moved up to enterprise and enterprise stole it from them. So, you know, the wins key deals can slack. Is there any magic to it's algorithm and what appears there as a key deal, or a key win that we could use? There used to be a link to it in the channel description. It's not there anymore. That is a good question. I was just gonna say, let's take some time to get to like tactics or to do's. As one to do, Ryan, would you be willing to try to track that down and find out who calculates that channel and report back to the team? Yeah, I'll find out. Okay, because I think that that could help us out. How do they call it, key deal? So, I was just filling around with sales quotes right now and it looks like you can search using your keywords and you might be able to find specific deals which have those keywords in them. So, I looked up for infrastructure code. Normally deals are not tagged as the dogs and so on but I found a bunch of deals tagged as infrastructure code, not tagged but had it in their comments. So, that might be a way to find deals that you want to get plugged into as far. Is that a report that you can run for that keyword? It maybe we can. I haven't tried that. I just tried doing this search and maybe I can export that. I'm not sure. I'm not an expert on sales force but at least there is a way to for people like me which is not that to a particular tier and not a popular news case to find deals where I can get plugged into. Yeah, so there's a couple, I have a couple of thoughts here so I know that pile has, I think even like a weekly meeting. So, I'll take, you know. Last time I showed up, they were really, really happy. And Canada, the last time I poked into this was, if you remember John tried to get us on this train a while ago and John was like, hey, each of you, these are your stable counterparts and sales. And I feel like that was really heading us on the right track and I like to get back to that where we have things we're focusing on. My thought for it is like, all of us should have some expertise across all segments. Mid-market enterprise SMB and Pubsec. So that way like, you know, like, it's not me if you're only focused on mid-market and all the get-offs messaging is mid-market and none of its hits pub the Pubsec market or none of it hits the enterprise market, right? So all of us need a little bit of knowledge across and then some of us need to go deep in some of those areas. So I want to get to that. All that's to say is I know that pile used to have a weekly meeting and I'll take it to do the poke back into that to find out what deals are on that because yes, QBR is a great way because they'll, they'll, they'll, they'll, they'll, they'll, they'll, they'll talk about in the QBR what they're top deals of coming are. But I think that this also evolves. Uh, I'm thinking for a moment, I was thinking like, is it worth like somebody or some, some of us going through the last set of QBRs and just pulling out like making a list of those top deals? Does that sound like a good use of time or should we like curb that and use other tactics now and wait until Q3? But then when we attend Q3 QBRs, that will be a list we want to generate. What do y'all think about that? I mean, I'm not needed to start. I'm keeping on because dog is back here chewing away. Like I think about that during them sometimes I'll like tag myself to come back for stuff and and sometimes I do sometimes I don't. And I know before we had gone to the point where I was like, open an issue for everything. Maybe we can meet in like a middle ground. And like whether it's all of us or one of us and sometimes I'll see something that's like security and I'm like, my head I'm like, oh, Cindy, and then a lot of times you've already seen it to be completely honest. But yeah, I don't know. I think it'd be good to keep our eyes out. Yeah, I think an issue for everything we hear wins in much, we're not gonna do that. Yeah, yeah. But I would say in the next set of QBRs, an artifact that I would like to team to generate out of those QBRs is a list of the top deals. So whether maybe we put it in an issue or maybe a Google Doc, but the idea is like, every rep puts their top deals in their slide deck. And so we would then just like pull that one bit of information. So you could just look at this one doc and be like, these are the top deals that people are pursuing. Right. To generate that artifact on the next set of QBRs. And then my question is, is it worth going back to the last set of QBRs and spending some time to generate that artifact? I don't know. I'm just kind of asking what you all think about that. Since we've got to do some research on here, I think it may be, especially since there's ancillary circumstance and we're gonna be pivoting a little bit doing some research, I think it may be a good idea. And we could just do like one issue, right? For all of us like QBR takeaways, have like a section for top deals, maybe a section where we each add a few bullet points on something we found interesting. That would be kind of easier to wield. But I think that's a good idea, personally. Okay, opposite that's like an optional idea. If you find yourself some spare cycles, open up a couple of QBR decks and just pull out that one slide and just that'll give you some stuff playing of like top deals. I don't want to task it because I think that if I poke into what a pile is doing, and I'm pretty sure that maybe Onell has something similar, I'll try to figure that out. But then almost certainly they also maybe have like even just a dashboard where then we can just pull out the top ops. And I will set it to do to myself. So, a text of dashboard in the last rating, there is a sales dashboard that gets shared in the worldwide sales cards. So that captures the latest. I'd like to get to it. Boom, Simon's already got it. So this dashboard has the top opportunities by dollar amount or let's just poke into it for a moment. I will not share my screen so we can put this on YouTube. Good catch, good catch. But, okay, so this is a helpful dashboard. If you look at this, there's like a forecast, there's top by region. So here's a place to start. So I'm gonna put this again on next week's meeting so that we can kind of keep this conversation going. But I think we have a few action items out of this meeting in some few tactics. And I'm gonna set to do, to do team review this dashboard and to do William add the four reasons to be in sales motion to the handbook. So I've got a document of summary of this conversation. I felt like this was really valuable and worth our time. I realized we're now like five, we've got like five or 10 minutes left. And there is another important thing. So on point three, here is the issue, I think. Yeah. So here is a question from the UX team who was working on redesigning these competitive pages. And their ask is for this part of the page, right? So they're gonna redesign the graphic that are working on this and you all have done your 15 features. And so then the question is for the bottom part of the page, what should this format be like? Now I probably know for a fact we don't want this tearing information because we don't want to put every feature. We want to keep that list consumable. So in order to make it consumable, it's gonna be summary in some fashion. So that capability may include functionality that's in multiple tiers. It's not always gonna be neatly in one tier. Does that make sense? So we probably have the tier information. The question is, does this look like a good format? Like there's the name of the capability and then some descriptor of it? What are you all envisioning for the competitive sections? We were talking about rating them 0, 1 and 2, which may actually be necessary when you think about things like, well it's in their product, but it costs money, it's in hours and it's free or something. Where there's some meaningful difference and we want to pick a 1 or a 2 instead of a 0 or a 1. And so maybe we need indicators of that here. I'm not sure that we do, but maybe we do that. So that is, that will be in here. So green check mark is 2. That's a yes. Red X is a 0 that's a no. And then we have another little symbol that is, that's a yellow or orange thing. It's kind of like partial. So that's, so our 0, 1 or 2 will end up on the page as like, so we'll basically should have the name of the feature. This is like 0, 1 or 2. And then maybe some descriptors. So this is kind of what I think. I think in phase 1, we have just a description of that capability. So you have the name of the capability and a generic descriptor that that one descriptor could be put on any page. In stage 2 or in some future iteration, this paragraph could be specific to the competitor. Right? So you could, like this one says, like bit bucket cloud was built with cloud in mind, although this also seems like it could be generic, whether they're comparing us to get lab or anybody else. But does that kind of make sense? So that you would get attached as a team. You've now selected your 15 features. There's then a step where you mark 0, 1 or 2, 4, I don't know, the top three tools. And then a future ask soon, probably still within this quarter, would be draft a description of that capability. And it would be like a two sentence, a one to two sentence descriptor. And then the idea is it'd be generic for all the tools to start, but then at some point in the future it could be specific. Does that sound like a reasonable ask? Yeah, it does to me. And it sounds like we're going to meet that, especially when we start looking at these, it's kind of partners where they're going to have, we're going to want this to be fairly friendly. So I think we're going to want to set that context. We should definitely be sure to inform the design and the teams and anyone else working on the site that we do want that to be very both eventually. Good call. So is there any other information that we would want in this block? Any other, like a link somewhere or another section or? I think we definitely want at least the ability to put in a free text link, because if the partners will probably have a partner page that we're linking to. So the partner page link will be like at the top of the page or it'll be like for the whole page. I don't think we would link it for every feature. Like if there's like 15 features or 15 capabilities, we wouldn't put a link on each block there. But what if we had a video or something that we wanted to. Yeah. Yeah, definitely for our for our technology partners, we should have a comparison. This is not a competitive. It's a comparison page because somebody's going to have the question. They're going to be like, well Google has Google Cloud Build. How does Google Cloud Build compare to get left CI? Well, we should have a page on that. And that page should link to our partner page, as since here's all the ways that you can use GitLab and Google together. What we did kind of like Lego is, you know, like had all these elements, but it kept it kind of lean for the actual visual, just capability, name of the capability that could be an anchor link with the score. And then if it has an anchor link, we click down that goes into the detail where it compares. And that way, if we build it, first step is get them all together, score them, have the visual. And then when the descriptions come, they just anchor link down to where they're at kind of all in one little area that I'm not like a long, laundry list, right? Like it should be wheeled. Right. That's exactly how they're designing the page. So they'll be like, cool. It'll look like this or maybe like this or, you know, there. Yeah, so they'll be this kind of graphic with the scoring at the top. Okay. Um, actually, uh, what is this? Like, there's a chart that, um, anyway, like it could look like this or it could be like the way I think of it as like a D&D chart where there's like a circle and it has like, or like Pokemon. If you all know what I'm talking about. And do, uh, so one of the ideas was instead of visually representing it with these like bars, a good way to represent this is like on a stats chart, um, like, uh, anyway. So that might be a cool way to do it. I'm just, I'm leaving it up to the UX team to figure out the best UX. We're just supplying the underlying data. But there'll be some visual graphic because we found that those are helpful to people. And then they can click. It's like to see like, well, how did it come up with this score? And then that'll go down the page to like a list of features. Like, like we have today, but instead of being like a list of like 437 features on one page, it will be like 15 consumable capabilities. So the summary takeaway that I'm going is, is we're basically saying use this exactly out. You know, feature comparison, uh, name of the, name of the capability, a little descriptor and then zero one or two for that section. And then we want to tell them, hey, we want this to be variable because to start, it'll be the same for all of them. So we can just get it up quickly. But then we'll want to iterate to make it specific so we can see something specific. Uh, that's super helpful. Let's chat for a moment. I'm apologize, Cindy. Let's come back to number four. But I just while we're on the topic of Somia, you're asking about, uh, configure. So the summary of this is I've asked this every single time we've done the exercise, like do we get rid of configured because it's a little bit weird. And so, I've chat with Kenny about it and Kenny was like, has been of the opinion that yes, we should keep those. And so my thought is as long as we make the page clear that we don't do what, you know, I don't know, chef, like chef does. So if it's, if the set of 15, if the set of 10 to 15 capabilities, like there's probably seven of them that we don't have. Like we just don't do that. And so when the little visual graphic is clear, like chef does like their point on this part is really high and our point is low. But we do do some infrastructure configuration stuff. And we should have that kind of listed. That's, that's my thought on it is yes, we have it, but we just make it clear and in the description, it should be clear like chef does this, what does this skill, I've doesn't do that, you love does this people use get lab with chef. If you've got Kubernetes, you probably don't need chef. Does that sound right? It does. And maybe we can chat on our one-on-one with more about this because I think there is some level of overlap between what we capture as features and CD and configure. So we might want to be very clear about everyone. Let's follow up one-on-one. I'll just say quickly on seven that harsh will schedule a call with this team. So I know that's on their plan, so look for that soon. Send you, do you want to say anything about number four? Just, I would encourage everybody to follow the conversations in the security channel that I put there. So 30 second background on this, said challenge me to see what we needed to do to grow security and so I put together a plan that's very broad and need to make some short-term progress on it. Some of the items are a lot longer term, but put together a Slack channel to start pulling in Mel since a lot of it is messaging and other folks. And Danielle asked on Friday, why is security important? And so I kind of got honestly irritated and said, well maybe David and Sid would like to answer that question and pile jumped in and answered it as well. And so he's got a document, yes it's outdated. I've asked them if there's something more current, but it's still pretty insightful in terms of where he's coming from and how they thinks about sales plays and sales progress and growth. So I would just encourage you to look at piles document and follow along in that channel. Because the other thing is Danielle kind of, I think had an aha moment that there's more opportunity on the inbound side to guide people towards security as well. And part of the genesis for the urgency of the web piece and the messaging was we went out with the MQ last week where we did really well. And so we're talking about hey we're a devsac ops company and we're really good in security and then you go to the homepage and there's nothing about security on the homepage. So I was trying to resolve that quickly and unfortunately didn't reach that resolution, but at least there's there's a lot of healthy discussion at the right levels about this so follow along. Cool. I'll just say one note we got to we got to hop off, but Alita put together a wonderful Microsoft report. they has a list of suggestions. So those are things that we can take as a team and start to follow up on. Core Mac and Brian I will share in particular to the top items actually in Parker I think this covers your space as well. So one of the ideas is that Microsoft is doing more agile stuff with agile. So as part of our agile, our agile play and our agile thinking we need to involve some competitive intel there. And then Parker and Brian there is obviously always a GitHub and GitHub actions content. So review that document, look for the stuff that applies to you. Think about what should my follow up to the speed and maybe the follow up is I don't do anything with this, but maybe the follow up is okay I created an issue and I add this to my plan or I think it's up to you. So review the document, think about what your next action would be and reach out to Alita to coordinate with them because I know she's also for example in another some prime I hate this stupid freaking group channels. I don't know if you all get these people slack you and it's like you know I have like the Cindy Somio William channel, the Cindy Somio William Cormech channel, the Cindy Somio William Cormech channel, was this a song that would involve me I try not to do that. You are really good at not doing it, but I'm saying like I currently have like four or five conversations that are like this but any and one of these dumb channels I have a message and it's like Alita's like yes and it's not Alita's fault either other people have started these channels but she's working on Angela and they said yes I'm working on Angela yes I'll loop in Cormech so anyway that's my final word on that so thank you.",
  "So it is the sick, meaning secure and govern growth and data science, meaning applied MLOPS and anti abuse team meeting. That's a big mouthful. We might get a better name over time. That's from meeting for September 14th or 15th in APEC and High Allen. Glad you're here. Why are you here when it's midnight? Glad you're here. Don't make it happen to come to this meeting. It's really late for you. So, but I'm glad thanks for coming at least once. So, News and events. I've got a lot of things on the agenda today because of some of this. So apologies for that. I think it's going to go down over time. I'm going to work to do more summarized communications to improve the signal of the noise rate ratio in my communications to groups of people, including this group of people. This will is written for this group, adding more items to our staff meeting in agenda, often as we only, rather than posting to our Slack channel. And I am going to be showing that people leaders on the team will attend this meeting or read the notes and not rely on the Slack channel. So keep that in mind. Let's see, B is a read only item unless anybody wants to discuss it. And see, Phil has. Hi, and welcome, Alan to the meeting. I've asked Alan to step in as acting full-stack manager for security policies while I hire any in. Alan has graciously accepted this wonderful opportunity. So welcome, Alan. Thank you. I've got the next item as well. So anti abuse is moving product sections from seek to data science. Data science is a thick of the arenaing of the model ups section. So data science will include two stages. The existing model ups, which has three groups in it, which model can talk more about. And the anti abuse stage, which only currently has one group, which is called anti abuse. I think at some point there are plans to split the anti abuse into two groups, but that's not a near-metre. And we're working for all the changes around that. There's lots of work there changes, lots of handbook changes. Mom, do you want to say anything more about data science or model ups? No, I think for us we just roll up to data science, everything else stays the same. We still have the two main groups applied MLM a lot of and then later data of spot of it. Yeah. So any thanks Thomas for continuing to compile and report on across all my teams that I'm responsible for. In the engineering allocation meeting on error budgets and reliability and security incidents, so really do appreciate that. Gotta give Neil a high five, too. they does have they does half of these now and. And apologies for the noise if I keep asking for what's the story behind what's going on with reliability or secure or error budget stuff just trying to provide your cover. And I apologize Neil, I totally forgot you took half of these since Thomas has been doing it for so long, but appreciate it. I know you volunteered for it and we discussed it, but I just forgot. Kind of a thankless role. Honestly, and I volunteered because the exposure I get from it, it's nice to be part of a different collective group of people. I was going to mention I'll type this in here, but Tiago had set up for container security a bot that weekly. I think it's Monday, sort of like Sunday, we'll ping the team and ask for volunteer to go and resource that data and we just enabled it for thread insights. It's actually pretty sweet and it just does all the work for you, Thomas, sorry, we don't have to think people ourselves. So I'll put a note in there for that. If it's read only and Bill, you've got G. Yeah, I'm talented, so we had an update from Juliana. The date's haven't been confirmed yet, but it'll be sometime from mid up to about three to two. I think Egroge sign offers it's gifted to be mid to same but before everyone goes on holiday. I've got a lot of time line in there, but the dates that dates on in the handbook yet. The big changes we're moving to do at the work day, that's not available yet. I haven't seen a demo of it, I don't know what questions will be asked, but there's an optional self evaluation, which will move into work day and the work that we do has managers will also happen on work day. At the moment, some people are using the Google Docs, which is listed on the talent assessment page for self evaluations and for the manager work. I'd suggest continuing to use those docs until we get access to work day and see what the exact differences are. Each I am Jay or read only, listen, anybody wants to discuss them. Yeah, I don't care. Yeah, apologies for the late like live addition to the agenda on this one, but one more note on a change we're rolling out within secure pretty lightweight and that we're establishing a second team with a dynamic analysis. And so issue is there folks want to play that would like to follow along or ask any questions about it. The plan for right now is I'm going to be serving as a team acting in the EM and in addition to normally scheduled. Some duties for lack of a better way of putting it and so happy to answer any questions to folks have about that. And we've done the same thing in three to the side, so it's worth both Neil and T. I got a teaching team. What are you going to call your team or how will you differentiate. Was not planning to differentiate it. It's just a second team with end dynamic analysis. We're not creating a new group. Which I think is the same pattern that's happening within threat insights as well as just two teams. No, I know that there's tangerine and there's navy. I'm not a tangerine person myself. I'm so. What a figure. Out. Yeah, another two color Thomas. I started a little down. That's the team. Tomato. I don't know. We'll figure it out. We'll figure it out. The differentiation. I think the difference between was happening in threat insights and with dynamic analysis is that this is a split or long feature category. I don't know what even though we're keeping that we're not super in the group. It is the distinction is a long like who's working on specific feature categories themselves. So the the where the fracture point is happening is a little different but the approach and effect are the same. I hope. So I want to big rocks and how they she's section. I know if it's a big rock that kind of blown here perhaps more or less. I did that survey where you got an awesome response rate from the team on how to improve the MR rate for the team. And then I took a really long time to go through other results and summarizing make initial recommendations. So the loss a little bit of momentum. I got caught up in other things across functional prioritization and a customer escalation. So since then this is actually used by John Hope to lead a discussion at the development off site last week on just improving engineering velocity is one of the things you used to power it. So an add value there. But I've seen no comments. I think for anybody in this group, which means either no time for got about it or it doesn't. We looked at it and it doesn't have much value. And any of those things are okay. I'm just curious where the group landed. And if you haven't taken a look yet to see if there's anything you want to take away from it on things you might want to consider. And I think it's not needed to do so. And to consider not to do but to consider. Anybody got a chance to read it yet. And think about it or not just yet. It's not my guess is perhaps everybody's really busy and they haven't looked yet. I mean, I don't know how I live with Jay Neil Tiago. We've talked about changes. I think Jay you've already looked at some changes around refinement that was near you. That you were going to look at for interviews and report back by the end of the quarter. Tiago and Neil, I can't remember me before we ended up with the three-dimcy. Yeah, I'm hoping that MRA does kind of an artifact or a byproduct of some other actions. The big thing we're doing is more whole type of work like random miscellaneous, not schedule, not PM necessarily actions or issues. And that actually is creating some more additional work like it's just like free time work. I want to change a pace, move to something else momentarily. And these are generally smaller types of issues too. So they're quicker to knock out. Therefore, they create more and more and more. So it's just been a cool byproduct. So I think that's helping us succeed there. Yeah, we're also seeing some success with a, we've implemented like a weekly refinement meeting. Kind of check in, make sure that stories are broken down tiny enough. I think with smaller bits of work, we're seeing a higher MR8. It's debatable whether or not that's like just inflated, right? Like you can work on a small piece of code and ship it. And you can do that a lot of times you're going to get a higher MR8, or trying to be reasonable with that. I am noticing a nice pickup after implementing the refinement meeting. So let's hope for the best. I was going to say one note on refinement in second analysis. We're experimenting with a new section in our finding feature. So it's called looking forward and in there. We're using that is like a baseline where we add issues that we think need refinement. That will most likely be worked on in the next one to three milestones. So we're using that as kind of a base cover. Or some engineer to go in and add their issues and make sure they get refined within this milestone. Not necessarily any implementation, but just refinement itself. I should stop talking about. Thank you. I'm going to talk much more about your comment. Yeah, I'll verbalize and then I'll say more and then I'll finish writing what I was going to put down under the under the just moment. So this was an agenda item with the EMs and I can say it now in the secure stage. That is the analyzer team. So this was a topic yesterday. So my I would assume that this is more like as a part of the industry, but not digest the content. And what I was about to write and I am cautious in saying this because it almost comes across a smug and that is not my intent. In that looking at the MR rate within sec compared to company wide historically runs two to three MRs per engineer per month higher. And I think I could do that has to do with the. I mean, I mean, we've taken this to be true or at least asserted it to be true in that it's smaller teams that are working closely together in less busy projects. Then we see within the Rails platform itself, which does have an impact. It's some it that's not to say that we cannot do better, but the comparison. The favorable comparison. At least to me and I will knit this at times will lessen the urgency on this particular topic and I have to admit that bias that I have. Thanks Thomas, thanks everyone. So I didn't say any comments in the issue that's totally fine. I'm going to answer some of it useful, some of the analysis useful and that's great. So I will close the issue accordingly and just link to these notes good stuff Thomas you've got item B. Okay, all right after this done. All right, bed wrap and the can't or won't fix security issues that way, maybe we may be having there's so we've got them. For security issues that are subject to federal. If you have a feature category that is dips compliant or certified, you're probably going to be part of the fed ramp evaluation and any security issue that has a CVE associated with it, which means dependency or container scanning specifically. Has to have a remediation plan even if they're false positives. And so that's led to a separate discussion on what do we need to do. For do we need to do anything related to security findings on the commercial versions of analyzer specifically that was the catalyst for this particular conversation. Because on container scanning we get a lot of findings related to Debbie and based images that that project has not shipped a fix for or won't fix ship a fix for. So there is a separate thread that is going on here about what to do and can we do deviation requests in bulk for this classes for this for this for this class of findings. The the TLDR is below and there's a couple of all there's a couple of all of options that are being brainstormed within this particular thread. So I wanted and I know I've said a lot of words and I didn't say it well, but I wanted to bring it here in case there was any questions or commentary. Nothing directly related to what you've just talked about, but sort of related for Fedram, you're looking at. Any tips related security issues that have been raised. How far are you going in terms of ordering to find anything that hasn't already been identified. There is of all link in another issue a separate issue that is get that has instructions from app sec on what they would like us to do is for setting up container scanning. And they have set up a project with a single configuration that they're asking us to use there is some debate as to. How that project has been configured because it uses a combination of three container scanning tools rather than one. And so they've asked us to use that as a baseline for the fifth images specifically since there you be or the UBI specific images. There are there equivalent in my mind even though they're there different meanings. The TLD talked to Epseyg. Got it. And the key of the kill the images are stable counterpart of folks on no at least in sec. And so he's been quite responsive and keen and they is also helping chase down answers when they doesn't have them so that's a. Big he's been a big help thus far. Yeah. So in thanks for bringing the set thumbs. So in the hallway so from the development staff main meeting. I copy and paste of the notes. And there but net is the TLD are is can folks request to me and our peers was can folks check with their teams to see if the approvals are affecting them. So this is the new approval rules on segregation of duty so last this group not that everybody's here but in the group and they should be is only exceptional but have has this had an impact these new rules. And I think that's a few cases where team members have realized that they need to get an additional approval. But I'm not aware that it's actually slowing things down. Okay. No loses good news on this problem unless we're miss unless it's happening and we're not noticing it where this long things down but just keep an eye on it in case it does. Everyone please so good stuff. So. With recent changes. We've done a couple different changes with the secure and governd broken out from secure and data ops team and this net is I just compared the name of my team with my peers. My peers have one word team names ops dev create etc mine is sec growth and data science which is pretty worthy and also makes it like when I go into dashboards I have to pull data from multiple places across my teams so I was thinking about one word name. I've started to get feedback on it naming things is really important at get lab to name the right kinds of things and give them good names so I'm going to run it by David to Santa and Marles he's great person to balance such things off of. I landed on enrichment because what we do makes other things better we enrich them. It's kind of a very broad term but there's cover what we do not sure we're going to change the name which I'm not sure it's going to affect anyone but me. That's actually my intent is only affects my stuff not everyone else's. But maybe everyone else is in a small way or others in a small way but we'll see. Any thoughts on this good idea bad idea. I'm not way to there something looking for feedback. I'll just see the other examples relate to either sections or stages whereas enrichment doesn't so you'd be introducing something new here. This it fixed me as well I have a subset of enrichment so it would be kind of enrichment light. I have I'm not sure I'm not sure we I think you and I'm so kind about this I'm not sure we would get approval to introduce a new. Our name or department level would certainly have to talk to people up about introducing that and work day. Okay. So a couple of things you know these kinds of things that would sometimes put in slack and I'm trying to avoid number of distinct slack messages of putting it in here. Making a lot read on Lingon possible so I've got see that which is not really so I would like to add announcements of work anniversary's new hires to the meeting template. PM does this I attended the PM staff meeting I was a guest speaker there this week and like the comradery we have good conradery the comradery there was pretty good. You know firms shadowing me today I think they said in on the PM meeting as well is it's a pretty good field just people really knowing each other well and getting well well. So this is just two things I took away from it is anniversary's new hires. Oh verbalized chagos comment. they always know who you had to hear this thing. Great idea for new hires don't care much about working in a series where it's about for that. But I'd say I always think the miss the bottom announcements as they cover the whole company versus the bot just announcing for our team. If no interest in that part I'm happy to exclude the Neil you like the idea of adding. Yeah, I heard them shows you don't. I mean just last week I think it was Phil celebrated their third year and I congratulated them but then I missed another team member in sec. You know because there's like 20 people in that list plus it's team member updates that's not a channel I look at a lot like weekly I just happen to see that the day out so. I do like being able to celebrate together in this group. Maybe also thanks or praise section like thanks for doing this and great job on that. So remind ourselves to do that as engineers we tend to focus on the problems and challenges and not the celebrating the wins. I used to Jason that we add new content into this document for that, whether we just link to the slack announcements that we've already made. I think it's nice to verbalize them. I think it's nice to link to the slack announcements but also verbalize that I know it sounds like a bunch of busy work. I don't want to do things twice. They've we add the sections and people use them as they see fit. Whatever that happens to be but please don't over don't create busy work for yourself either so so judgment call by each person. Thomas looks like you had a Thomas and Monjots and thoughts on this too. I like it. We don't celebrate enough we don't do enough for team cohesion team celebration across the board that just as a corollary. I think that I haven't communicated well. I was hoping to add this kind of thing to a monthly section of why I'd retrospectives new hires discretionary bonuses work anniversary's big feature releases. I mean anything that we want to announce and celebrate we ought to make sure that it's. I don't want to say shop to the rooftops but we're shop to the heavens but but if we if there are big deals and we don't make it and we undersell. Oh sorry and hey for Nando here so I'm shadowing Wayne now just to introduce myself from the technical marketing team and I'll send the document right now which is something that we do for our kind of get together team meetings. And they kind of shows you can kind of you can look through it. I shared it to everyone on the zoom chat but you can see that we provide updates the new team members and small little introductions. And you can see sections that we have on gratitude and actual spotlights that we show like who we're actually praising what they've done that's good. And how we can highlight that because that will motivate employees kind of really increase that morale because what we're seeing is. These employees are actually getting recognized for good work that they've done and they're getting shout outs because a lot of times. At least in our team the cases we don't really although we work with each other where we sometimes are kind of siloed busy working on different things so it's good to know what everyone's working on and what everyone's doing so somewhat related to to what you were just speaking on but just that I'd share that. Going D so I'm not going to read all this from Daniel Kroth but summarizing they is looking for feedback on the development vision and mission and direction. We're brainstorming on in the development department on mission and vision in particular the approach is one everybody open up a little spreadsheet and follow the instructions anybody interested so if you're interested in doing so to take about 10 to 15 minutes please do it in the next week. Good stuff there. So we covered also the development off site that Daniel sick as an action item follow up on Thomas you've got. Right because I cannot remember and so I'm hoping to crowdsource a little bit of just configuration or keyology so to speak. Is there a reason that we don't use reviewer relette. If folks can remember the reason I'm asking is is contained within that thread but that is a tool that actually is being used to track if we have enough maintainers and any given project and since we don't use it we're showing up. And so that's why I was that's why I'm asking. Yep. When you say reviewer will that are you talking about on the individual analyzers yeah. Speaking only for dash we haven't had a need for because we have six engineers that's just going to rule that the same six people. Yeah, rule is excited that's what I kind of think it is but it's from a larger like if the company like where do we need more maintainers is the question. And so what is the question that the organization is asking. I mean, I'd suggest they're looking in the wrong place if they're looking in real lead to see. To find out the number of maintainers that's the wrong place the engineering projects page should list all the maintenance if you set up your team yearma in treats correctly. What if thought that was more the single social choice. Apparently not. So yeah. Yeah, I'm looking at the chart I mean I think on somebody's project we just haven't filled it out. All of you like we have the API. We've got a couple of us we have one engineer that works on it. So we haven't gone in out of the maintainer there because they know who they are. So if we are trying to maintain that as a single social truth we need to just go through and scrub it. Sorry, Seth and reminded of this. I'm reminded of this spider person meme with the two spider men pointing at each other who's the reviewer who's the author it's it's the same person. It's been a long day so I'm a little punchy so but yes that makes sense. So say, you saying you haven't added up to individual team members, yeah, all files in the handbook here. Right, I believe for that one we there's just no injury for it. I mean we could. I think I think I think that should. Yeah, well, it sure it shouldn't be using just really it. They should be using that as a social search and I think if you've listed my kindness. That should cover. I follow up question would be does that does that cover the senior plus engineers must be a maintainer requirement or not. How much you buried the lead the what you call buried the lead. I took the read only off your comment there so you can. Well, we we're going to end with the best things of the day. That's all. But, but. But the maintainer requirement. Yes, it does. Oh, maybe because it's required for senior plus. Going back to that is just maintaining one or more. I think it's a requirement for a couple of. So I was talking about the Olivia and is. Yeah, no, I was just making sure we were finished with the topic above. All right. And we're at time so I will move on to take that as a prop. Yeah, Olivia has a pop back on slack to announce that the newest addition to their family is here and happened over the weekend. So I so big big congrats to their family for that and I will be. Hopefully to celebrate him. Later when they does when they when they returns to work. Google. Thanks everybody. Have a great day.",
  "So, as the sick growth data science staff meeting, in development for September 21st. So, I've got a number of read-only items and apologies that I have a number of a lot of items in here. It's a function of trying to do fewer updates periodically in Slack as things happen and more in the stock with the way that they get red or not. Got a couple read-only items in news and events, A, B, and C. And I guess I'm going to jump down to the item D. So, instead of changing or creating a team name that covers my teams of secure, govern, data science and growth, to something else that is not for words or five words, as my peers have teams that are named with one word, that just makes a little more verbose and challenging to communicate. Instead, I decided to update my read-me. And now, as a correct list of my teams, and also as sections for dashboards, I use it, I mean, the ad for well, goals and priorities and OKRs. It's a much simpler MVC and a simple boring solution as well. So, just mostly heads up on that. So, it's not me doing most of the talking, even though I put a couple items on here. Any volunteers to verbalize E, which actually is from Cheryl, from the development staff meeting. Yeah, I'll do that. So, Cheryl mentioned the development staff meeting that team members and who teams have been experiencing delays with laptop orders, new highs and refreshes. You can see the details in the document. She's also, they has the spreadsheet to pick. I think, curious to see if that's happening across these groups as well. I have this historically. I don't know if she's understanding collecting historical data. It's been resolved now, but I had one laptop those six months. I think she's collecting current challenges, but it probably couldn't hurt to put in this any historical ones that are likely to recur. TLD, with what she's looking at us, how do we, how do we resolve these? It seems so, the doesn't seem to be a really good process for keeping team members up to date on on their laptop. When it's coming, it seems that you just have to manage the team and keep asking, and get some of the examples they gave was that they reached out directly to someone and said, what's happening with the status of this laptop, and five days later it was ordered in a way, which is not the best process. It means you have to be noisy to get them down. Somebody said, we got to do the laptop refresh. I filled out the Google Doc form and they need a follow up on it and I see that I was going to approach it. I totally forgot about it. That was about such a non-saga. I'm still only able to act up. TLD. Somebody want to volunteer to verbalize Nick's item. Some of them also from the Dolan staff meeting. I can take that. Nick in the development staff meeting, he's following up on last week's item about group software subscriptions. they opened up initiative and put on what services people are interested in looking at this. Chris and I think Grammarly are the top two. Thanks, Mar. On T. So please review and provide feedback of interest did on the greenhouse nice to have. Sure, we have the best list. I came out of the development office site from two weeks ago. I got a shout-less two weeks ago. As one of the action items, I think to optimize those. So we have the we're evaluating candidates on the right things for next steps. Also, please take, if you haven't already, take the training which is being renamed to TeamOps. Meck is managing efficiently for something. I guess TeamOps, that's a better name than it's not an acronym. I can't remember left to guess. Might be good time to do it. I took it today and also to re-advertise it to your teams. I took about an hour. I learned a few things and overall I think it was just a good experience. Managing so everyone can contribute. Thanks, Seth, for putting that in that for the stands for. I think that's one of the reasonable change in the name. The TeamOps sounds catchy or too. I'd actually think it'd be really cool if we actually release this to the public. It's just a video by said introduction and then a rehash of various handbook pages that I'm updated and also some quizzes. So you can test your knowledge. But you'll see. How much you've got? Hi. It's a good segue in that. I'll wear it at the end of the release, which means it's retrospective time. So, section retrospective is going to be scheduled for next Wednesday during a currently scheduled coffee chat times and I'll be pushing those coffee chats back a half hour just like we did this past time. The one change we're going to be making with invites this time around is instead of just putting it on the stage calendars and advertising and slack. We're going to be using the group email addresses that we have to invite folks to attend. So if people click yes, they'll get the reminders. And so here's the the ask here is, which please check your Google Membership to make sure they're accurate. We've had some changes and so it's just a good time to check before we start actually trying to use them. So. Thomas to add to Google group. We have to open up a access request. Unless you own the group, you might have administrator, or privileges as a manager. I got some group people can self sign up for as well. This is seeping them in the group. Yeah. Thomas, you put something on slack this morning about naming conventions. I haven't just the follow up on that. We looking at renaming these groups. IT is looking to standardize how groups are named across the entire organization. Right now it is something that's only rolled out and for structure, but they're looking to roll this out everywhere. And so one of the IT managers that are linked to the handbooks showing what the convention they're moving towards is. And so I'll go grab that link and I'll add it here. Thank you for the for the reminder on that. So in the big rocks and hot issues section. So sec and data science. P.I. Performance indicator review is next happening on September 28th. It's week from today. Everyone is invited to participate. Sink are you sync if they're interested? I've been participating in these for a while when they're primarily about fraudic management metrics. I got some value out of it. There's more about what the questions were than what the content was. But it was interesting. You must have the two product managers. It's added the cross functional stuff that we've been tracking things like percentage of issues that are in various categories and error budgets and bugs behind a various types that are passed SLO etc. So it's kind of a good combination of those things. So Thomas and Neil and others have specific action items in here to help fill out some of the content. But everyone's definitely invited to collaborate on this. So number five. Somebody who has been verbalized somebody else's stuff already. Maybe verbalized this one by the. I can take it. Let's see. From Chun in this week's development staff meeting. Every team's information is updated in a single get lab issue on a weekly basis. Issue creation was fully automated thanks to Sam's script. And here's an example. Thanks, Jeff. So something we would want to do as well is summarize on a per group level, you know, for managing engineering manager or senior engineering manager to summarize and and tag the state holders that are interested weekly feels like a little too often to maybe every other week would be better. I'm planning on doing something similar at my level and tagging anybody interested. Christopher and Andrea are interested. But that doesn't just because I'm going to do it doesn't mean everybody else has to. Yeah, I think anti abuse is going to give it a go. Fill and I were talking about it. We're going to do it on a weekly cadence to at least try it out. Is it is it that Christopher's requesting this or is this just to get better visibility overall or. Christopher's actually is not requesting it. He's but he's in favor of it. And I've been in favor of it as well at a high level at least of just knowing what's going on so that I can know what the risks are and we have to date on the status of the things, et cetera. But definitely weekly seems like too often. And monthly seems like not often. Maybe every two weeks. Christopher's comment on it was if some teams start doing this he'll read them. But then they won't be getting updates from other teams so they wanted to make sure everyone hit the opportunity to at least do it so that he's not focusing on some teams over the other overalls. I see most people typing. I'll I'll I'll talk while I try to figure out how I'm finishing up the thought. I'm honestly struggling with issues or the best delivery vehicle for this kind of information. No, it's it's really intended. I mean, I like the summary because it kind of forces a thoughts on what's happened where we I mean what's happening now where the current risks now. But is there value gained by having the historical information that these kind of update issues would provide? That's that's the question that I keep coming back to on my head and to me that helps determine medium appropriate medium. If that makes any sense. And for what it's worth, Montez's updates in Slack. She's been doing this a while with it. It was good way for them and I to collaborate and they tags me and Ella Ron on the business side. So it was good way to stop getting questions from Ella Ron when I end doing the updates. That's why they started doing it. And not everyone reads all their emails often. Like it's easy to assume if you have you subscribed in box zero, like you read most of your emails in and within a day or two or getting them you may assume others do too and that may not be the case. Yeah, you could update the same issue. Thomas just create one. Some of our PMs do that for priorities across three insights and security policies. They've the same issue that we keep updating. That sort of removes the historical context that you'd be introducing with a set edition. I'm going to risk brainstorming life then. In Slack, there is a weekly created issue for features and hyper-arty bugs that have been closed in the past seven days. I would add additional content as as adding additional comments from each group around risks or praise or anything alone those lines would be worth adding on to that already created issue that we have. Wordsmithing needed. I'd say sort of that. That's worth trying. The only way that's going to fall down is a Christopher wants all of these on one issue board and it doesn't fit because it's you know it's different. Yeah, but we're not being asked to do that. I actually quite like your idea. Why summarise what we've closed when we already have an automated issue that does they just stay at an additional information. That is fair what makes sense and try it and see how it works and then let's hit rate on it. Am I? You had a question there as well? Yeah, mine was primarily about what sort of information is important to you or anyone who would be reading this just to guide what are updates will be. So like the audience, the important information that you care about or that you think will be valuable as a part of the subject. And what I say is, you know, do it works for you and your stakeholders but maybe like accomplishments active work and any risks concerns. And it bear also who to tag to like is, just as an example, not that monster doing it perfectly, but it is a good example. Mon doesn't tag the product manager because a product manager is is is is already in the details. But Montag's me and then Ella Ron on the business side because we were asking for updates. Like I don't know if you're a smart, like you're maybe asked your product manager. Would they want to see these or is it noise for them? Probably Thomas would want to see them. And be noticed maybe some people in your team but they probably already know. Maybe your UX counterpart, maybe your set counterpart, maybe not, maybe they're hurting and the loop on the details. And then kind of go from there. Thank you. Seth, I like your your next item, lunch and verbalist. Yeah, so how do you question in terms of transition with our Johnson? I don't know if there's an issue that describes how we should be sending messages. I know actually stepping in in the meantime. If she's taking over the CTO channel, if we should do our questions starting now to them way to October 1. Just wanted to get an idea how to rock communication. I don't know a bit of an issue. That lists all the details but like on the things that I was coordinating directly with Eric on. I was told this was like this direction that one's going that direction like for the engineering internship program that went from Eric to Christopher and that's that's Phil's not mine. I know for a customer escalation that I was on that went from which not because of customer names. He's going to go public that went from Eric to David, DeSanto and on some abuse stuff that Jay and Phil and I and others are working on. It's actually not determined but as they was the sponsor but I think that's going to be the group of egroup members I update periodically. My guess is probably going to go to Steve Lloyd and infrastructure since we're trying to prevent infrastructure challenges. So I'd say ask and if you don't know ask and hashtag CTO. Okay. But if you have any specific questions, I might know just from other discussions. So you have to ask in our channel first or now if you'd like and we'll see we know and if not then post hashtag CTO. Okay. But it sounds like we're not going to try to dump everything on Ashley. Probably is overwhelming but we're trying to distribute it out to other people. Oh there's some are definitely going to Ashley definitely. We've been trying the engineering staff meeting document I think it was last week on Tuesday they hit the meeting and they discussed all of this in that meeting. Okay. I'm sure you can find it on calendar. Yeah. Engineering staff. It's a great question. So we added a couple new sections including thanks in gratitude. So I'll review these so from me to folks that seem to have a great job meal and presenting and answering questions on error budgets and other related things in this week's engineering allocation meeting. And thanks Thomas for taking on the R&D US R&D tax calculation project. It's a lot of work but it's a save lots of money for the company. That's all we had for today. Thanks everyone to you guys. Thanks. Have a good one.",
  "you you your make sense. Hey, I'm Ar. Hi Nathan. Hey, how you doing? Good. Hello, everyone. So, I'm going to get started. It's the sick growth data science staff meeting. And so you've probably noticed we're experimenting rather than with recording the meeting and then me uploading the YouTube later on unfiltered instead live streaming. So we'll see how that works. And remember, you know, if I don't discuss anything confidential, not that we tend to in this meeting anyway, but if you do, it's okay. We can take the we can take the recording down and make a private later. So under new hires and anniversaries, my three anniversary was last week. I'm definitely flies. Thanks for the good us. Also a reminder separately to make sure you and your teams are considering team members for discretionary bonuses. And I have a link to an example of a recent one with a little linkie smile face is one that somebody gave to me. But it just reminds me to remind everyone else to make sure they're doing this. It's a great program. That can bypass. Yeah, on top of the discretionary bonuses, we have the new gift. Give a big program. Those are released like month to a go pretty recently. It's a way for managers to celebrate families, families, you know, family families. So there's a link to the end book. And if you're looking for something to send someone, there's the Swanky TX Allible on the Swackstore now. That would be much less. I can take the next one. It is the on X two year get lab anniversary today. So we have to stay on it on that. And also welcome, Nathan, to the group transferring from different part of your group transfering different part of get lab. Thank you. Yeah, looking forward to it. Yeah, I tell you, bro. So some celebrations, Mark has won, but Mark's here can someone volunteer to provide us. Yeah, I could take that. Julian represented get lab and vulnerability research at Langdev 22. The previous week talking about Lingo. There was a lot of interest from academic institutions and offers to collaborate on all things. Code analysis. This is a celebration because for VR being a research team academic, academic links and events are very important. We were not able to do this in the last couple years for obvious reasons. And just a few links around that. Great job, Julian. And this is definitely the kind of thing we want this section. Mark was asking about that and it's definitely nice achievement. It's stuff. In news and events, I've already said this, but from. Or it in product management. The compliance development team Nathan's team is moving from the government stage to the government stage along with their counterparts already moved from PM and user design and QA testing. Who moved the government state earlier this month. So Nathan and the compliance team will move to report the fill in mid November. And fill hadn't updated on the talent assessment, I guess, somebody want to. Yeah, I can grab the. We summarized maybe not read it all but summarize it. Thanks, Neil. Yeah, so we've we're kicking off the talent and to be your talent assessment. Things get started in the 19th this week. We had a couple manager and a training sessions. There's a ton of material. There's videos, documents, sessions. There's a list of templates to utilize. I want to bring you this call a special attention to the self assessment template. I would recommend you know having all of your team members tickling at that complete that as they wish. It's it's a new version. It has get lab values remote work competencies and leadership competencies as well. It actually closely models what we see in our promotion stock. So as if you're the team members that are thinking about that track getting promoted. This will really helps support both the talent assessment as well as that track. So take a look at that. And then those AMAs I think yeah, they occurred today or yesterday based on your time zones. They should be recorded. You can take a look at the documents on the you should all have that on your calendar. Cool. Reach out to your P.B.P. people business partner if you have questions. Which is a little bit. Yep. So on next to just also some other things from our people on to partner or stable counter parts really on a. They wanted to copy over from Christopher's staff meeting. The summary is that Linux foundation and growth and development opportunities. People can level up their skills with world class training and certification programs. Get as has access to the Linux foundation course catalog. They include two for exams. To sign up there's a link for an access request and indicate the career development goal. You want to achieve and you can assign yourself. And you're manager for approval and then assigned to it another specific person for allocation. Specific redemption could it's a some good. Playing opportunities not for people just people leaders but also. Individual computers as well. Also from the staff meeting company wide mentor mentorship program from Juliana. The team is still looking for about 20 mentors. The time commitment is one hour per month for five months. 30 minute bi weekly sessions sign up gate is tomorrow up to over six six. So please do sign up for interested and encourage folks on your teams. If they're interested in being mentors and doing so as well. Sweet. I think on the big rocks. I shared this over Slack. I copied several of you as MR reviewers. I'd like to invite everybody I shared it within our threat and such channel as well. But we had thought earlier in the year about breaking out and having groups specific team commanders. I just kind of better organized create more visibility because right now the stage. Get a lot of team meetings calendars. They're very noisy and I've seen a tendency or have it to just hide those and then people end up missing things like retrospectives that we want people to be aware of in the 10. So there's a couple changes and then the other one is utilizing our Google groups for attendees or guests. I guess it's called guests in Google. To instead of individual just so we're capturing especially as we have new team members joined people leave the Google groups kind of self managed that versus I'll shoot. I forgot to add you and people are unaware of team meetings and such. So take a look at that and see how flies and resonance. I Thomas is not here. I's hoping they could share an anecdote about last week's retrospectives. We're experimented with adding everybody directly to those meetings. And the tip of the ear on that. Neil is attendance and meetings on group calendars is about one fourth of attendance when individual people are invited. It's just too hard to keep track of the group meetings and see the monitor calendar and do them so. I think that they effectively don't work in terms of attendance. People miss them. So it's a royal pain to maintain the list of people invited each meeting as people switch teams new people come on board people leave that move teams. It's a pain to manage all that but it's much more effective. I think with groups that become easier and you know we still have to get those updated. And then groups where the group is invited. Yeah. I think that separately from a group calendar. Right totally different calendars. But I was talking about that has less effectiveness on attendance. Not a group. A group being invited. I'm not sure how that how well that works or not. But I was talking about little nuance there in terms of what I was thinking. Yeah, I wish the terminology was different as well. And I think it's based on the level of a calendar again like we have the secure stage and the protect stage calendars. Those aren't that noisy but again, I've seen a tendency for team members to hide those because I just want to super clean. What do I need to think about calendar? So that's that's where the angle is with having like a assessed team calendar for instance or threatens like team calendar. And then additionally if we have Google lists, I'll come list of people and you can add those to those meetings. It kind of self manages over time. And we can also add those instead of I don't know what Thomas did again. I expanded there's like 34 something people in those meetings the retrospects. I think they could have also and maybe they did maybe just expand it those and added everybody individually. But they could have added all these group lists. But I think they also asked to make sure there's our accurate. So maybe you felt there is risky just making sure we capture everybody to set it up. It looks like from the Google calendar documentation. The end user receives the invite the same exact way right. Is that is that accurate or I don't know. I haven't really found that. I've seen invites that have an expandable group of people versus. Okay. Got it but it still shows up on their on their personal calendar. We still the option to accept a coin. Cool. I will I'll try that out too. Does anyone get an invite if they're added to the group? Do they get a calendar invite? Nathan you're not in your head. Yeah, obviously and I'm pretty sure they like to receive an invite as well. I think they'll work well. Maybe it's the best combination then. Google groups invited to can it invited the meetings because that handles when people leave. They'll get a little bit of a movement of a calendar when they get added to a group. They'll get added to the calendar. I like it. I'm going to start using it myself too probably. Thanks for bringing this up. Good stuff. I'm going to start bringing this up. So I had them on flight actually with some cross functional collaboration across legal and university team. And so community contributors and various people in engineering actually got merged just great. The draft announcement would love feedback on this is I get lab is the public draft announcement. But we love your feedback on this, but it's good summary of the merge request as well. I get lab we've opened up our development director shadow program to open source community contributors and those and underrepresented groups. This program allows the shadow participate in a development director meetings for a week. We're by mentoring great learning opportunities and explore career development. If you're an exceptional open source contributor to get lab or you're in an underrepresented group. I'm not going to read all what that is according to the people of stage on that. Check out the program to see if you'd like to apply to the. So any feedback on this it looks it fill had some already. Then if somebody wants to verbalize that. Be great. Yeah, happy to fill likes it. We'll need to consider confidential topics like we do in this meeting. Crenny meeting the shadow attend and what level of access to external shadow would get for example. Whether to have access to Google Docs. Well, so whether the shadow has ever or is currently an app. I can't see because Wayne's little Chrisers in the way an app can't for a rolling. Yeah, all good points. I think I've addressed a lot of this already based on a lot of people's feedback and sorry. My cursor was in the way. So yeah, any other any other feedback. I'm back at Spelman. I'm curious Wayne. I saw you ask in the CEO channel about the CEO shadow. Why we haven't seen any external people yet. What feedback did you get? There was actually one external participant for the CEO shadow program different than this one. It was a community contributor and. So. And there are a lot of loops to jump through. For an external person, it's still in the CEO shadow program. If you're a community contributor or a. I think it's the word community contributor. You can apply it. Said the CEO or CEO talks has a lot of. Compatential conversations and conversations involving material non public information. MNPI that you know that can be used to German financials or infer them, which. You know, could. Create, you know, insider or you know, inappropriate trading risk. I think that's the concern with the CEO shadow program is said a lot of what they discusses is confidential MNPI. A small portion of what I discuss in comparison is confidential or MNPI. So that's why there were there were a little less concerns from legal online than on CIDS and which allowed them to approve it. But it still does exist if you're a community contributor, you can a. A prolific community contributor to get lab, you can apply to be a shadow. For of CIDS, which is pretty. Yeah, I'm thinking what we call the community contributors every month every month every month and we have an award. I wonder for. I think prolifics not the word that they. But we do vote and we choose somebody. Yeah, I don't know if it needs to be somebody who's voted as the one of the month or some other measure. No, no, I know, but I'm slandering if that would that might be a. A place for you to reach out. If you're looking for specific people that might be interested in one of the others rather just opening the door. You have a whole list of people on that block us. They're really focused. Cool. It's exciting. Wait. So other topic here is from engineering staff. Please review and comment anything it's missing in the development spend initials program spend by October 21st. This is for budgeting purposes. What do we want to spend money on not people in terms of. Rex, you know, who to hire how many people to hire in various teams, but so affordable license, training things, you know services to license, etc. We start with what did we spend last year confirm we still want to spend money on those things and if so if we want to spend more of the same but also other things. So please take a look at that to those other things you'd like to add or change. And lastly just what I had in the list is thanks to Chia go. I'm always not here. But helping to figure out why the past meeting where the past meeting recordings went. They kept on failing and it's. I didn't have access to them and it's not what they were in Chia. So they can't rather than mine. And they was able to find because they took over the meeting for a week or two, which I appreciate it. So they was able to find them and they got posted the last three weeks of meetings were posted to YouTube last week. So appreciate that. Chia go. That's all we have in the agenda anything else you all want to do discuss. Thanks everyone have a great day.",
  "So, South is Georgia and West according to the Census Bureau. Okay, good to know. And when most South Carolinians identify as from the South, or what they say they're from the East Coast. I don't know. I'd have to ask my wife that question. She's the South Carolina native. But they certainly sounds like she's from the South. That's the October 19th or an APAC October 20th. Sech growth data science staff meeting. Catch them on the other things as you too, streaming started. And looks like I feel you've got the first item. Sure. Yeah, we have two new highest for growth. I want to mention names, but we have a comment we'll probably add that data on the next week. Both around the end of the month around the 30 first of October. I think it is. The end of October, beginning of November. We have one intention. Who's coming on board and another engineer for one of the teams. So, it's great. Well done to come and the rest of the item for getting a set for. So we don't have any celebrations or news and events today. We're going to for the live stream. We're going to skip. Big rock hot issue A and come back to it since it's a confidential item. Jumping down to be. Please review Chris for notes on the Q4 okay ours for development and also their summary of the e group off site read out. Lots of good information there in goals coming our way and why. Many are things for all of our teams and some are specific to growth secure govern etc. I don't want to discuss the details on live stream so that's confidential but if you're just announcing in general is okay. So when we stop we stop the YouTube will revisit that one. If there are any questions or comments about specific things any general comments. Wasn't there really surprising it was your words only? That may be correct listen you and maybe it hits the client is the different big. I was going to talk about every out step yet I will in a convex. Next time is good point. And just when on the topic of AKS, you're watching us to be looking at these now and coming up with AKS for us and our tapes. I would give it another week before doing that. As they settle and more people give feedback on them and product management, it continues to collaborate with us on them, et cetera. Good question. I couldn't hurt to start now. Just assume, you know, if you do it now, there'll be more iteration on it between, you know, in the next week. Of course, there will be continued off in our first iteration of the past that week too. First week. So on, um, get a couple announcements here. Um, I'm hosting a public exploration of imposter syndrome in the hallway. Please encourage your team to participate if they're interested in. I'm doing this actually with Play to HQ. Uh, they do these things called circles where you can just put it out there and people join if they want to mentoring platform I use. So if you think anybody on your team might be interested, please let them know. So that's an idea on improving communication. I've got an issue like here. Um, the summary is we publish communications in many different places in Slack. various places in Slack and engineering we can review in meeting notes in, you know, recordings like this and it's really hard to get the right information to the right people without learning them with things that they don't care about. So the read rates for the engagement rates, the are pretty low. So I found this thing, um, this vendor that somebody recommended to me that they're using that is kind of a combination of LinkedIn and Facebook. Um, for informal communications. Um, so you can target and now it's been rolled skill, work structure initiative, such as cross functional teams. It's, uh, gives you reading engagement rates. Uh, so we can look at effectiveness. It also has a great board chart feature. So if you're interested, you know, if you either like it or don't like it, one of your both the idea of this, please comment in the issue. And if you like it and would like to participate in a demo or see more about it, um, I've got one engineering manager, not an our team who's interested in with me and it further so far. Uh, definitely, um, at least do so. It looks like you're the upcoming show. Um, it sounds great. I haven't looked into it, um, but the functionality and the engagement rights would certainly be interesting. Um, to look at, um, however it is an additional total website that we have to learn and use. Um, yeah, that's that was my first concern as well. Uh, when people actually want to use the other tool, even if it's better. Is, is how much better it is worth it to have a different thing to log into and use. I asked the vendor that to, uh, and they think it is of course that who knows. Uh, and so see them repeating from, uh, the staff meeting and Michelle anybody want to verbalize see. Um, yeah, I can do that. So Michelle, see a dog all in development. This quarter was to increase my attention by 15% and we need help this week before the quarter closes. Please add in qualified engineers as a maintainer this week if possible to allow existing maintainers one week to review before the quarter closes. It's good. So there are two read only items that since we're, uh, we're doing just fine on time. Why don't we actually read through those. All right, I'm first. This is an FYI, but we'll all get everything on dog yet issues and agenda document and everything scheduled today before I close it out. Um, second section retro. I'm getting it scheduled for next Wednesday and Thursday. So we'll do the same thing. We've done the past few times, uh, where it's scheduled that are normal coffee chat times. And I'll just bump those down a half hour later. Um, and I will repeat what I did last time and making sure that the meeting will be on the section count or the the stage calendars, but there will also be everyone invited to it. Because that actually got more engagement last time than did previous. So just a heads up that is coming. Great. Yeah, I think that makes the difference of inviting individual people or the group, the Google group of those people are next is more made. Uh, so the other end is please review the proposal from Justin Ferris to improve the cross functional PI reviews if you're interested in doing so. He's looking at iterating on that and cross functional meeting development, product management UX and quality. So that I'm going to turn turn off the live stream and do a local record for the company.",
  "But pay attention to that as a member of the page to a Michigan election. Alright, so we are live streaming as to YouTube. It's the secret of data science staff meeting for cover 46th or NAPAC, 25th. The, got a couple topics you talked about publicly. Actually, most of them in one will stop the live stream and good private reporting for just get Latin rivers. So some new celebrations. Or A-SILver. So no new virus, the universe, for each to mention not the biggest, celebration. I have excited I got my first non-git lab team number, shadow next week, someone actually from an underrepresented group. And I have another one lined up in about two weeks where they get lab community contributed or so. I'm excited. I didn't know if anybody would care about this or if I'd get full approval of it, et cetera. So good stuff. Also under news and events. So the press release at the QCOM that David DeSanta did on GitHub security and different solutions, helps secure organizations, end-end software supply chains. It's pretty cool to see secure and governed featured so prominently. And I think as someone mentioned, NAPAC pressure talk. Lots of know that we do the Zothinnet there that we're planning, this was mentioned publicly, the pressure is not really on, definitely, of course, but need to see that. Anybody else read the fresh release and have any thoughts on other impressions? Yeah, I read the press release. It's just great to see good to see recognition. People also look at the 15.5 release post, secure and governed groups so I mentioned in the Arizona, all the features that they're doing. So in terms of big rocks and hot issues, second one we're going to go private on the first one. Up to over 31st is the end of the quarter, as they turned flies. So please be sure to put your final updates for your okay hours and comment and then with a good bad and try and tag your manager. So they can review and provide feedback for closing them. So it doesn't need to be done on the last day or first day in the next quarter, but some context would be great. We are staying with Ally for Q4, at least in development, in engineering and likely willing to issues have staff Q4 where the advancement and enhancements to get lab will give up, do okay or tracking friendly things and with the amount of single source of truth and about blue jibiscus and in the end of the next quarter, I mentioned that we've heard that recently. In a hallway, gratitude or other items of one discussed before we go off the livestream at the top of that one net. None public talk.",
  "This is the sec growth data science staff meeting for November 2nd or for those in the second year. I started a live stream a little bit early so it would all get set up before everybody joined. So I'll give it another 30 seconds or so before we get started. Actually, well, we're waiting to get started. Rafael, you want to introduce yourself. Rafael is out my first outside of get lab director shadow. Yeah, hi everyone. Rafael has introduced. I'm a senior air flow engineer at astronomer, a previous senior engineer of data and a data scientist and just learning as much as I can this week and really having a good time meeting everyone. So thank you. So, I'm still you want to cover it ever once since it's from commute. Sure, come here once to welcome new engineers to growth. Ross is a full-stack engineer and Roy who's coming in as an intern, full-stack engineer. They both joined this week. I'm seeing it's like lots of welcomes and thumbs up. Which is neat from Mark and Camille and Tiago and Nathan. Thomas looks like you have item B. Yep, absolutely. So this is New Hires and Anniversary. So we had a two year work anniversary last week and now I want to make sure we call that out. Make sure them was was was was celebrated as well. So this is. Two years within the P.I security group or glad to have them. So I'm going to see you many more. Hope to see you here with for many more. So. Good stuff. So in celebrations. I'm going to read this one since it's for Phil. So please join me in graduating Phil for discussion. I bonus for living our values of collaboration and results for nomination from Jeff Burrows. Which if I had to say is Phil helped me walk through resolving. Get conflict locally on my machine. they had never done this before and was struggling with the steps in the documentation. Phil jumped in quickly. Help fix the issues and also walked through each step and explained each step. What it was doing to the MR for better equipment them to resolve those issues on their own in the future. And a metric criteria because help is above and beyond. Phil could have just added a commitment and fixed it. But it's like time to teach me something instead of. So what's that Phil? Thanks. I am always impressed when someone opens a matrix. A metric race to update 434 handbook pages and one guy. This wasn't surprised to them quite a few conflicts there. Why 434 and one MR? But to rename some guessing. I'm glad you write that down for me. I'm not. It was at 434 or 32. I can't remember that. they was it was moving security in the handbook. It's a moving in the tire section. But what I notice is when people do this they try to read everything in one major quest. You don't need to. You can do your redirects and you can move you. But you don't have to update other people's content people link to your pages. You can do that in the follow up if you've got the redirects right. But so. I think a lot of people just are finding a place. And then they ran into problems because it takes them a week to get all the approvals and by the branches is completely out. I think. Anyway, we worked. It was interesting. I enjoyed working with J. Heinle with J. before. So that was nice. Good stuff. Seeing lots of good as we're. I'm sorry. I haven't seen Tiago in a long time. I said let Tiago less than I saw you. It was prebeared. I'm shocked. This is the new. Like. Santa's coming to town. Let's go. Just I didn't recognize you at first. And you only started growing that beer two days ago. You know it, Thomas. So anyone want to verbalize be. I put it in here. But it's a good talk through this announcement. It's actually our acting. CTO. I'll take it. This is an announcement. It's been a long time coming. I saw. So we've been. So. If you've been here long. I remember when we announced the beginnings of the. The patent program through through legal. And there was there were catalyst for that. And here are the first two that I remember going through this particular patent program. So this is a big congratulations for team members on inventive innovative work. For two patents first vulnerability tracking using scope and offsets. So this was a collaboration with. And that was a collaboration with Julian. The departed James Johnson and and Lucas so that this is a way to help us make vulnerability tracking over time, particularly for sast and anything that's related to like code level. That's like which line of code this. Availability is related to. It's designed to help us get a whole lot more accurate over time and so this and. Was really is really need innovation really glad to see this here in the second one is for scalable code testing and benchmarking. Which looks to be a collaboration within the entirety of vulnerability research. Was really an Isaac Mark denasht in Michael and so. Big thank you to all and as a promo there is a there is a bonus program associated with us. And that is available here and there's linked to the slack announcement. So. Big thanks. And hopefully more to come. Good stuff. To news and events. If I had a handbook update that documents have development should collaborate with customers during customer escalations stem from a retrospective in a recent escalation from a large customer. So and I was the author of the MR so but I also think it's important to not just because I'm the author. I'm not going to be I put in there but I don't need to verbalize it when somebody you hasn't verbalized something we to that one. I just say go ahead. More. Yeah. team ops goal of care for Q for looking for volunteers to become trainers for details in the development staff meeting agenda if you're interested. Thanks so much. Anybody want to verbalize see I know it came from me too but you hear my voice too often. Yeah sure. Do we want to invite guest speakers to this meeting from other parts of the company perhaps starting with our stable counterparts in UX. That and product. And well the mark who couldn't make it but mark marks moment is a hems would definitely be nice. We had David to Santa on secure meetings back in the day and it was quite helpful. I think that's the useful we see this in growth. We see bring stable counterparts along and we would achieve to our product meetings as well. It's really useful for sure. I do isn't finding out what other what I can to pass it on. Anybody want to volunteer to organize like reach out to people and say we we're looking for guests and get them to maybe one guest a week. That they just took anybody want to volunteer. Well, how about we have it we don't this way someone will volunteer and I'll do it this time to find the first guest and then we we put someone else to find the next guest and we just rotate through that way. So all thing lots of thumbs up so. Great thanks Phil. I was a guest in the product management meeting. I don't know a month or so though and it was. It was good to hear the questions that not from from the product managers I work with but also from product managers I. I never spoken to. So. In the hallway. Little bit thanks Mark for pointing out the Q4 okayers epic for product management. they found it before I did and let us know about it lots of good detail in there. For various things although they are in flux also thanks Thomas for finding the best in class comparison with I linked here and also. Someone else down to slide version of that same document where I think it's the same document but it's on same topic so. Good for understanding the competitive analysis the plant the okay the draft okayers from PM. But also the competitive analysis so I have not I read the. Issue is initially an issue not epic. I haven't actually read these two this document and slide that yet but I'm planning to that it's pretty insightful. On be please close out. To three okayers with a final percentage complete. Add a good bad try like well what didn't what you want to try in the future in a comment and tag your manager review you know completing this in the next week would be great. I didn't say please do complete in the next week you know if you need more time that that's fine. We're going on with collaboration and other things. We're starting to think about. Uh, hold with a planning for the end of the year. Um, and a quick discussion with Wayne about this who reported out that our first priority is to book our leave. Um, not to worry about coverage but once we've all booked our leave. I suggest we. Um, create an issue for this group and share our leave plans so that we've more about who's here who's not here and what and apps we have. Um, who are our teams going to contact if there's an escalation or production incident and they're looking for management support from one of us. Um, I'm happy to volunteer to create the issue and this and there's someone else wants to do that. And we can start out and I leave them as we. And then Wayne that's going to be. And they still wants on that idea. Yeah, I know Phil you and I just discussed this a few minutes ago. I want to say to Genders that we're not going to coordinate who takes vacation when we're going to see who takes vacation when and then figure out what the coverage is. Because people take vacation when they when they when it makes sense for them and then we'll figure out the coverage based on all of that. Thanks for the distinction. Yeah. And all just anyway, there is a special coverage as you hear those incident managers. There is a schedule obviously but many of us will be on leave and so there's a call for volunteers for those who are around. And this is around the Christmas and the experience. Anyone wants to volunteer for coverage. And I notice a few. This group already had which is awesome. Cool, so I don't know who put an item be but that's great. Thank you. Thank you. But let's not forget. Um, but please do read it. In, uh, Thanks. And gratitude. So nice job, Jay and team at getting. The bug reproduced and resolved that where some users log had trouble logging in some of the time. Some users some of the time, which made hard to reproduce, especially when they use certain password manager browser plug in. But there's really hard to track so great job by Jay and you, I think, did a lot of work on this. Yeah, thank you. You did an excellent job on following up and digging in deeper. So all the thanks they covered to him. Very happy as how that turned out. Good. Since we have a little more time, I know we don't want to stretch meetings to the time of a lot of it. But the time, but when we when we. We talk through the read only items. Things there. Good stuff in there. There's a link to a handbook page about, uh, beautifying our UI for developers interested in contributing to UI improvements. Where we're used to seeing these come through as, as okay hours to burn down. Back well, so this is, but this is a different approach. It's nothing for volunteers and what it wants to. And we can contribute to our improvements within with someone in. Are you existing? I'll read that max. Quote max not here. No, yeah. I'll read that max. Quote the idea was to empower the peer to make changes. They are deemed to help themselves and resolve directly with the. And rather than following our existing product development flow. And that's what it was interesting. And I'll link the participation that Yonic on sati can now. It's just recently completed as a part of the beautiful find the, you know, initiative. they read it redesign the login page. So that was a really big. Task and I think that should in 153 maybe 154. I'll find the issue and link it, but they definitely learned a lot from it. It was very impactful and a great experience. You're all. Do you ever want to read your item? Rubberized your name? Show thing. I create a model to revisit the decision to. Where. A discussion in a mouse that don't have a sub type. The discussions didn't didn't lean heavily either way. There was a slight inclination there to. To remove or at the very least simplified by by not requiring people to go and click there. My own personal experience is that that thing was always getting my way. Maybe the type of a mouse that I contribute. And the general idea behind my proposal was that. Contributing should be simpler and smoother. We already have a lot of tasks that are required. A lot of boxes to be checked. A lot of a. Vassages to reply. So any anytime that we are adding friction to this. To this process, I think we should be very diligent. In the values where we, you know, benefit the cost benefit of that choice. And and. I was particularly happy that it took two to a door decision. If it turns out that we absolutely need that. It's a busy thing to revert and put back in and go from there. So good overall representation of our values. I think. Next year. I go. Um, quick poll. As a thing, you know, the more we connect the better. So I'm trying to have a good question. Things versus the connect on. So a bit of a silly one. But what's your favorite slack channel. Actually like to hear everybody on this. So mine is all caps. Notice I taught I typed it in all caps. Chia, go, what's yours? Or tell them us what's yours. I see yours there. Next. Mine is random. But. Mine is one for not shouting all caps when you said it. Sorry. Sorry. Yeah, Alright. There's. There's emoji in. Um. In Slack that's a flashing all caps. So I don't know why that's my favorite. Why is it? Why do you like it, J wird. I see you're plus one there. I don't know why I'm drawing to it, but I am. Y. Yeah. Uh, the low level humor just really hits. I don't know to say it's great. Like you know what people are cracking about you. Like the simple things. I love all caps. My recent one has been the New Zealand Museum in Grand Channel just because it was a way to extend the time that I spent with the new people that I met in Paris. The first people I met in Paris and aside from Mark, who's not here, but it still Mark is the only other person that I met from GitLab and it was awesome. I met Seth there. It was great. We had bees in the balcony. And it was just neat to keep the channel. The channel's gonna go so I'll just go back to the Sex Section social. Seth, it looks like, sex social was your, your favorite as well. Yeah, it's just nice to see what other people are up to. Alan, a sex social, your sex section, social, your favorite as well or a different one. It's true. I mean, we have so many pictures from vacations and other stuff. Like, this is great to see that. I recently joined the app doors channel. I kind of like Instagram. This just people post pictures of where they can go out doors that really appeals to me. We spend so much time sitting inside in front of the computer. It's great to see where people are going. And what they're doing with this there time. And it's also because most of our company is not. In some of them is fair as different seasons. So I'm seeing a lot of autumn textures whereas we're getting a discreet. Tomorrow looks like you have some others as well here, fan of. Yeah, similar to Phil, you mentioned like it's nice to see what other people are seeing. Another cool one in that regard is office today where other people post pictures of their office view of the day when people are like traveling around it's really cool to see all the little views that they have related to that. I'll let you look at that. Yeah. And then related to that dog is always a great way to start you morning. I mean, you're a dog person. So scrolling through dog picks definitely great. And dad jokes was one that I ran into recently that just good content in their all around. Do you need to be a dad to contribute? Or they don't go at you at the entrance. They don't card you. And that was my first question too. And I saw a lot of people posting. I think everything goes as long as it's a yay dad joke. Yay for inclusivity. Indeed. Maybe it looks like you're a fan of dad jokes as well. Any others? I'd quite like office today as well. Seeing other people around the world with their offices and I like Phil mentioned different seasons. So people inside and out. But yeah, dad jokes is a out of a early-career family. It's good to use some of those in the house all this well. Good. Good. Did we hear from everybody? I think we did. Did we miss anybody? No. Yeah, I got looks like you have another ready as well here. Yeah, I had a quick one there. I'm just enjoying watching Seth having to run back and forth. Look at all the fans about the story. Get going. Go. Yeah. That looks like I cannot. I'm over. Let me see if I can knock that over that. Looks like I'm a. It's so good. It's so hard. I had my hands full with the baby. That's what they talking about. And I didn't get to meet the baby in New Zealand. So this is good. Yeah, they didn't come up. Yeah. Hello. Hello. Hello. Hello. Lastly, I know we're on live stream. But rough, any questions for any of us? Is your shadowing this week? No, no questions today. Unfortunately. Sorry. Cool. All right. Thanks everybody. Have a great day. Before we go, I want to congratulate everybody. That's in New Zealand for being in uniform today. You can and well done on coordinating outfits. I'm sorry. All right.",
  "All right, so we are doing the sick growth data science staff meeting for November 9th. And we've got one item that's primarily confidential. We'll go to a private recording for that. And then, but the other things, I think we can talk about publicly, which is great. And it looks like Tiago, you've got the first item. I do, and I was just about with the second one. The first one is who have a new backhand maintainer very soon. The feedback right now is overwhelmingly positive. I'm not expecting any blockers, so I'm sharing it a little bit early, but Mehmet will be a maintainer from Tuesday. Probably a little bit of a due. And the second one, those about to put in is that we have a study date for a new senior backhand engineering threat insights, sort of Jen. That's the second use. I'm going to write it down. It's great. It helps with whatever occurs, more maintainers. All that is well on the on the on the new hire. We've got a new start in composition analysis now for one December rather than five December. So, well, that's another one coming in. Nice. So there are some major changes to my okay, I was going to last time we discussed them, which I think was just a week ago, but you know, it's all about iteration right. I think they're mostly going to be stabilized mostly stable now, pending more feedback from you all. And also further review, et cetera. So, please start working on yours as one week has already gone in the quarter. And two plus weeks, this quarter will be low productivity due to unwork stuff at least due to the holidays. So let's, I want to review live in a non public recording, which we'll do after the other item. So we'll jump back to that. So let's see here is the senior, I don't see it. Somebody want to read meals. Well, it's a good read only. Yeah, it's really interesting. No, I'm here. Yes, a lot of people today. It's awesome. No, it's really don't. I'm just sharing my okay ours. Okay, say anyone needs influence on structure and theirs. And could as it's great, you're doing it in an issue. I think the whole company is moving to issues versus ally. I stuff to do mine and ally, but I'm putting all the details in issues wherever possible. And just doing, you know, percentage done updates in ally. So recommend doing the same. Yeah, as a part of doing the same. I don't create stuff in ally unless you really need to or you get assigned something. Do the primary work in the issues. Right. Yeah, it's so much easier to draft an issues. It's more mutable. And then yeah, I represented those all in ally this week. So there's structure and there's measurable tasks, but I'm not having my team look at those. They look at the issues as well. Cool. Thanks, Mike. Here. Nathan, you're at something. Now they were talking about a car and we were with the right on the. Yes, since it's not really only I've just added my link in there for draft ones for compliance group as well. Yeah, still need to align them in all that, but at least if people to have a look at. Great. Seth, I've got mixed item. Yeah, so I just wanted to share a tool that I use during the recent review process. It's a nice tool just to pull up everyone's comments. So you pull up people's comments for the last year, two years, whatever. Really nice way to just refresh your memory on some of the things that they worked on that might not necessarily be MRs or issues. Just some of their contributions. One of the things that I found in there is you can start looking at communication patterns. You know, people that are very grateful or people that are really pushy or they forget to ask with the next step is in their comments. So it gave me some ideas in terms of coaching and ways I can help my team be more productive. I don't know if we've looked at this as a product area. We think get lab. We focus a lot on how do we move code through the process, but not necessarily how do we help write better communication. So I don't know if there's anything in get lab where we've thought about that. So I just want to share that. I think it's with an issue. Put it with that idea there. See, see if the product manager likes. I sorry Nathan. I think it's a good idea. I think it's a good idea. I think it's a good idea. I think it's a good idea. See if the product manager likes. I sorry Nathan. I skipped over you. No, I just can't say that's a great looking tool. By the way, for doing that analysis. The thing that I that reminded me was we were looking for a. For a balance to the MRAIT. KPI, right? So, oh, you got. Excellent. That's great. But what is the quality of those MRAITs and one of the things that I thought was. Analyzing the comments in an MRAF or for to try to get the sentiments. A cool. You had, you know, good MRAITs, but the sentiment of them was fairly negative. What's going on with that. Yeah, and the other thing I found is. You know, there's some people that will do reviews or comments on issues. And they'll put in, you know, massive amounts of paragraphs, options. and that doesn't show up in the MR rate or issues that they open, but clearly they're putting in a lot of effort in responding to other people. So this will help me pull that out. You could like continue the automation. We're in a three-legged sentiment analysis. Quick little word count. Build a score. Yeah. Yeah. Actually, we do have something similar for only a only applied ML. So we do take the comments and it's just, I have to check this tool as well because I wasn't using this tool, but really looking to, so how dividing the communication to various factors, as looking into how, if you're able to, yeah, like are you going on loops in the discussions? Is there, is the content actually valuable? How is your house the written communication really has effective? And so, yeah, I look into this, what I'll share from Lish share of share our one. So, the one we have, it's mainly in a lot of people's laptop. So we just got out of and shared this as well. You can have a look. And Thomas, you want to just talk about your question. Yeah. Sure. I'll start with the question. How do you think your engineers would feel about this tool if we're able to? The reason that I was curious, I really like it, but I'm scared by it. Because if not used carefully, it has a really big, big brother feel to it. That's why I was curious. I think that's a fair point. So for us, we used it collectively to get better. So I mean, so it was more about we all, we had a okay or on effective communication. And we wanted to have enough data to actually understand how best to communicate with each other. So, so that's how it was sort of first used as well to really understand various methods. So I think a lot of them were actually already going into a weekly based on their interactions and actually seeing what was working, what was not. It's really, really, it's on the very early days. So most of it was really having fun with it. But then it was an app interest where we wanted to do something more and make it or to be honest. But it was enough in the early days, people were at least helped in understanding how best to communicate. Because our team was all new and came from all different backgrounds, cultures, everything. So yeah, that helped just everyone on page with it. I don't have any concerns with this. I mean, we can go and look for issues and MRs that are also also sorted by team members, all the information available tools like this just make it easier for us to find things. So with our transparency, our team members should be thinking about how they're communicating at all times and the opportunity to get feedback on that and improve shouldn't be something that I think members are concerned about. I wrote something along those lines, feel, I don't know how other people's will feel. The way I feel is I'm already super conscious of what I'm writing. I know that these things can be dug up from any time anywhere, where it's a computer to you or a person. But the automation does bring the scale that comes with the feeling you've been watched. I think that as long as there's the two's been used to facilitate a process that involves a human, we should be okay. It's not a computer making decisions go right. He's your rating as determined. But I think I'll agree with them going crazy. Oh, I'm sure that's coming, isn't it? That's why they hasn't shared it yet. She's clean up. Just to add to that, I think, how are you looking at what B2 actually empower team members to use themselves to look back at their own stuff and use their own self-review? Rather than just manage to use them as well. So for the entire time, I'll jump into the next one. We're good. So this was just a question whether we have any policies or processes for financial supporting open source contributors. There's a company here that has recently talked about how they do it. We're running into a project that we depend on that essentially is one volunteer maintainer. It's out in the community. They kind of do it in their spare time. This would be kind of a nice project to be able to throw some money their way and say, hey, you know, make this more a part of your job. But I don't know that GitLab has ever financially contributed to open source projects. And I don't know if there's a reluctance or what this just suddenly come up. How much you have a comment? Let's take? Yeah, sorry. I was trying to wrap up for a motoralyze. I'm not sure I had that all about us. We do have the open source program, which gives away ultimate for free. So is there? I mean, I know that's attempted to be a substitute for, I mean, you're talking about dollars where this is like an in-kind contribution. But it's, how you've been looked at this? How have you, has this been thought of? No, I mean, the projects that we're relying on are on GitHub. I mean, certainly getting them over to get GitHub would be fine. But I don't think that that would be a main driver for them. If it's something we use and they need dollars or could use them. Let me see if, if I can, if we can find financial support and we did sponsor OS for a while in the past, which has multiple open source projects. So yeah, yeah, I know we do a lot of at the organization levels, but a lot of these projects come down to like someone who on the weekends likes to program this thing and are they asking for money? Not necessarily, but of the public or the one that I have a mind now they work specifically asking. But yeah, it wasn't just a specific ask. I think our projects where people put up like the little sponsor badge on GitHub and have some of these other financial tools. Send me the details and let me know what you're recommending. Yeah, I'll see. Sounds like a reasonable thing to do. Yeah. On only slightly related to this and probably at a smallest scale, but we had a maintaining where they both and beyond for an upstream gem that we're using in in in GitHub and we offering them a voucher for for GitLab swag. So not exactly called hard cash, but you can get some cool socks or a jumping jumper or something. Cool. That's that's nice to know we can do that. Yeah, there's a form in the handbook. Bill, you want to take a handbook, too? Yeah, let's move on. Last week we talked about having a coverage issue for managers. So our team members would know who's available at the times when many of us are likely to be on holiday. I've drafted a mission here. I've done it for I think it's the 23rd of December, the 3rd of January. I've done it by day. If we want to extend it, make it longer shorter. Let's entirely address. So the ask here is if you are working during that period, add your name into the appropriate row and closer to the time we will just socialise this with all of our teams. If they need management support for anything, it could be an access request. They just want someone to approve a production change, response to an insulin. That's what I think. I didn't go the other route of putting in who's going to be on leave. I thought we'd go this way. That way we don't, it doesn't have to remind confidential. We can open it up. Thanks Bill. I added a corresponding issue for the last two weeks of November. I'm going to be out those two weeks. In many in the US, they're going to be out I think it which week it is. But the first or the second one, due to the US holiday, Thanksgiving, many are going to be out many days. So it'd be great fill and Thomas and Maun, and then also Mark who's not on. Since I'm going to be out those two, and as I'm often reminded by you all, when I take vacation, I still check messages and I shouldn't. And I appreciate you holding me accountable to that. Yes, exactly Thomas. So I'm going to try to do a really good job of escalation paths. But I need to know when you are going to be out, those those two weeks as well. So I don't say, hey, go to Thomas for extra fill for that or Maun for that and you're actually out those days too. So if you are, that's fine. It's somebody else. Seth, you've got number four. Yeah. So we just hadn't got much communication on the laptop refresh program. There's a couple notes that haven't been responded. Nathan added a note about India, which is one of the ones that recently came up for self-precurement. Just don't know if there's a better way to get communication. I think one of the things that is important is our IT team knows it like when one person asks the question other people are also looking at the answer. So it's not just one question that's going on in the answer. So when I don't know if there's a way you can ask like this and just make sure we're getting good answers to this. Happy King people in Slack and addition to issues. Not everybody keeps track. Not everybody goes in about zero. So they may have missed the things in. I have not. I mean, these are questions that other people ask that I'm just following along for the answers. Go into here to ping the person or the group. But it doesn't need to be Seth. Just be Seth asked, you know, doesn't need to be you, Seth. I got it. I need to answer as anyways. Because well, thanks for bringing it up Seth and thanks for volunteering Thomas. I put number five on there, but I don't know if someone looks, you know, important. Anybody want to volunteer to verbalize this update from our CFPH? Or summarizing verbalize? Sure, I can do that. Brian Robinson, I wanted to basically, we live streaming where I came to live stream this. I haven't actually read what they are. Stop it. Yes, it's a really good one. I wanted to make everyone aware of two MS, the first MR is additional guidance on the holiday party budget for Q4. The second is a change to the get together grant and Q4 because of the large visiting grant and Q3, the holiday party budget and Q4, the get together grant was removed for Q4. The holiday grant can be used for in-person events as well. Please also, I'll make sure you coordinate with your manager and or equal member. Improgise, Fuminian convenience, this is my course. So, what's the TLD out here? We've just got, we've got just the one thing which is the party budget. Yeah. And to use it or lose it, please organize these holiday stuff with your team. It's great team building. And some more to do. And often it waits for the last minute and then sometimes doesn't happen effectively. Just on that, the get together grant was supposed to be taken and no Vemba. Is that but that's the one we can go and experience $30. So, some people will have already done that as soon as they sang. Yeah, it was. We had to run for me to bless Friday. I'm kind of curious. Expense outstanding. I think I sort of coming that any expenses already done will be experienced but just to stop moving forward. Is there a cat off? It's nearly lunchtime. Oh, I will have to do something when I have to look at that holiday party budget. I'll be next. Wait, go side. And maybe Thomas include Mark's folks. Your team coordinates, collaborates with them often. You know, filled your team is big enough to do something separately. Maybe, maybe not, whatever you and Thomas decide and I don't know if you want to do something separate or combine. But you have the more people, the harder it is to coordinate, but the more fun of this too. But whatever you all decide, I'm definitely good with. Yeah, you've got number six. Yeah, during a retro, we had recently, there was a lot of feedback around the planning and refinement process and improvements that we can make to it. I'm curious when you receive feedback like this, like for a process that happens kind of on the fly or in person, like the person creating issues, like sometimes we get together and we do that sometimes I do that alone. And then we review those issues later. How do you keep these guidelines in place? Or like, do you have a mechanism to be like, oh, make sure we're creating issues that have a small NBC or, oh, make sure that when we're doing refinement that the MR can be small enough, but also vertically sliced. So it goes to review more easily. Well, I was at the boring answer. It's a handbook first and make sure we're documenting our prices and team handbook punch. So that was the, that was like the number one idea. But I was just like, alright, well, how, you know, besides like having the handbook of why are you doing whatever process it is, do you all have like a different way of doing that or a, uh, some other practice? The 13 sites we tend to discuss these things in in retrospectors and create follow up issues after the retro for for a bit of discussion before going to the handbook with a, but it's time to go to the handbook. We've already had this discussion of the scene is fairly on the same page with what they want to do. This helps. Yeah, agree. That's a more casual way of approaching it. Although I've seen more success with them threading sites as well. Um, with these follow up tasks if we actually have an associated MR, like we start the conversation in a proposition like proposal versus just to open dialogue. So that's, it's been a personal goal of mine in the last quarter or so to be more handbook or in it. And so, and I found myself being more successful in our proposals. So I think if you're in that situation where you're trying to contradict something that's in the handbook, start a conversation with an MR. I know they're boring answer our apologies. It's okay. Thanks for the contributions. It's, um, sorry, Jay is your question. Okay, maybe you've got the handbook up that what makes you know, because no people aren't reading it every day. Is it more? Basically, yeah, yeah. Where's the guardrail? You know, like, how do you ensure that the team is following process? How do you ensure that you, you know, you yourself are following the the correct process besides just being like, I know I've outlined that in the handbook. Um, so what options do you have for automating the suggestion? And we can automate and retrospective. You know, we can put the data in the that sees that might help. And we'll say it depends on the on the situation you're implementing. Maybe, maybe that's one place to look for. Yeah. What about, like, circling back in an upcoming retro to make sure that you've followed the new process implementation or whatever change that you've done? Yeah. Yeah. Great. Yeah. Yeah. You can get the data approach. There's always saw things as well. If it's something you can track. So rather than thanks bring that up, Jay. Good stuff. Rather than going to a private recording and going into details on the Ocaris, since we're we're over schedule time that would say review the Ocaris to which you've been you've assigned yourself or you have been assigned where I did a bit of that today or you volunteered and many people volunteered for things who just greatly appreciated. Um, that we've iterated on them a good bit over the last week. Do you want to get started on them? Um, so review these at a digital summary here. I have to answer one, there's two things to note. In addition to, please look at the ones that are assigned to you in. Like, mom, I put two on you today without telling you an advance, apologies for that, but there's things you wouldn't be surprised by most likely. But as an example, and others as well, a smart, you volunteered for one. I put your name on another, you know, etc. Um, so the two thing that is the team ops training and coordinate that issue just self reported we want 50% of the team to take team ops training. I don't need to coordinate that myself. Anybody want to volunteer to do that. Either in this group or not here as an EM or even a engineer could truly take this. Anybody want to volunteer for that or know if somebody who might want to volunteer for that? I say we choose someone who hasn't taken it from this group. That'd be fun. It could be me. Does anyone not done team ops? No, when you, that's okay. I'm just curious. Has any major? Oh, I haven't done it yet. So I'm, I'm volunteer. I've had this gone here for three years. I had my name on it. So I'm going to say not fill for that reason. Otherwise, it might be fine with that. So it's just basically, uh, hanging people. Hey, don't forget, hanging all the managers making, you know, maybe every two weeks. Hey, if you're every month, hey, if you haven't asked your team to do this, ask them and ask them also to self report. That's all. So it's probably, you know, I'll pick that up and work every two weeks. Jay, I just added a link that has all the reports of who's done it. I'm so little here. I didn't even know that existed. That's awesome. Did you, sorry, Jay, did you say you're rolling here? I'm not trying to volunteer. Okay, cool. Thank you. And last one is that is one to mention, sec addressing, sec being secure and governed, free prioritized usability issues. Omar, I think you volunteered for this one earlier. Or did, yeah, or maybe it was a different one you volunteered for. I think it was the as one as to, okay, good. Yeah, many different things in flight today. So I may remove this one. It was part of a previous iteration of P.A. Product Management, okay, or so I was kind of worried this was when you volunteered for Omar. And it's, it's not so yay. So I may remove this one. I'm still thinking about that. So cool. Are the questions about these, you know, definitely or need more information, I'm sure many of you will on many of these, you know, let your manager know that you're PM know of to PM thing that need no and that's collaborate on an asynchronous thing that does need it. Take a look. Thanks, everybody.",
  "I don't know if you can see it couldn't now. So it's the sec growth data science staff meeting, which we just discussed a confidential topic. It's what, and now we're going to discuss the non-competential things. It looks like neat of the first item. Yeah, it's just a bit of news about new hires. The compliance group has seen you from team to engineer joining on November 28th. So that's Alan, once mainly based out of New Zealand as well. So that's awesome. And we have another hopefully some good news mixed week as well around this. Thank you, Ms. Mubin. Yeah, I got next. So we noted this in Slack last week, but it's worth repeating year. So we've got a four year work anniversary in a three year, or a anniversary for the first person that's the honor that you're in to derage. So they put up with us for a long time. So this is always worth celebrating. So glad they're here. So welcome to the center of the meeting. The center of the is an outside shadow is also a community contributor. Give that. And Thomas, you got the next item. Yep, so just news and events since we're coming up on a US holiday week next week. So we're going to go ahead and schedule it for the week after. So that'll be. And then November 30th or December 1st, depending upon location, we'll go ahead and do the same thing. We've been doing with two sessions. So just want to give body heads up to those. We're coming and going to be scheduled. It's stuff. So best in class, B. I also known as B. I. C. O. K. R. is for securing governor being finalized for Q4 by product management. With an ETF distributing them by the end of this week. Once they are, please be sure to engage on them ASAP as we want to accomplish the one slated it. 4 Q4 in Q4 wherever feasible. If you would help, we can consider changing team priorities of the teams working on the OKRs and those not to help out. Please also continue to give PM feedback and ask questions about the OKRs and the associated epic's and issues. And we're going to be sure we understand the goals and ways to deliver them as intervially and effectively as possible. It sounds a little bit scary. We're getting OKRs, you know, a couple weeks into the quarter. But the thing from PM is the best in class OKRs are likely going to be the work already in the backlog. A subset of the work already in the backlog that we're already working on or planning to. And we're going to be sure to do the next two or more releases, but we don't know if we won't know for sure until we see them and I'm on vacation for the next two weeks so you won't see me. Bringing you know, finding a light on these once there are now, which will I'm ringing up here. Any questions or comments about that. So the TLDR here is we're talking with our product managers. And we're talking about for us in Q4 that you've already prioritized that relates to based in class. Yes, correct. And then we need to choose between those and other things we should choose those. That's you know, it's very, very generic. You know guidance of course, but we don't know the details yet so it has to be generic. If you haven't already done so please add a comment on good bad and try on your Q3 you three OKRs and square. Two weeks into Q4 and I tag your manager for review and then close them sometime the next week or so would be great. In the hallway, you know, should be invite newly created Google groups the new that we created for each team has optional for this meeting so that. The individual contributors are more aware of this meeting in case anyone who attend or review the notes and reporting. I just put a note I didn't think it was necessary. I think just putting it on the group calendars enough there's a lot of events on the group calendar. I want to promote the idea that any event on the calendar you can go to you don't actually have to be on the specific invite. So I didn't think it was necessary. The other concern of course. As managers, we all know this if we invite people to a meeting they feel compelled to be there something comes from Wayne people will be like, oh, I need to go and we don't want to create that but we. I definitely understand we want to make sure people feel welcome. Good point. We have also learned that people would know group calendars primarily. Maybe do a polling slack to see if people wanted added but to your points out this let them know is just because everybody doesn't mean they have to come. It's exactly the opposite so but what would it really all think any strong opinions either way. I agree with with both of six says points there really but yeah we want to we want to advertise be that I think that's the slight polls are good. I could way to do that. I'm happy you're on that if no one else wants to. I feel that you're saying thank you so amount next week. I'm out next week but I can't hold next week's meeting because many of us in the US at least think can the two are are out I'm making sure. part of next week, do that how it is. So the week after I'm also out and looking for volunteers to organize this meeting. So Phil, you just, I see you volunteered on this, Thomas, you did too. Since you just volunteered in the last thing, Phil, Thomas, you wanna take this one? Yeah, I got it. Okay, I will do the transfer of the, as appropriate. Little keeping. Also, be aware that performance indicator meeting for second data science, it's monthly is November 30th. Also, well now it's all. So please plan accordingly, Phil, Thomas, and Maund to do your pre-work or homework and participate sync or async as appropriate. And it's wanna make sure we got an act on all these from Phil and Thomas and Maund. So I already saw that. Thank you. Seth, you have a comment about this. Yeah, just thanks for calling performance indicator. One thing to see so many acronyms being used and it's really hard to know what these meetings are about is we are overdosing on acronyms. Yeah, used to mean to me product intelligence because I was a team that reported to Phil but it doesn't mean that to me anymore. But it does mean to that team. We have also overloaded terms as Maund Taylor, like to remind, but we have two teams called data science, and we have a good kit lab, Mons and another one. And that creates confusion too. Good point. These are interesting things. If you wanna look at talks about what PM's goals are and what metrics they use, the engineering metrics that we're familiar with like, error budget and percentage of issues that are maintenance versus bug versus features. But this direction might be particularly interested in the PM metrics and like usage of the systems and customer growth. I find that stuff really interesting. You might, who, where you might not, but you're definitely welcome. Phil, you've got D. Oh, we have a get together. We normally have a get together grant for the first month of the quarter because it's Q4. Instead, we have an end up year holiday party budget. We talked with Christopher Asink and they is thinking of delegating that down to the sub department level, which means we have some flexibility and what we organise. I'm interested to hear what people in this group and your team, so please share this then. What they would like to do, do you want to do something at this level? Where we have maybe three meetings in a 24 hour period, and we invite a lot of people. Do you want to break that? Do you want to break out into smaller groups? Do you want to include your counterparts? A product and stable counterparts? Yeah. I'm interested to hear what people want to do. Yeah. Carmel and the growth team, they've started an issue to discuss it. Does discuss what they want to do? Any other questions? Yeah. Yeah. Model of people actually bring this up even in the team meeting. And probably even start a issue or a poll to discuss. Last time, obviously it was very small the team. But yeah. So hopefully, by we'll get more details. I'll just ask you a question. Aside of ordering food, does anybody have any great ideas on how to cash in on that 100 bucks? Oh, last year, it was four or five years. We did Secret Santa and it was really interesting to see how engaging everyone was. It was interesting definitely. We did it. They really wanted to know what the other person would actually want us to give. So yeah, that was that was fun. So what I'll do is I'll create one issue for this group. And I'll put some of the ideas that we've had. I'll put examples of what we've done last year. And I'll share it. I'll paint you all and let us you take your way to your teams. Create your own issues to say what you want to do. And we'll all come back together in a week or two and. And we'll go as we do. We don't need to check the latest guidance on what we can. What you can purchase as part of the holiday budget. Center a call. There was an update recently. So we want to make sure things like that center is still. All right, looking at the time I'll go next. It's hard to follow that up with metrics, but I'm going to anyway. So I was talking with Derek earlier this week and he's part of a working group for Dev Sec. And we've historically within sec so secure and govern. We've had a challenge with metrics and accurate metrics collection. And so he's looking for an engineer to help them with that to help reconcile this particular situation. Looking for a point of contact that they can work with across. The section itself. And so the so I was bringing this here and can find out if ever if. I was in EEM have an engineer that might be interested in a section wide initiative that would help that would be based within the Rails platform. Help out with this. And I won't look for hand raising lives, but please. Please consider and and get back to me. I'll be asking more later this week as well. So. I've been discussing this with Derek as around because there's a lot of updates made in compliance and I have an engineer who's working. Tile on that and I'll ask them whether they're willing to look at the section. Let me get back to you. Okay. Thank you, sir. Appreciate it. You've got next. Get I opened up a team or issue for planning our section team day still trying to figure out what the date should be. But we're thinking early in December. First question is what anyone like to go. Strict library with me on planning this out. And then second question is going to be around. In the past, then it's has been fairly low. So just brainstorming ideas on how we could improve our attendance there. Yeah, could be carried out. So. So. So, So, So, So, So, So, So, So, easier or harder to contribute. So like I've been contributing in GitLab for one and a half year and like it's been a great journey like I've been with GitLab, I've offered them Google somewhere for a full bit GitLab so like it was fine and it's been the order of the poster right for yeah. Like I'm enjoying contributing to GitLab. There are plenty of questions for this group. I know you've met a few of the people are previously in various meetings but any questions for this group of engineering managers and senior engineering managers and legal counsel. Did it happen to be here today? Not right, not but I let you know like I have been okay. A apologies that we went a good bit over on time but we had a lot to discuss and discuss one good stuff so thanks everybody. Have a great.",
  "I was the first to go. I'm not sure why, but I was the first to go and that meeting. It's a nice humor. So it's a sixth birthday and science staff meeting. Tiago, thanks for getting the live stream going. Just send me the link afterwards and I'll edited and put them in the meeting notes, et cetera. And also, I'm going to welcome Slayton today, who's my director, shadow and as a student at USC. Thanks for having fun. And small thing, hey, now in a notes on your view, it still says interim on your title and zoom. You might want to change that. Have some still interim. That's why. Oh, you're still interim. Okay. Yeah. The system works. The, um, so it looks like I kneel. You have the first items. Yes, so regarding new hires and anniversaries, um, I've been hiring for two senior front enrolls. One for third-end sites, one for security policies. We are, we filled the security policies. It's Ian James. I've went out to their LinkedIn profile. He's located outside of Melbourne, Australia, starting on January 23rd. And he's going to be reporting to Alan, you know, because obviously Alan has taken over that team as a plate. So that's amazing. I've already apologized for hiring somebody. Um, under his, you know, kind of things. But they also appreciates the work involved. We also have the threat and size position. We are on the like the final steps. I'm hoping to be able to share news later this week about that and that will have a similar start to anticipated. Cool. Tiger, you're up next. Uh, on the same vein, we've got to, to you, starters. We've got Mo, who a lot of you will know and they tends to watch these, uh, their videos so high, Mo. And, and Malcolm was a new Zealand and very excited to, to get these two people. And for the Americans, it's pronounced Melbourne, not Melbourne. I don't, can't even tell you what I said. But thank you. Well, Melbourne. Melbourne. Oh, that's a great news in a new starts when our big goals expand the team. In celebrations, I've got a couple of them here. Um, so the AI assist proof of concept demo was um, put out their in public. So great work by the incubation engineering team and the AI is the AI assisted team. Uh, so monstimcy and gradulations, mon to you and your team and to the and Fred on incubation engineering. Yeah, it's neat. Got the link there. It also will internal dog fooding. So we'll love feedback. So anyone using the Good Lab via Scored Extension can, uh, can basically use it. Cool. Yep. And you can see how to use it by, uh, by my, my, I'm watching a bit, this short video. So also, um, uh, I know I'm a little bit late to celebrate 156. It was released while I was out of the office, but it was still really neat to see all the great work by secure data science and government teams, the features included get abuse rate limiting to notified of administering traders when a user downloads more than extra repositories and why time period on demand, API security scans, scheduled dependency scans and the ability to manage scan results at both the group and subgroup levels, noting that automatic revocation of leaked personal access tokens, paths is coming soon. We're internally dog fooding. So all sorts of fun stuff out great stuff out there, and it was fun to brag about them on social media too. So thanks, everyone. I got the, the next item, but just piggybacking on on the way, one of the features that came out was the ability to, uh, verify commit signatures using SSH keys, uh, Brian in 13 sites contributed to that feature in, in code source. And they got a discussion here bonus for that. And there was really good. Uh, and, and this happened to all of go ahead and announce it, but we have two new maintainers in section. Uh, Mehmet is a back end maintainer now for good luck. And me how is a maintainer for database. Um, that's great. I'm just going to signal boost, uh, you know, we had a maintainer working group, um, Michelle's leading net, and we are still looking for more maintainers. I think at the last count, they're looking for about four backing maintainers, um, a training database maintainer, if anyone's interested, and of course we're looking for marine owners for other projects and across front end as well. Um, I see that I would track that for wind and q4. So if anyone in your teams is interested or you feel should become a maintainer, and reach out to me, let me know. I'll happily work with you to see if we can make that happen. Good stuff. So a news and events. So I also noted a number of mentioned have secure government and data science work in this week's earnings call. So uh, that was interesting. And there's an unofficial transcript of that here. So you can search for what you're working on and you may see, said, or Brian, uh, mentioning it. It's going to need either in prepared comments and or when questions answers to questions from analysts. Somebody want to verbalize our Taylor's comment? Yeah, I'm happy to do that. Um, Taylor is announcing that these that make some changes to the model up stage, uh, re-naming applied ML group to now be AI assistant and they've also added a new category to AI assistant called code suggestions, which is the maturation of the AI assistant Park Sieg into a product category. Well, that's a mouthful. You have just normal all the way. It's about if you have any questions. What's all that about, Mon? Um, a lot of name change, but I hope this is the final one. So what I understand is applied ML did not make much sense. Um, and so as a group, the name as AI assistant makes a lot more sense. Um, and so and and code suggestions actually says what what it's supposed to do. So so then it's a lot more easy, but yeah. So in big rocks and hot issues, uh, one repeat this, it was I think Sam Beckham put this in a couple of different Slack channels. Part of the reason for doing this is because people wanted more context and on Neil, for example, you mentioned that the teams working on pajamas migrations are getting a little burned out, uh, because they're doing it for a while and they can kind of loss side of the why we were doing it. So it wasn't just you and people on my teams. It was others as well. So Sam put together this great video and recorded presentation about the why on the pajamas migrations. Uh, he's available for questions, suggesting people watch the video, and it's said, or so overall, um, good stuff there. And thanks for bringing that up Neil in the past. This is a good, good, great feedback. That's not the only reason that Sam did this, but it's one of the reasons. Well, I appreciate that, Wayne. Yeah, it's really cool. And I've passed this along for the team. Uh, notably, it doesn't include things that are in the enterprise could base just as an alphabetical thing. There's a in the topic to come in more about that. But our team, specifically Alexander Currency has helped actually reconcile and get that list of the locations. So our team and Alexander are going to be looking at ways to approach that and help facilitate this occur. So you can find that within my okay, I'll list if you're in the issue. But yeah, thank you. I've put a list of, uh, I'm tracking the engineers across the TV scrubbing and price. I've added a list in here. These are the issues that are assigned to our engineers. And as we close them off, we'll complete that. If there are, if anyone needs any help with that, it'll once be the track additional teams are more than happy to do that across Q4 as well. Just reach out. So I think I have the the next item. So Christopher has an issue he'll he's kind of mentioned our engineering managers. It's a sort of a continuation of the best in class conversations with us time he's wanting engineering managers to lead the conversation and actually reach out to the PM's and ask, you know, what is it that we should be getting ready to do? If not already working on in Q4, what should we be getting ready to work on in Q1? We're just approaching this from multiple angles. A lot of the times our PM's will already be doing this. Our engineering managers and product managers are already having these conversations. Christopher's just asking our EM's to actually lead that conversation. So we can be clear across development of what we need to be ready to work on in Q1. There's a few links I've shared there and the doc. Night, you had a question for a comment. Yeah, just around the doc, we from the compliance perspective, we found that it didn't quite match up. So we're already started that discussion with a PM in compliance space to look at that best in class and work out what exactly that means for us and our group, but just for reference for everyone else. Yeah, brilliant. And I think that's why Christopher's asking us, just make sure that we're all aligned on what we're looking at doing. And nearly having a KR to look at, you know, what we can get ready for and doing Q1. So you already, you're already working on this. And Tiago, you have an issue to, okay, our round and blocking big features. It's more if the conversation changes, are there other things we need to do to unlock any new features that we're talking about? So that's the sort of thing that Christopher's looking for. Yeah, in the hallway, anyone check out the OpenAI chatbot? It's equally amazing and scary. I forget, but I took a, I didn't put it in the notes here at, I respond to, um, I want to get that a couple different topics. One that Tiago reminded me of related to some questions about credit card controls and that we use for preventing crypto mining. I thought I'm going to just take that person's question and put it in chat AI and see how if the answer it comes up with is better is accurate and if so is it better than when I wrote? It was better than what I wrote. So, and I've done a couple other things and it got, thing, it came up with really great answers that were absolutely wrong. But really well put together, at least in my opinion, on other topics. But what about it? I don't know if anybody else has checked it out, but, um, looks like Nate, you have thought about it at least. Yeah, I found a Chrome plugin that actually, when you do a Google search, I've added the chat, GT, GBT response on the right-hand side so you can appear what Google one that comes up with. It's really quite amazing. I don't know what it comes up with. I'm interested to see if I can match it up with AI assist as well and get an easy coding. Anyway, but I did see that Stack overflow have blocked it for now because of it's as you mentioned, way, but well written. How did they block it? How did they block it? I'm curious. I've linked to the, um, it's the opposed about it, but yeah. I mean, our wrong gang says in Stack overflow, just you have, which contributed. It's mostly what people read your boss. This is wrong. It's a big blame. The best way to get time to answer a question on the internet is to post the wrong answer. I think, I think it's discriminating against AI, just I think, post it wrong, somebody will come in and correct her. Anybody else checked in or have any impressions of it? It was a, it was a little laggy today. I think they're getting a lot more hype. I was definitely trying to play with it to see kind of what the boundaries are on it. It's definitely made smart some interest like using that and co pilot. I'm wondering how efficient engineering managers can be at, uh, you know, jumping back into the code a little easier. So I'm curious to play with the combination of the two. I saw some examples of answers from the handbook that were pretty good. And somebody also shared the text of somebody who will talk to, to interpret shell scripts, that one was quite impressive. You know what's going to happen now is somebody's going to do a TikTok video with all of us being fired by Chad G. P. Instead of by Elon. You're the first one. No, you're doing the presentation. The person who created that video. The time to be the first one because the the answer was better, right? Yeah, for me, we we've been looking just at the back and how the models have been built. So really just looking into that for a code suggestion and it is, um, there was just a lot of them there of, uh, finer details that are so important and so different just the way they use reinforcement and learning, uh, which is really cool. Yeah. Interesting. Bill, I moved a couple of your topics up to the from read only the discussion. And so that maybe you could discuss. Go. We've got the combined engine into view catchups for a sick data science and growth starting tomorrow. Um, tomorrow might Friday but AP. Um, there are three one hour sessions in there. Um, uh, the issue link is there. They should all be on the calendar. And these are open to anyone. So if there are people or not directly on the calendar and votes, um, please go ahead and add them. Um, you should be able to eat it those, uh, invites yourself. Uh, Neil asked a good question in that issue around it's been saying, um, uh, I'll just summarize that. In terms of what we experience my understanding is that budget has been allocated at the sub department level. And so we have a lot of discretion there. Uh, the TLDR is ask your manager before you experience something to make sure it's approved. But until we, we, one of the sessions was to expense some food or a beverage. Neil's question was, will, does this have to be something that you bring to the meeting? Um, I've answered that and please please correct me if you think I'm wrong here Wayne. Um, I think no, it doesn't, but it should be coupled with attending one of the meetings or one of the one of these catchups and maybe bring that to the conversation and tell us how you're experiencing it. So, um, some suggestions where it expands to Neil and bring it along. Not everyone wants to eat in Neil and try to be colleagues while they're having a conversation. Uh, another is actually going out for a meal and come back and talk about it. Uh, who you took out for the meal. Um, um, what what you talked about and and share that with the team. Uh, a third suggestion was, um, by the ingredients for Neil that you want to cook at home and come and tell us about the recipe that we chose or um, you wanted us to plan on cooking and the conversation. Wayne, how did I do encourage you? I'm, you, you do encourage your teams to attend if they're interested in being going to get together as group and just spend a little time together, not doing work specific things. One of the interesting aspects of an all remote company spread out over the world is things like this are important and that you get out of the what you put into the future. Uh, next item was also for me this is something that Wayne and I discussed, um, a seducing, um, there are some useful tips and, and there's a video there on, uh, filtering and Gmail. Um, really go to if you're interested in that sort of zero in box, um, email policy, you can filter everything away into a subject or you don't have to look at it. Um, I try and use this right now. I'm, I haven't got a zero in box, um, but the idea behind that is I'm filtering everything with I expect to come in. So anything that comes from get lab goes into a particular directory and what I end up seeing in my inbox is the email that I wasn't expecting to get and it sort of brings them to top of mind. Um, there is a video there. It's a bit long. You kind of have to, um, fast forward to get to the filtering. Now if anyone's interested though, I'm, I'm happy to share any of the, uh, some of the filters I use on get lab, um, uh, to filter it. Yeah. And would suggest making your teams know about this in case they're not using filters in Gmail, it can really help them if they're not. Jay, do you know about this? Jay. I think I was smiling box. I'm saying that. I'm just going to say is there a company one policy that we're zero in box? I thought it was just a suggestion. It's a suggestion. It's a suggestion. It's a suggestion. It's a suggestion. It's a suggestion. It's an auto filtering or auto filing can be very useful. I think I mentioned this in one of my, um, I did mention this in one of my, uh, skip levels, uh, instead of what's better in many ways is unsubscribing from labels and other end projects where you don't want updix. So you don't have to create filters in the first place. So you're getting a bunch of stuff you don't want to, you're never going to read. Go, go deal with it at the source rather than Gmail. Um, it's a tool. I'm going to, I'm going to slide down. I just say, well, my notifications are only received to do. As I said, I did have some filters. Uh, I just, yeah, maybe maybe it's time to look at it again. Maybe somebody had better filters than I did. I was going to say one more comment. Um, fill out one of you can share a sunscreen shot of your filters as they are today. That'd be cool. Someone did that in the past and it was like much easier than trying to read through the show. Like, oh, okay, that makes sense. And even if I don't have you can export them as well, that'd be pretty sweet. I can't do it. I couldn't do it in one screenshot. I made a much larger. Oh, no. What I'll do is, and I'm, um, I'll copy and paste if you and I'll put them in our, um, shared channel. I'll do that. Awesome. Yeah. Cool. That's all we have in the agenda. And we don't like that meetings extend to the time allocated. But I do want to ask a slidon as a shadow and listening in any questions, your observations, you have a question that you have for the group. Uh, no, no, no, no, no questions for this one. Thanks. Okay. Thanks, lady.",
  "and stay to you. We'll everybody. Don't think. So it's the set growth data science staff meeting for December 14th and just a quick welcome to Tony who's an engineer outside get lab engineering director shadow for me today. Hi everybody. All right. Neil is not here yet. Somebody want to verbalize Neil's item. I'm not in the agenda yet. I will take it. So just following up from one of the items below there is a new threat inside senior son and engineer starting on January 23rd. And I will leave their name out since this being live streamed but they are in Belgium. We need. It's great. Lots of starts. So a quick celebration is a cool demo of an upcoming secure feature for automatic revocation of leaked personal access tokens that Lucas recorded as I post rolling there. Need stuff there. Under nothing under news and events today this week under big rocks and hot issues. So clarification on next steps for managers for talent assessment. I'll put a link in there. You can read all of the details there. The next due date for calibration is December 22nd at the latest. Please don't wait until the last day. So I think most engineering managers are ready to wear this. But in case you're not. Now you are. Wouldn't for a volunteer to verbalize item B. I've got it. I'll take it. So this is from Michelle. So there's an issue that's been spun up for special coverage during the holiday period. So we're looking for volunteers to sign up for shifts underneath the development manager rotation. It's just it's a piece for incident management. That's an escalation is during the holiday period itself. So if you would please take a look and if you have availability, please. Please sign up. Exhaust. So engineering managers, you know, please if you're not ready to do so track the ask in this issue, deduct your thoughts on competition gaps. It's not an okay or a mind. I believe it is for Christopher. He's tracking this across all they didn't. Haskate it to their director boards. But it's something that he's tracking. So please do take a look. And in item D. If you haven't done a check in on percent complete. On your okay hours now, I in the last two weeks. Please do so in the next week. As we on the lack of updates can make stakeholders assume the worst, such as no progress and it is probably off track due to the lack of info, just kind of human nature. So you have no to update even if you don't have anything to update. If it's like no progress, that's say that that's fine. And people know. Thomas you got item E. So this is this is truly a question. So we passed week or two. We got the new process for for offers that adds that additional approval at the end of it. And so I'm curious for those that have done hiring how much additional time is that adding to the end of the process. So. So the thing that caught my attention is that I'm seeing approved offers in greenhouse, but that doesn't mean that it has gotten that last approval. Yet and I and getting some insight on how that works and how much longer it was how much time it's adding to it was something I'm keenly interested in so if you've hired yet. If you if you've done hiring since this is announced. How much time is it adding. We did this kick in. I thought it already had. I asked because I had the person I announced that took our offer. I'm sorry for turning like was. It was held up in the contract approval, but it was due to a PTO thing and then necessarily a new process. But something to be aware of. But yeah, I don't know. Okay. Years may have gotten into the wire on the new process. Okay. Yeah. I've got one that is awaiting. The traditional approval step myself. And I hear I should hear back this week. If your candidates if you're an offer approval. And your candidate. You know, has a you know deadline to make a decision like they have competing offers. Let your recruiter know they can they can push the process to go faster. So in hallway, I'll be out next week's. Have a coverage issue here linked in the notes. I've canceled next week's staff meeting. Does anyone want to volunteer to run the one December 28th? If not, I'll cancel that one too. That's a quick show hands who's going to attend the December 28th or 29th in 8th. Okay. So answered. Uh, cancel. Uh, we have more continue to go async. And who is the next. Uh, on DRI and listening our next outside guest and a Phil organized. I think the first one. We had some folks in the legal on which is great. Who's got next? Who wants next? I was going to say is there a formal list or anything like that? No, it's just looking for a volunteer each week. What's the cadence that we're trying to bring in outside guests? What do they want to work? I'll have to top my head. I think it'd be once month, once every two months. Anyone want to volunteer to do the one in first week of January? It has an idea who they might want to have as the as a outside guest. No, no, no. Okay. Maybe they will be in the future. If not, it's okay. So under thanks and gratitude, thanks Thomas and Neil for continuing to compile and present the error and security budget in focus all our teams in the weekly engineering allocation meeting. Much appreciated. It's all we had at the agenda. Thanks for everybody. Have a great day.",
  "That's exactly what happened. Once the recording starts, it always seems to be a wrong suggestion. Well, you do have to click the acknowledge button as well. So yeah, the and it's not predictable when things are going to live. So we got the Sync group data science stack meeting for January 11th or January 12th, the music. And you're just talking about traveling and having a good time off and also trying to get sick when traveling. So I think I have the first item. Several variations. So nice job by J and team. And the entire team, I'm reducing frogs on a camp takeovers. You're requiring email verification that they've been through logs in incorrectly, right on three times. It's pretty cool. And it was unobviously hard to get right in all of these cases. In all ways, such as if the users email wasn't irrevocably in the past. We stopped sending emails. That user because it keeps our email. It makes the mail providers when you do that more likely to accept the email. What it does is that user may never give email again. And that's not in a, when they're trying to validate the user with a required email that's at all. So we had to actually integrate the email for about the N and A. The back to to read white allow us to email addresses, even if they were on the Google rules. So anyway, good stuff. Number of announcements that I put in here, but I would love it different people who are in here than because I just copied them from Christopher's definitely. Yeah, I think I can take the first two. So we've got annual comp review starting soon. I think that kicked off on Monday, maybe Tuesday. I think there was a little bit of a delay. But that should be on workday. And there should be some messages in some of the management channels for that. And then the second one is there is team member professional coaching resources available. So we've had this for a while, but this is just a friendly reminder. There is a link to the document both modern health and then there's another professional coaching resource to take advantage of those benefits. Thanks, Jeff. Any volunteers to provide? So Christopher's given us their draft Q1 development on OKS. The link to the document there will be a course looking at our Q1 OKS, some of which will have to align with Christmas and with having to look through. You didn't want to run through them in this making? Why? No, great. There's still a draft mode and not of any of them are confidential or not. But read them and then while we're coaching other things, if anybody would like to and love to take questions on them, come on to anybody has any doubt or a picture. The, um, to under big rocks and hot issues, so all people leaders should review the, um, I'm Mark rotation issued a draft to make sure everybody who's eligible to be an instant manager does so and, uh, there were some cross-blires or not everybody that's supposed to be doing it is doing it yet, but that's okay. That happens. We'll figure it. We're figuring that out. Not just for our team, but for all teams. And if somebody is not eligible, there's various reasons for that, you know, there's a way to ask for an exemption for that and just for the justification as well. Like top reason is I'm on rotations, instant major rotations. It's sometimes, you know, it's a schedule, but it's sometimes outside of work hours. It's important outside of work hours in some countries that's not possible. That's a, and we don't have a way to do the eye on my rotation where it's only during people's work hours. So that's, if, if, if a team member was in a country where they can't participate, that, you know, that's not the success. There's other reasons to do it. That looks like you've got a question. Yeah. So we've been running the program for about a year. We have the criteria of everyone that's job eight and nine. I think about half the people have not done the eye my rotation. I don't know if there's a due date to get everyone into the rotation. Not that I know of, but maybe a soft due date would be by the end of Q1. That is that reasonable. It takes some time to go through the training and, you know, doing a couple. You know, it's, it's not in the person's in the eye mock on borders completely control the schedule. You've been very micro-preposed. There's some things that they need to do. Yeah. I think like a reasonable, at least for your turn staff. And if Q1, and if you want, and if you want is, uh, what David, is that? Uh, okay. Yep. Yeah. So three three and a half ones. That's okay. It looks like you have a comment. Yeah. Um, a staff engineer's, uh, according to the job family need to be in one of the on course schedules. So they can still be in Devon Core. Most of the staff engineers should already be in that one. I think we've gone ahead and created onboarding issues for eye knock. But technically according to their job family, they could remain in Devon Core and not do eye mock. Prep, prep doesn't need though. Perhaps we need more eye mock. Um, people, so maybe that's why we're asking staff engineers to migrate to the. Yes. And we want to spread the eye mock for more people. Um, to that in the more people that do it, the less impacted is on each person. I think it's a primary motivation. Why the one. I remember it looks like you've got comment. Yeah. And just kind of a follow up to sets around timeline expectations. Um, for anyone who asked on through, I'm all come boarding completed it. How long did it took a good take to get through most of the training and or the shadowing piece of it. Just a separate timeline or internal point, similarly. I don't recall exactly how I'm at took to do the training component of it, but it wasn't. It wasn't much to it. Um, shadowing was, um, you can set up a shadow eye mock schedule. I just subscribe to notifications for incident management and jumped in on calls and did shadowing that way. I find that that was much easier than trying to suit up a schedule. And that component of it was just waiting for enough incidents so that I could shadow and actually feel comfortable joining joining as an eye mock. Um, I don't it's particularly over the rest. It's a few hours maybe you read the training. Yeah. Yeah. Definitely not bad. And I think the new folks have the luxury of getting scheduled like subscribing to this, signing up. Um, the batch fillet and I were in a foreign fattman to go. We were just got added to a schedule a number of people to even realize. Tell the notification like Patriot of the Senate email saying, welcome. Yeah. But yeah, I agree a few hours of reading. Um, and then just kind of follow the various channels. I created a group in Slack with like devescalation. I'm like general incident management. Keep an eye on those channels. Effectivity. What fills that up. Oh, and subscribe to schedule that be cool to you. You can create a shadow schedule. Good stuff. Yeah. Thanks for the tips. Great question. It's coming over the hallway. Um, I would the first use set actually moved yours from reading only the whole as I think it's a cool idea. So, the good guy said. Um, so the first thing in the hallway is a Christopher and I recommend that all EN was in above at least, maybe everyone going to release the end and watch this 10 minute video from Sid on comparison in tool landscape. That's cool. Very pertinent to best in class BIC things and other stuff. So, good stuff there. Also, we have an ed guest in this meeting since legal trouble. And anyone want to go into it identify a guest for our next meeting. Thomas your your volunteer. Okay. Cool. Yeah. And then we'll ask again next time. Who wants to do the one after that? So, any request of teams or groups or what are you thinking, Thomas? No idea yet. Security. I'm thinking in terms of Fed ramp and all of the other initiatives that we have and the increased and increase and increase emphasis on vulnerability management and security, pretty sturdy concerns that and since we built tools for this, we may have interests. I think it's a great one. You know, and not after then, another, and a guessing might be to invite a director or senior and jury manager or manager from one of the other development teams that we not by design but just by what we use, we're not part of the core part of the product. We've got a lot of things that hang off the product, integrate the product in great ways and are part of the product of course, but the other teams interact with each other a lot. Then we interact with them. And that's not a negative on anybody. We more, I think perhaps having guests, because some of my peers or, you know, your peers, occasionally will be great. We can learn what they're up to and they can hear we're up to and things like that. So other candidates would be people like that. That's who I'd probably choose if they found a room that do want to guess, but I'm going to look for other volunteers first. Just 90. Seth, and so you've got see. Yeah, so just started a MR on our PTO page, just talked about domestic and family violence as a reason to take time off. It's something that is actually a lot more common than we might realize. So, I want to get that in the handbook as a particular reason, also, to for anyone, looking at taking time off, they understand that this is something that does happen and to seek support and to make sure they're in a safe place. When I was writing this, I actually found Australia and New Zealand. There may be some other countries actually have some legislative employment law around this, actually giving people time off. So figured we could take some of that and put that in our PTO policy. And then somewhat related is just kind of a comment here. One of the things I've noticed whenever you're looking at really steep performance drops with employees, it tends to be some of these issues like relationship or divorce or health problems or a bereavement or abuse. So it's just always kind of a lens that you look at performance through and figure out like, hey, it's not that they don't want to be working or being performing, they've got something else going on. Very good. Seth, Seth, it's a glad you added it. I have some comments or some suggestions in the MR just below. So it was making me things. It reminds me it's pretty cool that everyone can be sure to mute. It's not just something we say. You put a proposal into change in people some people up slash PTO policies. It's going to get an executive accepted. I don't know. You know, the DRI's, the ERI's been reviewing it, but it's really neat that everybody feels and can make suggestions to improve things. It makes things outside, things inside and to be stronger, but also things outside and to be kind of neat. I had the last item. At least we have as you know, in the thanks and gratitude, we don't remember the things in here, but thanks Thomas, we're not committing a work day performance review hack. I think it's a great thing to call it a hack of how to go export things at a work day in a way that is usable. So appreciate it. I used it. I think many things. That's everything we have in the agenda. Let's work with us. There's a happy friends and family day or Friday. And for those taking a few Monday next week for US holiday in July, I have four days weekend for NLK Junior Day.",
  "I should announce this is the set growths and data-sounding staff waiting for January tape. I don't know. Good. Good, George. Hey, Wayne. Hey, Thomas. George, how are you, sir? I am good. How about you? Doing all right. And I am admiring the reimagined series of elements on the wall behind you. I've shared this comment so many times. Sorry. No, no, I'd try and it's fine. Completely fine. It's not that actually, I'm at the anyway. It's a design practice I used to try. Well, I go. So we'll get started in about a minute. We're all really. I know. That means everybody else is late. I say in just since this is being watched. Is it possible, philosophically, is it possible to be late? No meetings are actually. Is it possible to be late? It sounds like a quote for somewhere. I don't know. I think yes, if anyone who joins late asks people to back up in the agenda, then you're actually late and you shouldn't ask for that. So, but all me interrupt. Hey, I'm. Hey, hey, how are you doing? We've started out 30 seconds. Do you have a good long weekend? Yeah, how about everybody else? George Thomas, how was your weekend? Relaxing. I'm largely good. I just need kids to not get sick anymore. So it's the set growth data center staff meeting for January 18th. We were. Talking about other things before we get started, but when we get started. So first, welcome, George. Who is my shadow this week and a get lab core community. I have core community contributor. Hey, everyone. So, what do we jump over to? Martin, let's take you to the next item. Yeah, I just wanted to give a huge shout out to Lucas and James for receiving the special script bonus on their efforts and recent customer escalation of not only Lucas and James member of the T. I'm, thank you for not only. Proposing the discretionary bonus, but also all your efforts on this as well as Neil is not present. So great collaboration across the state section and other teams as well. So, I'm going to be a very nice person. I'm going to be a very nice person. Well, I think I have the next one too, under news and events. The just in case you missed it. Week to personal access tokens will now be automatically revoked for all get lab or team members. So you step in the continued trajectory of making this enable for all customers. So we had to pay premium damage low. At only a year, you should pay 5 34 even Yeah, another question here. HARR cupcakes told me that a lot of things would happen on January 23, Thanks, Emma. So we've got a development newsletter that we're working on. Don't talk about in this meeting before. After reviewing getting Christopher's staff meeting, that's a good feedback on it from a number of folks. So the details are here as we get started on this in this epic. The first iteration is planned for February. If you have topics that you think should be included, or you want to weigh in on the. Center included, please collaborate on the issue for the February newsletter. And also please make your teams aware so they can collaborate on the content if they're in soon. Some have already collaborated on it. I think I just post this in less than 24 hours ago. Please also review draft Q10 okay hours for secure gather, govern group and data science. I put mine in earlier today. And you know, please start working on ones for your teams. Keeping these in mind, but also coming up with your own based on the overall themes and then get that value of course. Do we want to review these live? We've done that in the past. Do we want to do that? Maybe in zoom emoji up down on do you want to or up if you want to reveal it. One yes, two yes, okay that's enough. So I'm not going to share my screen because this issue is a book. I'm. I'm in the chat. George, I think I think I said this to you as well. See you have it. Okay. Good. So some of the themes and I've started in mind based off of Christopher's et cetera, but again, these are these are all draft so objective one increasing revenue by growing a customer's own mindset. And deliver results so continue. I'm going to summarize here continued work on federal. For SLAs for vulnerabilities meeting SLAs for vulnerabilities. Who for data science or AI assisted code suggestions MBC and a model registry MBC and these the the rest of these are this one are based off the product range of ones. Under secure continuous vulnerability scanning capabilities and depending dependency scanning. And also a set for secure a vision proof of concept for real times, task scanning with the new web UI. These are things are more in flux that they're on flux. But only product is settled on it or just yet, but it's great. We've got to really look at them. Questions or comments about those. As I realize my issue has two objective three so I will fix that as I talk. Do you want do you want feedback for commentary in this issue or do you want it on agenda or do you want in slack where do you want it. How about now. Okay. Side channel. Okay. Okay. I'll start now and I'll happily go. I'll write them where I'll write them in the issue. Done as well. Continuous vulnerability scanning is competing against. I'm not sure if you're getting licensed finder and so in composition analysis. So I'm dubious that both can be achieved particularly during this particular quarter, particularly with 60 know approaching at the very end. So and I think license finder replacement has the priority. And the real time, SAS to one target being web IDE or the web IDE replacements. Product is saying that that won't be ready web IDE replacement won't be ready for SAS until Q2 at the earliest. And so there I know. I'm hearing I hear the they're not settled on that one yet like you were saying earlier and so but I'll I'll put both of them in there. Yeah, just because I've been slightly in the the source issue that PM's goals are. Okay. So they can probably probably, you know, some of this but no, that's good to know. Good feedback. Great feedback. Objective to make sure the platform to continue to be the leading depth set. Cops platform continue to. TBD iterations to close best in class gaps pending discussion of product 100% of our teams are using get labs and okay. Are tool you know we're getting our file I kind of easy one for us to achieve but important to achieve. And raising the MR rate TBD it's an overall development goal we want to look at ours as well. Objective three career growth team members team member training or 360 feedback cycle figuring that out a hiring goal TBD. To be determined town assessment follow up an action plans based on feedback and finishing. The or if we'll finish complete type of get complete the gap analysis and delivery on. TBD short term wins first of your govern growth and data science and last and eradication health. Everybody gets and continue to burn down the list of customer impacting S1 and S2 books. We made progress on we will always make progress on these including in Q4 thoughts initial pots on on these. Wayne is is objective to KR one the zittle of a lot with objective three KR four so the gap analysis and the and the big gap. Yeah, good point. Very good point. We just simplify that. Where do you think it fits better doesn't fit that well in. I mean we're ready doing the efforts on big right so between the two I would keep objective to KR one. Yeah, I'm going to look at it to do to get in the wrong place anyway good catch the before you do because I was looking at the I was looking at Christopher's okay ours yesterday. I thought I had the same questions you argued but I had separated them eventually in that I think some teams haven't finished the gap analysis and I think this is to be a follow on to the work that's happening in this quarter whether as. To two dot one is what iterations have been identified that are not the quick wins. I think they're separate though it's it's fine fine margins. I'm still going to move it that's a good point I'm going to move it to the above one. Um, because it was definitely the wrong objective just to refresh see if that looks makes more sense. Basically I moved up simplified it and and moved it up from objective three objectives to. When for application help the resolve S1 and S2 are we just looking to achieve a particular velocity on a regular basis because we'll always have. Bugs coming in right. So it's not necessarily a burn down but maybe just a cat as to where we want to be or a threshold. Maybe maybe also with a focus on over do ones. Um, I don't know if we have any current over do ones but are you tracking the equivalent okay or for cue for was that about over do ones or any. Any. Last such act of there weren't any over do ones however throughout the course, the cue for like stuff mentioned if you did pop up on their S2. But they were work through and close down as you and so. We don't want to get to zero right because as Seth you mentioned they're always coming in we want to get to zero right but we don't want to have that as a goal it would be resolving number of them which should. Perhaps be the number we have currently and some more assuming more coming. But you know we'll figure that out. That that makes sense. Yep. Great question that. I'll focus on S3 and S4 might also be a good one because the list of S3 and S4 seem to be longer usually always a longer than S1 and S2. Okay, I know we're discussing this async which is great. Please put the comments later or not if you don't have in the Google Doc which is just fine you add them to the issue. Have the great some recovery there as well for folks who didn't make the meeting or read it later or we forget all the great feedback. All right moving on to the next topic can someone volunteer to provide see. Yeah, sure. Let's see from left from left staff meeting looking for volunteers to contribute to the audit work efforts this can be any EM or higher. So we can see these can also help with the technical bits Sam and Darva have started on this but we could use some help for context these efforts just to fire our financial audit and as such are important to overall success of the company. Or details in this document link here. Yeah, I just went through this I got some time to go this I volunteered for one part. I'm looking to volunteer for others to take a look see if you're interested for you or your engineers because there's some work for. That fits nicely in people leader and some for engineers as well some automation work. Is this a requirement just as a publicly traded company or is this just a standard business practice to have a financial audit every year. I don't know. Maybe sorry. Kind of related is this the audit that like the auditor sign off on as part of that or because we also talked about audits for federal amp and audits for this and audits for Ruby gems and we use a term audit quite a bit. Looking at the. Christopher staffing ITC G controls is what it's about. What is ITC G or an actual. What I see. In cool is my friend S p and my general controls. Great question. Maybe to ask. Does it research looks like it's part of socks which would be part of being a public company. Okay. Good. Thanks for volunteering to. Lead those Thomas and thank you've got next. Right. This is just a big thank you for me is so. Particularly for everybody's participation is weekly error budget issues and we've got to link to this week's. I've been able to go there for the agenda. It was my week to represent everyone here in engineering allocation meetings that happened my yesterday and the content here was hugely helpful not only in short cutting the amount of time it took to prepare for that conversation but also providing additional context as to what was going on. And so this was was a big help so thank you. Thank you for this and it's. I appreciate it and extremely helpful. I'm sorry you got to. I was going to. Yeah. Nice. Thank you. Great. I love that much. I've been seeing it for years. I miss it when I don't see it. You know, Alexander from my chase team is is staying in my house with me and they nearly got this mug. I say people going to ask you West. Jago and what have you done to him. So they they got a different mug. If they happens to use it and join a meeting they has to join through years in the count. Collet him. Any any questions for the group George. Which is also a good question for George George has been a core team member community contributor to get lab for many years. I introduced George to Timsol men is a base of all of a second. We've known each other for years. Tims on around as well. So George there's a community community contributor. Hello again, George. We we so each other tomorrow. We saw each other tomorrow. How are you enjoying the experience? It's been a great so far, very informative. I mean, I feel close to the Guilatim and it feels good to be part of this process here. Do you feel like all the core members would benefit from the experience? Absolutely. I brought this initiative in the court in Meding a while ago. And I will bring it again. So maybe others may be interested in joining. Yeah, it's great. It's great to have you and all this coming in. Bring us closer to the community. I like it. So welcome. One thing that George and I discussed earlier is, we don't have a lot of community contributions to our stages. Secure govern growth and data science. Compared to the other stages. And one of the reasons, maybe, that people like contributing to things that they use. And most of our stuff, not all of that, most of it is in, you need an ultimate license to use. And a community contributor can get an ultimate license to do community contribution work. And I'm not going to actually gravitate towards it unless there already had a customer that has an ultimate license. So I don't know if this would, this surely would not be the only thing to increase community contributions. First of the video of some including, have slash null, this handle. He's done a lot in the past and we appreciate him. But for multiple reasons, not just this one is move a subset of secure features. And maybe govern features as well to the open core of the open source part of the product. And rather than a big binder, like you can't get any of it unless you're an ultimate customer. Where we couldn't move too much or people would have no reason to pay, but maybe move just enough where the open source community gets access to those and value them. And then indirectly, they start using them and indirectly, then they have feedback on them and they can go and prove it themselves with everybody can contribute. So I know we've talked about this as a concept in the past and just figured out what it was in front of the group for their thoughts. Wayne, have we considered switching responsibilities on on the ultimate license? So for example, as soon as we notice a new core member contribution, we reach out and say, hey, he's an ultimate license valid for whatever we comfortable with and keep track of that and just, you know, use that to build a stronger link. Well, we've had the vaccine on us, have we thought about it? I don't know if we thought about it, but it sounds like a great idea. You mean, like, amazing. You're also great, George. You received, say, hey, he's your ultimate license. What does this do? Let me go have a look. I think it's already part of the heroes program where, you know, when you contribute after some time, you also get the ultimate license for a group. But I don't remember if it's like on the first tire or the second. Cool. You've made this weird. Is it combining ideas? Thomas, you're saying, yeah, George, when you're looking for or identifying where you're going to contribute, how do you identify that opportunity? Is it by issues? Is it by things you notice as a features you want? What do you, what do you, how do you look? Well, I have multiple ways. I mean, sometimes it's just something on the application that bothers me or it's like moving one pixel to the left or or there is something that I'm always always looking for migration initiatives where you, my great to the pajamas components and make the application more robust. And yeah, sometimes I just go through the community contributions, take a look what's going on. If there's anything I can help or what things are there right person or thing. But yeah, like open-sourcing, some parts of the security features could be really nice because, you know, when you contribute to something, it would be nice to get something out of it or use it later. And I think in the past historically, we have been open-sourcing features from the premium tyres and that would be something to consider. We're almost at scheduled time. Thanks everybody. We're great.",
  "people do like a DSLR. You have like the full setup. But nobody makes like a high quality kind of like plug-in play webcam like that. Yeah. So they were complaining about that. I like to achieve that quality. You have to have this like complicated setup and nobody's scratch that it's yet. Yeah. I mean, there's a bunch of people that have like all these hacks of like doing backgrounds and then running it through OBS and like, but it's not as simple as a couple options in Zoom. I did find the new avatars in Zoom. Moji's on your iPhone. Avatars for animals. Yeah. So you can be the new. Yeah. Yeah. Yeah. So you're like, you can celebrate like that. Right. Good is the sick growth data side staff meeting for January 25th or January 26th for those in A pack. There you go, Jay. That's funny. Uh, I was in a meeting where somebody had their child on their lap during the call and everybody without saying anything, slowly transitioned to using those and started like waving like this back and forth to see if they could make for getting their child that was and it was Tim's in film and like smile and it. So anyway. Let's see where to get started today. Thomas looks like you've got first item in celebrations. Yep. As I was also in that meeting, it was lovely. So just to say, when it was lovely, it was lovely moment. And in any case, to the agenda. So this was a previously announced in Slack, but we've got we had three pretty big work in a version. He's that happened in the past week. So I've progressed to Fadion and Olivier for five years each has founding members of the secure stage. So we've been here that long. And then Isaac for three years. So congrats to to the three of them and a pledge owner here. Over Seth. Yeah. Happy Australia Day. Australia Day. Did you start on right now? Yeah. It's an Aston you might or both your two new zelanders that two Kiwis though adopted or original. Do you happen to know what Australia Day is? Yes. Yeah. We do know what Australia Day is. But the guidance don't partake. Is that good rivalry in us? But yeah. So what is Australia Day? I'm just curious. Yeah. Well Australia. Australia Day is just their sort of national data, celebrate and have a public holiday. Fair enough. Yeah. Thanks. New Zealand or what would the equivalent be in New Zealand perhaps? Yeah. We've got white hanging day which comes up in Fib. And I guess it would be somewhat too. What's the American holiday with that? The close closest would be like independent stay but it's not quite the same because it's a treaty between the Europeans and the Maori. Thanks for bringing up Seth. It was nice to take the tangent on things like this to learn something new. Using events number one, I've got OKRs or now down in GitLab versus LA. Yeah. Big win for usability, collaboration and dog food. So in big rocks and hot issues, looking for volunteer to different volunteer need to verbalize A&B. I put them in there but be great to hear from others too. I'll take it from Christopher's staff meeting. Let's see. FYI on the Ruby 3 upgrade. We're currently asking teams to perform explore tests and explore a testing on an environment that is using Ruby 3 by Jan 31. While we do have a green pipeline running on Ruby 3, this is to catch things that may not be adequately covered in our test suite. Most of the checks, the box or acknowledge they are looking into it. This is mainly for visibility but if you notice anyone on the list who may not have seen it, we'd greatly appreciate some help following up. This issue contains the timeline that is being regularly updated. I'd say anybody found any snags associated with the Ruby 3 testing? Any EMs here? We we have an engineer go through pretty extensively. The gas functionality and everything seemed pretty good. Good here. Somebody else want to volunteer to verbalize B? I can take that one. So also from Christopher, there is an exercise we need to perform that will be labor intensive. We don't distribute it. Essentially what it is is we need to review a subset of MRs for fiscal year 23 to make sure the type labeling was correct. More specifically around feature where we could use the help. If you are an EM or a bug and want to get the word out, we are choosing testers reviewers for this exercise based on who merged to about 188 folks on this list. Your individual contributor and want to help out or willing to take on some of the reviews. I would also be greatly appreciated. Think right now Christopher is doing the testing or doing some testing. Would like to distribute the work and make sure that nobody spends more than one to two hours on this. Except you have a comment. Yeah, I don't know if anyone has any more insight as to why we're doing this or how these labels are being used for finance. I'm just more curious. It asks us to do this but it doesn't say why. My guess is it's for accounting on diverse colleagues but I wasn't sure. Looking for the animated response and zoom that goes like this but there doesn't seem to be one. Actually, don't know. Maybe add to the issue. Let's say to be else. I don't remember if it was specific to those accounting definitions or indeed versus cogs but I think what you're asking is correct. I remember that from Tuesday. Staff meeting that it was like what's the are we doing accurate accounting for percentage of work with feature versus maintenance versus bugs and so forth. So I'm going to go hunting for the canonical answer. I think I've seen it. I just also want the reasons that that's really good to know is if that's a finance concern. It drives us to make sure that it's even more accurate when those labels go in. Versailles, we're just kind of curious as to what percentage people are spending. First, we need to get it within a certain accuracy. I think knowing that it's important, I will help us drive that. Yes, and look for the overall trends. Don't spend too much time on is it a bug or is it a feature? If you spend more than a minute or two thing about that, you spent too long because it averages out over time. But good point we want to make it as accurate as possible. Maybe time box that thinking about it. So it doesn't go off into the outlier on time. I feel like I'm most of the work that. Most of the work that falls in the engineering allocation, I usually always label as maintenance. Do you all find that as well? Or do you do a lot of future development outside of product? Sorry, see that again? Most of the work that I signed, the issues that I create are all I often throw type maintenance on it. It's very, very like a brand new future. I'm wondering if you find that similarly or if you're assigning a lot of new future work often. We support static analysis. I think the engineering ratio, about 60% future work. I'm about at this 60, 30, 10 was it 30% maintenance and percent bugs. I think that kind of sticks be true, but I think we've been more on maintenance recently as Thomas's shaking is that? But Jay in terms of as a general rule for us, like if engineering is an issue in the work, it tends to be bugs or maintenance. If product is initiated in the work, it tends to be features. There's obviously some exceptions to that where engineers got a great idea and product signs off on it, then that would be a feature. But as a general rule, whoever initiates the work tends to fit it into a category. That's going to a great conversation. Great. Glad you ask, okay. Thomas looks like you found the why? Yep, did find the why or at least the why as articulated from Christopher staff, meaning you've got a link straight to the thread and that agenda folks want to. It's open to open with them, get live itself. I copied and paste straight from that section. And it is a sample review. It's not reviewing every single MR. It's been put up by development over a period of time because that would be quite a lot of. Synex and next in big rocks and how to choose that section we have. My updated still draft okayers are available in the slink. When we're done, we'll go back and revisit this and do a good of private recordings. Since I think some of them are confidential. I want to mention you know, the one shared with PM and the ones that will up to my boss, Christopher, they're not finalized yet. They may continue to change based on that and further iteration, collaboration on a mentioned. That we're in good shape. I'm putting them together, but you know they're not final yet. So at the end, we'll go to a private recording and make sure those and talk through them live. How much looks like you've got? The next item. All right. Bed ramp is the saga continues so we'll call this fed ramp episode six. The the the retirement of the of the assessments, but anyway, I'll figure out a better title for it later. The next the next the next milestone where going after is called the SAR or a security assessment report. And one of the things that all groups are being asked to validate is for issues with the with the with the relevant label, which is and you'll you'll see it because it's because it is the only one that's are related to it and it's scope to fed ramp itself. Are the should they be part of the scope and if so can we get a rough estimate for it? I found there are five issues in sec. They're none and growth. They're none and data science. Four of which I question whether or not they should be in scope. So I've pinged in EMs and PMs related to those issues. My my request is a buddy. If you get it, please get that done this week. If you can, it's just like is it should it be in scope? The remaining issue is one that's that's a it looks like it's on its way to being or to being completed. So so and this is not for delivery. This is estimation. I'm like it. It should it be in scope and rough t-shirt size. Swag, I think good. I love how important this is and then at the bottom of the list we have like an issue talking about bouncy castle. Yeah and that's the one that's going to be done. Right. Okay. So that's actually a library that we're using to test for it. Are they using TLS connections to the to the to the target itself? So yes, we're using bouncy castle to bounce around different type of connection protocols. So. Yeah. You want to verbalize your comment as well? Yeah. Sure. So I was just going to ask it's their time frame on the all the expectation on the time frames and the answer to while you're. Yeah. I'm talking to them. I'm just trying to get it through this week. Yeah. Because I noticed that compliance has to and it helped it. Yeah. There's two. And I don't know if they're actually yours. It looks like Connor put them on for compliance for lack of a better group to put it on. So I once again I question scope or if there's a cops setting in trouble from like security or infrastructure to this. Yes. Yes. This is an interesting topic for us with order of in across the whole product. We actually responsible for the order of ines were just the system behind it. So anyway, I'll go through that. Thank you, sir. I think it's your being on the public agenda. I'm going to switch to a private court.",
  "I'm getting the YouTube stream going. It takes a little bit. Go, raise. All right. So it is the Sec Growth Data Science staff meeting for February 1st. For February 2nd for those in APAC. I'll try to not forget to say that. We have a guest today, Runaul, who's my outside GetLab Shadow. Welcome Runaul to the group to the meeting. Hello, Runaul. Thank you. So, looks like Phil, you've got the first item. Yes, just a new high as an anniversary section. Hey, NAM, who is an R&T abuse team. It's just celebrating one year at Goodland. While we're talking work in a version, we'll talk, I'll add three to the list from Secure. First couple of from dynamic analysis with Craig and in Arter. So Craig with us for three years, Arter with one. And the NVish was from static analysis. It's been with us for one year and time flies. I didn't realize that it had been a year since a war three since they had joined us. So what everybody's here. Oh, glad we have this as a section. It's nice to have. Ninch these. Celebrate them. So a news and events. In the next week, please close your Q4, okay, ours. The final update and add a good bad try comment. So what went well. What didn't what we might try on something similar in the future and tag in your manager for review. And also, please work on your Q1, okay, ours. We'll remove the okay, okay, ours tracking to the GitLab product itself. There's a feature. And there that we're done putting. So please work on your Q1, okay, ours and review with your manager sometime in the next week as well. And mine can be found at the link into them. The link to them there. Thanks, Wayne. Good to have a. A proposed due date for Q1, okay, us. We've been discussing them. And teams. You're saying sometime in the next week. You'd be happy. I'm making it up. It feels about right. It doesn't need to be in the next week. It feels about right. It would be great. A little bit later to be fine, too. You know, the later we get started on, we solidify them. The later we're working on them. Although they're often to reflect and not always often to reflect the most important things we're working on anyway. So I guess my statement, I just said, is not true. At least some of the time. So good stuff there. I put in some items in the hallway in hallway A. Does someone want to volunteer to verbalize them other than me? Yeah, I can take that since I have one of them as well. So please read this week's VP development staff meeting notes. Link, you know, the top is included heads up for a proposal on them all error budgets are being tracked. Joliana from HR has some cash compensation comes and that was, you know, shared recently that should become available to everybody. So check out that the private manager's channel for more information. From Nick, the not only available is being deprecated and relabeled to deprecated. So that should be pretty obvious. I don't know if there's a migration effort taking place, so we're just going to have to look up for that deprecation label. And then Michelle would like to give a huge thanks to everyone helping boost maintainer ship. We've had a 27 maintainer's across front and back room back in and database the slots quarter. That's amazing. Awesome. And then I shared this on Slack. So I'm looking at to see if we have a coupon power user, which means that we have a shared credit card essentially. When we do expenses for things like software subscriptions, we have to go through a process where we get a digital credit card. And we use that. And so there's this thing. My team has been experiencing things like grammar league, for instance. We're just fine. The process is in horrible, but now we're getting expenses declined because we can't submit an annual amount, even though the subscriptions at the annual level. That's been monthly. So they're asking us to divide the the subscription by 12 and submit that amount every month. I don't want to do this. I already don't enjoy expenses to begin my country. You don't either. Does anyone know anything about this? Otherwise, I can just continue to escalate. I don't know if you can see if. Press or someone Christopher or someone might. Have a coupon how are you, sir, Card. Sound like an intent of thing. It is the power user like is that a specific type of coupon account. I think so. Yeah. I had a coupon. I was like. They're interesting. And the issue with the called virtual cards. And then you just get it's a credit card number that has a fixed limit on it. That sounds exactly what I'm looking for. So it sounds like I could do that for my team and maybe that sensible. The doctor to handbook described that being had a department level. So I'm wondering if what does that mean department level I suppose that's sec. Is that too broad, but you know there's a couple gaps in me. My team and sec. Department level would be a Christopher's you know the development department. Even higher. Yeah. Yeah. Maybe something for the VP development. Okay. I can do that. Thanks. Did you just know myself? Sure. I mean, yeah, I have team members actively looking at cool things like this. And I know there's separate conversations around this getting better corporate licensing established. So the Grammarly for instance needed a secondary approval. The manager couldn't just out right approve that software and we had to get additional. That has now been added to a list of pre-approved software that you can get. And I think on top of that we were looking at more of a corporate license. So anyone can just like log in the Grammarly. If they want they don't look like that's procedure at all. So I can probably extend the conversation in the that that comes up. Cool. Over to thanks and gratitude Wayne. Great job. Tom and Phil and Maan. And the development portions of the recent product performance into gear P. I perform a indicator reviews for secure and govern in the similar one for data science. It's a great example of a single collaboration to avoid the need for meetings. Overall good stuff. So those meetings got canceled. That lots of people in the cancel because we did everything. Async. Not just us but product and other. Inshad portions of the quad like UX and UX design and quality team set. So good stuff there. And also thanks Alan for the automation help on the product. What did you save? We would probably took you an hour or what I'm taking me eight. It's a really appreciate the help. It's everything we had in the agenda. Um, we're not. Do you have any. Um, questions or observations for the group as you've been. Uh, shadowing this week. And if you don't that's totally fine but figure out. Ask. Yeah. Thank you. I mean, uh, just one question I had to as about O.K.Rs. And looks like you're using one tool. Uh, for having O.K.R. but you think you using. Good lab itself to manage. Uh, your team's O.K.Rs right. So I think that's a new tool which, uh, or a service which you are. Kind of creating in GitLab. So where you can manage your O.K.Rs itself. We've got. Yes. We went from a commercial third party commercial tool called ally to our own tool. And we're dog. It's a, I don't know if it's a minimal. I don't know if it's an MVP. Um, but it's, it's, you know, minimal viable product. But it's been the same vein as an MVP. Um, we're using it ourselves first which we call dog fooding. Um, I don't know if it's available to paying users yet or in the open core product. Yeah, but I think some combination that is coming to our. We're getting experience with it ourselves. Uh, and using it ourselves was collaborating on things like that in GitLab. Works much better for us and we feel for our customers than using a separate tool. Where because we're in that tool and the collaboration is pretty good already threaded Composations and things like that. Uh, and tagging people where they are rather than having to go into some different UI and some different system. But GitLab as a, but GitLab product didn't have some of the same features as OKR. It was like a, a percent complete as an example. And now that's in there and there's other things too, but um, um, track them like we had issues and sub issues but not in the way that people would want to track objectives and key results in the O in the K or in the O chaos. So, um, overall it seems to be, um, I have a couple little nitpicky things for the team, which I passed on to the product manager who said, Yep, 30 and the thank you. We appreciate it's 30 in the roadmap. That's good. So overall it seems to be working pretty well for me. Does anybody else tried the new, uh, new stuff yet or used it much and if so, what are your impressions? I look I've tried it. We were sort of demying it where we're using work items and issues. Um, and Q4, uh, yeah, it seems nice as you mentioned, the some additional features that we'll be looking forward to. But it's really good just to be dog food and not using another application to track. Is that public? Is it anywhere I can access their tool or is still currently in private? Yeah. Okay. Now it's a, um, so we're currently logging them in and get lab internal project at the moment. In terms of the direction, so this is the started offers in incubation engineering project, which is like a single engineer group. There's plenty of, uh, there's a handbook pages for the incubation engineering team. So one engineer started off sort of developing something and now it's been brought into our plan stage. We're should I put it in the dock. Yeah, it's supposed to link, uh, as well to the documentation of the feature, which is officially alpha. Oh, right. Thanks. Thanks. Well, thanks. Thanks. That bill. That it's good as well. So, um, nice. Thank you. Yeah. Objective and key results person with disability in 156. Sorry, introduced in 156 to person with disability by default in their alpha. Um, to be interested in take a look there. It has some of the details. And that's in the public documentation. Any other questions or comments for the group group? Uh, group. Do you have any questions from her, know, as, as shadow being inflicted on shadowing me and my meetings and listening to be talk a lot, which I don't want to inflict on anyone more than necessary. Yeah, I have to don't set any questions. We've got. Great. Thanks, everybody. Have a great day. Cheers.",
  "It is 74 degrees here right now. Sorry, I was running late today. It's not like it was an interesting discussion about Brazil, Fahrenheit, Celsius, and travel, etc. It's the sick growth data science staff meeting for March 1st. Glad we're getting back to these. We haven't done one in a little in a while, a little while. I have a number of the items I'm going to have to volunteer to verbalize some of them. So in celebrations, lots of features have evolved by our teams in 159. I'm looking for to brag about them on social media. All sorts of good stuff. Did I saw on a list? Somebody want to verbalize a livis comment? Yeah, I'll take it. I think it's a great question. A little bit more. It's a good question. It's a good question. It's a good question. That's a good point. I also noted, Mike Edington indicated API discovery. MVC is live. It's in the documentation. I don't remember seeing a release post yet. It sounds like it might be similar. It's a very interesting thing. 1510. 1510. It was a release right on the boundary. I think we got right after the cut off for the release post. We decided to hold it so we could make sure that it was in before celebrating it. You'll see it coming. Think in 159. I know some are behind a feature. I think I counted four or five major things across various teams. It's pretty cool. There's some news and events. Recommend and reading the slide notes from sales click off SKO. That the slides there and also some notes that Christopher had from their staff meeting. And. Mon also was there and was a presenter, which is pretty cool. Any any is a public stream live stream, mom, but any. How was that scale over your impressions. Will you take a look. Well, I think it was. Firstly, it was. It was nice to actually see from the sales lands of things that they celebrated during the product, you know, so announcement on licenses and that sort of thing is. Something that was really important to them. For me, specifically, we got to also meet. One of the customer who's dog fooding. Coats suggestions and it was great to understand from from their lands. The use cases were it and how we can actually improvise. On the model as well as the fact of. Specifically for model of the support that sales also need on basically. How to educate and sell these features really. So. Yeah, and it was great to see everyone from different different different parts as well. So there was product that was sales. Customer success. Product marketing and. Yeah. Next to that one. And I know see you paste the link to your the deck that you and Taylor used for your presentation on model ups. Yes, yes, so so in the product keynote. David spoke about everything till. Data science. And then model ups and then that went into our presentation. So yeah. Good. Last in the news and events. I also recommend to recommend to the Q on kickoff from a Sid, which I haven't done yet myself. Um, there's an AMA in there and some slides and also recording, etc. I think I pre recorded video and also recording the AMA session. So good good stuff there. I know I had them but volunteers to volunteer maybe for each one to verbalize the whole way items. Sure. Please update percentage complete on your okay ours every two weeks. I think there's a type of here I'm being online. I'm being strict online. Maybe way. I'm just a being thank you. So yes, I'm asking everybody else. I'm asking everybody do this. I haven't done it myself yet. So I'm behind to. I don't know if I'm behind to someone probably up. I'm on this but I have not one of those that is so thanks. Thanks. Thanks, Jay. Thanks for pointing on my type of to that. What I wrote made no sense. Um. I'll read the second. So from York. You are our our CTO. If you're curious about how the sales team positions get lab. Take a look at the latest customer deck. I don't know if that came out of SKO or it just in general, but you will get announced that. In thanks and gratitude. Please keep in mind. Discretionary bonuses and also the hashtag. Thanks channel both for those on your in your teams and those on other teams. You know, thank people. Thank your own teams. They should be thank each other. Thank other teams. But in discretionary bonuses. I just put into. And I just approved one discretionary bonus. Um. So just it reminds me of that and I try to use the thanks channel to let it's it's great way to show appreciation. And this one read only item. We don't need to read. So we have the agenda. Anything else that we want to discuss? Thanks everybody. Have a great day.",
  "All right, so it's the Sec group data science staff meeting for March 8th. 1, 2. Bill, you're outside today. That's neat. Yeah, it is. Actually, it doesn't start raining on me. If it does, I'll run inside half or three to the meeting. There you go. So happy fourth year get lab of nursery, Thomas. Y'all have been afflicted by with me for a long time. That's not a plan. Look at there's some congrats also from Mawne and Camille and Neil in four years as huge. It's a Thomas, you've got news item number one. Yeah, all right. So this is from the Vultment staff meeting agenda and the link is straight to the to that particular discussion thread. There's been some unplanned required stops with upgrades and DB migrations and there's a bunch of links that are available here, including information about what the database team is doing and there is an ask for other teams, which is below. So and and so there's the ask information here. I don't see Tiago, but their antidote is is is is additional as is worthwhile additional insight in and context. So worth being aware of and knowing particularly as we get into more more database centric approaches. So in the hallway, I reviewed the values of hierarchy again recently. It's we're taking a look at the M scene. Have them looked at it in a while. Click on that link there. They know, they know, they don't share screen, they don't have to. I'll share screen on this. Is sharing a handbook page results. Good results enables to keep doing the right things that's top of the pyramid iteration and transparency, the most noticeable from outside the organization, they're the second level, which also helped to enable the third level of collaboration, diversity, including inclusion and belonging and efficiency. Those are the foundation of our values, but this is kind of how the hierarchy of the values come to play because we can't always make a perfect decision on what we're doing. So this helps us make a decision when we have to balance one against another. I think and this is not a. Now, shell kind of thing. This is guidance in general. So any impressions of this or thoughts on this? No, no. Okay. I'll ask a question. Sorry, it wasn't clear why you chose to share that today. Was there any, um, particular reason? Why? Um, good question for. Um, because it's it often or values, you can't make a perfect decision. It is so in general, not about a specific situation, but recently, but often you can't make a perfect decision. Trying to get the best results with the best iteration of the best transparency and collaboration and diversity and belonging and efficiency. You have to choose that some are going to be valued. Some are going to, you're going to do more on something on others. And when needing to do that, it's worth keeping this in, you know, kind of a hierarchy in mind, but not about any specific initiative or project or anything. I think it really useful. So I figured I'd say, and I hadn't, I don't think I'd read this since I onboarded this portion of the values portion of the handbook. And I read it again recently, like I have this helps. For things in perspective. Is that an interesting question? It does. Yeah. Thank you. It's a needle. You can go ahead. Okay. I could chime in. Yeah. On the anti-vacam, we notice like. Our projects are not open for public typically in a lot of our communication is confidential. So I feel like we often make this sacrifice of transparency over results, because the work requires it to some degree. Debated potentially, when having an epic potentially actually making two epic, one which would be confidential and one which would not be just so we could exercise that transparency. So yeah, just to reiterate, this is a sacrifice that our team usually has. Similar and vulnerability. Other teams too, including vulnerability research, sometimes vulnerability research is working on as patentable. So we don't want to make it public until we're ready to as an example. And there's transparency inside the company, and transparency outside the company as well. We try to be transparent inside the company as much as possible. And also, transparent outside the company as much as possible. But I know Jay, your team is very transparent inside the company, but not necessarily the public, based on what you work on. And it helps with your collaboration with the abuse team, that's responsible for the day to day, today of protecting GitLab. And it's useful for collaborating with the growth team. It looks off in the growth changes can create risk for abuse and abuse changes can create risk for growth, like they're two sides at the same coin and some case. So all that internal transparency is great. Even if we can't be externally transparent. So it's good to bring up Thomas. I'll finish writing this in just a moment. But this whole note about what is private versus public when we default to public for a lot of things. I've really found it quite interesting that we've codified Conway's law in that we are shipping transparent by default. And we actually have to make it's actually harder to have private conversations within the product because you have to have more steps in order to make it a confidential issue or a metric question for things along those lines. So I actually think it's really neat to see how it's been codified and quite frankly appreciate it. And so just I'm not trying to contradict, but I've always been amused and interested in kind of amazed how some of these things sneak into the product that are reflection out who we are. So anyway, you just thought it was neat. Wanted to share. Yeah, it looks like you're out. Yeah, thanks. So 360 feedback, I know it's not a timely discussion, but something we maybe start thinking about especially. So the cycle normally starts in July and I've linked off to the timeline on the handbook. The way you have an OKR that talks about career development, feedback, 360 feedback, that I linked off to. So we're touching on that topic now. What I'd like the team to maybe start thinking about is comprehensive. Just all of us, I'm calling it Wayne's World. I think Thomas, you've invented that previously. I love it. But you know, all of this action's Wayne supports. But it's typically up to, and last year, I think I've been an opt-in process, kind of tied to our individual birth plans. There's like a performance management and career development context as well, which could be kind of a theory for certain team members. What I like to think about again is if we all do that, two to big call-out reasons would be when I joined three years ago, we had a great thing. I got a lot of great feedback as a new employee from my peers as able to submit feedback to my peers. A lot of us haven't had that type of feedback in the last two years. And then we have a lot of new team members, hires and reliance team members. I think it really benefit from being able to provide and get feedback from their teams. So again, we're months out. I know there's other ways to conduct 360 feedback. I think Wayne, you have a comment about that. I like the system of logistics because it's very structured. Yeah, the Phil brought my attention earlier today, my time at yesterday's time. I think that our timelines for 360 feedback cycles are not in Q1. But we have a Q1O car that mentions doing 360s. Those two things are not consistent. So another way to do a 360, if somebody wants to, again, totally optional, is informally doing anonymous Google form, which anybody can set up anonymous as a configuration option, in a Google form versus required authentication. Invite peers and manage your instinct holders and just have three questions, open-ended questions. Which should I continue doing? Which should I start doing? Which should I stop doing? And you can get really great feedback that way with those kinds of very simple questions. That's a great option. So we'll go back and update the KRFQ1 to make it clear that that's an option for this. So Neo's suggesting that later in the year, potentially we make this compulsory. Is there a, no, sorry. Yeah, that's correct. I think when I love your suggestion, I think Google forms a great way. Again, it's opt-in. It's voluntarily based. That's not a bad thing, but it's not going to include everybody. I don't know if it's in a close approach. It's more about if you want to do it, I just don't know. Again, like I've seen in the last couple of years, I think you did a survey last year. I mean, was that six, eight months ago? I feel like you did a survey. But that's yeah. Thank you. Who are your teammates? It's a better job than this. I'm more thorough job than these questions and how they organize it and the better use for interface, but this is still a. I actually prefer this for myself. I think I still use culture amp, but I don't know why I use culture amp, I prefer this, but I prefer this, but it's just you get, I get a better response rate. But the, and more insightful feedback, because it's shorter, perhaps in what we do in culture amp. I also, I think more importantly, I direct message people, hey, I love your feedback here's in an anonymous Google form. they enslack versus culture amp, which I think sends an email or maybe slack messages to, but it's from a bot or a non, and a account you don't recognize versus someone you do. So maybe I get just get a better response rate to do that. Yeah, I think that goes back to the notion of if we're all doing it. Plus there's, there's an efficiency gain too if we're doing these kind of one off people have to get used to how to submit feedback and they appropriate manner. That can be like an experience I've gone through many, many, many times I recognize the first one or two, I'm like, okay, I'm doing this, I haven't done this for a while. And then those last ones I'm like, wow, I'm going to go to this, it's like anything you do repeatedly. And I do appreciate that with the culture I'm cycle. I appreciate the response rates, you know, we've all seen. We're not getting the full people giving us feedback, we have a repressed eight or whatever people in the cutting five or six. That's still going to happen, but just another anecdote on my experience. We will ignore that, Thomas. I think it's been the last two years. Yeah, I think it's, I think it's been optional as far as I can remember. But I may not remember back or enough. Like if you make people do it 360 and then don't want to, that's not a good feel, right? And then they're going to, they're going to feel it's, you know, it's prescribed them and they don't want to do it, which is not a good feeling for any order. They might do it in a more so I'm glad we make it optional folks who give that a little out of it. And optional, not do it if they don't want to do it. In the, in the, okay, or it says do a 360 feedback or what's the other option for team member. I self directed training self directed training. So I mean, that's another option too. It's, it's about growth, right? This okay is about individual growth. Two different potential ways to do it. There are others too, but self directed training or do a 360. Just a question on timing them if because I know if I thought we've also got a car around creating growth plans for all team members. And shouldn't the feedback cycle in 360 review go into the feedback? It comes off that go into that growth plan as well. So rather than creating a growth plan now and then doing 360 review later, switching them all around. I think they do do it makes most sense to you based on all this. Definitely flexible on what, you know, to do what makes most sense based on based on, you know, where we're at and where your team is at it, separate. So reading through the handbook Nathan, for the team members that went off to 360 feedback are required to have individual growth plan beforehand. I agree to what works best, but for that guidelines, I'm like, described it as a prerequisite. Is it too good? I haven't even done afterwards. I haven't sorry, but I don't want to read through the handbook page. I'll share my screen now. So yeah, team members, we went off to the 360 feedback. There's a couple of optional steps and then a couple of required steps. This is the one I was mentioning. I may be in to misinterpreting this if I am hypothesized. And then your question is there a discussion about, yeah, updating the growth plan. You would expect that right? Because that's good information. I'm not seeing that in far as the requirements. There's definitely, you know, it's a really long cycle. Starts in July conclude halfway through September. It's like two and a half months. And then guess what happens right about here, we start talking about end of year assessment. So. Oh, but then it's the benefit of this process if for team members who want to do it. That's you're up so well for talent assessment. The end of the year, there should be no surprises because you've been working with your manager. You've been getting feedback. You know, working on those action plans. So, I'm on couldn't make today, but of course, that's fine. All meetings are optional. You'd have some discretionary bonuses. So I am going to go find those. And summarize them. It just had them and now I don't. Those usually announce in what's happening at get lab or elsewhere. Team and rubbits team, I always get those to. I always complete those to and team and rubbits. Thanks. You know, so two of them were actually nominated by me. So, there's a familiar with those, but I'm not going to read all the details, but Alexander was nominated as was. I ran outside and I was in bed, and I ran goes out. And so did the. Well, yeah. That's myired blowover and for helping with the. Data analysis, for merge requests for our, socks audit. And to very much appreciate it there. You're going to jump in and help them various ways. And then, a Mon also gift that Bruno cardoso received discretionary bonus. For countries meet solving and brainstorming ghost users or smart issue, babeling using machine learning. of to solve and drive the solution and planning to automate be training of the model, which is pretty cool. So another friendly plug to for all of us to use, you know, an appropriate discretionary bonuses to recognize people and also, you know, if it's not discretionary bonus worthy, the thanks channel as well. For us, between each other, between our teams and with others outside of our teams as well, overall good stuff. Okay, I think that's all we had for today. Thanks everybody. Cheers.",
  "All right, so we've, this is the second growth data science staff meeting for March 22nd, 2023. So Nate looks like you've got the first thing to mention. Yeah, sure. So Elia, who is now senior front team engineer in the compliance group has celebrated four year anniversary last week. So yeah, massive milestone. Nice. I'm ready. You've got the next item. Yeah, I wanted to just celebrate a feature that we recently finished rolling out completely and then enabling by default with the release of 1510. So that features automatically resolving SaaS findings with rules that are disabled. This has been a widely requested feature and something that has caused a lot of noise. We're piled up a lot of noise for our customers in terms of false positives. If basically without this feature, if we had person with disability any rules, all of these findings would have just remained in a state that they would have to manually go in and resolve. So by introducing this, we provide a way for vulnerabilities to be resolved automatically. And one of the rules that we kind of coupled with this release was a very noisy rule of the tech object injection rule. And it's been our single biggest source of false positives across all of our languages and our scanners. I think Connor listed some numbers here. It's been dismissed at least for 52,000 times from ESLID and 273,000 times from some game. So that just shows you how many times people have not cared about this rule or considered it noise. So we're happy to release this person with disability the rule and auto resolved all those instances of that vulnerability with the last release. It's great. It's really cool. I think we should announce more than just in that in your group channel, but maybe in what's happening I get lab. Yeah. And now it's a good answer. Yeah, I can definitely do that. And you'd shout out to Lucas for shepherding the change along and getting it over the finish time. Good stuff. Good stuff. So under big rocks and hot issues, one mentioned that from Nick Wynn just that which is that we're seeing some instability related to the database recently. For example, CPU spikes, partitioning large tables can be really important to improve scalability. The database team is re-farming out the table, the largest tables where actions required related issues have been added to the epic that's linked to your epic 620. And you know, respective groups have been reached out to. So if you've got a ping then you're on their list and if not you're not but it's still worth taking a look. So it's also worth, I don't think they identify owners or de-eris for all tables. So if you, it's probably taking a worth that lists of the tables to see if one is one that maybe your team wants to take the de-eris action on, de-eris roll on if you, if it's not known. So there's some more detail here but good stuff to keep an eye on. Next item also happens to be for me. So please keep an eye on the Q1 okayr for talent assessment follow up where the manager and team members have an action plan, great action plan to discuss based on have a discussion based on the feedback. So it was a review, it was talent assessment, discuss it, come up with a couple of things that are actions, it doesn't need to do this. Everything of course in the talent assessment but you know one to two to three things is usually a good measure. And we want to make sure we do this by the end of Q1 because that's the goal. And I'm behind on mine as well. So apologies to Mawn and the VR team and Thomas and Phil that I have not done this with you all. So I'm behind on this myself but. Olivier who could make it today has a question. Can somebody verbalize that? Yeah, Olivier is basically asking for a child okayr's related to it for easier management. Yeah, it's good point is you know we're dog fooding the first major police. I think it's the first major release of okay hours in GitLab. So it's a good idea we're still figuring it out but good point. I think we're planning to do a what maybe it's instead of a table. You know a markdown table in the okay hour. Wait and I feel like we had that Phil was reviewing this with me when they updated it when they was sharing their screen. But we have something that I already checked. I raised this version that we're talking about three six two feet back. We were so weeks ago. That's where this topic came up. Yeah, I think it was either a 365 review or doing this. Sorry, 360 review. Yeah, exactly that's the care I was talking about. And there's tabular form that shows your direct reports. Do you have a link to that handy you composed on the agenda? No, I think that begs the same question. Discoverability is hard. Maybe maybe I see a post do something. Well, that's that's one of the role drawn out. So yeah, it is hard to catch the track. We're also this came up on Christopher staff meeting my boss of staff meeting to have can we get a report at workday for this rather than trying to track it manually and sort of we can. But good point. We will iteratively think about. Sorry, talking over you. Yeah, it's a neat. That was the pair of care and there's a care specific that has a table that has the senior managers. Let's do that. Nice. So maybe that'll do it. I don't know. I like the checkboxes as well. We're using that on other cares. Are you all enjoying using Gillam the okay our portion of Gillam? There are some nuances. Yeah, I haven't looked at the roadmap, but I hope that there's more being developed for it. Yeah, there's a feedback issue that you can keep adding to people still adding to. That's got a good roadmap. Think what Neil said earlier about discovery, discoverability. That's true to be a little challenging at times. Remember, unmute. What I yeah, there's definitely some challenges. It's it's it's you know, maybe a couple of iterations passed a minimum viable change. But you know, it's it's still early on. What is we don't have to use multiple tools. We're all in one tool where most people are inside Gillam. So we can link issues easily and ethics, et cetera. But that doesn't mean that the other things aren't still challenges. They still are. But yeah, good good good points. On the read only items, does anybody want to discuss them? Should we should we do should we verbalize any of them or not really needed? I think the NMB might be where the other discussion. I know for the other. The other one is for security issues. We have a mandate where we backport three versions. And I think this extends. I'm going to read through it. Just for that you want to verbalize. Yeah, that's. So I'm copied it. So my from our SRE team. I think that's for team. She's. There's an initiative to extend our maintenance policy. What do we do for security issues to extend that to functional changes that we may be to resume this work. To the last three release get live versions. They're starting a pilot in 1510. There's an issue that they're asking for feedback. There's also some AMA schedule. I think that may be in the past now for the AMA. So you can look at the doc. And then yeah, my my question was what does this actually mean? I know it's been an immense amount of overhead. I had a team member that was very much love was working on security fixes. They had a strong caveat that they needed to be backported. And so the preparation of all those MRs took so much effort and tracking. And it's not a couple days of effort. You're watching these MRs for like weeks and getting various levels of approval. I think there's there's an optimization that's being well thought out by them team for virus team. But I'm wondering like what are the circumstances that we wanted back to backport our work. Why is there a pivot? We're not just forward-looking. Hey, you need this bug fix. Get the upgraded next, mega version, your minimal version. I just don't know if anyone has more context or examples that be cool. I wonder if it has anything to do with supporting federal business as it seems like those institutions don't upgrade. That is quickly. Not sure where we are with FedRAMP in those types of customers but I wonder if has anything to do with that. And I must mean that's three major versions. Like we've just supported 1314 and 15. Is that right, Neil? I think it's minor. It's minor and it's including the current version. It's two backwards. That makes sense. I'm not sure it does. That makes sense. That makes sense. Nice. I'm just getting notes on what I mentioned. That's good stuff. Thanks for spring this one up Neil. Good stuff, thanks everybody. Have a great day.",
  "Now YouTube has caught up. We need to bloodstream their caught up with here. We can get started. So it's the second growth data sign and a second growth data sign staff meeting for March 29th. And why don't we jump into things? First is big rocks and how to use is it's been great to see demos attached to issues in merge requests. It really helps to get more feedback and improve you know more collaboration, more transparency, more iteration. I would recommend we also or maybe even instead upload to get lab on a filtered increased transparency and get more feedback in those issues merge requests are not confidential. I agree. I know a few cases where team members are just trying out the process and have been trying them adding them to issues rather than uploading to unfiltered. I'll be encouraging people to do that. Sometimes there's a procedure that these are useful. They're for let's not put them on and float with my just thing. We need to work through that and break that down and actually get them uploaded. It's more of a habit in my opinion. If I see cases like this, I'll be encouraging people to upload to unfiltered. Yeah, I agree with that. I uploaded a couple of today actually to drop into a new piece of documentation. But yeah, that's that's what I got to as well as like when you see an MR go by with like the little demo you might just upload that. I think it'll have one filtered. I usually throw it as like unlisted to get away like to be like a little shy about it like at least it's like uploaded, but it's not completely public. You're thinking about rotating those into the public sphere as well. I'm just thrilled we're doing the demos in the first place and we've really ramped that up. Unfiltered is doing it on filter to is icing like that's that's the extra 5% of the value maybe 10% like the other 90% is doing them in the first place. It's for that that item. So we would like to see more dog coding of the AI code suggestions beta and I have a link here to the instructions on how to use it and we're to get feedback. So far it has been primarily volunteers, but we don't have that name volunteers. So we're getting it feedback to iterate on as we'd like what we're baiting with customers as well some data customers, but from a tip from get lab team members we're not getting as many as we'd like I'd recommend instead of instead. Doing something like having every EM identify one person from each group to dog food it and get feedback good candidates based on the features currently available are team members that use VS code. We're going to support the web IDE as well get lab web IDE as well, but we don't support that yet. I think something like in the poll 70% of get of the sec and data science team members use VS code as their primary way to code so. And write code and JavaScript go or Python. No, so I left that Ruby Ruby is not that not good yet. And not not fully featured yet in the beta it is going to be those soon. So that would be the criteria is VS code and JavaScript go or Python. What is that's. I'd like us just to signal based again so we've got development channels for our stages we'll go and ask for volunteers again or link to your issue. But our front end engineers some of our previous engineers are using go. So TDR let's ask for volunteers again and if we don't then we can perhaps get a year to nominate people. And we can go for what do you think terms for your teams. I like it for I'm going to thank you. I want to signal boost it some more I mean I think this is more timing on my part I think you started this last week while I was out and so I want to go and emphasize it more this week as well. Let's see how they please do that let's see how goes. One thing we could possibly do at least within secure and no couple teams have reaction rotation, which is and basically somebody dedicated to solving bugs, engineers, any of the work that might be interrupible throughout the milestone so this going to be something that we use as well to encourage somebody to talk through this. If we don't give volunteers. Appreciate it screen ideas. Has anyone here used it yet? I did. I'm not writing much code these days. So was not useful to me. I see. Anybody else? Were you volunteer in check? Yes, of course. I'm gonna install it right now. Oh, thank you, everyone. If Mawn were able to make it, she'd be giving a very personal plea to ask for more feedback. Okay, that's Mawn's team developing. That's an obvious. So them team would really look more feedback. Next item. So please review the very early on draft was probably an over statement. draft Q2, okay, ours. Thomas and I were talking about this earlier when we caught up as an example. they got a chance to read them before I did. Just just fine. I'm being asked to come up with a first draft of Ocaras for my teams by April 11th. For the ones that we'll share with product, I'm gonna reach out to my counterpart, Hillary, to find out ETA and hers. So we'll see where those land. Thoughts on these as they apply to your teams. So if you click on that, like this is a mentioning ones in there. Not a lot of detail yet. There's a number of product ones that will wait to get an ETA from Hillary on. Unless we already know, right? Because some of the product managers already have things that go into this. Others are things like migrate. pajamas components. We can put them back in the past. We wanna do more of that. The view three upgrade for the front end. And we'll see where the others go. So take a look at this. See if it gives you ideas both on our current Ocaras and Q1 and the Q2 potential ones. Any initial impressions yet? And I'm really not gonna get totally understand. Get lab for data science as sparked by interest. And curious what it will hold. I'm curious, here more about implementing cross stage work well between securing create. I imagine there might be something dealing with ID and CLI integration, but you'd love to hear more. I was reading up on that one a little bit more. It's interesting that it's tied to this product investment team. And so the fact that it's being tied to that and it's something that it gives a little bit more information. It kind of some samples that they're looking at. It's, I wanna know more. It's, but anyway, it was curious that that was what it was to do. It's not a lot for us to sink our teeth into yet. Figure out what these mean. But it's good to have a general idea. And we're a month before the beginning of the quarter and we're talking about draft Ocaras. That's actually good time to be talking about draft Ocaras. Not three days before. So good stuff. I'll let you know what I hear from Hillary as well. I'm sure them team earned them if we're already working on their portions. Just damn shown up and hear you. So we wanna verbalize Eran's comment in the hallway. I can take it. You wanna am I? Yeah, sure I'll take it. And fly I floor secure and government folks. Eran was starting to implement some as recently accepted. For co-isle to track secure scan configuration, please reach out if you would like to be added to the MRs. I know they had brought this in front of the the sack architecture council. Think they've reviewed it. And now I'm just working through implementation. I was just looking at this. My first thought is, that the vulnerability research team is probably really interested in this. And I was gonna give them a heads-up on it. But I see at least two vulnerability researches already. And so, yay. So nice open question. What's top of mind for everyone? For me, it's currently the AI integration which I'm co-facilitating with Taylor and when the senior PMs and Mons team is of course a key actor on this. But that's a, what is top of mind to me, what's top of mind everybody else? Randomly pick somebody to start at Nate. What's top of mind for you? Yeah, sure. Top of mind for me at the moment is the click-hap's working group and how the implementation is coming along. So that's a big part of the group compliance big makes steps for us from a maintenance and engineering perspective. The other one is the working group for the software supply chain security. That's quite an interesting one. And relevant in government. Do you have people on your team who are on the working groups each of these? Yes. Next day. Jay, what's top of mind for you? I mean, echoing what you said about AI and ShaggbT and plugins coming in. It's hard not to avoid that's my Twitter feed is just bombarded by it and is fascinating. But more personally for my team, we have launched IDA verification at the first stage, which is just email, but it gets us into this path of being able to turn on phone verification as well as credit card verification. So that's what I'm observing monitoring today. Great stuff. I'm a what's top of mind for you lately. Yeah, I actually came across that AI integration working from your message earlier today, one of my team of physionic and I were discussing how do we kind of brainstorm ideas related to a product and integrate that with OpenAI? So it was a very time-and-posed that you had. I was sure. We quickly made the idea that is currently still in the process of being formed, but for your brainstorming was to, how are we gonna incorporate an OpenAI concept into code quality? So this was one I was suggest byonic, we're gonna be keeping like a close sense on the working group itself to see how this one don't have the working group, but it enabled us to work through this idea. So that's just a learning experiment going on right now. Be. Still, it's a, let's talk about for you. Three years on PTO at the same time, they're cross-gavent, so it's just late and I, and Governor the moment. And there's a lot being delivered or a lot that's planned to be delivered across Gavent. We're keeping, we're using those. We play updates, I've learnt one of them there. So just making sure that we're on track there's a few roll-outs, sort of timelines, that we keep in track of the. Last but not least, Thomas Woods, what's top of mind for you? We're offering circuit textures for self-managed installations. This seems to be the thing that I'm, but I'm a harping that it's something I'm harping on a lot of lately. I think it's a high, I think it also informs the sizing for GitLab, dedicated instances, and we've gotten so.com and I'm a centric and are thinking at least this harms the definition of done until a varied that I'm seeing this is a potentially large blind spot. And so it's top of mind and it keeps coming up. So that's why. Yeah, I didn't understand exactly what this meant. The thermoreference architectures until I looked it up, but we're the, what we tell customers to allocate, based on the size of their installs, what what CPU and storage and memory and more, that they need and adding more requirements on them, makes it they have to allocate more. And then to plan for that when they do upgrades, like as an example, we're adding a new feature that requires additional storage. This significantly more storage than what we recommended today for example, that's not just thing of just saying it, customers need to plan for those upgrades as an example. So yeah, it's really good to bring that to me. Often the almost like 99% of the time features we add don't have those kind of requirements, but that 1% of the time it could be really impactful if we don't plan for it properly. So last time I've been here, the thanks to Thomson Thill for the insight on the monthly sec performance indicator reviews. I reviewed it earlier today, since we didn't in a sync review, yay for a sync, and fewer meetings. Any big takeaways that either of you noticed, or I'm sure Jay and Umber and Nate, you haven't looked at this for even though it doesn't even existed perhaps, but any big takeaways? Not from my perspective, no, a lot of us, we're starting to incorporate and those weekly updates anyway, particularly the error about our updates. I'd love to automate some of the things that we put into the stock unit, like the scene to send a lot of issues and things, Alper had a good AI integration that I jokingly suggested they could write to automate most of us. Yeah, Thomas, anything from here? More of a surprise than a big takeaway than that in 15, 10. Normally, it's like when we look at MRS that emerged and it given milestone, it goes maintenance around 50%, then we're gonna be around around 30% on features and then it's gonna be hovering between 10 and 20% on bugs. What was interesting in 15, 10 is that we had a high number of maintenance simmers and featured delivery MRS went below bugs, and that's the first time I've ever seen that happen. And so it was just, it was a surprise to me when I noticed that earlier today. And honestly, I think it was a one off. I think it was due because of realignment and team's trying to bring onboard new team members into their work. And so that led to more maintenance tasks being assigned to anything else, but it's something that I'm curious about when I dig it up at work. I'll come grab the screenshot of the graph and I'll put it in here in just a moment. When did I notice by the ways? I knew we were working hard in thread insights to retire the error budget exception, so that we don't need any more because we're inside error budgets and it looks like we're closing it on that, that's great. I knew that was happening soon. I knew that was in progress, I didn't know as soon as it is, so that's great. Other things in there too, that stuff kind of, I don't know, J, or Emma or Nate, if you've got chances of looking there like any questions you have about it or any interesting things that you noted as perhaps you've been skimming or we've been talking about it and you hadn't seen this before. Now at the moment, we would like to take just a little more time to skim. Yeah, I was seeking that, but also I think what Phil said it looks like a lot of us could be automated. The details can be automated. The human insight, not. It's in the human insight, it's the most valuable part. The data, when the data looks different than people expect, it gives them an opportunity to say, why is that? And to carry a sped. It might be a good thing, it might be an ad thing, it might be neither, but that's where, that's where the review of these things come in, I think. So, since it's also, we're not talking about error but it's anymore, or FCLs in a weekly meeting. Right, that meeting's been canceled, TA, another recurring meeting canceled. So, we do want to keep an eye on those things. So doing this monthly async actually is a good thing to do. Rather than weekly discussing it across all of the teams.",
  "you you be also We're going to get a third of the meeting if we don't. We'll go all the way. Okay. Sounds good. Do it another 60 seconds. Okay. Olivier's got some comments in here, but it's going to feel kind of so, oh, okay. Got a third. Great. Nice. I was just UNI reading each other. Olivier's comments said that's not a good meeting. Thank you. So it's the secret data science staff meeting for April 12th. We were just deciding on where if we should have a meeting through a sink we said if we have three we'll do it. So all a sink. Glad to be so early on. Yeah. So news and events. I've got the item there. So my draft Q2 occurs. The link is here. If you want to review. One of the most, please don't add objectives or results under these. That talking to me first. I just asked me to add all of your own that you want. But I ended up with a few more than I was expecting in Q1. And I'm not sure in our new Ocare feature, which one does delete or remove actually delete something or just unlink it from mine. So I think I accidentally deleted somebody else's in Q1. So just add your own as appropriate and let me know if you think it should some or in part roll up under mine. The some of them are about product delivery items, which are not a book. But so I don't want to talk about those, but you know some of the themes. Have a talk about those privately, but not on the live stream. So some of the themes are career growth team members, including the neuro diversity training. It's the only key result I have under that. It's kind of a lame objective with one key results. Maybe we have some other things underneath there. And also Q2 application health. Just some similar trends and some new trends like my continued migration of pajamas components for better usability. The view three upgrade, E3 upgrade and then some things are a different identify. And start resolving a number of cross functional challenges and operational excellence. We've got to turn into. But. And also burning down the usability benchmarking benchmark insights. There was also another one. And we'll see here for some reason. Readily. Yeah, it's under it's under the product ones, it's not about feature delivery. Reviewed improved documentation of securing governs. Doing a pass through the documentation for securing govern the product documentation and improving it to help it drive devs. So this is just some of the ones out there. Any. Without talking publicly here in this in this stream about the product specific delivery ones, which are confidential. Anything any feedback? Any ideas on these? The operational excellence care that you talked about, which I just kind of found right now. Was it under application health? So you can do. The cross functional challenges and operational excellence. And we talking about being more efficient or responding to unplanned work. Do you have any additional ideas on we were going with this one? I think it's a teach team. What is it? What are the team? The quad for each team? So you know, development. You set and UX think that is like one might be. Feel the one you and I talked about earlier on the. Thread insights. When can other teams contribute to code maintain by thread insights. And what does that mean when they do? Like what are the responsibilities when they do? I think that's a great example of one of maybe we refinish the work on that on changing or. Procedures on that. I haven't read the MR that you sent me a link to just yet. Of course, we just discussed it. Ten minutes ago, but you know, I think it's things along those lines. Perhaps that's in the right. I think universe and things. Great. Got it. Thank you. I think my general feedback on these OKRs and by the way, I appreciate you getting them out early because I think that was. Um, it's always hard to plan, you know, midquarter or whatever, but I feel like sometimes they lack content. And so maybe an example like you just shared would be really helpful in the description. Maybe not like a, hey, this one's for antivies, but just like a just an example. Just the kind of get people going their interaction. Great feedback. Sometimes we have examples. Sometimes we don't do it. Sometimes that little picture. I'm not too concerned about this, but sometimes if you provide an example, it sets too much. People think with that mindset and they may not think of the bigger mindset of other ideas. They may have to, but I agree. Some of these are so big. At least one example helps. I think the benefits of having at least one example is better or not. I didn't think that that was a good example till till Phil just asked the question and then I thought, oh, so then we just discussed 20 minutes ago. That might be in that area, but yeah, really good feedback. Sure. Um, in big rocks and how to issues, Thomas is not here, but Olivier is an as a comment. Leave a you mind verbalizing commases comment and then you're response. Sure. It says give me a sec to look the right doc. So I'm chirping out from another call or here is so yes, to us is mentioning that we have codified language around what is an alpha or beta feature and was become to reliability. And to my asking is that impacts our thinking on when we announce releases of new software. And did that's I mean, that's pretty. On top of my mind, currently with a primary facing the release and roll out of the license scanner, production readiness figure apparently is required for a general availability feature. I think that's a bit overwhelming. I think I mean, there is some judgment to use, but whether or not to go that process because quite a few. I started that one for the license scanner and there's a lot of information to provide. I think it's makes sense when you're spinning up a new in for a new service, whatever that is very impactful to the overall performance of the good lab instance. Definitely not for just a regular new feature in the real smallest at at at same, but this is not written this way in the doc. So that's interesting and the I don't know how I mean I haven't heard about that being shared somewhere. So I don't know what the adoption of that general documentation, but that's definitely something to be considered by the development group to say. I hadn't seen that production readiness addition there, but I think we need to look at and see when that was added and get some more context. Because I agree with you, Olivia, this this shouldn't apply to every feature that we deploy. Yeah, and I just pointed to a slack thread that was shared. It's an engineering FYI channel. But I think we're working to clarify the difference between. Alpha Bay to experiment little close beta. There's all these terms. I know with some of the recent work in the new field. We're using some of the experimental more heavily. They'll protect ourselves and also reduce the amount of documentation necessary. Let's top a mind for everyone. I think it's a nice open question to ask. I always learned something when I asked this. For me, the AI integration work in group, which is across the company. Large portion of the company, which I'm helping I'm co facilitating. AI code suggestions open beta, which is Sam Mon's team is very diligently working on. I certainly related a bit separately from the integration work. We're making progress on Q10 okay ours. I was behind on mine. A little more caught up now, but I'm still behind on mine and you know the creating and iterating on Q21s. Olivia, how about you? Top priorities continues to be a bit of scans. This is a playing through the company goal. Look, ours and the big analysis that we are previously. So this is very important work. There are a lot of work complex project, but very exciting one. It's involving many timers. So that's a lot of coordination and it's also have some overlap with a group. So collaboration, cross group, which is interesting to. Bystand scanner, I still try to roll that out. Just to about from a customer call about a call with that distribution team to figure out how we can roll this out. By default for a self managed customer without blowing up their disk size. That's a very interesting topic too. And then the OQRC isn't like you finishing Q1s and looking at Q2s. That's the season 4 QRs. We're a well as Allen's. On the call, Allen's top of mind are role-based scan result policies. UX redesign for scan execution policies and performance improvements. Yeah, for me, it's the long-winded identity verification, which we should be rolling out the second stage, the telephone stage soon. Next week, the B.S. reports dashboard and AI and how it's going to potentially integrate with the diabetes features. And then we're going to talk about that a lot, maybe. Thank you for me right now, and we have some tremendously large projects that we're wrapping up getting those into the production environment. So feedback deprecation has been going on for nearly a year now. I think at the end of the month it'll be a solid year since development started. We've also had some smaller projects that are kind of interwoven into that feature. So that's tremendous. That huge success for the team. And then we're also rolling out the interaction with vulnerabilities when you dismiss them right now. It's just an option. We're going to extend that. So you have more reasons that you've dismissed vulnerability, which is something our customers have asked for a lot. Additionally, we're jumping into roadmap discussions. We have a lot as a new PM on the team. She's jumping right in. It's right at a great moment for everything. New PM. Rob no discussion. So it's like how do we align the teams. How do we get UX engaged to reengaged so that we can kind of really have a built confidence for a six to 12 million plan, which is kind of a rarity right. Like we're normally we're thinking a lot more short term. The miss. So we're setting analysis on what's up with my means we're wrapping up a few of the language conversions to some grip. No jaskan and to Gallaudet be specific. And then in addition to that. We've had a few conversations around the architecture that we'd like to support for sacred detection and future paths. So we're in the process of evaluating a couple of different approaches and in the benchmarking phase of that. That's very, very top of my from me. And then wrap that up 16 oh deprecations are running for them. So making sure we're on track with those and coordinating that appropriately with threat insights and other teams as well. Top of my for me is supporting teams to deliver across governor to use some grace we've got some some big deliverables coming out just making sure that teams aren't locked and helping out where I can. AI. Yeah, that's it's a hot topic at the moment. So looking at how our teams and which teams need to be involved in that. We've got Q2, okay, our planning which which we're in speed through. We're looking at. You what we need to deliver in Q2 and make sure we've got alignment with our counterparts. A little bit of time, speed on say availability. There's a daily stand-up is really started for that. And one of our teams is involved there's a discussion around whether we should have had a future change lock. And sort of non-development related one would be the imaging talent program which is an extension of the internship working court. There are some discussions on the adjustments leading adjustments and Smith on where we're hitting with that and looking forward to being involved. Great. Neil, you mentioned some whole way this last week don't ever response. Do you want to you want to talk to you this? Yeah, sure. So I'll verbalize the it's noticeable that this meeting bounces around. I think that's fine, but it also can create some uncertainty and it might diminish the quality this meeting as well. I don't know what the reasons are we need to discuss that either, but I think keeping this consistent. So, I think it can be an audience here as you're having a consistent time, something we can plan around. If it goes ASNC because it's some can make it, it might actually have a discussion. In my change the dynamics of certain individuals are in this call. The discussion might be different. So, I suggest we keep the schedule consistent. What I'm hoping. extra eye, nice casual, crazy. And like last week we went ASNIC because there wasn't much to discuss, but I will try to move it less often. It's mostly the AI working group that's made me. So more of a question for this group, when wine is busy and wine can't attain this mating at the sheath of time, should we go ice-sync or should we just go to the making? Or should I, or should it be moved to a time I can? Or should it be moved? I think we've seen all three cases sort of over the last month or so. So it would be good to. And I'm finding that you're in the course. I'm finding whatever the group prefers on this. What does everybody think? It depends on the topics. I mean generally you're driving conversation and we have questions for you. So I mean that could be some interesting topic to discuss just together with you. But I think from most of them, I might be wrong, but from most of them, it makes more sense if you're in the meeting. Well, my suggestion is that we don't make last minute changes half an hour before the meeting or an hour before the meeting. If earlier in the week, we identified as a class and we want to move it. Then we've got time to take the discussion. We've got time to contribute a second to turn on what is important and needs to be that we might need to be scheduled for. How does that sound as a first iteration? We don't cancel or reach a schedule with a meeting on the day. That's great consideration. Yeah. Absolutely. I think the item to there is probably a non-public. Okay, and as I get lab but not public public. So let's cover that after we go to a private recording in last week's B. If I wanted to discuss it. Those are the only two that we did from last week that we did a sink on that there were no responses on. Which I missed myself apologies for that. All right, let me stop the public and we'll start a private.",
  "you you going So, celebrations is a nice job Thomas for your discretionary bonus for exhibiting values of collaboration and iteration. When you're worked to help us make sure project link engagement. Based on feedback you see from leadership you iterated with the team to help us get excellent business and excellent business case, which we presented leadership all through. We're working under very tight timelines. And it's almost as not here, but eight times. Camille looks like you've got one as well. Yeah, so Doug also received our discretionary bonus for supporting the route of code suggestions. Beta, I think they works pretty closely with you. And yeah, congrats to Doug. Yes, we did. And definitely well deserved by Doug. So under news and events, please see this recently, Merzim, from Sid clarifying that features are never internal only. This was at Clavray with Sid, Sid wrote it. I just had some type of editing and readability editing and wanted to go the word out. And look at this. It's a good on features are never internal only. Also for me in three B. So from Christopher and staff meeting earlier today, we don't have OKRs right now around the MR rate, but please do keep an eye on it. Looks like there might be some pockets of performance, you know, MRs per team per month challenges. So make sure. We work with the teams on this. It also, you know, might be influenced by new team members who have joined it might be due to, you know, the reshuffling we did re-organization. So, you know, keep keeping eye on this. I have not looked at our teams and where our teams are at. I have no idea. I've not looked recently. I've probably a month or two ago, and I don't remember. And nothing jumped out at me is where we have challenges with this, but please take a look. So, please up the status update the status of your Q1 OKRs, many are way behind or the status is not accurate. They show way behind them really not. Which makes people think they're really way behind. If that's what the status says. So, and apologies for the Wayne spam as I tagged many people in many of them today where I saw I noticed that for Q1 OKRs. So, apologies for that. You're hearing mostly from me and then just a little bit from Camille so far, but glad that you're able to make it today Camille. So, my draft Q2 OKRs are updated and we'll up to Christ first. You know, as appropriate, please review and continue working on your own. I also put a link here to Christ first. So, many of these are not public. So, I'd like to do is do a review of them live. But after we go off the public recording and we'll go on a private inside GitLab recording. So, we'll go through those in detail when we're done with the other topics. Phil, you have a comment. It looks like. Yeah, I think the last one you mentioned not aligning with yours without talking with you first. How would you like us to do that just to say thanks for, for your flag? Yeah, and the contact with a bunch that I didn't care about and a bunch that I didn't. And even if it's important, well, I didn't care about as much. So, don't link yours to mine without just letting me know you'd like to do that unless I've already linked something of yours to mine. Or added something for you a moment. So, just, just, you know, write me in the, you know, the publicans I get lab, I get a lot of data science leaders channels saying, at way, you know, should, should I link this one to this one, this one to mind to this one on yours that'd be great just. Good to do that just just a quick question or if you're pretty sure I wanted there, just add it and then just tag me and let me know either way it works fine ask either ask or in advance if you want to or just let me know you have just so that I, I notice it getting linked either it's fine. On some of them, I think I had like 15 things when I really wanted to track five of those 15 things and they just kind of showed up on my list because people link them in and because that looked, they looked related or were related and And there's just more than what I was looking for for me to track just just because I'm not tracking it doesn't mean you shouldn't. As an example. It, so. I'm going to say, you've got the next item. Yep. Hot off the press as in this was just made public within the past hour and a half. We've got a news back in engineer position open and dynamic analysis. And so this is a, this is now public where go in internal as well as external with the simultaneously. So I wanted to go ahead and share since we added and now we're going to. We're going to work to fill this with as quickly as we could. So here it is. I'm happy that it's here. Great. So what skills are you looking for which group is it? It's dynamic analysis. We are looking for go laying primarily. They will also be working with the, I mean, but this group is as quite poly lot. So I mean, C sharp would be welcome. Ruby on rails would be welcome python would be welcome, but predominantly is going to be expressed through go like. Great. So one of my favorite questions to ask, what's top of mind for everybody. So you want to put your notes in here and then we'll. Robilize as we go. For me, it's a I a I and a I. Uh, my top three. And then also okay ours and I've also, you know, keeping on mind continuous vulnerability scanning and federap. So the big. Uh, product management track things that are important to the company. Uh, A I in terms of, you know, of course working with mon's team very closely where I can help on code suggestions, which are really important. But now and also, uh, cloud, um, hope facilitating with Taylor the AI enablement. Working group. It's all the AI features that we're working on across the company. And also keeping an eye on what meals team is doing in terms of one of those experimental features. So that's it's on my mind. Uh, Neil looks like you've got, uh, you've had been the next one. What's on your eye? Yeah, it's not top of mind. It's way up here in the off screen. But uh, yet AI and it's extending off the experiment we launched last Friday. We have explained this vulnerability. We're iterating on that wherever you're rapidly. That's that's taken a lot of my mental capacity. Additionally, Tiago has been out for I think two weeks and he's out for I think two more weeks. Some in the pick of that, trying to oversee a really large team. So it's a little crazy. It's okay. Bill, you're out there. Uh, just wrapping up Q1, okay, hasn't defining Q2, okay? Is it's more today's job than anything else started. Elevate last week with the manager train, which is, which is interesting. Um, uh, what else is going on? Just looking at what we're going to be delivering in Q2, which is related to, okay? Jay or up next or I'm going to have Jay if you're not, you know, ready to talk. Connection seems to be, can you guys hear me, okay? Yeah. Okay, cool. Um, still on the public broadcast. Uh, some review sense security issues related to a feature that anti abuse zones. Um, It's a very late address and safety. Uh, we're launching identity verification and, yeah. For me, uh, 60 no deprecation efforts are coming to a close. So just coordinating the timelines for all of that stuff in mind. Uh, we're trying to wrap up to send up the versions, scale on no JS. So we're going to close those out and then things that didn't list quite yet, but real time staff standing. We've got a few discussions around that. Um, and then ID integration work is also. I almost. Meal looks like you're next. If you're talking to your amused. Yeah, forgot it. Uh, so yeah, I grew up with this also, uh, thinking about AI. Um, we spent quite a lot of time discussing what could be the growths role in AI. Uh, first company because we don't really fit it naturally because we don't work on features. Uh, so yeah, big thanks for, uh, to the PM's that helped us go for this. And I think we are in a good path. How we can support the efforts. Uh, and yeah, that that's been the mind topic last week. Thank you. And if I were working on some training materials for people who know little or not or nothing about AI. On the people who've learned just enough to get by quickly, which is a large number of people, but to be able to do some AI experimental features based on third party services. So that's something I was just in a discussion with Juliana and others yesterday and how can we get that training. Stuff together to point people in the right direction because you're not alone. Your team is not alone at that. Many, many teams are in that same boat. Feel. Just happy on to what Camille shared. We've been thinking a lot about AI and with regards to Q2 okay, our planning. And as Camille noted, like, we don't naturally have fit into that feature ownership area where we can just integrate AI, but are trying to think of our contribution of two lenses is one, when we get to that point when can we add AI to what we own. And then, too, is like, how can we bring awareness and raise like in the adoption of the AI features that come that we take to market through things like acquisition loops making it very easy to find them or surface them in the early product experience. And so, just to discover moments and things like that stuff that's maybe a little more naturally in our real house, but can aid in the adoption of the and hopefully. Drive revenue for the business through the specter. Yes, I'm next. So we have a lot of sources of priorities. We've got the yearly's we've got cross-functionals we've got OK ours we've got long-term road maps strategy sessions and just trying to reconcile. How each group in the stage oriented self for prioritization decisions like how does it decide what it's staffing and what's most important. How does it know where it can draw lines and where those and where those autonomy and decisions happen to be and and discerning also. What events that can happen that can change prioritization alignment for each group because we've got a lot of moving parts right here and it's. At the risk of business speak, this rather dynamic. That's a moment. Indeed, I think it's an understatement. Cool. So I'm going to turn off the YouTube live feed and then we'll talk more details about OK ours. So give me just a second. And this is public inside get lab not public to the public so feel free to stick around.",
  "have yes yes yes and a I've already started. I need a high fill. Everyone. I am. So to get started here, welcome Alex and them back to the Engineering Director shadow program that you did in the past. And you're doing it again. Any interesting learnings or observations from this week. So far. Well, probably it's very interesting to see how the company is being adopted to the ML development, not only from the technical part, where usually we work with more and with the AIC team, but also from the management side. Yeah, it looks interesting and really, probably helps us better helps us to understand. I mean, I see clearly right now that the way how we need to work from the documentation. So probably does the main part. So for me, the main, maybe, our scam of this week is that kind of path between management and the technical development, the kind of how to explain better the machine learning results that we obtain every week and how to present them better to the management. Next, let's enter. Nate looks like you got the first thing under new hires and the investors. Yeah, so Hattish from the compliance group had their first during a Vizory, could live in a Vizory last week, which was a great achievement. So congrats to Hattish. And Emma, you've got me? Yeah, just a few more to pull out in the section, Brian Williams, second year, Eulerie, the second year in James, is for sure, second round, everyone. Thanks, Emma. And we got a celebration as well, Nate. Looks like. Yeah, just something I wanted to call out was whose effort has been added to the Rails technical interviews. And this is a great achievement, because I know we're light on the interviewers and the APAC regions. So it'll be great. So what's top of mind for everyone? One of my favorite questions to ask. So what's top of mind for me is driving code suggestions usage, which is up significantly today. We're not going to have to actual numbers, no live broadcast. That's public, but great stuff there. But in make sure the system can handle a load. We had two incidents today as the load went up significantly. The system went down significantly. But Alexander is actually on that team. And Alexander was engaged on those as we're many others. And got a result, which is good. And whilst preparing for being out next week, yay. I was just starting to type in there. So many of you will have seen the quarterly results. I am A from earlier in the week. And there were some slides and recordings and an AMA doc where I said the E group and various others presented. Big thing that's come out of that is there's a change in the way we're working. There's a sense of urgency. We've got competing with GitHub and AI. It's become the big thing. And we're all learning related to what Wayne and Alexander have been saying we're all learning about machine learning and what AI is and how we develop differently. But it's got me thinking about how we manage or how we lead teams differently in the different approaches that might be needed there. So I don't have any answers yet. But it seems we're sinking a little bit more. There's definitely a lot more urgency. So I'm trying to think through how that changes how our teams operate on a day-to-day basis. I think I'm next. Matureing AI features. You know, we got through that initial push. We've got some more ideas. There's a company organizational shift to focus on beta features, less experiments. So Matureing those getting those really permanently fulfilling, I guess. We have a new one which is pretty cool to resolve a vulnerability. It's a work on progress. We're trying to gather thoughts with that user workflow. Looks like, but essentially it will offer a create MR button. So cool. Now I've been understanding the vulnerability. AI has spent some information including a code suggestion. Can I apply that as a patch, step off an MR, and continue that on? You know, the goal is to connect our development efficiencies. That's a big goal of AI is how can we, you know, improve develop a process, work with the SDLC. So yeah, we're trying to figure out what that looks like. Additionally, we hosted two AMAs, slash fireside chats this week. Mondays was a little bit smaller group because I was a pack after you've brought us a person on, but today's we had over 50 people and attendance tons of questions, great conversation. You know, we filled that 30 minutes up. Just fine. I linked to the doc so you can all see that. And I think you would have recorded somewhere and an or those go. I'm a, you are up. Yeah, that's exciting stuff. Sorry, I was just copying something over. Top of mind for me is we're working on starting to expand advance vulnerability tracking for SAS and secret detection. We've talked about this a little bit in the past. Right now we're more focused on identifying some quick wins that we can use for improvements as well as defining what the long-term path looks like. So that's top of mind. In addition to that supporting team members that are working on high priority initiatives outside of the group. So one of the things mentioned previously was AI just working with one of the team members to make sure they have everything that's needed in order to support that request. One thing that I will link down below. One of our team members, D-Rege, will be hosting a talk titled Get Now from in secure everything in which you'll talk about some of the security issues that he's come across working on the front end. How did the band against them and proactive measures others could take? To assist with protecting our platform. So that talks coming up late tonight or I guess early tomorrow depending on where you're at within the next one for us. Definitely want to check out. Thanks, Emma. I think I'm next. So top of mind for me is the software supply chain security working group and the build provenance which we have a working with NPM build at the moment and just how that feeds into the source of standard and then the adherence report which the compliance group is currently building and all of the sort of works to give it to create that. So yeah, top one for me around planning and building that. And also I think someone to my there around supporting some of our engineers working on other initiatives that I am such like that. All right, thank you. Next two things, customer work flows and how they flow through each of the stages that we have and how those represent both opportunities as well as constraints, particularly within sec since we're organized by topic rather than workflow or work streams. So any type of customer facing workflow touches both stages and it will and it will flow through a whole bunch of different groups. And so those are those represent opportunities in that there's different things that each of these stages support as well as they also provide constraints and being able to recognize where those are is strikes me as important, how important not exactly sure yet but I'm wrestling with it. And also related and importance, just since I've got dynamic analysis as well, processes of workflows within that group, we've we're recognizing overhead and trying to see if a pivot and how we work might smooth out the delivery processes that we have particularly given that it's a much smaller group than it has been in the past. Thanks Thomas. So I moved a couple items up from read only to the not read only section. So it's about there's some already some async discussion there which is great and I think maybe just important and verbal as in general. Yeah the engagement survey, if you haven't seen that in Slack or in your email or the details that there as well. Well, they's a really useful and the more teams and people you work with the more useful and interesting that the feedback is it's really something that we can look to address any feedback. So please do encourage your teams to complete this before the seventh of June. And then as mentioned before the judges will be a talk on the secure everything I'm getting out from and Neil, you had a comment about this. Yeah the pleasure of working with Raj, a couple years I guess I'm trying to remember. Couldn't keep them away from security fixes. they was always working on they is a trailblazer in terms of our that process that I think some of the presentations about a lot of overhead, a lot of things you need to do extra MRs, lots of waiting. But additionally for those I didn't know we've had past I don't think we did one last year in the last 12 months but we had the security awards program so we've had the quarterly and annual results and I looked off to the handbook page and you can see their rajas right at the top like two x the second place for contributions. So yeah they knows what you're talking about. Yeah. They do have one topic but I think it's not a public one so we'll cover that after we're done with all the others. I just have one thanks in gratitude and I was thanks Camille and Phil for keeping an eye on the code suggestions in product announcement feature flag. The MR got delayed a bit that the feature flag turns on the features but that was very much appreciated. I came in this morning go, hey it's on somebody turned it on while I was asleep that's awesome. So appreciate it.",
  "Yeah, I complain I have really wavy and hair and then my wife reminds me of all our family management friends who are less here than I do at the same age and don't complain about that. Okay, meetings, no streaming live on YouTube and I'm talking about my lack of haircuts. It's a secret data science meeting of June 7, 2023 and Thomas, you have the first item. And before I get there, I will say the advantage of my personal hair style is that I can have no bad hairdays and so I'll want to smile but moving on. Something that we've talked about before, something that has become official because that MR is now merged in the official get-laborally state is changing. There's no longer the 22nd as of 166 and so more information is available at the other under that link. I'm sure that this will cause a little bit of chaos and our planning cycles in the coming releases but change, come with. So, hearing nothing else I also see, I've got the next one. So moving on for those of us that work and go version 1910 dropped, we typically have a habit of pending to minor versions when we're using this so it's just going to basically be a rebuild. There's a bunch of security fixes that are available as a part of this so be thinking in terms of compliance and everything's only lines of federal happens so forth. So anyway, if you're working and go, this is encouragement to kick off a new pipeline and a new release on the new version and built on the new release of GoLank itself. Cool. My favorite subject, next is what's top of mind for everyone? For me it's AI and I didn't say AI three times and things are still analyzing in all our plans and execution it says AI and I know I am way behind on updating the okay areas based on the changed plans and I need to update the okay areas, at least the ones that I own or we own, but it's there. They're lagging or our actual plans are and I feel bad that it's second month of the quarter and I haven't done it but I've been slamming those things but nobody's complaining but I still need to. Could you, could you have an example of what do you, what do you like? What's changing? What should we be like? I think we said, you know, X number of experimental features in Y time and we're not we we we're more focused on that and I could work on specific features in not a large number of them. So that's like I need to update that one in particular. That's the one that in particular, I'm thinking about just you're not, I didn't scare everybody like a bunch of things you're going to change so thanks Phil. It's that one in particular I need to update and I also haven't reviewed like any of the others. I think I got to sign some things that I haven't looked at yet or I barely looked at that I need to. Okay. Thomas, how much have you? All right. I will I will link and talk at the same time. The iterative versus incremental development practices and there is a difference between the two and wondering if we're beginning to be guilty of swapping out the eye and credit from iteration to incremental. And so with us that's coming to mind because we're increasingly hearing stories of we've got when we swarm on particular areas of the code base that we've got people tripping over each other and to be wondering if that's a sign of more of an incremental approach rather than an iterative approach. I think there's a book about that adding X amount of developers late stage and our project doesn't complete the task in the earlier. Top of mind for me is a bar request which we currently have going on. I'll be limited with my details here but abuse maintenance which we have. And dogs, so GTV is looking good this week. Any new product proposal about rate limiting and rate limit exemptions? Who? Hey. Yeah. Sorry. And top of mind there for me is just the engineering changes as well recently and excuse me, the roadmap impact. So just trying to work through what that means for compliance and I don't have a short term borrow going on as well. I'm just working through all that at the moment. So that's top of mind for me. And also that the courtly earnings was very interesting. Indeed. Yeah, I'm not privy to what those are going to be of course beforehand. I'm not. Thankfully, I'm not privy to such things. I have no idea that you know, I was I was definitely refreshing my browser to see when they'd be released and how the market would would react. So but you know, I try to not look things on a daily no more monthly no quarterly basis, but it's also hard not to at least look at it in detail quarterly. Some of our teams have been working on some projects that have been going on for a long time. Jay's team has won, which is which is sort of being rolled out and managed right now. Our gross team has another I won't go into it to meet in details around that. But that's work that goes back a year and a half now, which is being rolled out this week in next week. So we're watching that. We're we're looking at last minute changes and responding to feedback. Cool. I sorry, I've been scrolling. I think I'm next. All a voice talking about AI. I think what's also type of mine is we're having two new back and into yours. Doing the team formally, 16 to but we've started the coordination. So I'm aligning on boarding buddies. I'm going to have two front end engineers kind of more project focused. So they can get going on some tasks and then back in engineers. Those are going to be coming from Tiago's team, but those will be a great resource for back and type questions to little big great hands. Cool. So I had a couple of things just looking at my to do list lower priority to do and reading myself, but this is interesting. The OS top 10 from large language models project is that their OS is open source and they're really good at open collaboration with anybody interested. I've done some stuff with OS with the OS people volunteering to work on OS things. This was pretty kind of topical in need as an OS top 10 from large language models. Not sure how much you can say there as it's it's it's it's it's it's a there but like specific recommendations are hard. So if I had time I would put a little time into it. You know, I'd go into the GitHub project and put some comments in and make some recommendations, but I don't have the time. But at least now, but maybe I will in the future and Neil, you had a thought on this. Yeah, so I think Phil has been doing awesome sharing resources. They brought this to my attention a couple of weeks. I raised to my team. We have been getting ready for beta. We have a security performance to ability evaluations specific to security this bit really well. I linked off to a thread. We'll start that conversation. A lot of interesting thoughts. What's really new about this this list is when we think about that OS code. Um, vulnerabilities are all you've seen is they're very specific to exploits things like that. Where these are more some of these are behavioral. It's like user training like expected users to do it this way or not this way. It's not like a code thing. It's more of a human thing that we need to be aware of. So yeah, very interesting topic. I was very excited a couple of weeks ago to start a brown bag. I don't know where the time went. And now I'm going to be here pretty soon. But I think that'd be really neat. Schedule a brown bag and by anyone who wants to join. We've got to just go through this list and share stories. The examples things like that is a lot of great thoughts. I'm sure that might be a good way to kick it off and expose this to everybody. I still something I can schedule by all means. I'm just not sure if I can run it. Why do you think someone from vulnerability raceage would be good to involve in there? Yeah, no, just nobody volunteer. It's definitely a volunteer kind of thing. They're really, they're also they're down to three people from four as one team members on paternity leave starting two days ago, to neat. So he's going to be out for a couple of months. And the team is actually three of the four people on the team actually volunteered for a lot of the AI work. Not specific to security, but more. Turns out they had some of the skills around various ways to do ID integration for jet brains and for NeoVim and Sublime and EMAX. And they didn't for example, proof of concept of IDE integration for AI code suggestions using something called language server protocol, LSP. There's a you write it in LSP once and then multiple things can use it to massively over simplify and say it incorrectly. But we're actually using that architecture from the vulnerability research team in a lot of the IDE, so just kind of neat. So they've been doing research. More than vulnerability research, more as of late than now getting back to the vulnerability side. And they weren't interested in this, but it's good point to. I can go by the means go ahead and get something settled for next week. Hey, I guess it's a heads up. Yeah, not a request. No, no, I think it'll be a more or less agenda less, it'll just be like we're going to review this. We're going to go through these and talk about what's stopping mine 30 minutes. And if there's more conversation, we can do more of these or we can break it up. And that's a good start. Good start. So on D, you probably we've probably all seen the the t-shirt, probably now also meme of, you know, be careful or I will replace you with a very small shell script. You know, you're wet lettering on a black t-shirt. Reminds me of this is I'm thinking about trying this private GPT thing where you basically, it's an open source project. You run a private GPT on your own computer, train no more you give it. And I don't know if I train on all my emails, all my slack messages, all my get lab issues and MRs I've worked on and Google Docs can it replace me? Like if I get the time to do this, which I probably won't, I'm going to train and all this stuff. Again, it's all private. This is in some of the data elsewhere. And then I'm going to say, I don't know, it makes like J said X what would Wayne say? Like I will take a slack message from J, I'm making a banana and said like I wonder what if if it's going to figure out what I would say. And you may actually get a response that I've copied and pasted out of this thing. I mean, it's it's not very good. It's very slow. Like it takes 45 seconds on a normal computer to do one response. And it takes hours and hours and hours to train. But we'll see. Or perhaps you all will assume that I have already had been replaced when you get a future message. We'll see. I've not loaded this yet. I'm going to think about it though. I guess I'm done. All right, we're uh, we're a couple read-only items and let's anybody want to read them. I think we're done.",
  "There's a need to know the couple of seconds. Okay. So it's the secret data science staff meeting for June 14th, 2023 or 15th, where Can you see the Clouds I'm getting. Welcome to the source content. Let me remind you to start by sharing some听 links on content about the cloud. oh, Where are we going to go to number number 138疫 crack, and such amount of attracting. Well we're going to collect net estimates earlier in the documentary for I mean, so I'm pretty much glad to, you know, test out the BLA features of the ASS existing and to see what you are actually working on. So it feels good to get inside the top level of what things are going. So in that's my learning so far. Thanks, Enjorn. So it looks like you've got the first item. Yeah, just a celebration. The free user initiative is something that grows in particular has been working on for about the last year and a half. We've been a lot of the changes of requirements, lots of changes and stops to, in terms of rolling it out. Just due to the work that's been rolling out this week. And that's been rolling out this week. And that's been growing from the team. There are some team members who aren't in growth teams anymore who worked on that. I believe even J and you're in your former growth team probably started working on this year and we've been working on that before coming into your business. So I'm massive team effort. And well done to everyone. Congrats to the team. This has been a long effort to get there with all the different nuances and many, many, many, many different iterations on the plan, not the code, necessarily, but the plan on as we got feedback from users and iterate on the business requirements is those changed, et cetera. So it's congrats. So this is live now. Is that right? Yeah, it's been and crimitially rolled out. And I think they started it like 100 users. They started putting them in read only and they flowed it down to five users. So it's the five years of luck is now in. Got it. And has that scaled existing? These aren't just users going forward. They've actually like a retroactively done it. There are still some notifications to be sent out to some existing groups. There is a little bit of ongoing work there on how to get that many emails sent out and a short space of time. So the team is still looking at optimizing for that. But certainly for new groups that's in place now. Well, groups created after a certain date. It's not just new groups. There has been multiple notifications going back from months. Living users know that this is coming and leading those groups created after a certain date of groups that have been around for a bit longer. Is still ongoing. You wanted to jump back and Jay, we can get you an issue. I'm very happy you're on that right now. So thank you very much for the offer, but going to politely decline. That's what I was thinking. Good news and events. We move code suggestions to use a Google model versus our own for the forget labs own projects today. So please do encourage your teams to try it out and provide feedback. There's an issue on how to use it and we're to provide feedback there. How much have you got? Yeah, I shamelessly copy this from the development staff agenda doc. But mid your check in reminder that as launch, there's a slack announcement and book page. Just tend to be team member led. It runs through the end of July and the follow one to that. Like an optional output of this is individual gross plans. However, if people want to participate in 360 reviews and individual gross plan is required. So there's the there's the carrot for IGPs. If folks need or want one. Thanks. I wasn't at the staff meeting which was earlier this morning. My time and I just had a couple of questions that you might be able to answer. So you're saying that 360s are still optional. And they're often okay. Yeah, do we have any any stay in that as leaders can we can we mandate this for a certain team. So if we can get useful. Or is it often at the individual level? I don't think that question was asked. But I assume it's often at individual level on way not on if you have a different understanding. I'm certainly sounds like it. If you have to create an IGP first. Yeah, that's the same. I was hoping that it would be up down to another and up to. I like 360s. I think we get valuable feedback out. Anyway, I'll follow up as Julia. My favorite question. What's top of mind for everyone and Alan put that in a sync. I'll read Alan's. Alan's top of mind items are midyear check-ins, which Thomas just mentioned. Promotion docs getting together for teams in Poland. That's neat. And also demo environment automation. Thomas looks like you've got next. Most Jay is going to chuck in front of me and as is on as an armor. Yeah, sure. I'll steal. Maybe I might all steal after that. And a quarter is coming up soon. You're kidding. Really? Am I wrong? Am I ahead by a month? I can't possibly be right. We're ahead. We're halfway through the quarter. Yeah. I said really like, oh my gosh, this quarter is gone by fast. We're halfway through. Time flies fast. Good middle middle of the quarter. So you've been warned. Let's see. So okay, ours, making sure those are on track. And my team should be resolving a bar request soon. So pretty happy to get back to roadmap work. Yeah, that's our map. Into the. Yeah, I've been involved with a customer escalation recently. That's been very top of mind. A major check-ins like Thomas mentioned that kicked out yesterday. We're also tying in some career conversations into that. So been heavily involved with that. And then also on the static analysis front vulnerability tracking has been a big focus for our team. And one that I didn't finish adding is on the secret detection front where discussing bringing the secret revocation service into the product from the scare. Excuse me, the security automation team. So that's been a discussion that we've been having. And pushing forward. Cool. For me, I hit my priorities lately or top of my AI related things in terms of the world. The Google change working with Mons and infrastructure and others on that. Promotion process planning and pre-work. I also hit inbox zero today, both in email and Slack. For the first time in a while. And that's a good feeling. Yeah, I'm jinxing myself by saying it. But because, you know, once you hit zero to the last for long, but it's nice to be actually get there. Feel. Just one of the things for where kind of is elevates, which all managers will go through. And one of the cohorts, I think we're on cohorts. There was a virtual concert group and now we're on cohort one. Other managers will get to go through that over the next six to 12 months. That's quite interesting at the moment. Looking at OKRs, making some changes mid quarter to some of our OKRs to reflect changing requirements. And just within supporting the teams on major deliverables. Cool. A quick question on elevated. If you might know, are there multiple cohorts at me at the same time? Or is it okay? I think this is, this is, there is. What's the right word? There are multiple groups in different times zones doing the doing elevate right now. And they'll be starting another round. I'm not sure when. I can find out for you if you're interested. We don't identify that. Like in the next month, I think it starts roughly. Yeah, wasn't sure if there were just staggering for once or if there were like multiple classes going on at the same time is decided to do your city. Sure, there are multiple. There are three streams that you can choose and you choose it based on time zone. They recommend that you stay in the same. Take the same class each time so that you're with the same group. Excellent. Cool. Thank you. So we're out of agenda. It's good discussion as always. On shaman, do you have any questions for Jay or Thomas or Umber or Phil or I based on what we discussed? Any questions or observations? I mean, I was able to understand a few other things to be ready on this. But I mean, I do have a question. I don't know who might be able to may know answering this. I see a lot of many things in terms of like, I see a lot of feature requests which are, you know, being directed towards you guys and then you would have to go to the document team and ask them how to build them. So I mean, how do you say that, you know, we are going to build this feature and there's not feature because you will always tell these what I'm going to answer. I want to answer. Wayne, you might be the answer of this one given. And I apologize. I started multitasking. Can can you repeat? No, I'm just curious. I mean, not the prioritization thing, but, you know, what features do you want to be building and all those things? How do we choose what features to build specifically in AI? Yeah. Yeah. Thanks, sir. I couldn't make it today. You know, all means are optional. Get lab. She'd probably have an opinion about that too. Although Phil probably does as well as some of their teams are working on AI features. And we look at where AI can be motion to act for our customers, which is hard to figure out with confidence, where it's most useful and then work in those areas. And we've done a number of experiments. Sometimes they're really, really successful and people really like them and sometimes not so much. And that's okay because we're doing, you know, minimal viable change experiments on them, so we can get user feedback. Like the code suggestions features, gotten a lot of great feedback and a lot of usage. One that one of Phil's teams specifically, Neil's team has been working on is the explain the vulnerability feature, which also is getting a lot of good feedback from the users. So that's a, it's hidden miss, but that's why we're doing minimal, we're doing experiments to cool what fail fast. If a feature does not end up being useful that we predict might be, we, we take a step back and then, remove it or at least don't move it forward. Phil, is that, is that kind of how it's working from your perspective as well or maybe you have a different perspective? Yeah, we brainstormed. And actually we asked all of our team members for ideas and then we did what we do across the project and development. We sent them up to our PM and they prioritized, they looked at, and some cases what aligns with their current roadmap. And other cases they're looking at competitors and other cases they're looking at. How easy it is to get an experimental feature deployed, but the prioritization is done at the product level like just like any other feature. So I mean, I just had one, if you don't mind, I guess what is too, because he's, you know, looking over with the static analysis thing. We actually had a meeting with finish earlier this week and so I got to know about that. Simgrip is like it's producing a lot more force positive and positive in positive. So I mean, how do you ending that like are you still transitioning with care or like like what's up? Yeah, just so I understand specifically what you're asking, you're asking about we, you've noticed that we've seen a trend in higher false positives and false negatives. Yeah, so what I mean, how is the transition going for the good level analysis and specifically in the semigrap rules that vulnerability research has been working on. Yeah, so there's a few different things we're doing right now. One is we're trying to introduce some sort of benchmarking to help with rural efficacy. That's going to talk about through a few different initiatives that we have ongoing. One specific area we're using is a tool that we're looking to build will help run like the rules that we have within static analysis or within our semigrap based analyzer against multiple projects. And then from there we'll get out put it whether what the true positive positive rates went to be so that's one initiative. Another way that we're looking to tackle this is finding more ways to get feedback from our customers on the rules that are being generated or being used. So in sense, it's a customer detects a false positive right now there's really no easy mechanism for somebody to report on that false positive. So we've talked about different ways that we can introduce that within the UI. And then also partnering with VR. Our vulnerability research team in order to address some of that feedback and also improve rural quality. So just a few ways at the moment that we're looking to tackle the false positive. Let me add on to that if you'll let me. Okay. Let me add on to that. Yeah, let me add on that a little bit. So for some graph rules their intention is to replace other open source analyzers that we already have in place and the when the when those when the rule transitions are being done. The effort is not on making the rules the best they can. The effort is to make the rules match the eggs the rules that we were replacing as completely as possible. The reason for that is that the transition path is that we'll have the new semegrip rule pack running with the other analyzer side by side. And as long as they find the same things, they show up as one vulnerability rather than two. They're being dual reported. And so when we do the transition, it's about completeness of the rules being ported. And then once we turn off the original analyzer and some greptakes over that allows for tuning for efficacy. So there's a two step process that has to happen. I mean, it's not even but as you was saying for the base analyzers. I mean, do you have proposals for all of them? I'm like, I'm not sure you'll say something for a type script. I wasn't going to make that. For type script, it started with the S lens. So there were originally 16 different SAS analyzers that are being compressed down to ideally into one, two, three or four. So, and we added in recent times, at least introduced any new analyzers outside of like I guess the main goal is. Yeah, as solid shows the main goal is consolidating to our sub-grapes analyzer. What we have, I think we're down to 10 to 12 at the moment. So ultimately the goal would be to get to one single consolidated experience across all the new facts. So. Thank you. Thank you. I'll just keep you as to. Christine does the project. Thank you for the question. Great. Yeah, great question. I'm sure. Great. Thanks everybody. Have a great day and fill. Since we didn't get to finish our previous discussion, where would jump back on that others. Yeah.",
  "I'm going to do it. Hey, Jay, how are you? Hey, Wayne, what's up? I'm doing pretty good. How are you doing? Good. Let's see how many people come today if it makes sense to still the meeting. You get a, looks like you shave and you got a haircut. It's been a while. Yes, too long. I was trying to scaring people with my lack of haircut when I joined Zoom. Let's see here. Yeah, we're forward. I have accepted, but I know we've moved this around a good couple of times. Let's give it another minute to see if we want to go. All right. We got a quorum. We got three. There we go. Hey, I'm here. So it's the sick growth data science stock meeting. Your June 27th. My shadow today may join us. May not. It's pretty late for her. Pa, wash them and the leak. But they joins. We'll let them give a quick introduction. If not, we won't. Overall, I still was item. We've graded a certain certainty. My thing is the right. On their announcement, which I think is not public. But you can see the slack link. That's pretty cool. Anyone want to volunteer to read. It's a verbalized. News and events. Item A. Maybe summarize of it. Summary summary of it. I got to go forward. Am I. Go. Yeah. So from your. We basically are looking to provide customers with a better enterprise level support experience. As a result, in order to do so. We are asking or supporting to engage development sooner when faced with challenging support tickets. Expect that request for help issues. And not contain everything required. So by using this method of including engineers earlier, we're hoping to get to those troubleshooting steps. Fast from the process so that we get these results back to the customer. Really. That kind of aligns with the let's see. I think there's a 16 to support issues that should be easy to resolve. Um, coordination with the spreadsheet with issues assigned to each group. Is that would you agree that falls right in line with the. The announcement from your. I think it's I think it's at related. Improving the sport for customers. Being more proactive than a moving sport. It makes sense. Jay, you have a way to that. Is that word group or. You might have only been tagged on it if. If you needed to be, but yeah, I will. I think that's the right. I think that's right. It's only if you so if you didn't get tagged in it. Draw for hook. At least for now. I will say on one observation our group is that is that we've seen a recent uptick. In questions being asked by a slide. The section request for help project. Um. What a bit more than in recent weeks. So it might be related to this. It might be. This might be one of the factors. Causing that, but I don't think it's the. I'm sorry. Did you say you're getting an uptick in like kind of communication from support asking for. Yeah, from from support and solutions are context both. So like requests issues help reproducing items. So like that. Um, anti abuse works in some popular areas. So there's been no shortage of contact between support and our team. Don't like a lot of interfacing. Uh, I haven't set up a weekly. Reminder or weekly like a discussion with any support team members, but I'm about to do it because. It seems like we're contacting all the time. So. Um. Yeah. Well, anecdotal there. Yeah, we have scheduled as scheduled a support same between. Engineering and support this week to see if we can identify some common trends across the index and then test issues. So we try to get the root of the problem rather than just playing. What we'll also speak. Nice. What's top of mind for everyone for me. It's AI including this merger quest on a documentation change. I've been collaborating on related some code changes on code suggestions and which models we're using. As needed covering for Thomas, well, he's out, which is not much. I've covered from Umer and Olivier and Thomas's other folks, but I do. I think involved one or two small things and also various other things and also. Long time in process blog post about shadow programs, which I think is going to go forward soon. Umer, how about you. Yeah, I'll kind of like I just mentioned the. I think that we've seen in support requests were trying to bring some ways to condition. We resolve your support those. So that's one big thing. Made your checking conversations is another. And then lastly, the death cycle is primarily worked that we're doing on the team. One of which is vulnerability tracking and then the second major item that. We're working through is secret detection, false positive testing. So just keeping tabs on those items. Yeah, AI is definitely creeping up my. My ladder of things and I'm, you know, got at the top of mind. I'll be taking over a. An effort, Sean Carroll is going to be going on vacation for a month. So I'll be stepping into manage the code suggestions testing. We're also doing model testing. I'm sure is you're where Wayne. Um, beyond that, we are closing out a bar request that anti abuse has been involved in for like three weeks. Um, and then returning back to. Businesses usual so kind of getting everybody back aligned with our roadmap and continuing that work. And then we're going to go to the next. Great. I'm going to stop the public recording and then we got one non public thing out. So you can get sick.",
  "you you you you you Okay, thank you all so much for joining us for another CS skills exchange session. I did post the notes document in the chat that we had a few folks join us after that so we post that document again in the chat. It's also part of the meeting invite. One ask that I have before we get into today's topic is that the Q3 session is live. We are looking for a few slots there to still fill. We have some AM and PM sessions. So if you happen to have a session or a topic that you'd like to cover, please take a look at that issue and let me know what date you will be available. And then we'll pass it off to Taylor to cover today's topic. We'll be talking about data sciences and there's some key components around that that Taylor is going to talk us through. So take it away. Awesome, thanks. Hi, everyone. My name is Taylor McCasslin and I'm a principal product manager for our model ops section. So today I want to talk about an intro to data science. So basically what I want to do is first start with a couple of the use cases that data scientists have with GitLab and then talk about how you can use various features of GitLab to accomplish a lot of the use cases for data scientists. So I'm going to start initially with a presentation, just kind of give you a foundation of some of the problems in use cases for data scientists and then I'm going to jump into a demo within a project. The project is something that you can work and play around with. My goal here today really is to give you a taste of how to use GitLab in a very particular way that data scientists work. So let's dive in. First, just a reminder, everything here is for informational purposes. Everything we're going to talk about is subject to change. I'll talk a little bit about some roadmap items as well so that those could shift in timelines. I want to start first by defining some of the components of model ops, the way that we're defining them internally at GitLab. So there's three areas that our model ops section is focused on today. We've got data ops, which is everything related to ELT of data, extracting loading, transforming data. We want to make it really easy for you to connect data sources to GitLab pipelines so that you can do something interesting with it. You'll see why this is important when we get to our demo here at a bit. Then we've got ML ops, which is truly all about productionizing data workloads. Now that you've got data connected to your pipeline, you want to do something interesting with it. You want to run experiments. You want to train a model. You want to test models. You want to deploy those models. All the foundations of building, training and deploying a model. This is a pretty industry standard term. You'll hear model ops and ML ops sort of interchangeably depending on the customer. A lot of it just comes down to data science is building and exploring data sets. Then finally we've got a plight of mail. This is really about taking machine learning and applying it to a production application. For us internally at GitLab, we're now starting to introduce machine learning to get that features to make them smarter or more automated. Our first feature in this area will be suggested reviewers, which we'll talk a little bit about here a bit. This is the foundation of model ops. You'll hear these terms, particularly internally is this is how we're defining our approach to machine learning. A lot of these terms are industry standards. You may hear customers talk about them as well. I want to talk a little bit about some of the common pitfalls when you've got data scientists working within a software development environment. Some of these things will sound very familiar to the early days of DevOps. You've got a lot of teams that have data scientists that kind of live off to the side. They work in silos that have special teams. A lot of times data scientists are not software engineers. They are not DevOps engineers. They're not using tools like GitLab. In many cases, they're not using standard DevOps practices. They're using one off machine learning tools that are still relatively new. If you think about it in the realm of software development, data science is still in its early days. We're still cutting our teeth on the tools, the techniques, the companies, the open source projects within the machine learning space. It's also very early. What this leads to is this hand-off function and finger pointing where there's a lot of uncertainty about how data science works. For one, it's not like a traditional software development lifecycle. It's a lot more iterative. It looks a lot like the actual process. However, it is very experimental and very different to the way that traditional software development works. Very few data science teams think about security, which is a little problematic these days, especially considering how much data we're pushing through models and what we're using models to do. That's some of the common pitfalls. If you have heard our cell strategy with GitLab, a lot of this comes down to this complexity. The current state of machine learning looks very similar to DevOps 10 years ago. Lots of point solutions, lots of individual companies and open source projects that you have to glue together. They all have different data models. They have a lot of complexity with them. There's a lot of lack of transparency between all of these tools, because they don't talk to each other. We're trying to do for machine learning what we've done for the DevOps space is bringing all of these tools together, help glue them together and make it easier to share your data across your software projects and actually do something productive with that data. A common thing that we hear when we're talking with data scientists sounds very similar to those early DevOps problems. It worked on my machine. This is what we see with data scientists, because they're not software engineers, because they're not DevOps engineers. They're downloading whatever open source package and installing whatever Python packages onto their local machines. They're downloading whatever data they can get their hands on. It's very hard to replicate data science at scale, especially when you start introducing more team members. In many cases, companies start with one or two data scientists, where this isn't a huge problem. With the moment that data scientists start producing value, creating models that do interesting things that they want to integrate into their applications, you end up in this problem of DevOps of, well, how do I replicate those results? How do I integrate that into my software development, life cycle? How do I create a repeatable cycle so that my software engineers can repeat what the data science has been able to produce on their machines? So it looks very similar to those early days of DevOps. In fact, that is really all we're trying to do with our model-op stage is bring the foundations and the best practices of DevOps to all of these individual components to really make things reputable, to make them scalable, and to introduce continuous development and integration to data scientists. We want to take data science that right now is off on an island over there. We want to bring those data scientists into GitLab so that when data science is ready to productionize models, they're already source controlled. They're already running in repeatable environments. They're already running in GitLab so that it's easier to integrate into those production applications that are built with GitLab. The way that I think about this today is that model-ops for us is really a land and expand within our existing customers. We want to bring new usage seats online with those data scientists who aren't using GitLab today, but their organizations are. So that's really how we're approaching this. When you think about the way that we're approaching data science, really what we're trying to do is create these very simple hand-offs between these different stages. When you're thinking about data ops, it's really about getting the data, cleaning it, processing it, connecting it to a GitLab pipeline. We want to connect data to code. We've got source code today, CICD, the Arbrettan Butter, things that we've done for a decade now. We want to bring that to data scientists so that they can introduce those concepts to their data science development lifecycle. It's very common to talk to data science teams and they're not even using Git. They're not using any type of CICD. So when we try to talk to them about coming on to GitLab, it's going back to the original here's introducing Git. CICD, GitLab, and getting them on board to understand how to use those technologies. And when you think about handing off models to production, this is when we take data science and we go back to DevOps, where we're introducing those repeatable software builds and ability to deploy to production. Let's take a look at some of the differences between these personas and the way that they work every single day. When you've got data ops folks, let me just build this out. We've got a lot of data engineers, data analysts, generally they'll have data in their name. These may be more similar to software developers. As it takes a lot of code to process data to collect it, to clean it, to do something with it. I've never talked with a company whose data was not messy. It was not all over the place. There's a lot of code that gets written to try to collect and clean up that mess of data. This is where your whole thing is like ELT, which is extract load and transform. There are many platforms like Snowflake, Google BigQuery that do these types of solutions to take data that's all over the place and in many different shapes and forms and standardize it and clean it and make it easy to interact with. For MLops, what you'll generally see is data scientists or machine learning engineers. While they may have the title engineer or software developer in their name, they're not like traditional software developers. They're generally not going to be building production services and solutions. Instead they're going to be very experimental. They know just enough software development skills to be dangerous. They generally try to use the simplest solution to produce value with those machine learning techniques. Then we've got, of course, our classic DevOps software engineers, DevOps engineers. They're really focused on velocity, repeatability, security, those traditional DevOps principles. When we take a look at these users and build out what they're trying to accomplish with the data ops folks, you're really trying to aggregate all of those disasperate data sets. You're trying to clean them and shape them to make them available to the business in a way that's not complex. It doesn't have a lot of cases that you'll have to handle. If you've ever interacted with business data a lot of times you end up with crazy SQL queries that have to take into account that one special case, have to merge lots of tables together. That's really what data ops tries to fix is to make all of that simpler so that it's easy and straightforward to get business answers out of data from companies. For ML ops, it's about starting to explore those data sets to find opportunities to understand business problems that could be solved with machine learning use cases. They're building and training machine learning models to answer some of those business cases and to create value for the organization. Ultimately, data science wants to help produce a value from this data and make it useful to an organization. With DevOps folks, these are the traditional things that we're familiar with already, building, testing code, writing code, repeatable CICD, deploying those things to production, doing that in a really scalable, repeatable method. One of the tools that these folks use for data ops with that ELT platforms, like I've mentioned, BigQuery, Snowflake, Singer, in some cases, Meltono, which is a company that was starting to get lab and was spun out. You've got a lot of data pipelines and data warehouses, lots of data all over the place basically. We're seeing a shift now where organizations are starting to put a lot of their data into the cloud. So tools like Snowflake, Google BigQuery, AWS, a lot of those companies are moving data into the cloud to make it easier to do something like that data. This is a lot of just SQL, honestly. We have actually a data science team here at GitLab and a data team. If you Google Data Team GitLab, you'll find all of this stuff that our own data team does to try to make sense of all of the data that we produce here at GitLab so that we can make business insights into it. We're just now starting to get to where we're applying machine learning to some of that data to really create interesting value from it. For ML ops folks, you're looking at technologies like Python notebooks, which are basically interactive environments that are generally written in Python, where you can explore data in a really fast and iterative way and in a very display focused manner so that you can see the data that you're interacting with with code. We're going to look at a Python notebook here shortly. They're using open source ML frameworks. There are tons of open source technologies that are used by data scientists. I would say most of the data science realm is open source and so there's a lot of OSS community. There's a lot of just downloading things, throwing them together in an environment and try to get them to work. You've now started to see the rise of data science platforms. In many cases, these are companies that are building around open source libraries like ML flow. If you think about, or if you've heard of a company called Databricks, they built an off-low to build a company around it, very similar to the way to get lab has. We're now seeing these data science platforms that are very point solution-based. They do particular aspects of data science really well, but they don't integrate with a lot of tools. You end up having to glue a lot of these pieces together. DevOps folks, IDEs, CICD platforms, source code management platforms. What we want to do is we want to take all of these unique individuals. We want to bring them all together within GitLab so that the handoffs of what they're developing is much more straightforward. We want to collaborate with each other. We want to help them interact with each other's code and repeatable and scalable processes. This kind of leads me now to some of the product features that we're developing. I want to make it really clear that we're still very early in this space. We're just now spinning up our teams around these different product areas. We have introduced a couple of features. Some of which I'm going to demo today, which include GPU support for GitLab Runner, which is a way to do specialized computing with our existing GitLab Runner capabilities. We've introduced better support for Python notebooks, which includes cleaning them up. And allowing them to be run within merger Quest so that you can comment and do standard merger quests with. We're now rendering those more beautifully so that if you've got embedded images and then they all show within GitLab a lot of what we've been focused on as far as what I call just quality of life improvements. These were things that didn't work on GitLab for machine learning use cases that we just had to fix so that they worked to get those data scientists to start using GitLab. So I do want to talk a little bit about what this looks like in practice and then we'll jump over to my demo. So I want to focus particularly on MLOps because this is that sort of joint piece where you take a lot of the data science and you move it into the production workloads. You've seen our infinity loop with all of our different stages. MLOps kind of has its own version of that ML loop which introduces this sort of design phase. When you think about it machine learning is a lot about getting access to data, exploring it, trying different things. You go and sort of an iteration loop just with exploration before you then actually start building and training models. Sometimes those models don't do what you think they should or don't produce any value. So you go back to the drawing board. So there's this heavy design component around machine learning that really is about what data do I have and exploring how you can use that to find value. In the middle you've got the model development piece which is really about data engineering which is what I was talking about where you're exploring that data to find new opportunities in it. You're running various data checks. This is where a lot of Python notebooks come in where you're just kind of exploring what the data looks like and how it works, where you might be able to produce value. And even just what data do I had access to? This is where you start building those models and finding those insights within the data. And then once you've got a model that is producing value, then we're going to hand it over to engineering and help them get it integrated into a software product. That's where you then kind of start all over again. You take the model and you try to reverse it into the software development ecosystem where in many cases Python is going to be the language of choice for machine learning. And so what happens if you've got a Ruby on Rails application? How do you take Python code and put it into Ruby on Rails? That's where the operations piece of data science comes in and that's a very messy process because the software engineers have to replicate what the data science is doing in the language and software stack that's being used for that production application and get it all working again. So that's where we're a P to build the really becomes a problem. And then setting up how that application triggers the model, how it does inference, how it integrates into the development lifecycle. So let's take now this sort of unique in-al-ops development process in a lay it on top of our infinity loop. And so the things you see highlighted today are some of the things that we're going to look at in our my demo project. Basically we're trying to take that experimental cycle and bring it into GitLab in our sort of infinity loop here. One thing you'll notice is that all the features that I have indicated on our graph today span across the entire GitLab lifecycle and software development lifecycle. There's something very unique about model ops for us is that rather than organizing in our traditional sort of stage and groups that are very uniquely focused, model ops is horizontal. We sit across all of GitLab. As we're introducing GitLab to these machine learning features, we're going to change various aspects of the platform across the platform to make it work for these data science use cases. So this is just the beginning. There's lots of other features that we're going to be adding here. But this is what we're going to focus on looking at practically today. And with that I'm going to pivot over to a little demo project. I just want to caveat. I'm not a software developer. So you will see things here that are probably not suitable for production. I just wanted to get something working to give you an illustration of how you can use GitLab features today in a machine learning use case. Hopefully this is big enough for everyone if I need to make it bigger. Just let me know. So I've got a software project here today. This is actually public. You can use this with customers. You can work this. You can play around with it. I want to walk you through just the foundations of some of these pieces. So I actually want to start initially with a Python notebook. So this project is handwritten digit recognition. This is a common sort of hello world for machine learning scientists where we want to take an image of a handwritten digit and we want a machine to know what digit we wrote. This is a data set that is called minced. They have a large data set for a lot of these sort of intro problems to machine learning. I used it because it's very easy to access their data set, which is why I wanted to play around with it. If you Google digit recognition, you'll find many tutorials to replicate this yourself. So let's walk through this. I've got a Python notebook open here. I want to quickly just show you what a Python notebook is. It's actually just a JSON file that produces interesting output. We have recently added support for renderings files and you can now use these within Merch request. We render it in the source code view here. But you can see that this is a mix of code and exploration where I can write code and see the immediate output of it. So I don't have to work in a software development environment just in an IDE. Instead, I can write code directly in a Python notebook and immediately see the results from it. So let me kind of walk you through just one of these notebooks and introduce you to the problem of handwritten digit recognition. So a couple things. This is how many data scientists start exploring a data set. So I first want to get access to my data set. That is something that I'm using here with torch vision. They have access to data sets. The minced company that I talked about before, they have lots of different data sets. It's included with a lot of Python packages like torch or other open source ML products. We'll look at another one here in a minute. So I'm just importing my packages here. I'm going to set some very basic parameters around what I'm trying to do in terms of loading those data sets that I was talking about earlier. One thing that's nice about using a standardized data set is that they're normally organized by training and testing data sets. I'll show you what that means here in a minute. I'm basically just loading up the data getting it connected to torch so that I can do something with it. And then starting to explore the data, look at the different images that are in this data set, exploring how many test samples I have and validation samples. So you see by writing this code, you then get the immediate output of it. So I can see that I've got 30,000 training samples here. I've got 10,000 validation samples and 10,000 test samples here. I'll explain this as we continue going through. And so what I will did was then said, let's take a look at these images. They're in this data set. I just want to see what they look like. So I've got a variety of these images here. As you can see, they're handwritten digits. And what's nice about this data set in particular, and one of the reasons I picked it is that these images are all the same size. They're optimized that you can do very basic machine learning on it without having to handle weird edge cases like image sizing, image formats and all of that. It's very straightforward. They're all very unique images. They're in the same format and shape and size. And so what we want to do here basically is we've got these images that we don't know what's in them. And we want to train a model to actually be able to recognize the digit that's in it and tell it back to us. So we're going to use a very simple multilayer perceptron model here. You don't need to know anything about data science here. If I don't know much about data science, I'm not a data scientist. But this is where you can start playing around with different machine learning models here. And so we're going to take the data that we've got and we're going to bundle all of these images into different sizes. We're going to then start running them through a machine learning project here. And so I'm going to take a couple of images and I want to see what the current data set is. This is a completely untrained model. It's a packaged model that comes with torch vision. I haven't done anything to this model yet. And so when you get an image of this one here, it's going to predict wrongly that it's a zero. This five is a six. This eight is predicted as a zero. This two is predicted as a six. This one is predicted as a zero. So completely wrong, not even close. Unnot surprising here. We have to teach the model how to look at these. And so basically all we did here was take a very generic machine learning model. And we just passed the data in and we got an output. We haven't done any training here. And so this is kind of the foundation of how machine learning works is you take an input in this case the image of a number. We run it through the model and we get now put. And it's prediction of what it thinks it is. In many cases, you'll hear this called inference with a machine learning model. We're inferring the values based on a data set that will passing the model. And so when we do get to production, this is where the handoff of models comes in. Once we train this model and get it working, we should be able to hand it to an image and it should be able to tell us what's in that image. That's inference. And that's what we would build into our software application. It looks very similar to an API where I would give it an image and it would give me back a value. And then we can build interesting applications that do something around that. That's called inference. But in this case, we haven't trained anything. So we actually need to do the training so that the model does something interesting. And so here we go doing some of the training of that model. This is where it becomes important that we've got the training and the validation data sets where we actually know the data of what that image is supposed to return so that we can tell the model about it and the model can learn that hey, this image of a one is represented as a one and then we can teach it one to 10. And so we run this through. I'm not going to go into a lot of the details of data science here. You can play around with this on your own time. Basically, we're just training this model and by passing it, bundles of images were effectively training the model to recognize the digits that are in those data sets. And you can see that by training it just one time, we actually get a really high 90% tile accuracy. We can continue training it in what's called ethics. We're in your basically retraining the model over and over and over again in a very short amount of time. We can get that accuracy up to 98, 99% to correctly identify these use cases. But you can see where Python books make this really interesting because I can start to see the actual data and it's impact on my models in a very visual way. What happens a lot with Python notebooks is that data science is kind of do this exploration. They train a model. There are many different types of models that can be used. And so a lot of it kind of goes back to your like middle school class where you were fitting a line on your graph and calculator. That's a lot of what machine learning is like is you're just trying to fit the data science or a data set into a defined model and get that model optimized to return the correct values that you're expecting. And so to do this, we're doing a lot of evaluating the training data that we've got which are just unlabeled images and the validation data that's associated with those image to say, hey model, you predicted it too. It was actually a one. So the model can learn from that. So that's what we call labeled data where the images we have the labels for them of what their correct values are. This is called supervised learning. If we didn't have the labels for it would be called unsupervised learning. Again, I'm not going to get into this specific machine learning. But that's how we can kind of pull all of this together. And so once we take this trained model that we've now taught how to identify images, let's go back to our original example and we get a one. We get predicted a one. We get given a five. It's predicted five. You can see we've got a very high level of accuracy now. Now this is a model that is useful for us and that we could take to an application to actually recognize digits. A common thing that you might want to do after you've done this is maybe introduce it to the alphabet. Start doing letter recognition. Get into OCR. So this is a exploration of this data set. We've done some interesting just see what's in the data. We've run it through a model. We've been trained that model and validated the output of it. And now we've got a model that is a high prediction. Like a 98% tile model. And so now I want to do something interesting with this. Now we've validated that we've got a model that works here. So this is kind of in that exploration step that I was talking about earlier. We're just playing with Python notebooks at this moment. So now let's go back to that software repository and take a look at how we're actually going to do something interesting with this. So the first thing I want to introduce you to is just let's take a quick look at the C.I. Amyl file here. This is where you're going to start losing data scientists because they don't understand the Amyl files. They don't understand containers. They don't understand C.I.C.D. And so we're introducing data scientists to the concepts of GitLab. One thing that we'll start doing in the future is creating C.I. templates that data scientists can use so they don't have to figure out C.I. Amyl files. They don't have to build all these steps together. We'll start building UIs for them to connect and create these C.I. Amyl files. But let's take a look at this. So we've got just two simple stages here, set up and train. And my set up environment, all I'm doing is building a Docker container that I've got in my registry here. You'll notice that I'm creating this on a schedule. I'll show you why that's important here in a second. Once we've got our environment stood up, then I want to use that C.I. image that we've published to the registry. And I want to run a simple Python file on it. That's all this project does. Very straightforward. And in fact, all we really care about is this train section. The funny part, when I was putting this together, the hardest part is just getting an environment to build your models and work in where you can just interact with them. I recently have a new in one chip on Apple. It took me hours to get a Python environment stood up on my machine that I could actually run a Python notebook on. Whereas with GitLab CI, I had a very simple Docker environment stood up almost instantly. So it's one of those where the concepts that we have within GitLab can really enable us to help data scientists scale very quickly. So let's take a look at that Docker container real fast. So we've got a Docker fire here. It's based on the TensorFlow image. If you're thinking, wait a second, you were using Torch and your Python notebook. Why are we using TensorFlow? Great point. That's exactly kind of this exploration of data science. I'm comfortable from an exploratory standpoint with Torch. It's what I was originally trained with. So I played around with Torch first. And then when I started building my software development lifecycle, I wanted to switch to TensorFlow. And so I wanted to convert what I did in that other library to this more common and well known library to make it easier for folks to use. I'm going to install some custom requirements here. Let's take a look at those real fast. In my requirements file, I've got a couple of Python packages, which are common for machine learning, TensorFlow, which is that image that was just talking about an open source machine learning framework. And notebooks, which is a Python notebook environment, we've got Torch again. And so you can build out this requirements file with whatever Python packages you need and pass those to my container. So very, very simple Docker environment. Like I said, I'm probably not even doing this the right way for a production environment. This is just what I could quickly put together. But what's really cool about this is, I don't care about the Docker environment at all. I just want to get to my machine learning tasks. So I don't want to have to continuously rebuild my environment all of the time. So what I did was basically create a where did it go? Merge requests. I wanted to create an environment where I could start building this application. And so let's actually show you in a different way. If I go to my scheduled pipelines, I've actually got a build container. Job that is just going to trigger that container build. So let's go back and take a look at that. So every week, I'm going to have a scheduled pipeline run that's going to go and build my Docker container and push it to the registry. So let's go take a look at the registry real fast. They go to the container registry. Here's my registry image. You can see in fact the last night it built. So this image is going to rebuild itself with the latest version of all of these libraries every single week. I don't have to do anything with it. I can download my Docker container here, load it into my local environment, and have a new fresh Docker image with all the things that I want in it. This is how we start getting data scientists to build repeatable environments that other software engineers and team members can start to interact with. And one thing you'll notice here, it's a pretty heavy image, too. A lot of these machine learning libraries include lots of default data sets. They include lots of different types of models. This is now an interesting opportunity where my DevOps software engineers can come and help me reduce the size of this and start creating this more repeatedly using slimmer images. All the things that may not as a DevOps engineer don't know how to do. So we've already created an environment where anybody can contribute to my Docker container and help make this environment repeatable, scalable, more usable. So I've got this environment that I can now start to do some of the interesting with. So let's take a look at that Python file that I mentioned that all of this runs. So what you're going to see here is very similar to what I did in that Python notebook, just re-implemented with the new model choice that I used here. In this case, I'm using a library called Carost. I like it because it's very straightforward. If you look at the amount of code that's here compared to my Python notebook, it's a lot less. And this is kind of the beauty of the experimental aspect of machine learning is that we can use Python notebooks to be very verbose and experimental to see what different parameters, what different models to do, and then pass that into my sort of production model here and keep it very similar. So you'll see very similar things here. I'm taking that minced dataset. I'm loading it. I'm taking a look at it. I'm creating and shaping that model. Loading in the training test samples, creating the batch that I want to use and then training my model here. We'll take a look at the output of one of these jobs here in just a second. And then printing out a couple of just data pieces. But one thing that I want to highlight is this last piece, which is this model save. Once we've trained that model, I then want to take that model and export it. There are lots of different file formats that get used for models. In this case, I'm using an H5 file, which is really just kind of like a JSON file that just takes the trained model. It's parameters and package it together so that you could load this model into your environment very easily. And so what you'll see normally with these types of models is that you want to export your model and then host it somewhere so that other people can buy that model and ingest it. If you think about retraining a model, let's say we wanted to train it on digits or on letters, I would then go and retrain this model on letter sets. And I would have it the new model that supported letters. I would then want to pass that model to my engineering team to load into the production application so they could start recognizing digits. The way to do that is to export the model so that they can import it into their environment. And so what becomes nice is that this model can actually cross languages. I'm using a Python library here, but there are Ruby on Rails, there are other language connectors that can read these models and put them into the native language, the application may be developed on. So this is kind of the way that we hand models off to production that can be used in a unique way. So let's take a look at one of these jobs real fast. Let's go into one of my pipelines. I'm going to just choose one random one here. Let's go into this one. So we've got that set up job that I was talking about earlier. Let's go to the top here. Starting with Docker, we're pulling in all of the different pieces. We're loading that tensorflow image, compiling it, pulling in all of the packages that we're defined in my requirements filed. Lots of stuff here. Like I said, these packages are big and heavy and have lots of stuff in them. And then pushing that to the registry. So there's our Docker image that works cool. Glad to see that. Now let's look at this training piece. So we've got our Docker image spinning up. It's pulling that Docker image from the registry. It's initializing, blah blah blah. So we've got the downloading the data set. So there's me loading in all my data. In this case, we're failing to load Kuda, Kuda's a GPU runner. I'm not using a GPU runner. At this point, so that's going to fail. This library likely handles that pretty gracefully. And so we then start to run that Python file that I was talking about earlier. So we've got some of the printed data sets that I was talking about. In this particular library, it comes with 60,000 training sets and 10,000 test samples. And then we're going to start running that through our TensorFlow model. Here is me looking at that model. What it's doing. Again, and I'm going to go through all of this. I'm in fact, I probably can't even explain what a lot of this does. But you can see there's some parameters in here. And then I train the model and get a test accuracy. And then I save that model is a M5 file. Cool. That's it. That's all this project does. But I had a done anything at this point. I haven't saved that model anywhere. It's in my container, but I haven't exported it in a way that I can actually get access to NCI. So let's now start to expose some of these files to this project. So I've got a couple of just sample of Merchor Quest here that do various things. And so I want to go into this model export. So let's take a look at what I'm doing in this file. All I'm doing is creating an artifact that includes this trained model. That's all I'm doing here. And so let's take a look at what this looks like. We've got our original job here. We've got our training job. We saw that earlier. In this case, I expanded the number of ethics that I could actually train it to get to something interesting. You can see that as we go through here, it's getting better in its accuracy as we go. But it's definitely not as accurate as the other one that we were using before. Totally fine, whatever. But we've got that model here. We are then uploading that artifact to the artifact of this job. And in fact, there it is. I can browse it. And now I've got this artifact that can be produced repeatedly. Very cool. Very interesting to see my model here is about two megabytes. This is we train it more. It'll get bigger. Now we're starting to get somewhere where I've got a model that's repeatedly generated with CI. Again, this is an reproduction repo, but you can imagine how we now have an environment where every week, I've got a new fresh Docker container to get spun up. It's running my model. And now I want to actually start to do something interesting when I do this model and make it usable for people. So let's go back to my merger quest and we'll move on to the next one. So now I want to actually package that model together in a way that could be pulled from different applications or from different repositories. So I'm going to take that artifact that I had before. So there's my artifact and my trained model. And now I actually want to publish it to the package repository. So I'm going to create this is the manual jobs that I can decide when I push this model version. I'm going to create a variable so that I can define this version. And then all I'm going to do is take that file. I'm going to push it to the package registry. Okay, so let's go actually take a look at our package registry. Where is it? Here we go. And there it is. There's my model. My first version of this generic package. I'm using a generic package here because it lets me put any file that I want in it in the future. We'll support proper machine learning models here. But for now, there's my file. In fact, I can download it. If I look at other, if I look at the file itself, this now allows me to interact with this package from other software projects. I can hit the get lab package registry. Can pull this model into other software packages. That's a big repeatability when here. Now I can repeatably publish this model and make it available to other software packages. So let's go back to this whole thing. Let me show you what one of these pipelines looks like. One. There we go. Let's see which one go. Oh wait, I want to look at the murder quest. So if that model, let's look at a pipeline here. Yeah, let's look at this one. So I've got this published job here. It runs my model and all it's doing here is pushing that image to the repository to the package registry. Very simple. This took me a while to figure out how to do. This is the piece that data science is aren't familiar with of how to start productionizing a lot of their data science workload. So this is where we want to really help make these things more understandable. CI templates to make this very usable. Now I want to show you one other last thing that as we start doing this, we can then layer on top of their machine learning or other get lab features. Come on, we're a little bit more requests. So now I actually want to take everything we've done this far and I just want to add security is getting to it. This is something that we offer out of the box with GetLab. It's very simple to enable. I'm going to add all of my security scanning capabilities. So I'm going to now enable our secure. Let's take a look at what this actually looks like in practice. So all I'm doing now is looking at all of the security vulnerabilities that I have. And now I've got a very useful list of things of how I can improve the security of my software project. In my Dockerfile, I'm not properly setting users. And so I'm running these things as root. I'm not using specific tagged versions of libraries. So I'm just trusting that the latest version is going to be secure and is going to work and not break things. These are really obvious DevOps things now that me as someone who is not a DevOps engineer can now very quickly understand and layer into my software development lifecycle. I can check this for least secrets. We can scan the container for security vulnerability. So you can see how just by doing some very basic things to start using the capabilities that we have with it in GetLab, we can get a lot more value and build much better machine learning models. So that's going to conclude my demo here. That's kind of an overview and an intro to how you can use various GetLab features within the machine learning context. The only last thing I'm going to leave you with is some of the things that we're working on at the moment. With our MLOps team, we are working on Python notebook enhancements to make those Python notebooks work better. We're soon to move to a model registry. So I showed you how to pass that package to the package registry. We're going to support a machine learning model package. In fact, we're going to try to create a standard around this to create a new way to share repeatedly these models. And then we're going to add support for external for advanced computing. So enabling GPU runners make them very easy to use. You saw where my GPU had failed in my test example because I'm not using the runner that has a GPU enabled on it. We support this today for self hosted runners. But that requires you to spin up a GetLab runner connected to GetLab. It puts all of the work on you. We'll soon offer GPU enabled runners natively on GetLab.com. And then on the applied ML piece, this is us taking machine learning and applying it to GetLab. Our first feature is coming out in 15.4, which is suggested reviewers, which is an novel machine learning algorithm that learns from your source code and your commit history and suggests reviewers for your merge requests based on the changes that are in them. So if we think about what we were doing with that model before, rather than images of digits and labels, we're passing it the contribution graph. And we're getting in the model to tell us back who should be a recommended reviewer. So like I said, that will be releasing in 15.4. We'll then move to suggested labels to have merger requests and issues on Mac, label themselves. And then we'll move to intelligent code security. We'll actually have a machine learning model suggesting how to fix security vulnerabilities and creating merger requests for those fixes. So those are just some of the things that the model ops team is working on. So we're kind of working in a dual track here where we want to make it easy or to run models and use them with GetLab features. And then we want to apply machine learning to getLab itself to make it smarter and more intelligent. So that is an overview of kind of the intro to data science, a quick view of how you can use existing GetLab features with machine learning capabilities. I encourage you go play around with this repository. If you Google intro to machine learning courses or just tutorials, you can leverage this framework to explore some data science models yourself with either TensorFlow or Torch. So hopefully this is useful and interesting to you. Hopefully this gives you a little insight into how data science is starting to use GetLab. And there is much, much more to come from our model ops team moving forward. I realize I have not left a huge much time for questions. But if you've got questions, put them in the dock and I can respond to Async to them. Yeah, we have actually a great list of questions in the dock. If we have a couple of minutes, we can probably take maybe one or two live and then absolutely the rest will probably have to be a think. So me and looks like you have the first one. Maybe we'll start with that and see how long we go. Yes, thank you. Thank you Taylor for the presentation. This was excellent and very, very insightful. The question I had was with regards to the Jupiter notebooks. You showed it being rendered in GetLab. Are we planning for it to be editable within GetLab, using the GetLab editor? Is that a plan in the future? Yeah, absolutely. That's what I'm vaguely calling Enterprise Jupiter notebooks. Basically, there should be a software environment behind that image that imports basically just a Python environment. We want to enable you to spin up a environment with GetLab runner to basically press play on that notebook and then be able to edit interactive with it, replay cells. Very similar to Jupiter hub. That will be a paid ultimate plus feature for customers. For now, we wanted to get it just so that you could render and view them, but we definitely want to create live running notebooks. Excellent. Thank you. I don't know if Leo's going on. Oh, there you. Leo looks like you have the next one. Yes, actually, I just wanted to know. The model that you were using, does it use pixel pattern to identify the numbers from the images? It's not using pixel patterns from the sense that nobody made those, but it is effectively what that model is doing. Basically, we handed it image and we tell it this is a one and it reverses to figure out what that one is. It is behind the scenes using something that would be similar to what we think of as a pixel pattern. In fact, in that last image, in that Python notebook, you can see basically what the machine sees of that image. Now, of course, it's not actually looking at it's data representations, but yeah, it's a good way to think about that. Great. Did you have any follow-up there, Leo? Sorry. No, I appreciate the insight. Thank you. Thank you. Probably just one more, and then we'll take the rest of the thing. Cherry looks like you have the third one. Yeah, thank you, Taylor. It's a great demo. So, I'm working with the customer, and I have seen it with other customers. They're different, they is being the work and the pipeline for platform versus the little version. Did you know the word, Risa, I can't even say that word to I'm just wondering, is our applied ML? Is it really a consider from practice point of view as a delivery pipeline? Yeah, so it's a fair way to think about that. From the standpoint of like a customer, when they turn on suggested reviewers, that's not going to be something that you're going to have to see all of the workings of these ML ops workflows. Behind the scenes, yes, we do have get lab pipelines that are extracting data, they're transforming in, they're training a model, they're inferring them all. All of that's done holistically within get lab CI, but customers won't see that. There will be a simple job that will trigger our internal pipeline, and they'll see those recommendations within their UI. But yeah, that's effectively the right way to think about it is that it is a production machine learning pipeline. And that's a building with applied ML. Cool, so there work on something we call that the next best conversation. Rive is to engage the customer and the present offers. So it's very interesting. We will get you to talk to this customer for sure. I think just lighting up all the dates, that will be great. I like your example. Yeah, that's a good plug for me. If you've got customers who mentioned machine learning, they don't know how to get started with get lab or maybe they're already doing something today. If you've got those customers, I want to talk to them. I want to have them help shape our roadmap as we develop here. I'm always happy to talk through both this example and this presentation to talk through some of our roadmap with these customers. So don't hesitate. Thank you for that. I will reach out to both the time. I paint you a few times, but finally we have some dates that will work for you and us. We had some sessions already. I think they were on the right time to look at their pipelines. They did a starting permitting data. But of course, that's a lot of challenges. Yeah, absolutely. And I mean, as you've seen here a lot of this talking with customers is just introducing them to get lab features and how they can use them in a data science context. So it's a lot of DevOps one on one with these customers teaching them how to use get lab. Awesome. I think we're about out of time. I will respond to the rest of these questions in this Google Doc. I really appreciate all of the questions. And hopefully you've found this useful. Like I said, feel free to use this repository, however you like. Do please fork it because I will use this for my own customer demos. And that's all I've got for you. Wonderful. Thank you all so much for your time. Thank you, Taylor. Great presentation today. Awesome. Thanks everyone. Thank you all.",
  "And actually did that hero. Cool. Awesome. Nice. Right on. Yeah. I had been doing contribution scenes back in 2019. Really? Cool. What you're being a good player, being a good player, it's pretty cool. What's your favorite areas of work in on the app? Get left the platform. Yeah. Don't figure your stage. The last contribution that I did was Alina feels that there were missing on how to deploy a Kubernetes cluster with Terraform and give that to CICD. So that's something that I've been working on. And it's like the, yeah, the, Most of it comes out. I also had another experience with Terraform. That has been the opportunity to To be using a kid luck for infrastructure. Oh, right on. So we don't have very few people here today. Oh, wait. As I say that, new joins. Can you. Getting started here. A couple different announcements. I will read them since I got the second one and the first one is from Nate who's not here. So Nate wanted to mention that. He's now back in maintainer. That's great. And also all announced on behalf of Thomas is welcome back for a few on the dynamic analysis team. And I mean, you've got the comment on Thomas's news item. Do you mind verivolizing? Yeah, absolutely. So it sounds like some of the team was curious about application security as the main and how to get some more training. Something that came up was we do have a really neat platform available to us. It's called secure code where it's actually a vendor that we've integrated training with. So if you're in a vulnerability, that's offered as one of those training opportunities for our users, which is really nice. They also have a very extensive platform. You can choose your language. So Thomas was informed that not only do we have access the group has extended access to all engineers. So there's I think 700 people. I might be able to rest of my videos of boatload of people were added and given access. It's good blood. It's good bandaged. So pretty much everyone in engineering shouldn't have able to log in with SSO into secure code warrior. I additionally shared that with my team. Thank you Thomas for raising us. It's great. It's a great platform. Which should become more familiar with it. They also host competitions. This is something we did like a year ago. And we had like 25 30 of us all took place in this competition where there was multiple rounds and you get points and there's a leaderboard. That's something we could also do. So as a scene of my team might be directly interested in having like a mini competition as a good lab specific training project that you can get into pretty quick or you can build your own. So you definitely explore this. Need. So second answer. I used to post a link directly when one of our teams does something interesting. They think a general public want to know about so often you know announcements or a YouTube video etc. So I've started in that directly and would like team members to post themselves and I'm happy to repost and promote. I can also put the text and formatting. You know this increases the reach of the notice of the cool things we do by not just being Wayne and also. I think LinkedIn maybe has labeled me as a spammer perhaps. So the more other people post unless I do and I just announced. Promote those messages that would be great and some have already done that but if you see a reduction in me and me nudging others to post that's why. There, anti abuse teachers might have got a band you. Perhaps perhaps or perhaps just people are sick of hearing from me on LinkedIn which is fine to maybe it's humans labeling the as spammer's not systems. Yeah, we'll see. Do if anybody's curious why the change that's why. Anyway, we want to volunteer. These items that I copy across. To verbalize it. Let's see. Lisa's that we're not triaging on the community manager class because the number of MR coaches. So that's an active number of on triage. These consider making yourself a bill if you are a coach. I knew you have a comment on that. Yeah, again, I appreciate the reminder. Somebody in their personal goals well, brought this up. I've had effective coaches on my team in the past. So I've had my current team member. They're going to reach out to Alexander. Terrence fee I recommended them as a liaison he's got a great experience they was really effective and I'm sure they still is. And kind of navigating through and pushing forward requests and it's not like the coaches have to take on this work. It's more about disseminating getting this information in the right hands and in the right teams as part of that role as well. So what I'll do is I'll ask my team member that's engaging in this to additionally share kind of their experience. I think that'll help further encourage because I think once you've done it and you get into it, it's not that big of a deal. It's a great way to contribute to the community. Just the triaging just the making sure that ends up in the right. You're a handshake. It's I think it's both it's an opportunity to kind of pick off work that you're familiar with and you want to help push forward. But you can also help facilitate finding the right the right team. Because some of this just goes into like a bucket. CC MR comes through it gets flagged as needs attention and then the coaches kind of evaluate and say okay what team is most. Similar with this scope this context versus just trying to take a song and make it more muddy you know they can get it to the right hands. I'm on right. I'm 100 here here. I have you experienced some of this burden before not finding a review. I'm a relevant area. I'm going to. Can you repeat this question. The question is around community. Merjory requests not being reviewed. That's sort of an amount of time for a really gain them into the right hands to be reviewed have you experienced any problem with that. No. No. Okay. How about all 100 just general support like you know we have SLOs internally and we try to support those for CCC requests as well that you know within two days responding we're kind of keeping things moving. How do you feel the support generally been. I don't find that a perenn are like. Like the score for. And get that. S I yes. It's like every time that I use it is mostly available so. Yeah, I never marks all of having any issue late. Legally with. Having like about requests with that or. Or something like that. Cool. It's good news. I think this came up from leave because there are metrics that show the the turnaround time the SLO. So and I think it's similar to our maintainers is the ratio is an exactly what we wanted to be to provide the the best assistance to that group of people. I can't hear you win. You're not muted though. Nothing. You can move forward with the agenda if you can't figure it out next minute. We're waiting type it out in one of us to be blessed. Okay, one more try. Yes, there it is. All right, well, I'm not sure what's going on with my zoom today. So thank. So I'll handle so you've done some changes to our documentation. Which is great. Periods J or near or fill. Do you have to know many places in our documentation for your areas of the product that. And you can point our hundreds and if you've been interested. If I'm 100, if you can review and see if you have any ideas on improvement. You want documentation links for. The stages that we're working on all specific features. Both in areas you think need more improvement versus less perhaps. Yeah, we had an issue with a list of documentation that we want to try to do. Neals not in the sea. Let's see if we can find that and we'll point it to you. This is something to go to the R. But I can definitely take that up and provide that. But yeah, there's a list of docs that we're going to review in the same manner. That's where you're looking for when this general. Okay, yeah, this would be more specific to our sack or threat into the environment management docs, but we can accept from that. Peter, if you're interested in our home, but you've done a great job with updating other parts of the get that documentation. So we'd love your feedback on these parts as well. If you're interested. Yeah, for sure. Thanks. So. Do we want to do a periodic maybe every quarter every two quarters virtual off site with everyone on the team optionally invited and the basalt leaves are optional. The agenda could say looks on the light, but I listed below. I've done a few of these with my boss Christopher with my and my. And my peers. And also I participated in some of your works or CTUs just on the left and topics, not I wasn't invited the whole thing that's overall they facilitated. Greek information sharing. Collaboration and relationship building. So some potential topics and update from fill, mind, Thomas and I under areas of responsibility and context. What we see interact with the job side the team perhaps each engineering manager does the same click over view what their group does and what they're doing and with their channel and bizarre mother excited about. And also volunteers from anyone on the team to present a top of the interest. Who get a guest speakers from other teams as if they're interested in also you know a fun activity or two thoughts should we do simple like this. Generally, yeah, I think I think that'd be great to have them all press. What would you put that would you put that like in the middle of the shorter is that way, people are kind of going already and not trying to wrap up for spin ups. It seems reasonable. It also not towards the 22nd, you know, not nearing the end of a release. Got it. So I have to do the second version of the quarter shifts. Neil Philardy. Sounds like a great idea. I know some of our product counterparts have virtual off sites this week because they're doing that to plan for the next quarter. Preg, we would do us two weeks prior to that so we could feed and talk about what we're done and what challenges we get. Yeah, towards the end of the quarter could be quite good. Yeah, I think it's great to do as well. I think it'd be an extension of this session more concentrated more dialogue focused as well. You know, here we're doing like a lot of agenda topics getting feedback, but you have to be neat to have like specific topics to discuss and depth. Great. Any volunteers to organize. In the ends, we can be no. Would we now be looking at doing it towards the end of Q3. Or the middle of Q3. Middle of Q3. Yeah. We've got a week before the 22nd. I'll try to measure and we can collaborate. I should tell me. Thanks. I know we only have a subset of the team here today. It'll let us all collaborate. Awesome. The other writers we have in the agenda are read only. So we'll leave them there. So I know Alejandro you've only been. This is your second meeting as a shadow. And then throughout the day any early impressions as of being a shadow and also any questions for Jay or Neil or Phil. Yeah, I'm the first impression that I have since the first meeting with them had this morning. And the way that give that documents is meeting like. For keeping them. Everything there is a. Falcon on on the meeting can be. Available for. For all at the persons that. That where able to join or. Or something. That helps to be. To be. And I think we're not communication in style. And I don't really say. I feel like it's really amazing. The way that give a does that. Great. To I've got you. I'm by the way, thanks for finding that issue on. Terraform and that our terraform we're not making recommendations on terraform files and code suggestions as we try to do that since you know terraform and I tried to demonstrate the feature for you. And I think that's what we're doing. We're doing it. And it's a. There was a follow up question by the way in that issue of the file the file type. So might be a. What the file type was called it said or I've and how that gets sent to the back end. You could respond to that when you get your answer to the great and again, thank you for finding that issue on that. Yep, no, it's not that will be my fairs. But reports and. Great. Thanks everybody."
]